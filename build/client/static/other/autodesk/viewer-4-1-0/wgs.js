var WGS = (function (exports,THREE$1) {
'use strict';

var name = "@adsk/wgs.js";
var version = "0.0.17";
var description = "Collection of components for three.js";
var license = "UNLICENSED";
var repository = {"type":"git","url":"https://git.autodesk.com/WGS/wgs.js.git"};
var main = "dist/wgs.js";
var module$1 = "dist/wgs.module.js";
var scripts = {"build":"gulp","dev":"gulp develop","serve":"gulp serve","watch":"gulp watch","clean":"gulp clean","touch":"gulp touch","docs":"typedoc --out docs/ src/","test":"typings install && mocha -r ts-node/register ./tests/unittests/test*.ts","eslint":"eslint src --ext=.ts","postpublish":"gulp deploy","rollup":"node --max-old-space-size=4096 node_modules/rollup/bin/rollup"};
var dependencies = {"@types/three":"0.84.8","core-js":"2.5.0","xhr2":"0.1.4"};
var peerDependencies = {"three":"0.71.0"};
var devDependencies = {"@types/chai":"4.0.0","@types/mocha":"2.2.41","babel-core":"6.25.0","babel-plugin-external-helpers":"6.22.0","babel-preset-es2015":"6.24.1","browser-sync":"2.18.12","chai":"4.0.2","del":"3.0.0","eslint":"3.19.0","eslint-plugin-import":"2.3.0","gulp":"3.9.1","gulp-file":"0.3.0","gulp-mirror":"1.0.0","gulp-rename":"1.2.2","gulp-replace":"0.6.1","gulp-s3-upload":"1.6.4","gulp-uglify":"3.0.0","mocha":"3.4.2","rollup":"0.50.0","rollup-plugin-babel":"2.7.1","rollup-plugin-commonjs":"8.0.2","rollup-plugin-includepaths":"0.2.2","rollup-plugin-json":"2.3.0","rollup-plugin-node-resolve":"3.0.0","rollup-plugin-typescript2":"0.8.0","run-sequence":"2.0.0","typedoc":"0.7.1","typings":"2.1.1","uglify-js":"3.0.26"};
var publishConfig = {"registry":"https://art-bobcat.autodesk.com/artifactory/api/npm/autodesk-npm","access":"public"};
var json = {
	name: name,
	version: version,
	description: description,
	license: license,
	repository: repository,
	main: main,
	module: module$1,
	scripts: scripts,
	dependencies: dependencies,
	peerDependencies: peerDependencies,
	devDependencies: devDependencies,
	publishConfig: publishConfig
};

function createCommonjsModule(fn, module) {
	return module = { exports: {} }, fn(module, module.exports), module.exports;
}

var _global = createCommonjsModule(function (module) {
// https://github.com/zloirock/core-js/issues/86#issuecomment-115759028
var global = module.exports = typeof window != 'undefined' && window.Math == Math
  ? window : typeof self != 'undefined' && self.Math == Math ? self
  // eslint-disable-next-line no-new-func
  : Function('return this')();
if (typeof __g == 'number') __g = global; // eslint-disable-line no-undef
});

var hasOwnProperty = {}.hasOwnProperty;
var _has = function (it, key) {
  return hasOwnProperty.call(it, key);
};

var _fails = function (exec) {
  try {
    return !!exec();
  } catch (e) {
    return true;
  }
};

// Thank's IE8 for his funny defineProperty
var _descriptors = !_fails(function () {
  return Object.defineProperty({}, 'a', { get: function () { return 7; } }).a != 7;
});

var _core = createCommonjsModule(function (module) {
var core = module.exports = { version: '2.5.0' };
if (typeof __e == 'number') __e = core; // eslint-disable-line no-undef
});

var _isObject = function (it) {
  return typeof it === 'object' ? it !== null : typeof it === 'function';
};

var _anObject = function (it) {
  if (!_isObject(it)) throw TypeError(it + ' is not an object!');
  return it;
};

var document$1 = _global.document;
// typeof document.createElement is 'object' in old IE
var is = _isObject(document$1) && _isObject(document$1.createElement);
var _domCreate = function (it) {
  return is ? document$1.createElement(it) : {};
};

var _ie8DomDefine = !_descriptors && !_fails(function () {
  return Object.defineProperty(_domCreate('div'), 'a', { get: function () { return 7; } }).a != 7;
});

// 7.1.1 ToPrimitive(input [, PreferredType])

// instead of the ES6 spec version, we didn't implement @@toPrimitive case
// and the second argument - flag - preferred type is a string
var _toPrimitive = function (it, S) {
  if (!_isObject(it)) return it;
  var fn, val;
  if (S && typeof (fn = it.toString) == 'function' && !_isObject(val = fn.call(it))) return val;
  if (typeof (fn = it.valueOf) == 'function' && !_isObject(val = fn.call(it))) return val;
  if (!S && typeof (fn = it.toString) == 'function' && !_isObject(val = fn.call(it))) return val;
  throw TypeError("Can't convert object to primitive value");
};

var dP$1 = Object.defineProperty;

var f = _descriptors ? Object.defineProperty : function defineProperty(O, P, Attributes) {
  _anObject(O);
  P = _toPrimitive(P, true);
  _anObject(Attributes);
  if (_ie8DomDefine) try {
    return dP$1(O, P, Attributes);
  } catch (e) { /* empty */ }
  if ('get' in Attributes || 'set' in Attributes) throw TypeError('Accessors not supported!');
  if ('value' in Attributes) O[P] = Attributes.value;
  return O;
};

var _objectDp = {
	f: f
};

var _propertyDesc = function (bitmap, value) {
  return {
    enumerable: !(bitmap & 1),
    configurable: !(bitmap & 2),
    writable: !(bitmap & 4),
    value: value
  };
};

var _hide = _descriptors ? function (object, key, value) {
  return _objectDp.f(object, key, _propertyDesc(1, value));
} : function (object, key, value) {
  object[key] = value;
  return object;
};

var id = 0;
var px = Math.random();
var _uid = function (key) {
  return 'Symbol('.concat(key === undefined ? '' : key, ')_', (++id + px).toString(36));
};

var _redefine = createCommonjsModule(function (module) {
var SRC = _uid('src');
var TO_STRING = 'toString';
var $toString = Function[TO_STRING];
var TPL = ('' + $toString).split(TO_STRING);

_core.inspectSource = function (it) {
  return $toString.call(it);
};

(module.exports = function (O, key, val, safe) {
  var isFunction = typeof val == 'function';
  if (isFunction) _has(val, 'name') || _hide(val, 'name', key);
  if (O[key] === val) return;
  if (isFunction) _has(val, SRC) || _hide(val, SRC, O[key] ? '' + O[key] : TPL.join(String(key)));
  if (O === _global) {
    O[key] = val;
  } else if (!safe) {
    delete O[key];
    _hide(O, key, val);
  } else if (O[key]) {
    O[key] = val;
  } else {
    _hide(O, key, val);
  }
// add fake Function#toString for correct work wrapped methods / constructors with methods like LoDash isNative
})(Function.prototype, TO_STRING, function toString() {
  return typeof this == 'function' && this[SRC] || $toString.call(this);
});
});

var _aFunction = function (it) {
  if (typeof it != 'function') throw TypeError(it + ' is not a function!');
  return it;
};

// optional / simple context binding

var _ctx = function (fn, that, length) {
  _aFunction(fn);
  if (that === undefined) return fn;
  switch (length) {
    case 1: return function (a) {
      return fn.call(that, a);
    };
    case 2: return function (a, b) {
      return fn.call(that, a, b);
    };
    case 3: return function (a, b, c) {
      return fn.call(that, a, b, c);
    };
  }
  return function (/* ...args */) {
    return fn.apply(that, arguments);
  };
};

var PROTOTYPE$1 = 'prototype';

var $export = function (type, name, source) {
  var IS_FORCED = type & $export.F;
  var IS_GLOBAL = type & $export.G;
  var IS_STATIC = type & $export.S;
  var IS_PROTO = type & $export.P;
  var IS_BIND = type & $export.B;
  var target = IS_GLOBAL ? _global : IS_STATIC ? _global[name] || (_global[name] = {}) : (_global[name] || {})[PROTOTYPE$1];
  var exports = IS_GLOBAL ? _core : _core[name] || (_core[name] = {});
  var expProto = exports[PROTOTYPE$1] || (exports[PROTOTYPE$1] = {});
  var key, own, out, exp;
  if (IS_GLOBAL) source = name;
  for (key in source) {
    // contains in native
    own = !IS_FORCED && target && target[key] !== undefined;
    // export native or passed
    out = (own ? target : source)[key];
    // bind timers to global for call from export context
    exp = IS_BIND && own ? _ctx(out, _global) : IS_PROTO && typeof out == 'function' ? _ctx(Function.call, out) : out;
    // extend global
    if (target) _redefine(target, key, out, type & $export.U);
    // export
    if (exports[key] != out) _hide(exports, key, exp);
    if (IS_PROTO && expProto[key] != out) expProto[key] = out;
  }
};
_global.core = _core;
// type bitmap
$export.F = 1;   // forced
$export.G = 2;   // global
$export.S = 4;   // static
$export.P = 8;   // proto
$export.B = 16;  // bind
$export.W = 32;  // wrap
$export.U = 64;  // safe
$export.R = 128; // real proto method for `library`
var _export = $export;

var _meta = createCommonjsModule(function (module) {
var META = _uid('meta');


var setDesc = _objectDp.f;
var id = 0;
var isExtensible = Object.isExtensible || function () {
  return true;
};
var FREEZE = !_fails(function () {
  return isExtensible(Object.preventExtensions({}));
});
var setMeta = function (it) {
  setDesc(it, META, { value: {
    i: 'O' + ++id, // object ID
    w: {}          // weak collections IDs
  } });
};
var fastKey = function (it, create) {
  // return primitive with prefix
  if (!_isObject(it)) return typeof it == 'symbol' ? it : (typeof it == 'string' ? 'S' : 'P') + it;
  if (!_has(it, META)) {
    // can't set metadata to uncaught frozen object
    if (!isExtensible(it)) return 'F';
    // not necessary to add metadata
    if (!create) return 'E';
    // add missing metadata
    setMeta(it);
  // return object ID
  } return it[META].i;
};
var getWeak = function (it, create) {
  if (!_has(it, META)) {
    // can't set metadata to uncaught frozen object
    if (!isExtensible(it)) return true;
    // not necessary to add metadata
    if (!create) return false;
    // add missing metadata
    setMeta(it);
  // return hash weak collections IDs
  } return it[META].w;
};
// add metadata on freeze-family methods calling
var onFreeze = function (it) {
  if (FREEZE && meta.NEED && isExtensible(it) && !_has(it, META)) setMeta(it);
  return it;
};
var meta = module.exports = {
  KEY: META,
  NEED: false,
  fastKey: fastKey,
  getWeak: getWeak,
  onFreeze: onFreeze
};
});

var SHARED = '__core-js_shared__';
var store = _global[SHARED] || (_global[SHARED] = {});
var _shared = function (key) {
  return store[key] || (store[key] = {});
};

var _wks = createCommonjsModule(function (module) {
var store = _shared('wks');

var Symbol = _global.Symbol;
var USE_SYMBOL = typeof Symbol == 'function';

var $exports = module.exports = function (name) {
  return store[name] || (store[name] =
    USE_SYMBOL && Symbol[name] || (USE_SYMBOL ? Symbol : _uid)('Symbol.' + name));
};

$exports.store = store;
});

var def = _objectDp.f;

var TAG = _wks('toStringTag');

var _setToStringTag = function (it, tag, stat) {
  if (it && !_has(it = stat ? it : it.prototype, TAG)) def(it, TAG, { configurable: true, value: tag });
};

var f$1 = _wks;

var _wksExt = {
	f: f$1
};

var _library = false;

var defineProperty = _objectDp.f;
var _wksDefine = function (name) {
  var $Symbol = _core.Symbol || (_core.Symbol = _library ? {} : _global.Symbol || {});
  if (name.charAt(0) != '_' && !(name in $Symbol)) defineProperty($Symbol, name, { value: _wksExt.f(name) });
};

var toString = {}.toString;

var _cof = function (it) {
  return toString.call(it).slice(8, -1);
};

// fallback for non-array-like ES3 and non-enumerable old V8 strings

// eslint-disable-next-line no-prototype-builtins
var _iobject = Object('z').propertyIsEnumerable(0) ? Object : function (it) {
  return _cof(it) == 'String' ? it.split('') : Object(it);
};

// 7.2.1 RequireObjectCoercible(argument)
var _defined = function (it) {
  if (it == undefined) throw TypeError("Can't call method on  " + it);
  return it;
};

// to indexed object, toObject with fallback for non-array-like ES3 strings


var _toIobject = function (it) {
  return _iobject(_defined(it));
};

// 7.1.4 ToInteger
var ceil = Math.ceil;
var floor = Math.floor;
var _toInteger = function (it) {
  return isNaN(it = +it) ? 0 : (it > 0 ? floor : ceil)(it);
};

// 7.1.15 ToLength

var min = Math.min;
var _toLength = function (it) {
  return it > 0 ? min(_toInteger(it), 0x1fffffffffffff) : 0; // pow(2, 53) - 1 == 9007199254740991
};

var max = Math.max;
var min$1 = Math.min;
var _toAbsoluteIndex = function (index, length) {
  index = _toInteger(index);
  return index < 0 ? max(index + length, 0) : min$1(index, length);
};

// false -> Array#indexOf
// true  -> Array#includes



var _arrayIncludes = function (IS_INCLUDES) {
  return function ($this, el, fromIndex) {
    var O = _toIobject($this);
    var length = _toLength(O.length);
    var index = _toAbsoluteIndex(fromIndex, length);
    var value;
    // Array#includes uses SameValueZero equality algorithm
    // eslint-disable-next-line no-self-compare
    if (IS_INCLUDES && el != el) while (length > index) {
      value = O[index++];
      // eslint-disable-next-line no-self-compare
      if (value != value) return true;
    // Array#indexOf ignores holes, Array#includes - not
    } else for (;length > index; index++) if (IS_INCLUDES || index in O) {
      if (O[index] === el) return IS_INCLUDES || index || 0;
    } return !IS_INCLUDES && -1;
  };
};

var shared = _shared('keys');

var _sharedKey = function (key) {
  return shared[key] || (shared[key] = _uid(key));
};

var arrayIndexOf = _arrayIncludes(false);
var IE_PROTO = _sharedKey('IE_PROTO');

var _objectKeysInternal = function (object, names) {
  var O = _toIobject(object);
  var i = 0;
  var result = [];
  var key;
  for (key in O) if (key != IE_PROTO) _has(O, key) && result.push(key);
  // Don't enum bug & hidden keys
  while (names.length > i) if (_has(O, key = names[i++])) {
    ~arrayIndexOf(result, key) || result.push(key);
  }
  return result;
};

// IE 8- don't enum bug keys
var _enumBugKeys = (
  'constructor,hasOwnProperty,isPrototypeOf,propertyIsEnumerable,toLocaleString,toString,valueOf'
).split(',');

// 19.1.2.14 / 15.2.3.14 Object.keys(O)



var _objectKeys = Object.keys || function keys(O) {
  return _objectKeysInternal(O, _enumBugKeys);
};

var _keyof = function (object, el) {
  var O = _toIobject(object);
  var keys = _objectKeys(O);
  var length = keys.length;
  var index = 0;
  var key;
  while (length > index) if (O[key = keys[index++]] === el) return key;
};

var f$2 = Object.getOwnPropertySymbols;

var _objectGops = {
	f: f$2
};

var f$3 = {}.propertyIsEnumerable;

var _objectPie = {
	f: f$3
};

// all enumerable object keys, includes symbols



var _enumKeys = function (it) {
  var result = _objectKeys(it);
  var getSymbols = _objectGops.f;
  if (getSymbols) {
    var symbols = getSymbols(it);
    var isEnum = _objectPie.f;
    var i = 0;
    var key;
    while (symbols.length > i) if (isEnum.call(it, key = symbols[i++])) result.push(key);
  } return result;
};

// 7.2.2 IsArray(argument)

var _isArray = Array.isArray || function isArray(arg) {
  return _cof(arg) == 'Array';
};

var _objectDps = _descriptors ? Object.defineProperties : function defineProperties(O, Properties) {
  _anObject(O);
  var keys = _objectKeys(Properties);
  var length = keys.length;
  var i = 0;
  var P;
  while (length > i) _objectDp.f(O, P = keys[i++], Properties[P]);
  return O;
};

var document$2 = _global.document;
var _html = document$2 && document$2.documentElement;

// 19.1.2.2 / 15.2.3.5 Object.create(O [, Properties])



var IE_PROTO$1 = _sharedKey('IE_PROTO');
var Empty = function () { /* empty */ };
var PROTOTYPE$2 = 'prototype';

// Create object with fake `null` prototype: use iframe Object with cleared prototype
var createDict = function () {
  // Thrash, waste and sodomy: IE GC bug
  var iframe = _domCreate('iframe');
  var i = _enumBugKeys.length;
  var lt = '<';
  var gt = '>';
  var iframeDocument;
  iframe.style.display = 'none';
  _html.appendChild(iframe);
  iframe.src = 'javascript:'; // eslint-disable-line no-script-url
  // createDict = iframe.contentWindow.Object;
  // html.removeChild(iframe);
  iframeDocument = iframe.contentWindow.document;
  iframeDocument.open();
  iframeDocument.write(lt + 'script' + gt + 'document.F=Object' + lt + '/script' + gt);
  iframeDocument.close();
  createDict = iframeDocument.F;
  while (i--) delete createDict[PROTOTYPE$2][_enumBugKeys[i]];
  return createDict();
};

var _objectCreate = Object.create || function create(O, Properties) {
  var result;
  if (O !== null) {
    Empty[PROTOTYPE$2] = _anObject(O);
    result = new Empty();
    Empty[PROTOTYPE$2] = null;
    // add "__proto__" for Object.getPrototypeOf polyfill
    result[IE_PROTO$1] = O;
  } else result = createDict();
  return Properties === undefined ? result : _objectDps(result, Properties);
};

// 19.1.2.7 / 15.2.3.4 Object.getOwnPropertyNames(O)

var hiddenKeys = _enumBugKeys.concat('length', 'prototype');

var f$5 = Object.getOwnPropertyNames || function getOwnPropertyNames(O) {
  return _objectKeysInternal(O, hiddenKeys);
};

var _objectGopn = {
	f: f$5
};

// fallback for IE11 buggy Object.getOwnPropertyNames with iframe and window

var gOPN$1 = _objectGopn.f;
var toString$1 = {}.toString;

var windowNames = typeof window == 'object' && window && Object.getOwnPropertyNames
  ? Object.getOwnPropertyNames(window) : [];

var getWindowNames = function (it) {
  try {
    return gOPN$1(it);
  } catch (e) {
    return windowNames.slice();
  }
};

var f$4 = function getOwnPropertyNames(it) {
  return windowNames && toString$1.call(it) == '[object Window]' ? getWindowNames(it) : gOPN$1(_toIobject(it));
};

var _objectGopnExt = {
	f: f$4
};

var gOPD$1 = Object.getOwnPropertyDescriptor;

var f$6 = _descriptors ? gOPD$1 : function getOwnPropertyDescriptor(O, P) {
  O = _toIobject(O);
  P = _toPrimitive(P, true);
  if (_ie8DomDefine) try {
    return gOPD$1(O, P);
  } catch (e) { /* empty */ }
  if (_has(O, P)) return _propertyDesc(!_objectPie.f.call(O, P), O[P]);
};

var _objectGopd = {
	f: f$6
};

'use strict';
// ECMAScript 6 symbols shim





var META = _meta.KEY;



















var gOPD = _objectGopd.f;
var dP = _objectDp.f;
var gOPN = _objectGopnExt.f;
var $Symbol = _global.Symbol;
var $JSON = _global.JSON;
var _stringify = $JSON && $JSON.stringify;
var PROTOTYPE = 'prototype';
var HIDDEN = _wks('_hidden');
var TO_PRIMITIVE = _wks('toPrimitive');
var isEnum = {}.propertyIsEnumerable;
var SymbolRegistry = _shared('symbol-registry');
var AllSymbols = _shared('symbols');
var OPSymbols = _shared('op-symbols');
var ObjectProto = Object[PROTOTYPE];
var USE_NATIVE = typeof $Symbol == 'function';
var QObject = _global.QObject;
// Don't use setters in Qt Script, https://github.com/zloirock/core-js/issues/173
var setter = !QObject || !QObject[PROTOTYPE] || !QObject[PROTOTYPE].findChild;

// fallback for old Android, https://code.google.com/p/v8/issues/detail?id=687
var setSymbolDesc = _descriptors && _fails(function () {
  return _objectCreate(dP({}, 'a', {
    get: function () { return dP(this, 'a', { value: 7 }).a; }
  })).a != 7;
}) ? function (it, key, D) {
  var protoDesc = gOPD(ObjectProto, key);
  if (protoDesc) delete ObjectProto[key];
  dP(it, key, D);
  if (protoDesc && it !== ObjectProto) dP(ObjectProto, key, protoDesc);
} : dP;

var wrap = function (tag) {
  var sym = AllSymbols[tag] = _objectCreate($Symbol[PROTOTYPE]);
  sym._k = tag;
  return sym;
};

var isSymbol = USE_NATIVE && typeof $Symbol.iterator == 'symbol' ? function (it) {
  return typeof it == 'symbol';
} : function (it) {
  return it instanceof $Symbol;
};

var $defineProperty = function defineProperty(it, key, D) {
  if (it === ObjectProto) $defineProperty(OPSymbols, key, D);
  _anObject(it);
  key = _toPrimitive(key, true);
  _anObject(D);
  if (_has(AllSymbols, key)) {
    if (!D.enumerable) {
      if (!_has(it, HIDDEN)) dP(it, HIDDEN, _propertyDesc(1, {}));
      it[HIDDEN][key] = true;
    } else {
      if (_has(it, HIDDEN) && it[HIDDEN][key]) it[HIDDEN][key] = false;
      D = _objectCreate(D, { enumerable: _propertyDesc(0, false) });
    } return setSymbolDesc(it, key, D);
  } return dP(it, key, D);
};
var $defineProperties = function defineProperties(it, P) {
  _anObject(it);
  var keys = _enumKeys(P = _toIobject(P));
  var i = 0;
  var l = keys.length;
  var key;
  while (l > i) $defineProperty(it, key = keys[i++], P[key]);
  return it;
};
var $create = function create(it, P) {
  return P === undefined ? _objectCreate(it) : $defineProperties(_objectCreate(it), P);
};
var $propertyIsEnumerable = function propertyIsEnumerable(key) {
  var E = isEnum.call(this, key = _toPrimitive(key, true));
  if (this === ObjectProto && _has(AllSymbols, key) && !_has(OPSymbols, key)) return false;
  return E || !_has(this, key) || !_has(AllSymbols, key) || _has(this, HIDDEN) && this[HIDDEN][key] ? E : true;
};
var $getOwnPropertyDescriptor = function getOwnPropertyDescriptor(it, key) {
  it = _toIobject(it);
  key = _toPrimitive(key, true);
  if (it === ObjectProto && _has(AllSymbols, key) && !_has(OPSymbols, key)) return;
  var D = gOPD(it, key);
  if (D && _has(AllSymbols, key) && !(_has(it, HIDDEN) && it[HIDDEN][key])) D.enumerable = true;
  return D;
};
var $getOwnPropertyNames = function getOwnPropertyNames(it) {
  var names = gOPN(_toIobject(it));
  var result = [];
  var i = 0;
  var key;
  while (names.length > i) {
    if (!_has(AllSymbols, key = names[i++]) && key != HIDDEN && key != META) result.push(key);
  } return result;
};
var $getOwnPropertySymbols = function getOwnPropertySymbols(it) {
  var IS_OP = it === ObjectProto;
  var names = gOPN(IS_OP ? OPSymbols : _toIobject(it));
  var result = [];
  var i = 0;
  var key;
  while (names.length > i) {
    if (_has(AllSymbols, key = names[i++]) && (IS_OP ? _has(ObjectProto, key) : true)) result.push(AllSymbols[key]);
  } return result;
};

// 19.4.1.1 Symbol([description])
if (!USE_NATIVE) {
  $Symbol = function Symbol() {
    if (this instanceof $Symbol) throw TypeError('Symbol is not a constructor!');
    var tag = _uid(arguments.length > 0 ? arguments[0] : undefined);
    var $set = function (value) {
      if (this === ObjectProto) $set.call(OPSymbols, value);
      if (_has(this, HIDDEN) && _has(this[HIDDEN], tag)) this[HIDDEN][tag] = false;
      setSymbolDesc(this, tag, _propertyDesc(1, value));
    };
    if (_descriptors && setter) setSymbolDesc(ObjectProto, tag, { configurable: true, set: $set });
    return wrap(tag);
  };
  _redefine($Symbol[PROTOTYPE], 'toString', function toString() {
    return this._k;
  });

  _objectGopd.f = $getOwnPropertyDescriptor;
  _objectDp.f = $defineProperty;
  _objectGopn.f = _objectGopnExt.f = $getOwnPropertyNames;
  _objectPie.f = $propertyIsEnumerable;
  _objectGops.f = $getOwnPropertySymbols;

  if (_descriptors && !_library) {
    _redefine(ObjectProto, 'propertyIsEnumerable', $propertyIsEnumerable, true);
  }

  _wksExt.f = function (name) {
    return wrap(_wks(name));
  };
}

_export(_export.G + _export.W + _export.F * !USE_NATIVE, { Symbol: $Symbol });

for (var es6Symbols = (
  // 19.4.2.2, 19.4.2.3, 19.4.2.4, 19.4.2.6, 19.4.2.8, 19.4.2.9, 19.4.2.10, 19.4.2.11, 19.4.2.12, 19.4.2.13, 19.4.2.14
  'hasInstance,isConcatSpreadable,iterator,match,replace,search,species,split,toPrimitive,toStringTag,unscopables'
).split(','), j = 0; es6Symbols.length > j;)_wks(es6Symbols[j++]);

for (var wellKnownSymbols = _objectKeys(_wks.store), k = 0; wellKnownSymbols.length > k;) _wksDefine(wellKnownSymbols[k++]);

_export(_export.S + _export.F * !USE_NATIVE, 'Symbol', {
  // 19.4.2.1 Symbol.for(key)
  'for': function (key) {
    return _has(SymbolRegistry, key += '')
      ? SymbolRegistry[key]
      : SymbolRegistry[key] = $Symbol(key);
  },
  // 19.4.2.5 Symbol.keyFor(sym)
  keyFor: function keyFor(key) {
    if (isSymbol(key)) return _keyof(SymbolRegistry, key);
    throw TypeError(key + ' is not a symbol!');
  },
  useSetter: function () { setter = true; },
  useSimple: function () { setter = false; }
});

_export(_export.S + _export.F * !USE_NATIVE, 'Object', {
  // 19.1.2.2 Object.create(O [, Properties])
  create: $create,
  // 19.1.2.4 Object.defineProperty(O, P, Attributes)
  defineProperty: $defineProperty,
  // 19.1.2.3 Object.defineProperties(O, Properties)
  defineProperties: $defineProperties,
  // 19.1.2.6 Object.getOwnPropertyDescriptor(O, P)
  getOwnPropertyDescriptor: $getOwnPropertyDescriptor,
  // 19.1.2.7 Object.getOwnPropertyNames(O)
  getOwnPropertyNames: $getOwnPropertyNames,
  // 19.1.2.8 Object.getOwnPropertySymbols(O)
  getOwnPropertySymbols: $getOwnPropertySymbols
});

// 24.3.2 JSON.stringify(value [, replacer [, space]])
$JSON && _export(_export.S + _export.F * (!USE_NATIVE || _fails(function () {
  var S = $Symbol();
  // MS Edge converts symbol values to JSON as {}
  // WebKit converts symbol values to JSON as null
  // V8 throws on boxed symbols
  return _stringify([S]) != '[null]' || _stringify({ a: S }) != '{}' || _stringify(Object(S)) != '{}';
})), 'JSON', {
  stringify: function stringify(it) {
    if (it === undefined || isSymbol(it)) return; // IE8 returns string on undefined
    var args = [it];
    var i = 1;
    var replacer, $replacer;
    while (arguments.length > i) args.push(arguments[i++]);
    replacer = args[1];
    if (typeof replacer == 'function') $replacer = replacer;
    if ($replacer || !_isArray(replacer)) replacer = function (key, value) {
      if ($replacer) value = $replacer.call(this, key, value);
      if (!isSymbol(value)) return value;
    };
    args[1] = replacer;
    return _stringify.apply($JSON, args);
  }
});

// 19.4.3.4 Symbol.prototype[@@toPrimitive](hint)
$Symbol[PROTOTYPE][TO_PRIMITIVE] || _hide($Symbol[PROTOTYPE], TO_PRIMITIVE, $Symbol[PROTOTYPE].valueOf);
// 19.4.3.5 Symbol.prototype[@@toStringTag]
_setToStringTag($Symbol, 'Symbol');
// 20.2.1.9 Math[@@toStringTag]
_setToStringTag(Math, 'Math', true);
// 24.3.3 JSON[@@toStringTag]
_setToStringTag(_global.JSON, 'JSON', true);

// getting tag from 19.1.3.6 Object.prototype.toString()

var TAG$1 = _wks('toStringTag');
// ES3 wrong here
var ARG = _cof(function () { return arguments; }()) == 'Arguments';

// fallback for IE11 Script Access Denied error
var tryGet = function (it, key) {
  try {
    return it[key];
  } catch (e) { /* empty */ }
};

var _classof = function (it) {
  var O, T, B;
  return it === undefined ? 'Undefined' : it === null ? 'Null'
    // @@toStringTag case
    : typeof (T = tryGet(O = Object(it), TAG$1)) == 'string' ? T
    // builtinTag case
    : ARG ? _cof(O)
    // ES3 arguments fallback
    : (B = _cof(O)) == 'Object' && typeof O.callee == 'function' ? 'Arguments' : B;
};

'use strict';
// 19.1.3.6 Object.prototype.toString()

var test = {};
test[_wks('toStringTag')] = 'z';
if (test + '' != '[object z]') {
  _redefine(Object.prototype, 'toString', function toString() {
    return '[object ' + _classof(this) + ']';
  }, true);
}

// true  -> String#at
// false -> String#codePointAt
var _stringAt = function (TO_STRING) {
  return function (that, pos) {
    var s = String(_defined(that));
    var i = _toInteger(pos);
    var l = s.length;
    var a, b;
    if (i < 0 || i >= l) return TO_STRING ? '' : undefined;
    a = s.charCodeAt(i);
    return a < 0xd800 || a > 0xdbff || i + 1 === l || (b = s.charCodeAt(i + 1)) < 0xdc00 || b > 0xdfff
      ? TO_STRING ? s.charAt(i) : a
      : TO_STRING ? s.slice(i, i + 2) : (a - 0xd800 << 10) + (b - 0xdc00) + 0x10000;
  };
};

var _iterators = {};

'use strict';



var IteratorPrototype = {};

// 25.1.2.1.1 %IteratorPrototype%[@@iterator]()
_hide(IteratorPrototype, _wks('iterator'), function () { return this; });

var _iterCreate = function (Constructor, NAME, next) {
  Constructor.prototype = _objectCreate(IteratorPrototype, { next: _propertyDesc(1, next) });
  _setToStringTag(Constructor, NAME + ' Iterator');
};

// 7.1.13 ToObject(argument)

var _toObject = function (it) {
  return Object(_defined(it));
};

// 19.1.2.9 / 15.2.3.2 Object.getPrototypeOf(O)


var IE_PROTO$2 = _sharedKey('IE_PROTO');
var ObjectProto$1 = Object.prototype;

var _objectGpo = Object.getPrototypeOf || function (O) {
  O = _toObject(O);
  if (_has(O, IE_PROTO$2)) return O[IE_PROTO$2];
  if (typeof O.constructor == 'function' && O instanceof O.constructor) {
    return O.constructor.prototype;
  } return O instanceof Object ? ObjectProto$1 : null;
};

'use strict';









var ITERATOR = _wks('iterator');
var BUGGY = !([].keys && 'next' in [].keys()); // Safari has buggy iterators w/o `next`
var FF_ITERATOR = '@@iterator';
var KEYS = 'keys';
var VALUES = 'values';

var returnThis = function () { return this; };

var _iterDefine = function (Base, NAME, Constructor, next, DEFAULT, IS_SET, FORCED) {
  _iterCreate(Constructor, NAME, next);
  var getMethod = function (kind) {
    if (!BUGGY && kind in proto) return proto[kind];
    switch (kind) {
      case KEYS: return function keys() { return new Constructor(this, kind); };
      case VALUES: return function values() { return new Constructor(this, kind); };
    } return function entries() { return new Constructor(this, kind); };
  };
  var TAG = NAME + ' Iterator';
  var DEF_VALUES = DEFAULT == VALUES;
  var VALUES_BUG = false;
  var proto = Base.prototype;
  var $native = proto[ITERATOR] || proto[FF_ITERATOR] || DEFAULT && proto[DEFAULT];
  var $default = $native || getMethod(DEFAULT);
  var $entries = DEFAULT ? !DEF_VALUES ? $default : getMethod('entries') : undefined;
  var $anyNative = NAME == 'Array' ? proto.entries || $native : $native;
  var methods, key, IteratorPrototype;
  // Fix native
  if ($anyNative) {
    IteratorPrototype = _objectGpo($anyNative.call(new Base()));
    if (IteratorPrototype !== Object.prototype && IteratorPrototype.next) {
      // Set @@toStringTag to native iterators
      _setToStringTag(IteratorPrototype, TAG, true);
      // fix for some old engines
      if (!_library && !_has(IteratorPrototype, ITERATOR)) _hide(IteratorPrototype, ITERATOR, returnThis);
    }
  }
  // fix Array#{values, @@iterator}.name in V8 / FF
  if (DEF_VALUES && $native && $native.name !== VALUES) {
    VALUES_BUG = true;
    $default = function values() { return $native.call(this); };
  }
  // Define iterator
  if ((!_library || FORCED) && (BUGGY || VALUES_BUG || !proto[ITERATOR])) {
    _hide(proto, ITERATOR, $default);
  }
  // Plug for library
  _iterators[NAME] = $default;
  _iterators[TAG] = returnThis;
  if (DEFAULT) {
    methods = {
      values: DEF_VALUES ? $default : getMethod(VALUES),
      keys: IS_SET ? $default : getMethod(KEYS),
      entries: $entries
    };
    if (FORCED) for (key in methods) {
      if (!(key in proto)) _redefine(proto, key, methods[key]);
    } else _export(_export.P + _export.F * (BUGGY || VALUES_BUG), NAME, methods);
  }
  return methods;
};

'use strict';
var $at = _stringAt(true);

// 21.1.3.27 String.prototype[@@iterator]()
_iterDefine(String, 'String', function (iterated) {
  this._t = String(iterated); // target
  this._i = 0;                // next index
// 21.1.5.2.1 %StringIteratorPrototype%.next()
}, function () {
  var O = this._t;
  var index = this._i;
  var point;
  if (index >= O.length) return { value: undefined, done: true };
  point = $at(O, index);
  this._i += point.length;
  return { value: point, done: false };
});

// 22.1.2.2 / 15.4.3.2 Array.isArray(arg)


_export(_export.S, 'Array', { isArray: _isArray });

// call something on iterator step with safe closing on error

var _iterCall = function (iterator, fn, value, entries) {
  try {
    return entries ? fn(_anObject(value)[0], value[1]) : fn(value);
  // 7.4.6 IteratorClose(iterator, completion)
  } catch (e) {
    var ret = iterator['return'];
    if (ret !== undefined) _anObject(ret.call(iterator));
    throw e;
  }
};

// check on default Array iterator

var ITERATOR$1 = _wks('iterator');
var ArrayProto = Array.prototype;

var _isArrayIter = function (it) {
  return it !== undefined && (_iterators.Array === it || ArrayProto[ITERATOR$1] === it);
};

'use strict';



var _createProperty = function (object, index, value) {
  if (index in object) _objectDp.f(object, index, _propertyDesc(0, value));
  else object[index] = value;
};

var ITERATOR$2 = _wks('iterator');

var core_getIteratorMethod = _core.getIteratorMethod = function (it) {
  if (it != undefined) return it[ITERATOR$2]
    || it['@@iterator']
    || _iterators[_classof(it)];
};

var ITERATOR$3 = _wks('iterator');
var SAFE_CLOSING = false;

try {
  var riter = [7][ITERATOR$3]();
  riter['return'] = function () { SAFE_CLOSING = true; };
  // eslint-disable-next-line no-throw-literal
  
} catch (e) { /* empty */ }

var _iterDetect = function (exec, skipClosing) {
  if (!skipClosing && !SAFE_CLOSING) return false;
  var safe = false;
  try {
    var arr = [7];
    var iter = arr[ITERATOR$3]();
    iter.next = function () { return { done: safe = true }; };
    arr[ITERATOR$3] = function () { return iter; };
    exec(arr);
  } catch (e) { /* empty */ }
  return safe;
};

'use strict';









_export(_export.S + _export.F * !_iterDetect(function (iter) {  }), 'Array', {
  // 22.1.2.1 Array.from(arrayLike, mapfn = undefined, thisArg = undefined)
  from: function from(arrayLike /* , mapfn = undefined, thisArg = undefined */) {
    var O = _toObject(arrayLike);
    var C = typeof this == 'function' ? this : Array;
    var aLen = arguments.length;
    var mapfn = aLen > 1 ? arguments[1] : undefined;
    var mapping = mapfn !== undefined;
    var index = 0;
    var iterFn = core_getIteratorMethod(O);
    var length, result, step, iterator;
    if (mapping) mapfn = _ctx(mapfn, aLen > 2 ? arguments[2] : undefined, 2);
    // if object isn't iterable or it's array with default iterator - use simple case
    if (iterFn != undefined && !(C == Array && _isArrayIter(iterFn))) {
      for (iterator = iterFn.call(O), result = new C(); !(step = iterator.next()).done; index++) {
        _createProperty(result, index, mapping ? _iterCall(iterator, mapfn, [step.value, index], true) : step.value);
      }
    } else {
      length = _toLength(O.length);
      for (result = new C(length); length > index; index++) {
        _createProperty(result, index, mapping ? mapfn(O[index], index) : O[index]);
      }
    }
    result.length = index;
    return result;
  }
});

'use strict';



// WebKit Array.of isn't generic
_export(_export.S + _export.F * _fails(function () {
  function F() { /* empty */ }
  return !(Array.of.call(F) instanceof F);
}), 'Array', {
  // 22.1.2.3 Array.of( ...items)
  of: function of(/* ...args */) {
    var index = 0;
    var aLen = arguments.length;
    var result = new (typeof this == 'function' ? this : Array)(aLen);
    while (aLen > index) _createProperty(result, index, arguments[index++]);
    result.length = aLen;
    return result;
  }
});

'use strict';


var _strictMethod = function (method, arg) {
  return !!method && _fails(function () {
    // eslint-disable-next-line no-useless-call
    arg ? method.call(null, function () { /* empty */ }, 1) : method.call(null);
  });
};

'use strict';
// 22.1.3.13 Array.prototype.join(separator)


var arrayJoin = [].join;

// fallback for not array-like strings
_export(_export.P + _export.F * (_iobject != Object || !_strictMethod(arrayJoin)), 'Array', {
  join: function join(separator) {
    return arrayJoin.call(_toIobject(this), separator === undefined ? ',' : separator);
  }
});

'use strict';





var arraySlice = [].slice;

// fallback for not array-like ES3 strings and DOM objects
_export(_export.P + _export.F * _fails(function () {
  if (_html) arraySlice.call(_html);
}), 'Array', {
  slice: function slice(begin, end) {
    var len = _toLength(this.length);
    var klass = _cof(this);
    end = end === undefined ? len : end;
    if (klass == 'Array') return arraySlice.call(this, begin, end);
    var start = _toAbsoluteIndex(begin, len);
    var upTo = _toAbsoluteIndex(end, len);
    var size = _toLength(upTo - start);
    var cloned = Array(size);
    var i = 0;
    for (; i < size; i++) cloned[i] = klass == 'String'
      ? this.charAt(start + i)
      : this[start + i];
    return cloned;
  }
});

'use strict';




var $sort = [].sort;
var test$1 = [1, 2, 3];

_export(_export.P + _export.F * (_fails(function () {
  // IE8-
  test$1.sort(undefined);
}) || !_fails(function () {
  // V8 bug
  test$1.sort(null);
  // Old WebKit
}) || !_strictMethod($sort)), 'Array', {
  // 22.1.3.25 Array.prototype.sort(comparefn)
  sort: function sort(comparefn) {
    return comparefn === undefined
      ? $sort.call(_toObject(this))
      : $sort.call(_toObject(this), _aFunction(comparefn));
  }
});

var SPECIES = _wks('species');

var _arraySpeciesConstructor = function (original) {
  var C;
  if (_isArray(original)) {
    C = original.constructor;
    // cross-realm fallback
    if (typeof C == 'function' && (C === Array || _isArray(C.prototype))) C = undefined;
    if (_isObject(C)) {
      C = C[SPECIES];
      if (C === null) C = undefined;
    }
  } return C === undefined ? Array : C;
};

// 9.4.2.3 ArraySpeciesCreate(originalArray, length)


var _arraySpeciesCreate = function (original, length) {
  return new (_arraySpeciesConstructor(original))(length);
};

// 0 -> Array#forEach
// 1 -> Array#map
// 2 -> Array#filter
// 3 -> Array#some
// 4 -> Array#every
// 5 -> Array#find
// 6 -> Array#findIndex





var _arrayMethods = function (TYPE, $create) {
  var IS_MAP = TYPE == 1;
  var IS_FILTER = TYPE == 2;
  var IS_SOME = TYPE == 3;
  var IS_EVERY = TYPE == 4;
  var IS_FIND_INDEX = TYPE == 6;
  var NO_HOLES = TYPE == 5 || IS_FIND_INDEX;
  var create = $create || _arraySpeciesCreate;
  return function ($this, callbackfn, that) {
    var O = _toObject($this);
    var self = _iobject(O);
    var f = _ctx(callbackfn, that, 3);
    var length = _toLength(self.length);
    var index = 0;
    var result = IS_MAP ? create($this, length) : IS_FILTER ? create($this, 0) : undefined;
    var val, res;
    for (;length > index; index++) if (NO_HOLES || index in self) {
      val = self[index];
      res = f(val, index, O);
      if (TYPE) {
        if (IS_MAP) result[index] = res;   // map
        else if (res) switch (TYPE) {
          case 3: return true;             // some
          case 5: return val;              // find
          case 6: return index;            // findIndex
          case 2: result.push(val);        // filter
        } else if (IS_EVERY) return false; // every
      }
    }
    return IS_FIND_INDEX ? -1 : IS_SOME || IS_EVERY ? IS_EVERY : result;
  };
};

'use strict';

var $forEach = _arrayMethods(0);
var STRICT = _strictMethod([].forEach, true);

_export(_export.P + _export.F * !STRICT, 'Array', {
  // 22.1.3.10 / 15.4.4.18 Array.prototype.forEach(callbackfn [, thisArg])
  forEach: function forEach(callbackfn /* , thisArg */) {
    return $forEach(this, callbackfn, arguments[1]);
  }
});

'use strict';

var $map = _arrayMethods(1);

_export(_export.P + _export.F * !_strictMethod([].map, true), 'Array', {
  // 22.1.3.15 / 15.4.4.19 Array.prototype.map(callbackfn [, thisArg])
  map: function map(callbackfn /* , thisArg */) {
    return $map(this, callbackfn, arguments[1]);
  }
});

'use strict';

var $filter = _arrayMethods(2);

_export(_export.P + _export.F * !_strictMethod([].filter, true), 'Array', {
  // 22.1.3.7 / 15.4.4.20 Array.prototype.filter(callbackfn [, thisArg])
  filter: function filter(callbackfn /* , thisArg */) {
    return $filter(this, callbackfn, arguments[1]);
  }
});

'use strict';

var $some = _arrayMethods(3);

_export(_export.P + _export.F * !_strictMethod([].some, true), 'Array', {
  // 22.1.3.23 / 15.4.4.17 Array.prototype.some(callbackfn [, thisArg])
  some: function some(callbackfn /* , thisArg */) {
    return $some(this, callbackfn, arguments[1]);
  }
});

'use strict';

var $every = _arrayMethods(4);

_export(_export.P + _export.F * !_strictMethod([].every, true), 'Array', {
  // 22.1.3.5 / 15.4.4.16 Array.prototype.every(callbackfn [, thisArg])
  every: function every(callbackfn /* , thisArg */) {
    return $every(this, callbackfn, arguments[1]);
  }
});

var _arrayReduce = function (that, callbackfn, aLen, memo, isRight) {
  _aFunction(callbackfn);
  var O = _toObject(that);
  var self = _iobject(O);
  var length = _toLength(O.length);
  var index = isRight ? length - 1 : 0;
  var i = isRight ? -1 : 1;
  if (aLen < 2) for (;;) {
    if (index in self) {
      memo = self[index];
      index += i;
      break;
    }
    index += i;
    if (isRight ? index < 0 : length <= index) {
      throw TypeError('Reduce of empty array with no initial value');
    }
  }
  for (;isRight ? index >= 0 : length > index; index += i) if (index in self) {
    memo = callbackfn(memo, self[index], index, O);
  }
  return memo;
};

'use strict';



_export(_export.P + _export.F * !_strictMethod([].reduce, true), 'Array', {
  // 22.1.3.18 / 15.4.4.21 Array.prototype.reduce(callbackfn [, initialValue])
  reduce: function reduce(callbackfn /* , initialValue */) {
    return _arrayReduce(this, callbackfn, arguments.length, arguments[1], false);
  }
});

'use strict';



_export(_export.P + _export.F * !_strictMethod([].reduceRight, true), 'Array', {
  // 22.1.3.19 / 15.4.4.22 Array.prototype.reduceRight(callbackfn [, initialValue])
  reduceRight: function reduceRight(callbackfn /* , initialValue */) {
    return _arrayReduce(this, callbackfn, arguments.length, arguments[1], true);
  }
});

'use strict';

var $indexOf = _arrayIncludes(false);
var $native = [].indexOf;
var NEGATIVE_ZERO = !!$native && 1 / [1].indexOf(1, -0) < 0;

_export(_export.P + _export.F * (NEGATIVE_ZERO || !_strictMethod($native)), 'Array', {
  // 22.1.3.11 / 15.4.4.14 Array.prototype.indexOf(searchElement [, fromIndex])
  indexOf: function indexOf(searchElement /* , fromIndex = 0 */) {
    return NEGATIVE_ZERO
      // convert -0 to +0
      ? $native.apply(this, arguments) || 0
      : $indexOf(this, searchElement, arguments[1]);
  }
});

'use strict';




var $native$1 = [].lastIndexOf;
var NEGATIVE_ZERO$1 = !!$native$1 && 1 / [1].lastIndexOf(1, -0) < 0;

_export(_export.P + _export.F * (NEGATIVE_ZERO$1 || !_strictMethod($native$1)), 'Array', {
  // 22.1.3.14 / 15.4.4.15 Array.prototype.lastIndexOf(searchElement [, fromIndex])
  lastIndexOf: function lastIndexOf(searchElement /* , fromIndex = @[*-1] */) {
    // convert -0 to +0
    if (NEGATIVE_ZERO$1) return $native$1.apply(this, arguments) || 0;
    var O = _toIobject(this);
    var length = _toLength(O.length);
    var index = length - 1;
    if (arguments.length > 1) index = Math.min(index, _toInteger(arguments[1]));
    if (index < 0) index = length + index;
    for (;index >= 0; index--) if (index in O) if (O[index] === searchElement) return index || 0;
    return -1;
  }
});

// 22.1.3.3 Array.prototype.copyWithin(target, start, end = this.length)
'use strict';




var _arrayCopyWithin = [].copyWithin || function copyWithin(target /* = 0 */, start /* = 0, end = @length */) {
  var O = _toObject(this);
  var len = _toLength(O.length);
  var to = _toAbsoluteIndex(target, len);
  var from = _toAbsoluteIndex(start, len);
  var end = arguments.length > 2 ? arguments[2] : undefined;
  var count = Math.min((end === undefined ? len : _toAbsoluteIndex(end, len)) - from, len - to);
  var inc = 1;
  if (from < to && to < from + count) {
    inc = -1;
    from += count - 1;
    to += count - 1;
  }
  while (count-- > 0) {
    if (from in O) O[to] = O[from];
    else delete O[to];
    to += inc;
    from += inc;
  } return O;
};

// 22.1.3.31 Array.prototype[@@unscopables]
var UNSCOPABLES = _wks('unscopables');
var ArrayProto$1 = Array.prototype;
if (ArrayProto$1[UNSCOPABLES] == undefined) _hide(ArrayProto$1, UNSCOPABLES, {});
var _addToUnscopables = function (key) {
  ArrayProto$1[UNSCOPABLES][key] = true;
};

// 22.1.3.3 Array.prototype.copyWithin(target, start, end = this.length)


_export(_export.P, 'Array', { copyWithin: _arrayCopyWithin });

_addToUnscopables('copyWithin');

// 22.1.3.6 Array.prototype.fill(value, start = 0, end = this.length)
'use strict';



var _arrayFill = function fill(value /* , start = 0, end = @length */) {
  var O = _toObject(this);
  var length = _toLength(O.length);
  var aLen = arguments.length;
  var index = _toAbsoluteIndex(aLen > 1 ? arguments[1] : undefined, length);
  var end = aLen > 2 ? arguments[2] : undefined;
  var endPos = end === undefined ? length : _toAbsoluteIndex(end, length);
  while (endPos > index) O[index++] = value;
  return O;
};

// 22.1.3.6 Array.prototype.fill(value, start = 0, end = this.length)


_export(_export.P, 'Array', { fill: _arrayFill });

_addToUnscopables('fill');

'use strict';
// 22.1.3.8 Array.prototype.find(predicate, thisArg = undefined)

var $find = _arrayMethods(5);
var KEY = 'find';
var forced = true;
// Shouldn't skip holes
if (KEY in []) Array(1)[KEY](function () { forced = false; });
_export(_export.P + _export.F * forced, 'Array', {
  find: function find(callbackfn /* , that = undefined */) {
    return $find(this, callbackfn, arguments.length > 1 ? arguments[1] : undefined);
  }
});
_addToUnscopables(KEY);

'use strict';
// 22.1.3.9 Array.prototype.findIndex(predicate, thisArg = undefined)

var $find$1 = _arrayMethods(6);
var KEY$1 = 'findIndex';
var forced$1 = true;
// Shouldn't skip holes
if (KEY$1 in []) Array(1)[KEY$1](function () { forced$1 = false; });
_export(_export.P + _export.F * forced$1, 'Array', {
  findIndex: function findIndex(callbackfn /* , that = undefined */) {
    return $find$1(this, callbackfn, arguments.length > 1 ? arguments[1] : undefined);
  }
});
_addToUnscopables(KEY$1);

'use strict';



var SPECIES$1 = _wks('species');

var _setSpecies = function (KEY) {
  var C = _global[KEY];
  if (_descriptors && C && !C[SPECIES$1]) _objectDp.f(C, SPECIES$1, {
    configurable: true,
    get: function () { return this; }
  });
};

_setSpecies('Array');

var _iterStep = function (done, value) {
  return { value: value, done: !!done };
};

'use strict';





// 22.1.3.4 Array.prototype.entries()
// 22.1.3.13 Array.prototype.keys()
// 22.1.3.29 Array.prototype.values()
// 22.1.3.30 Array.prototype[@@iterator]()
var es6_array_iterator = _iterDefine(Array, 'Array', function (iterated, kind) {
  this._t = _toIobject(iterated); // target
  this._i = 0;                   // next index
  this._k = kind;                // kind
// 22.1.5.2.1 %ArrayIteratorPrototype%.next()
}, function () {
  var O = this._t;
  var kind = this._k;
  var index = this._i++;
  if (!O || index >= O.length) {
    this._t = undefined;
    return _iterStep(1);
  }
  if (kind == 'keys') return _iterStep(0, index);
  if (kind == 'values') return _iterStep(0, O[index]);
  return _iterStep(0, [index, O[index]]);
}, 'values');

// argumentsList[@@iterator] is %ArrayProto_values% (9.4.4.6, 9.4.4.7)
_iterators.Arguments = _iterators.Array;

_addToUnscopables('keys');
_addToUnscopables('values');
_addToUnscopables('entries');

var TYPED = _uid('typed_array');
var VIEW$1 = _uid('view');
var ABV = !!(_global.ArrayBuffer && _global.DataView);
var CONSTR = ABV;
var i = 0;
var l = 9;
var Typed;

var TypedArrayConstructors = (
  'Int8Array,Uint8Array,Uint8ClampedArray,Int16Array,Uint16Array,Int32Array,Uint32Array,Float32Array,Float64Array'
).split(',');

while (i < l) {
  if (Typed = _global[TypedArrayConstructors[i++]]) {
    _hide(Typed.prototype, TYPED, true);
    _hide(Typed.prototype, VIEW$1, true);
  } else CONSTR = false;
}

var _typed = {
  ABV: ABV,
  CONSTR: CONSTR,
  TYPED: TYPED,
  VIEW: VIEW$1
};

var _redefineAll = function (target, src, safe) {
  for (var key in src) _redefine(target, key, src[key], safe);
  return target;
};

var _anInstance = function (it, Constructor, name, forbiddenField) {
  if (!(it instanceof Constructor) || (forbiddenField !== undefined && forbiddenField in it)) {
    throw TypeError(name + ': incorrect invocation!');
  } return it;
};

// https://tc39.github.io/ecma262/#sec-toindex


var _toIndex = function (it) {
  if (it === undefined) return 0;
  var number = _toInteger(it);
  var length = _toLength(number);
  if (number !== length) throw RangeError('Wrong length!');
  return length;
};

var _typedBuffer = createCommonjsModule(function (module, exports) {
'use strict';











var gOPN = _objectGopn.f;
var dP = _objectDp.f;


var ARRAY_BUFFER = 'ArrayBuffer';
var DATA_VIEW = 'DataView';
var PROTOTYPE = 'prototype';
var WRONG_LENGTH = 'Wrong length!';
var WRONG_INDEX = 'Wrong index!';
var $ArrayBuffer = _global[ARRAY_BUFFER];
var $DataView = _global[DATA_VIEW];
var Math = _global.Math;
var RangeError = _global.RangeError;
// eslint-disable-next-line no-shadow-restricted-names
var Infinity = _global.Infinity;
var BaseBuffer = $ArrayBuffer;
var abs = Math.abs;
var pow = Math.pow;
var floor = Math.floor;
var log$$1 = Math.log;
var LN2 = Math.LN2;
var BUFFER = 'buffer';
var BYTE_LENGTH = 'byteLength';
var BYTE_OFFSET = 'byteOffset';
var $BUFFER = _descriptors ? '_b' : BUFFER;
var $LENGTH = _descriptors ? '_l' : BYTE_LENGTH;
var $OFFSET = _descriptors ? '_o' : BYTE_OFFSET;

// IEEE754 conversions based on https://github.com/feross/ieee754
function packIEEE754(value, mLen, nBytes) {
  var buffer = Array(nBytes);
  var eLen = nBytes * 8 - mLen - 1;
  var eMax = (1 << eLen) - 1;
  var eBias = eMax >> 1;
  var rt = mLen === 23 ? pow(2, -24) - pow(2, -77) : 0;
  var i = 0;
  var s = value < 0 || value === 0 && 1 / value < 0 ? 1 : 0;
  var e, m, c;
  value = abs(value);
  // eslint-disable-next-line no-self-compare
  if (value != value || value === Infinity) {
    // eslint-disable-next-line no-self-compare
    m = value != value ? 1 : 0;
    e = eMax;
  } else {
    e = floor(log$$1(value) / LN2);
    if (value * (c = pow(2, -e)) < 1) {
      e--;
      c *= 2;
    }
    if (e + eBias >= 1) {
      value += rt / c;
    } else {
      value += rt * pow(2, 1 - eBias);
    }
    if (value * c >= 2) {
      e++;
      c /= 2;
    }
    if (e + eBias >= eMax) {
      m = 0;
      e = eMax;
    } else if (e + eBias >= 1) {
      m = (value * c - 1) * pow(2, mLen);
      e = e + eBias;
    } else {
      m = value * pow(2, eBias - 1) * pow(2, mLen);
      e = 0;
    }
  }
  for (; mLen >= 8; buffer[i++] = m & 255, m /= 256, mLen -= 8);
  e = e << mLen | m;
  eLen += mLen;
  for (; eLen > 0; buffer[i++] = e & 255, e /= 256, eLen -= 8);
  buffer[--i] |= s * 128;
  return buffer;
}
function unpackIEEE754(buffer, mLen, nBytes) {
  var eLen = nBytes * 8 - mLen - 1;
  var eMax = (1 << eLen) - 1;
  var eBias = eMax >> 1;
  var nBits = eLen - 7;
  var i = nBytes - 1;
  var s = buffer[i--];
  var e = s & 127;
  var m;
  s >>= 7;
  for (; nBits > 0; e = e * 256 + buffer[i], i--, nBits -= 8);
  m = e & (1 << -nBits) - 1;
  e >>= -nBits;
  nBits += mLen;
  for (; nBits > 0; m = m * 256 + buffer[i], i--, nBits -= 8);
  if (e === 0) {
    e = 1 - eBias;
  } else if (e === eMax) {
    return m ? NaN : s ? -Infinity : Infinity;
  } else {
    m = m + pow(2, mLen);
    e = e - eBias;
  } return (s ? -1 : 1) * m * pow(2, e - mLen);
}

function unpackI32(bytes) {
  return bytes[3] << 24 | bytes[2] << 16 | bytes[1] << 8 | bytes[0];
}
function packI8(it) {
  return [it & 0xff];
}
function packI16(it) {
  return [it & 0xff, it >> 8 & 0xff];
}
function packI32(it) {
  return [it & 0xff, it >> 8 & 0xff, it >> 16 & 0xff, it >> 24 & 0xff];
}
function packF64(it) {
  return packIEEE754(it, 52, 8);
}
function packF32(it) {
  return packIEEE754(it, 23, 4);
}

function addGetter(C, key, internal) {
  dP(C[PROTOTYPE], key, { get: function () { return this[internal]; } });
}

function get(view, bytes, index, isLittleEndian) {
  var numIndex = +index;
  var intIndex = _toIndex(numIndex);
  if (intIndex + bytes > view[$LENGTH]) throw RangeError(WRONG_INDEX);
  var store = view[$BUFFER]._b;
  var start = intIndex + view[$OFFSET];
  var pack = store.slice(start, start + bytes);
  return isLittleEndian ? pack : pack.reverse();
}
function set(view, bytes, index, conversion, value, isLittleEndian) {
  var numIndex = +index;
  var intIndex = _toIndex(numIndex);
  if (intIndex + bytes > view[$LENGTH]) throw RangeError(WRONG_INDEX);
  var store = view[$BUFFER]._b;
  var start = intIndex + view[$OFFSET];
  var pack = conversion(+value);
  for (var i = 0; i < bytes; i++) store[start + i] = pack[isLittleEndian ? i : bytes - i - 1];
}

if (!_typed.ABV) {
  $ArrayBuffer = function ArrayBuffer(length) {
    _anInstance(this, $ArrayBuffer, ARRAY_BUFFER);
    var byteLength = _toIndex(length);
    this._b = _arrayFill.call(Array(byteLength), 0);
    this[$LENGTH] = byteLength;
  };

  $DataView = function DataView(buffer, byteOffset, byteLength) {
    _anInstance(this, $DataView, DATA_VIEW);
    _anInstance(buffer, $ArrayBuffer, DATA_VIEW);
    var bufferLength = buffer[$LENGTH];
    var offset = _toInteger(byteOffset);
    if (offset < 0 || offset > bufferLength) throw RangeError('Wrong offset!');
    byteLength = byteLength === undefined ? bufferLength - offset : _toLength(byteLength);
    if (offset + byteLength > bufferLength) throw RangeError(WRONG_LENGTH);
    this[$BUFFER] = buffer;
    this[$OFFSET] = offset;
    this[$LENGTH] = byteLength;
  };

  if (_descriptors) {
    addGetter($ArrayBuffer, BYTE_LENGTH, '_l');
    addGetter($DataView, BUFFER, '_b');
    addGetter($DataView, BYTE_LENGTH, '_l');
    addGetter($DataView, BYTE_OFFSET, '_o');
  }

  _redefineAll($DataView[PROTOTYPE], {
    getInt8: function getInt8(byteOffset) {
      return get(this, 1, byteOffset)[0] << 24 >> 24;
    },
    getUint8: function getUint8(byteOffset) {
      return get(this, 1, byteOffset)[0];
    },
    getInt16: function getInt16(byteOffset /* , littleEndian */) {
      var bytes = get(this, 2, byteOffset, arguments[1]);
      return (bytes[1] << 8 | bytes[0]) << 16 >> 16;
    },
    getUint16: function getUint16(byteOffset /* , littleEndian */) {
      var bytes = get(this, 2, byteOffset, arguments[1]);
      return bytes[1] << 8 | bytes[0];
    },
    getInt32: function getInt32(byteOffset /* , littleEndian */) {
      return unpackI32(get(this, 4, byteOffset, arguments[1]));
    },
    getUint32: function getUint32(byteOffset /* , littleEndian */) {
      return unpackI32(get(this, 4, byteOffset, arguments[1])) >>> 0;
    },
    getFloat32: function getFloat32(byteOffset /* , littleEndian */) {
      return unpackIEEE754(get(this, 4, byteOffset, arguments[1]), 23, 4);
    },
    getFloat64: function getFloat64(byteOffset /* , littleEndian */) {
      return unpackIEEE754(get(this, 8, byteOffset, arguments[1]), 52, 8);
    },
    setInt8: function setInt8(byteOffset, value) {
      set(this, 1, byteOffset, packI8, value);
    },
    setUint8: function setUint8(byteOffset, value) {
      set(this, 1, byteOffset, packI8, value);
    },
    setInt16: function setInt16(byteOffset, value /* , littleEndian */) {
      set(this, 2, byteOffset, packI16, value, arguments[2]);
    },
    setUint16: function setUint16(byteOffset, value /* , littleEndian */) {
      set(this, 2, byteOffset, packI16, value, arguments[2]);
    },
    setInt32: function setInt32(byteOffset, value /* , littleEndian */) {
      set(this, 4, byteOffset, packI32, value, arguments[2]);
    },
    setUint32: function setUint32(byteOffset, value /* , littleEndian */) {
      set(this, 4, byteOffset, packI32, value, arguments[2]);
    },
    setFloat32: function setFloat32(byteOffset, value /* , littleEndian */) {
      set(this, 4, byteOffset, packF32, value, arguments[2]);
    },
    setFloat64: function setFloat64(byteOffset, value /* , littleEndian */) {
      set(this, 8, byteOffset, packF64, value, arguments[2]);
    }
  });
} else {
  if (!_fails(function () {
    $ArrayBuffer(1);
  }) || !_fails(function () {
    new $ArrayBuffer(-1); // eslint-disable-line no-new
  }) || _fails(function () {
    new $ArrayBuffer(); // eslint-disable-line no-new
    new $ArrayBuffer(1.5); // eslint-disable-line no-new
    new $ArrayBuffer(NaN); // eslint-disable-line no-new
    return $ArrayBuffer.name != ARRAY_BUFFER;
  })) {
    $ArrayBuffer = function ArrayBuffer(length) {
      _anInstance(this, $ArrayBuffer);
      return new BaseBuffer(_toIndex(length));
    };
    var ArrayBufferProto = $ArrayBuffer[PROTOTYPE] = BaseBuffer[PROTOTYPE];
    for (var keys = gOPN(BaseBuffer), j = 0, key; keys.length > j;) {
      if (!((key = keys[j++]) in $ArrayBuffer)) _hide($ArrayBuffer, key, BaseBuffer[key]);
    }
    if (!_library) ArrayBufferProto.constructor = $ArrayBuffer;
  }
  // iOS Safari 7.x bug
  var view = new $DataView(new $ArrayBuffer(2));
  var $setInt8 = $DataView[PROTOTYPE].setInt8;
  view.setInt8(0, 2147483648);
  view.setInt8(1, 2147483649);
  if (view.getInt8(0) || !view.getInt8(1)) _redefineAll($DataView[PROTOTYPE], {
    setInt8: function setInt8(byteOffset, value) {
      $setInt8.call(this, byteOffset, value << 24 >> 24);
    },
    setUint8: function setUint8(byteOffset, value) {
      $setInt8.call(this, byteOffset, value << 24 >> 24);
    }
  }, true);
}
_setToStringTag($ArrayBuffer, ARRAY_BUFFER);
_setToStringTag($DataView, DATA_VIEW);
_hide($DataView[PROTOTYPE], _typed.VIEW, true);
exports[ARRAY_BUFFER] = $ArrayBuffer;
exports[DATA_VIEW] = $DataView;
});

// 7.3.20 SpeciesConstructor(O, defaultConstructor)


var SPECIES$2 = _wks('species');
var _speciesConstructor = function (O, D) {
  var C = _anObject(O).constructor;
  var S;
  return C === undefined || (S = _anObject(C)[SPECIES$2]) == undefined ? D : _aFunction(S);
};

'use strict';







var ArrayBuffer$1 = _global.ArrayBuffer;

var $ArrayBuffer = _typedBuffer.ArrayBuffer;
var $DataView = _typedBuffer.DataView;
var $isView = _typed.ABV && ArrayBuffer$1.isView;
var $slice = $ArrayBuffer.prototype.slice;
var VIEW = _typed.VIEW;
var ARRAY_BUFFER = 'ArrayBuffer';

_export(_export.G + _export.W + _export.F * (ArrayBuffer$1 !== $ArrayBuffer), { ArrayBuffer: $ArrayBuffer });

_export(_export.S + _export.F * !_typed.CONSTR, ARRAY_BUFFER, {
  // 24.1.3.1 ArrayBuffer.isView(arg)
  isView: function isView(it) {
    return $isView && $isView(it) || _isObject(it) && VIEW in it;
  }
});

_export(_export.P + _export.U + _export.F * _fails(function () {
  return !new $ArrayBuffer(2).slice(1, undefined).byteLength;
}), ARRAY_BUFFER, {
  // 24.1.4.3 ArrayBuffer.prototype.slice(start, end)
  slice: function slice(start, end) {
    if ($slice !== undefined && end === undefined) return $slice.call(_anObject(this), start); // FF fix
    var len = _anObject(this).byteLength;
    var first = _toAbsoluteIndex(start, len);
    var final = _toAbsoluteIndex(end === undefined ? len : end, len);
    var result = new (_speciesConstructor(this, $ArrayBuffer))(_toLength(final - first));
    var viewS = new $DataView(this);
    var viewT = new $DataView(result);
    var index = 0;
    while (first < final) {
      viewT.setUint8(index++, viewS.getUint8(first++));
    } return result;
  }
});

_setSpecies(ARRAY_BUFFER);

_export(_export.G + _export.W + _export.F * !_typed.ABV, {
  DataView: _typedBuffer.DataView
});

var _typedArray = createCommonjsModule(function (module) {
'use strict';
if (_descriptors) {
  var LIBRARY = _library;
  var global = _global;
  var fails = _fails;
  var $export = _export;
  var $typed = _typed;
  var $buffer = _typedBuffer;
  var ctx = _ctx;
  var anInstance = _anInstance;
  var propertyDesc = _propertyDesc;
  var hide = _hide;
  var redefineAll = _redefineAll;
  var toInteger = _toInteger;
  var toLength = _toLength;
  var toIndex = _toIndex;
  var toAbsoluteIndex = _toAbsoluteIndex;
  var toPrimitive = _toPrimitive;
  var has = _has;
  var classof = _classof;
  var isObject = _isObject;
  var toObject = _toObject;
  var isArrayIter = _isArrayIter;
  var create = _objectCreate;
  var getPrototypeOf = _objectGpo;
  var gOPN = _objectGopn.f;
  var getIterFn = core_getIteratorMethod;
  var uid = _uid;
  var wks = _wks;
  var createArrayMethod = _arrayMethods;
  var createArrayIncludes = _arrayIncludes;
  var speciesConstructor = _speciesConstructor;
  var ArrayIterators = es6_array_iterator;
  var Iterators = _iterators;
  var $iterDetect = _iterDetect;
  var setSpecies = _setSpecies;
  var arrayFill = _arrayFill;
  var arrayCopyWithin = _arrayCopyWithin;
  var $DP = _objectDp;
  var $GOPD = _objectGopd;
  var dP = $DP.f;
  var gOPD = $GOPD.f;
  var RangeError = global.RangeError;
  var TypeError = global.TypeError;
  var Uint8Array = global.Uint8Array;
  var ARRAY_BUFFER = 'ArrayBuffer';
  var SHARED_BUFFER = 'Shared' + ARRAY_BUFFER;
  var BYTES_PER_ELEMENT = 'BYTES_PER_ELEMENT';
  var PROTOTYPE = 'prototype';
  var ArrayProto = Array[PROTOTYPE];
  var $ArrayBuffer = $buffer.ArrayBuffer;
  var $DataView = $buffer.DataView;
  var arrayForEach = createArrayMethod(0);
  var arrayFilter = createArrayMethod(2);
  var arraySome = createArrayMethod(3);
  var arrayEvery = createArrayMethod(4);
  var arrayFind = createArrayMethod(5);
  var arrayFindIndex = createArrayMethod(6);
  var arrayIncludes = createArrayIncludes(true);
  var arrayIndexOf = createArrayIncludes(false);
  var arrayValues = ArrayIterators.values;
  var arrayKeys = ArrayIterators.keys;
  var arrayEntries = ArrayIterators.entries;
  var arrayLastIndexOf = ArrayProto.lastIndexOf;
  var arrayReduce = ArrayProto.reduce;
  var arrayReduceRight = ArrayProto.reduceRight;
  var arrayJoin = ArrayProto.join;
  var arraySort = ArrayProto.sort;
  var arraySlice = ArrayProto.slice;
  var arrayToString = ArrayProto.toString;
  var arrayToLocaleString = ArrayProto.toLocaleString;
  var ITERATOR = wks('iterator');
  var TAG = wks('toStringTag');
  var TYPED_CONSTRUCTOR = uid('typed_constructor');
  var DEF_CONSTRUCTOR = uid('def_constructor');
  var ALL_CONSTRUCTORS = $typed.CONSTR;
  var TYPED_ARRAY = $typed.TYPED;
  var VIEW = $typed.VIEW;
  var WRONG_LENGTH = 'Wrong length!';

  var $map = createArrayMethod(1, function (O, length) {
    return allocate(speciesConstructor(O, O[DEF_CONSTRUCTOR]), length);
  });

  var LITTLE_ENDIAN = fails(function () {
    // eslint-disable-next-line no-undef
    return new Uint8Array(new Uint16Array([1]).buffer)[0] === 1;
  });

  var FORCED_SET = !!Uint8Array && !!Uint8Array[PROTOTYPE].set && fails(function () {
    new Uint8Array(1).set({});
  });

  var toOffset = function (it, BYTES) {
    var offset = toInteger(it);
    if (offset < 0 || offset % BYTES) throw RangeError('Wrong offset!');
    return offset;
  };

  var validate = function (it) {
    if (isObject(it) && TYPED_ARRAY in it) return it;
    throw TypeError(it + ' is not a typed array!');
  };

  var allocate = function (C, length) {
    if (!(isObject(C) && TYPED_CONSTRUCTOR in C)) {
      throw TypeError('It is not a typed array constructor!');
    } return new C(length);
  };

  var speciesFromList = function (O, list) {
    return fromList(speciesConstructor(O, O[DEF_CONSTRUCTOR]), list);
  };

  var fromList = function (C, list) {
    var index = 0;
    var length = list.length;
    var result = allocate(C, length);
    while (length > index) result[index] = list[index++];
    return result;
  };

  var addGetter = function (it, key, internal) {
    dP(it, key, { get: function () { return this._d[internal]; } });
  };

  var $from = function from(source /* , mapfn, thisArg */) {
    var O = toObject(source);
    var aLen = arguments.length;
    var mapfn = aLen > 1 ? arguments[1] : undefined;
    var mapping = mapfn !== undefined;
    var iterFn = getIterFn(O);
    var i, length, values, result, step, iterator;
    if (iterFn != undefined && !isArrayIter(iterFn)) {
      for (iterator = iterFn.call(O), values = [], i = 0; !(step = iterator.next()).done; i++) {
        values.push(step.value);
      } O = values;
    }
    if (mapping && aLen > 2) mapfn = ctx(mapfn, arguments[2], 2);
    for (i = 0, length = toLength(O.length), result = allocate(this, length); length > i; i++) {
      result[i] = mapping ? mapfn(O[i], i) : O[i];
    }
    return result;
  };

  var $of = function of(/* ...items */) {
    var index = 0;
    var length = arguments.length;
    var result = allocate(this, length);
    while (length > index) result[index] = arguments[index++];
    return result;
  };

  // iOS Safari 6.x fails here
  var TO_LOCALE_BUG = !!Uint8Array && fails(function () { arrayToLocaleString.call(new Uint8Array(1)); });

  var $toLocaleString = function toLocaleString() {
    return arrayToLocaleString.apply(TO_LOCALE_BUG ? arraySlice.call(validate(this)) : validate(this), arguments);
  };

  var proto = {
    copyWithin: function copyWithin(target, start /* , end */) {
      return arrayCopyWithin.call(validate(this), target, start, arguments.length > 2 ? arguments[2] : undefined);
    },
    every: function every(callbackfn /* , thisArg */) {
      return arrayEvery(validate(this), callbackfn, arguments.length > 1 ? arguments[1] : undefined);
    },
    fill: function fill(value /* , start, end */) { // eslint-disable-line no-unused-vars
      return arrayFill.apply(validate(this), arguments);
    },
    filter: function filter(callbackfn /* , thisArg */) {
      return speciesFromList(this, arrayFilter(validate(this), callbackfn,
        arguments.length > 1 ? arguments[1] : undefined));
    },
    find: function find(predicate /* , thisArg */) {
      return arrayFind(validate(this), predicate, arguments.length > 1 ? arguments[1] : undefined);
    },
    findIndex: function findIndex(predicate /* , thisArg */) {
      return arrayFindIndex(validate(this), predicate, arguments.length > 1 ? arguments[1] : undefined);
    },
    forEach: function forEach(callbackfn /* , thisArg */) {
      arrayForEach(validate(this), callbackfn, arguments.length > 1 ? arguments[1] : undefined);
    },
    indexOf: function indexOf(searchElement /* , fromIndex */) {
      return arrayIndexOf(validate(this), searchElement, arguments.length > 1 ? arguments[1] : undefined);
    },
    includes: function includes(searchElement /* , fromIndex */) {
      return arrayIncludes(validate(this), searchElement, arguments.length > 1 ? arguments[1] : undefined);
    },
    join: function join(separator) { // eslint-disable-line no-unused-vars
      return arrayJoin.apply(validate(this), arguments);
    },
    lastIndexOf: function lastIndexOf(searchElement /* , fromIndex */) { // eslint-disable-line no-unused-vars
      return arrayLastIndexOf.apply(validate(this), arguments);
    },
    map: function map(mapfn /* , thisArg */) {
      return $map(validate(this), mapfn, arguments.length > 1 ? arguments[1] : undefined);
    },
    reduce: function reduce(callbackfn /* , initialValue */) { // eslint-disable-line no-unused-vars
      return arrayReduce.apply(validate(this), arguments);
    },
    reduceRight: function reduceRight(callbackfn /* , initialValue */) { // eslint-disable-line no-unused-vars
      return arrayReduceRight.apply(validate(this), arguments);
    },
    reverse: function reverse() {
      var that = this;
      var length = validate(that).length;
      var middle = Math.floor(length / 2);
      var index = 0;
      var value;
      while (index < middle) {
        value = that[index];
        that[index++] = that[--length];
        that[length] = value;
      } return that;
    },
    some: function some(callbackfn /* , thisArg */) {
      return arraySome(validate(this), callbackfn, arguments.length > 1 ? arguments[1] : undefined);
    },
    sort: function sort(comparefn) {
      return arraySort.call(validate(this), comparefn);
    },
    subarray: function subarray(begin, end) {
      var O = validate(this);
      var length = O.length;
      var $begin = toAbsoluteIndex(begin, length);
      return new (speciesConstructor(O, O[DEF_CONSTRUCTOR]))(
        O.buffer,
        O.byteOffset + $begin * O.BYTES_PER_ELEMENT,
        toLength((end === undefined ? length : toAbsoluteIndex(end, length)) - $begin)
      );
    }
  };

  var $slice = function slice(start, end) {
    return speciesFromList(this, arraySlice.call(validate(this), start, end));
  };

  var $set = function set(arrayLike /* , offset */) {
    validate(this);
    var offset = toOffset(arguments[1], 1);
    var length = this.length;
    var src = toObject(arrayLike);
    var len = toLength(src.length);
    var index = 0;
    if (len + offset > length) throw RangeError(WRONG_LENGTH);
    while (index < len) this[offset + index] = src[index++];
  };

  var $iterators = {
    entries: function entries() {
      return arrayEntries.call(validate(this));
    },
    keys: function keys() {
      return arrayKeys.call(validate(this));
    },
    values: function values() {
      return arrayValues.call(validate(this));
    }
  };

  var isTAIndex = function (target, key) {
    return isObject(target)
      && target[TYPED_ARRAY]
      && typeof key != 'symbol'
      && key in target
      && String(+key) == String(key);
  };
  var $getDesc = function getOwnPropertyDescriptor(target, key) {
    return isTAIndex(target, key = toPrimitive(key, true))
      ? propertyDesc(2, target[key])
      : gOPD(target, key);
  };
  var $setDesc = function defineProperty(target, key, desc) {
    if (isTAIndex(target, key = toPrimitive(key, true))
      && isObject(desc)
      && has(desc, 'value')
      && !has(desc, 'get')
      && !has(desc, 'set')
      // TODO: add validation descriptor w/o calling accessors
      && !desc.configurable
      && (!has(desc, 'writable') || desc.writable)
      && (!has(desc, 'enumerable') || desc.enumerable)
    ) {
      target[key] = desc.value;
      return target;
    } return dP(target, key, desc);
  };

  if (!ALL_CONSTRUCTORS) {
    $GOPD.f = $getDesc;
    $DP.f = $setDesc;
  }

  $export($export.S + $export.F * !ALL_CONSTRUCTORS, 'Object', {
    getOwnPropertyDescriptor: $getDesc,
    defineProperty: $setDesc
  });

  if (fails(function () { arrayToString.call({}); })) {
    arrayToString = arrayToLocaleString = function toString() {
      return arrayJoin.call(this);
    };
  }

  var $TypedArrayPrototype$ = redefineAll({}, proto);
  redefineAll($TypedArrayPrototype$, $iterators);
  hide($TypedArrayPrototype$, ITERATOR, $iterators.values);
  redefineAll($TypedArrayPrototype$, {
    slice: $slice,
    set: $set,
    constructor: function () { /* noop */ },
    toString: arrayToString,
    toLocaleString: $toLocaleString
  });
  addGetter($TypedArrayPrototype$, 'buffer', 'b');
  addGetter($TypedArrayPrototype$, 'byteOffset', 'o');
  addGetter($TypedArrayPrototype$, 'byteLength', 'l');
  addGetter($TypedArrayPrototype$, 'length', 'e');
  dP($TypedArrayPrototype$, TAG, {
    get: function () { return this[TYPED_ARRAY]; }
  });

  // eslint-disable-next-line max-statements
  module.exports = function (KEY, BYTES, wrapper, CLAMPED) {
    CLAMPED = !!CLAMPED;
    var NAME = KEY + (CLAMPED ? 'Clamped' : '') + 'Array';
    var GETTER = 'get' + KEY;
    var SETTER = 'set' + KEY;
    var TypedArray = global[NAME];
    var Base = TypedArray || {};
    var TAC = TypedArray && getPrototypeOf(TypedArray);
    var FORCED = !TypedArray || !$typed.ABV;
    var O = {};
    var TypedArrayPrototype = TypedArray && TypedArray[PROTOTYPE];
    var getter = function (that, index) {
      var data = that._d;
      return data.v[GETTER](index * BYTES + data.o, LITTLE_ENDIAN);
    };
    var setter = function (that, index, value) {
      var data = that._d;
      if (CLAMPED) value = (value = Math.round(value)) < 0 ? 0 : value > 0xff ? 0xff : value & 0xff;
      data.v[SETTER](index * BYTES + data.o, value, LITTLE_ENDIAN);
    };
    var addElement = function (that, index) {
      dP(that, index, {
        get: function () {
          return getter(this, index);
        },
        set: function (value) {
          return setter(this, index, value);
        },
        enumerable: true
      });
    };
    if (FORCED) {
      TypedArray = wrapper(function (that, data, $offset, $length) {
        anInstance(that, TypedArray, NAME, '_d');
        var index = 0;
        var offset = 0;
        var buffer, byteLength, length, klass;
        if (!isObject(data)) {
          length = toIndex(data);
          byteLength = length * BYTES;
          buffer = new $ArrayBuffer(byteLength);
        } else if (data instanceof $ArrayBuffer || (klass = classof(data)) == ARRAY_BUFFER || klass == SHARED_BUFFER) {
          buffer = data;
          offset = toOffset($offset, BYTES);
          var $len = data.byteLength;
          if ($length === undefined) {
            if ($len % BYTES) throw RangeError(WRONG_LENGTH);
            byteLength = $len - offset;
            if (byteLength < 0) throw RangeError(WRONG_LENGTH);
          } else {
            byteLength = toLength($length) * BYTES;
            if (byteLength + offset > $len) throw RangeError(WRONG_LENGTH);
          }
          length = byteLength / BYTES;
        } else if (TYPED_ARRAY in data) {
          return fromList(TypedArray, data);
        } else {
          return $from.call(TypedArray, data);
        }
        hide(that, '_d', {
          b: buffer,
          o: offset,
          l: byteLength,
          e: length,
          v: new $DataView(buffer)
        });
        while (index < length) addElement(that, index++);
      });
      TypedArrayPrototype = TypedArray[PROTOTYPE] = create($TypedArrayPrototype$);
      hide(TypedArrayPrototype, 'constructor', TypedArray);
    } else if (!fails(function () {
      TypedArray(1);
    }) || !fails(function () {
      new TypedArray(-1); // eslint-disable-line no-new
    }) || !$iterDetect(function (iter) {
      new TypedArray(); // eslint-disable-line no-new
      new TypedArray(null); // eslint-disable-line no-new
      new TypedArray(1.5); // eslint-disable-line no-new
      new TypedArray(iter); // eslint-disable-line no-new
    }, true)) {
      TypedArray = wrapper(function (that, data, $offset, $length) {
        anInstance(that, TypedArray, NAME);
        var klass;
        // `ws` module bug, temporarily remove validation length for Uint8Array
        // https://github.com/websockets/ws/pull/645
        if (!isObject(data)) return new Base(toIndex(data));
        if (data instanceof $ArrayBuffer || (klass = classof(data)) == ARRAY_BUFFER || klass == SHARED_BUFFER) {
          return $length !== undefined
            ? new Base(data, toOffset($offset, BYTES), $length)
            : $offset !== undefined
              ? new Base(data, toOffset($offset, BYTES))
              : new Base(data);
        }
        if (TYPED_ARRAY in data) return fromList(TypedArray, data);
        return $from.call(TypedArray, data);
      });
      arrayForEach(TAC !== Function.prototype ? gOPN(Base).concat(gOPN(TAC)) : gOPN(Base), function (key) {
        if (!(key in TypedArray)) hide(TypedArray, key, Base[key]);
      });
      TypedArray[PROTOTYPE] = TypedArrayPrototype;
      if (!LIBRARY) TypedArrayPrototype.constructor = TypedArray;
    }
    var $nativeIterator = TypedArrayPrototype[ITERATOR];
    var CORRECT_ITER_NAME = !!$nativeIterator
      && ($nativeIterator.name == 'values' || $nativeIterator.name == undefined);
    var $iterator = $iterators.values;
    hide(TypedArray, TYPED_CONSTRUCTOR, true);
    hide(TypedArrayPrototype, TYPED_ARRAY, NAME);
    hide(TypedArrayPrototype, VIEW, true);
    hide(TypedArrayPrototype, DEF_CONSTRUCTOR, TypedArray);

    if (CLAMPED ? new TypedArray(1)[TAG] != NAME : !(TAG in TypedArrayPrototype)) {
      dP(TypedArrayPrototype, TAG, {
        get: function () { return NAME; }
      });
    }

    O[NAME] = TypedArray;

    $export($export.G + $export.W + $export.F * (TypedArray != Base), O);

    $export($export.S, NAME, {
      BYTES_PER_ELEMENT: BYTES
    });

    $export($export.S + $export.F * fails(function () { Base.of.call(TypedArray, 1); }), NAME, {
      from: $from,
      of: $of
    });

    if (!(BYTES_PER_ELEMENT in TypedArrayPrototype)) hide(TypedArrayPrototype, BYTES_PER_ELEMENT, BYTES);

    $export($export.P, NAME, proto);

    setSpecies(NAME);

    $export($export.P + $export.F * FORCED_SET, NAME, { set: $set });

    $export($export.P + $export.F * !CORRECT_ITER_NAME, NAME, $iterators);

    if (!LIBRARY && TypedArrayPrototype.toString != arrayToString) TypedArrayPrototype.toString = arrayToString;

    $export($export.P + $export.F * fails(function () {
      new TypedArray(1).slice();
    }), NAME, { slice: $slice });

    $export($export.P + $export.F * (fails(function () {
      return [1, 2].toLocaleString() != new TypedArray([1, 2]).toLocaleString();
    }) || !fails(function () {
      TypedArrayPrototype.toLocaleString.call([1, 2]);
    })), NAME, { toLocaleString: $toLocaleString });

    Iterators[NAME] = CORRECT_ITER_NAME ? $nativeIterator : $iterator;
    if (!LIBRARY && !CORRECT_ITER_NAME) hide(TypedArrayPrototype, ITERATOR, $iterator);
  };
} else module.exports = function () { /* empty */ };
});

_typedArray('Int8', 1, function (init) {
  return function Int8Array(data, byteOffset, length) {
    return init(this, data, byteOffset, length);
  };
});

_typedArray('Uint8', 1, function (init) {
  return function Uint8Array(data, byteOffset, length) {
    return init(this, data, byteOffset, length);
  };
});

_typedArray('Uint8', 1, function (init) {
  return function Uint8ClampedArray(data, byteOffset, length) {
    return init(this, data, byteOffset, length);
  };
}, true);

_typedArray('Int16', 2, function (init) {
  return function Int16Array(data, byteOffset, length) {
    return init(this, data, byteOffset, length);
  };
});

_typedArray('Uint16', 2, function (init) {
  return function Uint16Array(data, byteOffset, length) {
    return init(this, data, byteOffset, length);
  };
});

_typedArray('Int32', 4, function (init) {
  return function Int32Array(data, byteOffset, length) {
    return init(this, data, byteOffset, length);
  };
});

_typedArray('Uint32', 4, function (init) {
  return function Uint32Array(data, byteOffset, length) {
    return init(this, data, byteOffset, length);
  };
});

_typedArray('Float32', 4, function (init) {
  return function Float32Array(data, byteOffset, length) {
    return init(this, data, byteOffset, length);
  };
});

_typedArray('Float64', 8, function (init) {
  return function Float64Array(data, byteOffset, length) {
    return init(this, data, byteOffset, length);
  };
});

// 20.2.2.20 Math.log1p(x)
var _mathLog1p = Math.log1p || function log1p(x) {
  return (x = +x) > -1e-8 && x < 1e-8 ? x - x * x / 2 : Math.log(1 + x);
};

// 20.2.2.3 Math.acosh(x)


var sqrt = Math.sqrt;
var $acosh = Math.acosh;

_export(_export.S + _export.F * !($acosh
  // V8 bug: https://code.google.com/p/v8/issues/detail?id=3509
  && Math.floor($acosh(Number.MAX_VALUE)) == 710
  // Tor Browser bug: Math.acosh(Infinity) -> NaN
  && $acosh(Infinity) == Infinity
), 'Math', {
  acosh: function acosh(x) {
    return (x = +x) < 1 ? NaN : x > 94906265.62425156
      ? Math.log(x) + Math.LN2
      : _mathLog1p(x - 1 + sqrt(x - 1) * sqrt(x + 1));
  }
});

// 20.2.2.5 Math.asinh(x)

var $asinh = Math.asinh;

function asinh(x) {
  return !isFinite(x = +x) || x == 0 ? x : x < 0 ? -asinh(-x) : Math.log(x + Math.sqrt(x * x + 1));
}

// Tor Browser bug: Math.asinh(0) -> -0
_export(_export.S + _export.F * !($asinh && 1 / $asinh(0) > 0), 'Math', { asinh: asinh });

// 20.2.2.7 Math.atanh(x)

var $atanh = Math.atanh;

// Tor Browser bug: Math.atanh(-0) -> 0
_export(_export.S + _export.F * !($atanh && 1 / $atanh(-0) < 0), 'Math', {
  atanh: function atanh(x) {
    return (x = +x) == 0 ? x : Math.log((1 + x) / (1 - x)) / 2;
  }
});

// 20.2.2.28 Math.sign(x)
var _mathSign = Math.sign || function sign(x) {
  // eslint-disable-next-line no-self-compare
  return (x = +x) == 0 || x != x ? x : x < 0 ? -1 : 1;
};

// 20.2.2.9 Math.cbrt(x)



_export(_export.S, 'Math', {
  cbrt: function cbrt(x) {
    return _mathSign(x = +x) * Math.pow(Math.abs(x), 1 / 3);
  }
});

// 20.2.2.11 Math.clz32(x)


_export(_export.S, 'Math', {
  clz32: function clz32(x) {
    return (x >>>= 0) ? 31 - Math.floor(Math.log(x + 0.5) * Math.LOG2E) : 32;
  }
});

// 20.2.2.12 Math.cosh(x)

var exp = Math.exp;

_export(_export.S, 'Math', {
  cosh: function cosh(x) {
    return (exp(x = +x) + exp(-x)) / 2;
  }
});

// 20.2.2.14 Math.expm1(x)
var $expm1 = Math.expm1;
var _mathExpm1 = (!$expm1
  // Old FF bug
  || $expm1(10) > 22025.465794806719 || $expm1(10) < 22025.4657948067165168
  // Tor Browser bug
  || $expm1(-2e-17) != -2e-17
) ? function expm1(x) {
  return (x = +x) == 0 ? x : x > -1e-6 && x < 1e-6 ? x + x * x / 2 : Math.exp(x) - 1;
} : $expm1;

// 20.2.2.14 Math.expm1(x)



_export(_export.S + _export.F * (_mathExpm1 != Math.expm1), 'Math', { expm1: _mathExpm1 });

// 20.2.2.16 Math.fround(x)

var pow = Math.pow;
var EPSILON = pow(2, -52);
var EPSILON32 = pow(2, -23);
var MAX32 = pow(2, 127) * (2 - EPSILON32);
var MIN32 = pow(2, -126);

var roundTiesToEven = function (n) {
  return n + 1 / EPSILON - 1 / EPSILON;
};

var _mathFround = Math.fround || function fround(x) {
  var $abs = Math.abs(x);
  var $sign = _mathSign(x);
  var a, result;
  if ($abs < MIN32) return $sign * roundTiesToEven($abs / MIN32 / EPSILON32) * MIN32 * EPSILON32;
  a = (1 + EPSILON32 / EPSILON) * $abs;
  result = a - (a - $abs);
  // eslint-disable-next-line no-self-compare
  if (result > MAX32 || result != result) return $sign * Infinity;
  return $sign * result;
};

// 20.2.2.16 Math.fround(x)


_export(_export.S, 'Math', { fround: _mathFround });

// 20.2.2.17 Math.hypot([value1[, value2[,  ]]])

var abs = Math.abs;

_export(_export.S, 'Math', {
  hypot: function hypot(value1, value2) { // eslint-disable-line no-unused-vars
    var sum = 0;
    var i = 0;
    var aLen = arguments.length;
    var larg = 0;
    var arg, div;
    while (i < aLen) {
      arg = abs(arguments[i++]);
      if (larg < arg) {
        div = larg / arg;
        sum = sum * div * div + 1;
        larg = arg;
      } else if (arg > 0) {
        div = arg / larg;
        sum += div * div;
      } else sum += arg;
    }
    return larg === Infinity ? Infinity : larg * Math.sqrt(sum);
  }
});

// 20.2.2.18 Math.imul(x, y)

var $imul = Math.imul;

// some WebKit versions fails with big numbers, some has wrong arity
_export(_export.S + _export.F * _fails(function () {
  return $imul(0xffffffff, 5) != -5 || $imul.length != 2;
}), 'Math', {
  imul: function imul(x, y) {
    var UINT16 = 0xffff;
    var xn = +x;
    var yn = +y;
    var xl = UINT16 & xn;
    var yl = UINT16 & yn;
    return 0 | xl * yl + ((UINT16 & xn >>> 16) * yl + xl * (UINT16 & yn >>> 16) << 16 >>> 0);
  }
});

// 20.2.2.21 Math.log10(x)


_export(_export.S, 'Math', {
  log10: function log10(x) {
    return Math.log(x) * Math.LOG10E;
  }
});

// 20.2.2.20 Math.log1p(x)


_export(_export.S, 'Math', { log1p: _mathLog1p });

// 20.2.2.22 Math.log2(x)


_export(_export.S, 'Math', {
  log2: function log2(x) {
    return Math.log(x) / Math.LN2;
  }
});

// 20.2.2.28 Math.sign(x)


_export(_export.S, 'Math', { sign: _mathSign });

// 20.2.2.30 Math.sinh(x)


var exp$1 = Math.exp;

// V8 near Chromium 38 has a problem with very small numbers
_export(_export.S + _export.F * _fails(function () {
  return !Math.sinh(-2e-17) != -2e-17;
}), 'Math', {
  sinh: function sinh(x) {
    return Math.abs(x = +x) < 1
      ? (_mathExpm1(x) - _mathExpm1(-x)) / 2
      : (exp$1(x - 1) - exp$1(-x - 1)) * (Math.E / 2);
  }
});

// 20.2.2.33 Math.tanh(x)


var exp$2 = Math.exp;

_export(_export.S, 'Math', {
  tanh: function tanh(x) {
    var a = _mathExpm1(x = +x);
    var b = _mathExpm1(-x);
    return a == Infinity ? 1 : b == Infinity ? -1 : (a - b) / (exp$2(x) + exp$2(-x));
  }
});

// 20.2.2.34 Math.trunc(x)


_export(_export.S, 'Math', {
  trunc: function trunc(it) {
    return (it > 0 ? Math.floor : Math.ceil)(it);
  }
});

// Works with __proto__ only. Old v8 can't work with null proto objects.
/* eslint-disable no-proto */


var check = function (O, proto) {
  _anObject(O);
  if (!_isObject(proto) && proto !== null) throw TypeError(proto + ": can't set as prototype!");
};
var _setProto = {
  set: Object.setPrototypeOf || ('__proto__' in {} ? // eslint-disable-line
    function (test, buggy, set) {
      try {
        set = _ctx(Function.call, _objectGopd.f(Object.prototype, '__proto__').set, 2);
        set(test, []);
        buggy = !(test instanceof Array);
      } catch (e) { buggy = true; }
      return function setPrototypeOf(O, proto) {
        check(O, proto);
        if (buggy) O.__proto__ = proto;
        else set(O, proto);
        return O;
      };
    }({}, false) : undefined),
  check: check
};

var setPrototypeOf = _setProto.set;
var _inheritIfRequired = function (that, target, C) {
  var S = target.constructor;
  var P;
  if (S !== C && typeof S == 'function' && (P = S.prototype) !== C.prototype && _isObject(P) && setPrototypeOf) {
    setPrototypeOf(that, P);
  } return that;
};

var _stringWs = '\x09\x0A\x0B\x0C\x0D\x20\xA0\u1680\u180E\u2000\u2001\u2002\u2003' +
  '\u2004\u2005\u2006\u2007\u2008\u2009\u200A\u202F\u205F\u3000\u2028\u2029\uFEFF';

var space = '[' + _stringWs + ']';
var non = '\u200b\u0085';
var ltrim = RegExp('^' + space + space + '*');
var rtrim = RegExp(space + space + '*$');

var exporter = function (KEY, exec, ALIAS) {
  var exp = {};
  var FORCE = _fails(function () {
    return !!_stringWs[KEY]() || non[KEY]() != non;
  });
  var fn = exp[KEY] = FORCE ? exec(trim) : _stringWs[KEY];
  if (ALIAS) exp[ALIAS] = fn;
  _export(_export.P + _export.F * FORCE, 'String', exp);
};

// 1 -> String#trimLeft
// 2 -> String#trimRight
// 3 -> String#trim
var trim = exporter.trim = function (string, TYPE) {
  string = String(_defined(string));
  if (TYPE & 1) string = string.replace(ltrim, '');
  if (TYPE & 2) string = string.replace(rtrim, '');
  return string;
};

var _stringTrim = exporter;

'use strict';






var gOPN$2 = _objectGopn.f;
var gOPD$2 = _objectGopd.f;
var dP$2 = _objectDp.f;
var $trim = _stringTrim.trim;
var NUMBER = 'Number';
var $Number = _global[NUMBER];
var Base = $Number;
var proto = $Number.prototype;
// Opera ~12 has broken Object#toString
var BROKEN_COF = _cof(_objectCreate(proto)) == NUMBER;
var TRIM = 'trim' in String.prototype;

// 7.1.3 ToNumber(argument)
var toNumber = function (argument) {
  var it = _toPrimitive(argument, false);
  if (typeof it == 'string' && it.length > 2) {
    it = TRIM ? it.trim() : $trim(it, 3);
    var first = it.charCodeAt(0);
    var third, radix, maxCode;
    if (first === 43 || first === 45) {
      third = it.charCodeAt(2);
      if (third === 88 || third === 120) return NaN; // Number('+0x1') should be NaN, old V8 fix
    } else if (first === 48) {
      switch (it.charCodeAt(1)) {
        case 66: case 98: radix = 2; maxCode = 49; break; // fast equal /^0b[01]+$/i
        case 79: case 111: radix = 8; maxCode = 55; break; // fast equal /^0o[0-7]+$/i
        default: return +it;
      }
      for (var digits = it.slice(2), i = 0, l = digits.length, code; i < l; i++) {
        code = digits.charCodeAt(i);
        // parseInt parses a string to a first unavailable symbol
        // but ToNumber should return NaN if a string contains unavailable symbols
        if (code < 48 || code > maxCode) return NaN;
      } return parseInt(digits, radix);
    }
  } return +it;
};

if (!$Number(' 0o1') || !$Number('0b1') || $Number('+0x1')) {
  $Number = function Number(value) {
    var it = arguments.length < 1 ? 0 : value;
    var that = this;
    return that instanceof $Number
      // check on 1..constructor(foo) case
      && (BROKEN_COF ? _fails(function () { proto.valueOf.call(that); }) : _cof(that) != NUMBER)
        ? _inheritIfRequired(new Base(toNumber(it)), that, $Number) : toNumber(it);
  };
  for (var keys = _descriptors ? gOPN$2(Base) : (
    // ES3:
    'MAX_VALUE,MIN_VALUE,NaN,NEGATIVE_INFINITY,POSITIVE_INFINITY,' +
    // ES6 (in case, if modules with ES6 Number statics required before):
    'EPSILON,isFinite,isInteger,isNaN,isSafeInteger,MAX_SAFE_INTEGER,' +
    'MIN_SAFE_INTEGER,parseFloat,parseInt,isInteger'
  ).split(','), j$1 = 0, key; keys.length > j$1; j$1++) {
    if (_has(Base, key = keys[j$1]) && !_has($Number, key)) {
      dP$2($Number, key, gOPD$2(Base, key));
    }
  }
  $Number.prototype = proto;
  proto.constructor = $Number;
  _redefine(_global, NUMBER, $Number);
}

var _aNumberValue = function (it, msg) {
  if (typeof it != 'number' && _cof(it) != 'Number') throw TypeError(msg);
  return +it;
};

'use strict';



var _stringRepeat = function repeat(count) {
  var str = String(_defined(this));
  var res = '';
  var n = _toInteger(count);
  if (n < 0 || n == Infinity) throw RangeError("Count can't be negative");
  for (;n > 0; (n >>>= 1) && (str += str)) if (n & 1) res += str;
  return res;
};

'use strict';




var $toFixed = 1.0.toFixed;
var floor$1 = Math.floor;
var data = [0, 0, 0, 0, 0, 0];
var ERROR = 'Number.toFixed: incorrect invocation!';
var ZERO = '0';

var multiply = function (n, c) {
  var i = -1;
  var c2 = c;
  while (++i < 6) {
    c2 += n * data[i];
    data[i] = c2 % 1e7;
    c2 = floor$1(c2 / 1e7);
  }
};
var divide = function (n) {
  var i = 6;
  var c = 0;
  while (--i >= 0) {
    c += data[i];
    data[i] = floor$1(c / n);
    c = (c % n) * 1e7;
  }
};
var numToString = function () {
  var i = 6;
  var s = '';
  while (--i >= 0) {
    if (s !== '' || i === 0 || data[i] !== 0) {
      var t = String(data[i]);
      s = s === '' ? t : s + _stringRepeat.call(ZERO, 7 - t.length) + t;
    }
  } return s;
};
var pow$1 = function (x, n, acc) {
  return n === 0 ? acc : n % 2 === 1 ? pow$1(x, n - 1, acc * x) : pow$1(x * x, n / 2, acc);
};
var log$1 = function (x) {
  var n = 0;
  var x2 = x;
  while (x2 >= 4096) {
    n += 12;
    x2 /= 4096;
  }
  while (x2 >= 2) {
    n += 1;
    x2 /= 2;
  } return n;
};

_export(_export.P + _export.F * (!!$toFixed && (
  0.00008.toFixed(3) !== '0.000' ||
  0.9.toFixed(0) !== '1' ||
  1.255.toFixed(2) !== '1.25' ||
  1000000000000000128.0.toFixed(0) !== '1000000000000000128'
) || !_fails(function () {
  // V8 ~ Android 4.3-
  $toFixed.call({});
})), 'Number', {
  toFixed: function toFixed(fractionDigits) {
    var x = _aNumberValue(this, ERROR);
    var f = _toInteger(fractionDigits);
    var s = '';
    var m = ZERO;
    var e, z, j, k;
    if (f < 0 || f > 20) throw RangeError(ERROR);
    // eslint-disable-next-line no-self-compare
    if (x != x) return 'NaN';
    if (x <= -1e21 || x >= 1e21) return String(x);
    if (x < 0) {
      s = '-';
      x = -x;
    }
    if (x > 1e-21) {
      e = log$1(x * pow$1(2, 69, 1)) - 69;
      z = e < 0 ? x * pow$1(2, -e, 1) : x / pow$1(2, e, 1);
      z *= 0x10000000000000;
      e = 52 - e;
      if (e > 0) {
        multiply(0, z);
        j = f;
        while (j >= 7) {
          multiply(1e7, 0);
          j -= 7;
        }
        multiply(pow$1(10, j, 1), 0);
        j = e - 1;
        while (j >= 23) {
          divide(1 << 23);
          j -= 23;
        }
        divide(1 << j);
        multiply(1, 1);
        divide(2);
        m = numToString();
      } else {
        multiply(0, z);
        multiply(1 << -e, 0);
        m = numToString() + _stringRepeat.call(ZERO, f);
      }
    }
    if (f > 0) {
      k = m.length;
      m = s + (k <= f ? '0.' + _stringRepeat.call(ZERO, f - k) + m : m.slice(0, k - f) + '.' + m.slice(k - f));
    } else {
      m = s + m;
    } return m;
  }
});

'use strict';



var $toPrecision = 1.0.toPrecision;

_export(_export.P + _export.F * (_fails(function () {
  // IE7-
  return $toPrecision.call(1, undefined) !== '1';
}) || !_fails(function () {
  // V8 ~ Android 4.3-
  $toPrecision.call({});
})), 'Number', {
  toPrecision: function toPrecision(precision) {
    var that = _aNumberValue(this, 'Number#toPrecision: incorrect invocation!');
    return precision === undefined ? $toPrecision.call(that) : $toPrecision.call(that, precision);
  }
});

// 20.1.2.1 Number.EPSILON


_export(_export.S, 'Number', { EPSILON: Math.pow(2, -52) });

// 20.1.2.2 Number.isFinite(number)

var _isFinite = _global.isFinite;

_export(_export.S, 'Number', {
  isFinite: function isFinite(it) {
    return typeof it == 'number' && _isFinite(it);
  }
});

// 20.1.2.3 Number.isInteger(number)

var floor$2 = Math.floor;
var _isInteger = function isInteger(it) {
  return !_isObject(it) && isFinite(it) && floor$2(it) === it;
};

// 20.1.2.3 Number.isInteger(number)


_export(_export.S, 'Number', { isInteger: _isInteger });

// 20.1.2.4 Number.isNaN(number)


_export(_export.S, 'Number', {
  isNaN: function isNaN(number) {
    // eslint-disable-next-line no-self-compare
    return number != number;
  }
});

// 20.1.2.5 Number.isSafeInteger(number)


var abs$1 = Math.abs;

_export(_export.S, 'Number', {
  isSafeInteger: function isSafeInteger(number) {
    return _isInteger(number) && abs$1(number) <= 0x1fffffffffffff;
  }
});

// 20.1.2.6 Number.MAX_SAFE_INTEGER


_export(_export.S, 'Number', { MAX_SAFE_INTEGER: 0x1fffffffffffff });

// 20.1.2.10 Number.MIN_SAFE_INTEGER


_export(_export.S, 'Number', { MIN_SAFE_INTEGER: -0x1fffffffffffff });

var $parseFloat = _global.parseFloat;
var $trim$1 = _stringTrim.trim;

var _parseFloat = 1 / $parseFloat(_stringWs + '-0') !== -Infinity ? function parseFloat(str) {
  var string = $trim$1(String(str), 3);
  var result = $parseFloat(string);
  return result === 0 && string.charAt(0) == '-' ? -0 : result;
} : $parseFloat;

// 20.1.2.12 Number.parseFloat(string)
_export(_export.S + _export.F * (Number.parseFloat != _parseFloat), 'Number', { parseFloat: _parseFloat });

var $parseInt = _global.parseInt;
var $trim$2 = _stringTrim.trim;

var hex = /^[-+]?0[xX]/;

var _parseInt = $parseInt(_stringWs + '08') !== 8 || $parseInt(_stringWs + '0x16') !== 22 ? function parseInt(str, radix) {
  var string = $trim$2(String(str), 3);
  return $parseInt(string, (radix >>> 0) || (hex.test(string) ? 16 : 10));
} : $parseInt;

// 20.1.2.13 Number.parseInt(string, radix)
_export(_export.S + _export.F * (Number.parseInt != _parseInt), 'Number', { parseInt: _parseInt });

'use strict';
// 19.1.2.1 Object.assign(target, source, ...)





var $assign = Object.assign;

// should work with symbols and should have deterministic property order (V8 bug)
var _objectAssign = !$assign || _fails(function () {
  var A = {};
  var B = {};
  // eslint-disable-next-line no-undef
  var S = Symbol();
  var K = 'abcdefghijklmnopqrst';
  A[S] = 7;
  K.split('').forEach(function (k) { B[k] = k; });
  return $assign({}, A)[S] != 7 || Object.keys($assign({}, B)).join('') != K;
}) ? function assign(target, source) { // eslint-disable-line no-unused-vars
  var T = _toObject(target);
  var aLen = arguments.length;
  var index = 1;
  var getSymbols = _objectGops.f;
  var isEnum = _objectPie.f;
  while (aLen > index) {
    var S = _iobject(arguments[index++]);
    var keys = getSymbols ? _objectKeys(S).concat(getSymbols(S)) : _objectKeys(S);
    var length = keys.length;
    var j = 0;
    var key;
    while (length > j) if (isEnum.call(S, key = keys[j++])) T[key] = S[key];
  } return T;
} : $assign;

// 19.1.3.1 Object.assign(target, source)


_export(_export.S + _export.F, 'Object', { assign: _objectAssign });

var background_vert = "uniform vec3 color1;\nuniform vec3 color2;\nvarying vec2 vUv;\nvarying vec3 vColor;\nvoid main() {\n    if (uv.y == 0.0)\n        vColor = color2;\n    else\n        vColor = color1;\n    vUv = uv;\n    gl_Position = projectionMatrix * modelViewMatrix * vec4( position, 1.0 );\n}\n";

var background_frag = "varying vec3 vColor;\nvarying vec2 vUv;\nuniform samplerCube envMap;\nuniform vec3 uCamDir;\nuniform vec3 uCamUp;\nuniform vec2 uResolution;\nuniform float uHalfFovTan;\nuniform bool envMapBackground;\n#include<env_sample>\nconst int bloomRange = 4;\n#include<ordered_dither>\nuniform float envMapExposure;\n#if TONEMAP_OUTPUT > 0\nuniform float exposureBias;\n#include<tonemap>\n#endif\nvec3 rayDir(in vec2 vUv) {\n    vec3 A = (uResolution.x/uResolution.y)*normalize(cross(uCamDir,uCamUp)) * (uHalfFovTan * 2.0);\n    vec3 B = normalize(uCamUp) * (uHalfFovTan * 2.0);\n    vec3 C = normalize(uCamDir);\n    vec3 ray = normalize( C + (2.0*vUv.x-1.0)*A + (2.0*vUv.y-1.0)*B );\n    return ray;\n}\nvec3 getColor(in vec3 rd) {\n    return RGBMDecode(textureCube(envMap, adjustLookupVector(rd)), envMapExposure);\n}\nvoid main() {\n    vec3 rd = rayDir(vUv);\n    vec3 outColor;\n    if (envMapBackground) {\n        outColor = getColor(rd);\n#if TONEMAP_OUTPUT == 1\n        outColor = toneMapCanonOGS_WithGamma_WithColorPerserving(exposureBias * outColor);\n#elif TONEMAP_OUTPUT == 2\n        outColor = toneMapCanonFilmic_WithGamma(exposureBias * outColor);\n#endif\n    }\n    else {\n        outColor = vColor;\n    }\n    gl_FragColor = vec4(orderedDithering(outColor), 1.0);\n}\n";

var BackgroundShader = {
    uniforms: {
        "color1": { type: "v3", value: new THREE$1.Vector3(41.0 / 255.0, 76.0 / 255.0, 120.0 / 255.0) },
        "color2": { type: "v3", value: new THREE$1.Vector3(1.0 / 255.0, 2.0 / 255.0, 3.0 / 255.0) },
        //"irradianceMap": {type: "t", value: 1.0},
        "envMap": { type: "t", value: null },
        "envRotationSin": { type: "f", value: 0.0 },
        "envRotationCos": { type: "f", value: 1.0 },
        "exposureBias": { type: "f", value: 1.0 },
        "envMapExposure": { type: "f", value: 1.0 },
        "uCamDir": { type: "v3", value: new THREE$1.Vector3() },
        "uCamUp": { type: "v3", value: new THREE$1.Vector3() },
        "uResolution": { type: "v2", value: new THREE$1.Vector2(600, 400) },
        "uHalfFovTan": { type: "f", value: 0.5 },
        "envMapBackground": { type: "i", value: 0 }
    },
    vertexShader: background_vert,
    fragmentShader: background_frag
};

var pack_depth = "\nvec4 packDepth( const in float depth ) {\n    vec4 enc = vec4(1.0, 255.0, 65025.0, 160581375.0) * depth;\n    enc = fract(enc);\n    enc -= enc.yzww * vec4(1.0/255.0,1.0/255.0,1.0/255.0,0.0);\n    return enc;\n}\nfloat unpackDepth( const in vec4 rgba_depth ) {\n    return dot( rgba_depth, vec4(1.0, 1.0/255.0, 1.0/65025.0, 1.0/160581375.0) );\n}\n";

var depth_texture = "\nuniform sampler2D tDepth;\nuniform vec4 projInfo;\nuniform float isOrtho;\nuniform mat4 worldMatrix_mainPass;\nvec3 reconstructCSPosition(vec2 fragCoords, float z) {\n    return vec3((fragCoords * projInfo.xy + projInfo.zw) * mix(z, -1.0, isOrtho), z);\n}\nvec3 reconstructWorldPosition(vec2 fragCoords, vec2 screenUv) {\n    float zCam = texture2D(tDepth, screenUv).z;\n    vec3 csPos = reconstructCSPosition(fragCoords, zCam);\n    return (worldMatrix_mainPass * vec4(csPos, 1.0)).xyz;\n}\n";

var tonemap = "\nfloat luminance_post(vec3 rgb) {\n    return dot(rgb, vec3(0.299, 0.587, 0.114));\n}\nfloat luminance_pre(vec3 rgb) {\n    return dot(rgb, vec3(0.212671, 0.715160, 0.072169));\n}\nvec3 xyz2rgb(vec3 xyz) {\n    vec3 R = vec3( 3.240479, -1.537150, -0.498535);\n    vec3 G = vec3(-0.969256,  1.875992,  0.041556);\n    vec3 B = vec3( 0.055648, -0.204043,  1.057311);\n    vec3 rgb;\n    rgb.b = dot(xyz, B);\n    rgb.g = dot(xyz, G);\n    rgb.r = dot(xyz, R);\n    return rgb;\n}\nvec3 rgb2xyz(vec3 rgb) {\n    vec3 X = vec3(0.412453, 0.35758, 0.180423);\n    vec3 Y = vec3(0.212671, 0.71516, 0.0721688);\n    vec3 Z = vec3(0.0193338, 0.119194, 0.950227);\n    vec3 xyz;\n    xyz.x = dot(rgb, X);\n    xyz.y = dot(rgb, Y);\n    xyz.z = dot(rgb, Z);\n    return xyz;\n}\nvec3 xyz2xyY(vec3 xyz) {\n    float sum = xyz.x + xyz.y + xyz.z;\n    sum = 1.0 / sum;\n    vec3 xyY;\n    xyY.z = xyz.y;\n    xyY.x = xyz.x * sum;\n    xyY.y = xyz.y * sum;\n    return xyY;\n}\nvec3 xyY2xyz(vec3 xyY) {\n    float x = xyY.x;\n    float y = xyY.y;\n    float Y = xyY.z;\n    vec3 xyz;\n    xyz.y = Y;\n    xyz.x = x * (Y / y);\n    xyz.z = (1.0 - x - y) * (Y / y);\n    return xyz;\n}\nfloat toneMapCanon_T(float x)\n{\n    float xpow = pow(x, 1.60525727);\n    float tmp = ((1.05542877*4.68037409)*xpow) / (4.68037409*xpow + 1.0);\n    return clamp(tmp, 0.0, 1.0);\n}\nconst float Shift = 1.0 / 0.18;\nfloat toneMapCanonFilmic_NoGamma(float x) {\n    x *= Shift;\n    const float A = 0.2;\n    const float B = 0.34;\n    const float C = 0.002;\n    const float D = 1.68;\n    const float E = 0.0005;\n    const float F = 0.252;\n    const float scale = 1.0/0.833837;\n    return (((x*(A*x+C*B)+D*E)/(x*(A*x+B)+D*F))-E/F) * scale;\n}\nvec3 toneMapCanonFilmic_WithGamma(vec3 x) {\n    x *= Shift;\n    const float A = 0.27;\n    const float B = 0.29;\n    const float C = 0.052;\n    const float D = 0.2;\n    const float F = 0.18;\n    const float scale = 1.0/0.897105;\n    return (((x*(A*x+C*B))/(x*(A*x+B)+D*F))) * scale;\n}\nvec3 toneMapCanonOGS_WithGamma_WithColorPerserving(vec3 x) {\n    vec3 outColor = x.rgb;\n    outColor = min(outColor, vec3(3.0));\n    float inLum = luminance_pre(outColor);\n    if (inLum > 0.0) {\n        float outLum = toneMapCanon_T(inLum);\n        outColor = outColor * (outLum / inLum);\n        outColor = clamp(outColor, vec3(0.0), vec3(1.0));\n    }\n    float gamma = 1.0/2.2;\n    outColor = pow(outColor, vec3(gamma));\n    return outColor;\n}\n";

var ordered_dither = "vec3 orderedDithering(vec3 col) {\n    const vec4 m0 = vec4( 1.0, 13.0,  4.0, 16.0);\n    const vec4 m1 = vec4( 9.0,  5.0, 12.0,  8.0);\n    const vec4 m2 = vec4( 3.0, 15.0,  2.0, 14.0);\n    const vec4 m3 = vec4(11.0,  7.0, 10.0,  6.0);\n    int i = int(mod(float(gl_FragCoord.x), 4.0));\n    int j = int(mod(float(gl_FragCoord.y), 4.0));\n    vec4 biasRow;\n    if      (i==0) biasRow = m0;\n    else if (i==1) biasRow = m1;\n    else if (i==2) biasRow = m2;\n    else           biasRow = m3;\n    float bias;\n    if      (j==0) bias = biasRow.x;\n    else if (j==1) bias = biasRow.y;\n    else if (j==2) bias = biasRow.z;\n    else           bias = biasRow.w;\n    return col + bias / 17.0 / 256.0;\n}\n";

var cutplanes = "#if NUM_CUTPLANES > 0\nuniform vec4 cutplanes[NUM_CUTPLANES];\nvoid checkCutPlanes(vec3 worldPosition) {\n    for (int i=0; i<NUM_CUTPLANES; i++) {\n        if (dot(vec4(worldPosition, 1.0), cutplanes[i]) > 0.0) {\n            discard;\n        }\n    }\n}\n#endif\n";

var pack_normals = "\n#define kPI 3.14159265358979\nvec2 encodeNormal (vec3 n) {\n    return (vec2(atan(n.y,n.x)/kPI, n.z)+1.0)*0.5;\n}\nvec3 decodeNormal (vec2 enc) {\n    vec2 ang = enc * 2.0 - 1.0;\n    vec2 scth = vec2(sin(ang.x * kPI), cos(ang.x * kPI));\n    vec2 scphi = vec2(sqrt(1.0 - ang.y * ang.y), ang.y);\n    return vec3(scth.y * scphi.x, scth.x * scphi.x, scphi.y);\n}\n";

var hatch_pattern = "#ifdef HATCH_PATTERN\nuniform vec2 hatchParams;\nuniform vec3 hatchTintColor;\nuniform float hatchTintIntensity;\nfloat curveGaussian(float r, float invWidth) {\n    float amt = clamp(r * invWidth, 0.0, 1.0);\n    float exponent = amt * 3.5;\n    return exp(-exponent*exponent);\n}\nvec4 calculateHatchPattern(vec2 hatchParams, vec2 coord, vec4 fragColor, vec3 hatchTintColor, float hatchTintIntensity ) {\n    float hatchSlope = hatchParams.x;\n    float hatchPeriod = hatchParams.y;\n    if (abs(hatchSlope) <= 1.0) {\n        float hatchPhase = coord.y - hatchSlope * coord.x;\n        float dist = abs(mod((hatchPhase), (hatchPeriod)));\n        if (dist < 1.0) {\n            fragColor = vec4(0.0,0.0,0.0,1.0);\n        } else {\n            fragColor.xyz = mix(fragColor.xyz, hatchTintColor, hatchTintIntensity);\n        }\n    } else {\n        float hatchPhase = - coord.y / hatchSlope + coord.x;\n        float dist = abs(mod((hatchPhase), (hatchPeriod)));\n        if (dist < 1.0) {\n            fragColor = vec4(0.0,0.0,0.0,1.0);\n        } else {\n            fragColor.xyz = mix(fragColor.xyz, hatchTintColor, hatchTintIntensity);\n        }\n    }\n    return fragColor;\n}\n#endif\n";

var env_sample = "\nuniform float envRotationSin;\nuniform float envRotationCos;\nvec3 adjustLookupVector(in vec3 lookup) {\n    return vec3(\n            envRotationCos * lookup.x - envRotationSin * lookup.z,\n            lookup.y,\n            envRotationSin * lookup.x + envRotationCos * lookup.z);\n}\nvec3 RGBMDecode(in vec4 vRGBM, in float exposure) {\n    vec3 ret = vRGBM.rgb * (vRGBM.a * 16.0);\n    ret *= ret;\n    ret *= exposure;\n    return ret;\n}\nvec3 GammaDecode(in vec4 vRGBA, in float exposure) {\n    return vRGBA.xyz * vRGBA.xyz * exposure;\n}\nvec3 sampleIrradianceMap(vec3 dirWorld, samplerCube irrMap, float exposure) {\n    vec4 cubeColor4 = textureCube(irrMap, adjustLookupVector(dirWorld));\n#ifdef IRR_GAMMA\n    vec3 indirectDiffuse = GammaDecode(cubeColor4, exposure);\n#elif defined(IRR_RGBM)\n    vec3 indirectDiffuse = RGBMDecode(cubeColor4, exposure);\n#else\n    vec3 indirectDiffuse = cubeColor4.xyz;\n#ifdef GAMMA_INPUT\n    indirectDiffuse.xyz *= indirectDiffuse.xyz;\n#endif\n#endif\n    return indirectDiffuse;\n}\n";

var id_decl_vert = "#ifdef USE_VERTEX_ID\nattribute vec3 id;\nvarying   vec3 vId;\n#endif\n";

var id_vert = "\n#ifdef USE_VERTEX_ID\nvId = id;\n#endif\n";

var id_decl_frag = "#if defined(MRT_NORMALS) || defined(MRT_ID_BUFFER)\nvarying highp float depth;\n#define gl_FragColor gl_FragData[0]\n#endif\n#if defined(MRT_ID_BUFFER) || defined(ID_COLOR)\n#ifdef USE_VERTEX_ID\nvarying vec3 vId;\n#else\nuniform vec3 dbId;\n#endif\n#endif\n#if defined(MRT_ID_BUFFER) || defined(MODEL_COLOR)\nuniform vec3 modelId;\n#endif\n";

var id_frag = "\n#if defined(USE_VERTEX_ID) && (defined(MRT_ID_BUFFER) || defined(ID_COLOR))\nvec3 dbId = vId;\n#endif\n#ifdef MRT_ID_BUFFER\n#ifdef MRT_NORMALS\nconst int index = 2;\n#else\nconst int index = 1;\n#endif\n#ifndef ENABLE_ID_DISCARD\nconst float writeId = 1.0;\n#endif\ngl_FragData[index] = vec4(dbId.rgb, writeId);\n#ifdef MODEL_COLOR\ngl_FragData[index+1] = vec4(modelId.rgb, writeId);\n#endif\n#elif defined(ID_COLOR)\n#ifdef ENABLE_ID_DISCARD\nif (writeId==0.0) {\n    discard;\n}\n#endif\ngl_FragColor = vec4(dbId.rgb, 1.0);\n#elif defined(MODEL_COLOR)\n#ifdef ENABLE_ID_DISCARD\nif (writeId==0.0) {\n    discard;\n}\n#endif\ngl_FragColor = vec4(modelId.rgb, 1.0);\n#endif\n";

var final_frag = "#ifdef HATCH_PATTERN\ngl_FragColor = calculateHatchPattern(hatchParams, gl_FragCoord.xy, gl_FragColor, hatchTintColor, hatchTintIntensity);\n#endif\n#if defined(USE_LOGDEPTHBUF) && defined(USE_LOGDEPTHBUF_EXT)\ngl_FragDepthEXT = log2(vFragDepth) * logDepthBufFC * 0.5;\n#endif\n#ifdef MRT_NORMALS\ngl_FragData[1] = vec4(normal.x, normal.y, depth, gl_FragColor.a < 1.0 ? 0.0 : 1.0);\n#endif\n#include<id_frag>\n";

var theming_decl_frag = "uniform vec4 themingColor;\n";

var theming_frag = "gl_FragColor.rgb = mix(gl_FragColor.rgb, themingColor.rgb, themingColor.a);\n";

var instancing_decl_vert = "\n#ifdef USE_INSTANCING\nattribute vec3 instOffset;\nattribute vec4 instRotation;\nattribute vec3 instScaling;\nvec3 applyQuaternion(vec3 p, vec4 q) {\n    return p + 2.0 * cross(q.xyz, cross(q.xyz, p) + q.w * p);\n}\nvec3 getInstancePos(vec3 pos) {\n    return instOffset + applyQuaternion(instScaling * pos, instRotation);\n}\nvec3 getInstanceNormal(vec3 normal) {\n    return applyQuaternion(normal/instScaling, instRotation);\n}\n#else\nvec3 getInstancePos(vec3 pos)       { return pos;    }\nvec3 getInstanceNormal(vec3 normal) { return normal; }\n#endif\n";

var shadowmap_decl_common = "\nuniform float shadowESMConstant;\nuniform float shadowMapRangeMin;\nuniform float shadowMapRangeSize;\n";

var shadowmap_decl_vert = "\n#ifdef USE_SHADOWMAP\nvarying vec4 vShadowCoord;\nuniform mat4 shadowMatrix;\n#endif\n";

var shadowmap_vert = "\n#ifdef USE_SHADOWMAP\n{\n    vec4 worldPosition = modelMatrix * vec4( position, 1.0 );\n    vShadowCoord = shadowMatrix * worldPosition;\n}\n#endif\n";

var shadowmap_decl_frag = "\n#ifdef USE_SHADOWMAP\nuniform sampler2D shadowMap;\nuniform vec2      shadowMapSize;\nuniform float     shadowDarkness;\nuniform float     shadowBias;\nuniform vec3      shadowLightDir;\nvarying vec4 vShadowCoord;\n#include<shadowmap_decl_common>\nfloat getShadowValue() {\n    float fDepth;\n    vec3 shadowColor = vec3( 1.0 );\n    vec3 shadowCoord = vShadowCoord.xyz / vShadowCoord.w;\n    shadowCoord.xyz = 0.5 * (shadowCoord.xyz + vec3(1.0, 1.0, 1.0));\n    bvec4 inFrustumVec = bvec4 ( shadowCoord.x >= 0.0, shadowCoord.x <= 1.0, shadowCoord.y >= 0.0, shadowCoord.y <= 1.0 );\n    bool inFrustum = all( inFrustumVec );\n    float shadowValue = 1.0;\n    if (inFrustum) {\n        shadowCoord.z = min(0.999, shadowCoord.z);\n        shadowCoord.z -= shadowBias;\n#ifdef USE_HARD_SHADOWS\n        vec4 rgbaDepth = texture2D( shadowMap, shadowCoord.xy );\n        float fDepth = rgbaDepth.r;\n        if ( fDepth < shadowCoord.z ) {\n            shadowValue = 1.0 - shadowDarkness;\n        }\n#else\n        vec4 rgbaDepth = texture2D( shadowMap, shadowCoord.xy );\n        float shadowMapValue = rgbaDepth.r;\n        shadowValue = exp(-shadowESMConstant * shadowCoord.z) * shadowMapValue;\n        shadowValue = min(shadowValue, 1.0);\n        shadowValue = mix(1.0 - shadowDarkness, 1.0, shadowValue);\n#endif\n    }\n    return shadowValue;\n}\n#else\nfloat getShadowValue() { return 1.0; }\n#endif\nvec3 applyEnvShadow(vec3 colorWithoutShadow, vec3 worldNormal) {\n#if defined(USE_SHADOWMAP)\n    float dp  = dot(shadowLightDir, worldNormal);\n    float dpValue = (dp + 1.0) / 2.0;\n    dpValue = min(1.0, dpValue * 1.5);\n    float sv = getShadowValue();\n    vec3 result = colorWithoutShadow * min(sv, dpValue);\n    return result;\n#else\n    return colorWithoutShadow;\n#endif\n}\n";

var float3_average = "float averageOfFloat3(in vec3 value) { \n    const float oneThird = 1.0 / 3.0; \n    return dot(value, vec3(oneThird, oneThird, oneThird)); \n} \n";

var line_decl_common = "\n#define TAU     6.28318530718\n#define PI      3.14159265358979\n#define HALF_PI 1.57079632679\n#define PI_0_5  HALF_PI\n#define PI_1_5  4.71238898038\n#define ENABLE_ID_DISCARD\n#define VBB_GT_TRIANGLE_INDEXED  0.0\n#define VBB_GT_LINE_SEGMENT      1.0\n#define VBB_GT_ARC_CIRCULAR      2.0\n#define VBB_GT_ARC_ELLIPTICAL    3.0\n#define VBB_GT_TEX_QUAD          4.0\n#define VBB_GT_ONE_TRIANGLE      5.0\n#define VBB_INSTANCED_FLAG   0.0\n#define VBB_SEG_START_RIGHT  0.0\n#define VBB_SEG_START_LEFT   1.0\n#define VBB_SEG_END_RIGHT    2.0\n#define VBB_SEG_END_LEFT     3.0\nvarying vec4 fsColor;\nvarying vec4 dbId;\nvarying vec2 fsOffsetDirection;\nvarying vec4 fsMultipurpose;\nvarying float fsHalfWidth;\nvarying vec2 fsVpTC;\nvarying float fsGhosting;\n";

var prismWood = "#if defined( PRISMWOOD )\n#define ONE 0.00390625\nfloat GetIndexedValue(vec4 array, int index)\n{\n    if (index == 0)\n        return array[0];\n    else if (index == 1)\n        return array[1];\n    else if (index == 2)\n        return array[2];\n    else if (index == 3)\n        return array[3];\n    else\n        return 0.0;\n}\nint GetIndexedValue(ivec2 array, int index)\n{\n    if (index == 0)\n        return array[0];\n    else if (index == 1)\n        return array[1];\n    else\n        return 0;\n}\n#if defined( USE_WOOD_CURLY_DISTORTION_MAP )\nfloat SampleCurlyPattern(vec2 uv)\n{\n    vec2 uv_wood_curly_distortion_map = (wood_curly_distortion_map_texMatrix * vec3(uv, 1.0)).xy;\n    WOOD_CURLY_DISTORTION_CLAMP_TEST;\n    vec3 curlyDistortion = texture2D(wood_curly_distortion_map, uv_wood_curly_distortion_map).xyz;\n    if(wood_curly_distortion_map_invert) curlyDistortion = vec3(1.0) - curlyDistortion;\n    return curlyDistortion.r;\n}\nvec3 DistortCurly(vec3 p)\n{\n    if (!wood_curly_distortion_enable) return p;\n    float r = length(p.xy);\n    if (r < 0.00001) return p;\n    const float INV_ANGLE_INTERVAL = 1.27323954;\n    const float NUM_INTERVAL = 8.0;\n    float theta = atan(p.y, p.x);\n    if (theta < 0.0)\n        theta += PI2;\n    float intIdx = theta * INV_ANGLE_INTERVAL;\n    int idx0 = int(mod(floor(intIdx), NUM_INTERVAL));\n    int idx1 = int(mod(ceil(intIdx), NUM_INTERVAL));\n    const vec4 HASH_TABLE1 = vec4(0.450572,0.114598, 0.886043, 0.315119);\n    const vec4 HASH_TABLE2 = vec4(0.216133,0.306264, 0.685616, 0.317907);\n    float offset0 = idx0 < 4 ? GetIndexedValue(HASH_TABLE1, idx0) : GetIndexedValue(HASH_TABLE2, idx0-4);\n    float offset1 = idx1 < 4 ? GetIndexedValue(HASH_TABLE1, idx1) : GetIndexedValue(HASH_TABLE2, idx1-4);\n    const float maxOffset = 100.0;\n    offset0 = (offset0 - 0.5) * maxOffset;\n    offset1 = (offset1 - 0.5) * maxOffset;\n    vec2 uv0 = vec2(p.z + offset0, r);\n    float shiftWeight0 =  SampleCurlyPattern(uv0);\n    vec2 uv1 = vec2(p.z + offset1, r);\n    float shiftWeight1 =  SampleCurlyPattern(uv1);\n    float interpWeight = fract(intIdx);\n    float shiftWeight = mix(shiftWeight0, shiftWeight1, interpWeight);\n    const float INV_MIN_RADIUS = 2.0;\n    float shiftWeightAdjust = smoothstep(0.0, 1.0, r * INV_MIN_RADIUS);\n    r -= wood_curly_distortion_scale * (shiftWeight * shiftWeightAdjust);\n    float thetaNew = atan(p.y, p.x);\n    vec3 pNew = p;\n    pNew.x = r * cos(thetaNew);\n    pNew.y = r * sin(thetaNew);\n    return pNew;\n}\n#endif\nvec3 un2sn(vec3 range)\n{\n    return range * 2.0 - 1.0;\n}\nfloat inoise(vec3 p)\n{\n    vec3 modp = mod(floor(p), 256.0);\n    modp.xy = modp.xy * ONE;\n    vec4 AA = texture2D(perm2DMap, vec2(modp.x, modp.y), 0.0) * 255.0;\n    AA = AA + modp.z;\n    AA = mod(floor(AA), 256.0);\n    AA *= ONE;\n    vec3 gradx1 = un2sn(texture2D(permGradMap,vec2(AA.x,0.0),0.0).xyz);\n    vec3 grady1 = un2sn(texture2D(permGradMap,vec2(AA.y,0.0),0.0).xyz);\n    vec3 gradz1 = un2sn(texture2D(permGradMap,vec2(AA.z,0.0),0.0).xyz);\n    vec3 gradw1 = un2sn(texture2D(permGradMap,vec2(AA.w,0.0),0.0).xyz);\n    vec3 gradx2 = un2sn(texture2D(permGradMap,vec2(AA.x + ONE,0.0),0.0).xyz);\n    vec3 grady2 = un2sn(texture2D(permGradMap,vec2(AA.y + ONE,0.0),0.0).xyz);\n    vec3 gradz2 = un2sn(texture2D(permGradMap,vec2(AA.z + ONE,0.0),0.0).xyz);\n    vec3 gradw2 = un2sn(texture2D(permGradMap,vec2(AA.w + ONE,0.0),0.0).xyz);\n    p -= floor(p);\n    vec3 fadep = p * p * p * (p * (p * 6.0 - 15.0) + 10.0);\n    return mix( mix( mix( dot(gradx1, p ),\n                          dot(gradz1, p + vec3(-1.0, 0.0, 0.0)), fadep.x),\n                     mix( dot(grady1, p + vec3(0.0, -1.0, 0.0)),\n                          dot(gradw1, p + vec3(-1.0, -1.0, 0.0)), fadep.x), fadep.y),\n                mix( mix( dot(gradx2, p + vec3(0.0, 0.0, -1.0)),\n                          dot(gradz2, p + vec3(-1.0, 0.0, -1.0)), fadep.x),\n                     mix( dot(grady2, p + vec3(0.0, -1.0, -1.0)),\n                          dot(gradw2, p + vec3(-1.0, -1.0, -1.0)), fadep.x), fadep.y), fadep.z);\n}\nfloat inoise(float p)\n{\n    float modp = mod(floor(p), 256.0);\n    modp = (modp + 256.0) * ONE;\n    float permx = texture2D(permutationMap, vec2(modp, 0.0), 0.0).r;\n    float gradx = texture2D(gradientMap, vec2(permx, 0.0), 0.0).r*2.0-1.0;\n    float permy = texture2D(permutationMap, vec2(modp + ONE, 0.0), 0.0).r;\n    float grady = texture2D(gradientMap, vec2(permy, 0.0), 0.0).r*2.0-1.0;\n    p -= floor(p);\n    float fadep = p * p * p * (p * (p * 6.0 - 15.0) + 10.0);\n    return mix(gradx * p, grady * (p - 1.0), fadep);\n}\nfloat multiband_inoise(vec3 p, int bands, vec4 w, vec4 f)\n{\n    float noise = 0.0;\n    for(int i = 0; i < 4; ++i)\n    {\n        if (i >= bands) break;\n        noise += GetIndexedValue(w, i) * inoise(p * GetIndexedValue(f, i));\n    }\n    return noise;\n}\nfloat multiband_inoise(float p, int bands, vec4 w, vec4 f)\n{\n    float noise = 0.0;\n    for(int i = 0; i < 4; ++i)\n    {\n        if (i >= bands) break;\n        noise += GetIndexedValue(w, i) * inoise(p * GetIndexedValue(f, i));\n    }\n    return noise;\n}\nvec3 Distort3DCosineRadialDir(vec3 p)\n{\n    float radius = length(p.xy);\n    if (radius < 0.00001) return p;\n    vec2 theta = p.xy / radius;\n    float radiusShift = 0.0;\n    for (int i = 0; i < 4; ++i)\n    {\n        if (i >= wood_fiber_cosine_bands) break;\n        radiusShift += GetIndexedValue(wood_fiber_cosine_weights, i) * cos(p.z * RECIPROCAL_PI2 * GetIndexedValue(wood_fiber_cosine_frequencies, i));\n    }\n    const float MIN_RADIUS = 1.5;\n    float weight = clamp(radius / MIN_RADIUS, 0.0, 1.0);\n    if(weight >= 0.5)\n        weight = weight * weight * (3.0 - (weight + weight));\n    p.xy += theta * radiusShift * weight;\n    return p;\n}\nvec3 Distort3DPerlin(vec3 p)\n{\n    vec3 pAniso = vec3(p.xy, p.z * wood_fiber_perlin_scale_z);\n    p.xy += multiband_inoise(pAniso, wood_fiber_perlin_bands, wood_fiber_perlin_weights, wood_fiber_perlin_frequencies);\n    return p;\n}\nvec3 Distort(vec3 p)\n{\n    if(wood_fiber_cosine_enable)\n        p = Distort3DCosineRadialDir(p);\n    if(wood_fiber_perlin_enable)\n        p = Distort3DPerlin(p);\n    return p;\n}\nfloat DistortRadiusLength(float radiusLength)\n{\n    radiusLength += multiband_inoise(radiusLength, wood_growth_perlin_bands, wood_growth_perlin_weights, wood_growth_perlin_frequencies);\n    if (radiusLength < 0.0) radiusLength = 0.0;\n    return radiusLength;\n}\nfloat ComputeEarlyWoodRatio(float radiusLength)\n{\n    float fraction = mod(radiusLength, wood_ring_thickness) / wood_ring_thickness;\n    if (fraction <= wood_ring_fraction.y)\n       return 1.0;\n    else if(fraction <= wood_ring_fraction.x)\n       return (1.0 - (fraction - wood_ring_fraction.y) / wood_fall_rise.x);\n    else if(fraction <= wood_ring_fraction.w)\n       return 0.0;\n    else\n       return ((fraction - wood_ring_fraction.w) / wood_fall_rise.y);\n}\nvec3 DistortEarlyColor(vec3 earlyColor, float radiusLength)\n{\n    float expValue = 1.0 + multiband_inoise(radiusLength,wood_earlycolor_perlin_bands,wood_earlycolor_perlin_weights,wood_earlycolor_perlin_frequencies);\n    earlyColor = pow(abs(earlyColor), vec3(expValue));\n    return earlyColor;\n}\nvec3 DistortLateColor(vec3 lateColor, float radiusLength)\n{\n    float expValue = 1.0 + multiband_inoise(radiusLength,wood_latecolor_perlin_bands,wood_latecolor_perlin_weights,wood_latecolor_perlin_frequencies);\n    lateColor = pow(abs(lateColor), vec3(expValue));\n    return lateColor;\n}\nvec3 DistortDiffuseColor(vec3 diffAlbedo, vec3 p)\n{\n    p.z *= wood_diffuse_perlin_scale_z;\n    float expValue = 1.0 + multiband_inoise(p, wood_diffuse_perlin_bands, wood_diffuse_perlin_weights, wood_diffuse_perlin_frequencies);\n    diffAlbedo = pow(abs(diffAlbedo), vec3(expValue));\n    return diffAlbedo;\n}\nfloat LayerRoughnessVar(float roughness, float earlyWoodRatio)\n{\n    return earlyWoodRatio * wood_groove_roughness + (1.0 - earlyWoodRatio) * roughness;\n}\nfloat hashword(vec2 k)\n{\n    k = mod(k, vec2(256.0)) * ONE;\n    float a = texture2D(permutationMap, vec2(k.x, 0.0)).x + k.y ;\n    a = texture2D(permutationMap, vec2(a, 0.0)).x ;\n    return a*255.0;\n}\nfloat wyvillsq(float rsq)\n{\n    if (rsq >= 1.0) return 0.0;\n    float tmp = 1.0 - rsq;\n    return tmp*tmp*tmp;\n}\nfloat Weight2DNeighborImpulses(vec3 p, float woodWeight)\n{\n    if(woodWeight <= 0.0) return 0.0;\n    float poreRadius = wood_pore_radius * woodWeight;\n    vec2 left = floor((p.xy - poreRadius) / wood_pore_cell_dim);\n    vec2 right = floor((p.xy + poreRadius) / wood_pore_cell_dim);\n    float weight = 0.0;\n    float invRsq = 1.0 / (poreRadius * poreRadius);\n    const float norm =  1.0 / 15.0;\n    for (int j = 0; j <= 4; j++)\n    {\n        if (j > int(right.y - left.y)) continue;\n        for (int i = 0; i <= 4; i++)\n        {\n            if (i > int(right.x - left.x)) continue;\n            vec2 pij = vec2(float(i) + left.x,float(j) + left.y);\n            float hRNum = hashword(pij);\n            float impPosX = mod(hRNum, 16.0) * norm;\n            float impPosY = floor(hRNum / 16.0) * norm;\n            impPosX = (pij.x + impPosX)* wood_pore_cell_dim;\n            impPosY = (pij.y + impPosY)* wood_pore_cell_dim;\n            float dsq = (p.x - impPosX) * (p.x - impPosX) + (p.y - impPosY) * (p.y - impPosY);\n            weight += wyvillsq(dsq * invRsq);\n        }\n    }\n    return weight;\n}\nfloat Weight3DRayImpulses(vec3 p)\n{\n    int segIdx = int(floor(p.z / wood_ray_seg_length_z));\n    float factor = p.z / wood_ray_seg_length_z - float(segIdx);\n    int segIdx1 = segIdx - 1;\n    if ( factor > 0.5 )\n        segIdx1 = segIdx + 1;\n    float theta = atan(p.y, p.x);\n    float sliceIdx = floor(((theta + PI) * RECIPROCAL_PI2) * wood_ray_num_slices);\n    if ( sliceIdx == wood_ray_num_slices)\n        sliceIdx-=1.0;\n    ivec2 arrSegs = ivec2(segIdx, segIdx1);\n    float weight = 0.0;\n    const float norm =  1.0 / 15.0;\n    float radialOffset = 5.0;\n    float radialLength = length(p.xy);\n    for (int seg = 0; seg < 2; seg++)\n    {\n        float hRNum = hashword(vec2(sliceIdx, GetIndexedValue(arrSegs, seg)));\n        float rn1 = mod(hRNum,16.0) * norm;\n        if (radialLength < radialOffset * rn1)\n            continue;\n        float rayTheta = rn1;\n        rayTheta = ( ( sliceIdx + rayTheta ) / wood_ray_num_slices ) * ( 2.0 * PI ) - PI;\n        float rayPosZ = (hRNum/16.0)* norm;\n        rayPosZ = ( float(GetIndexedValue(arrSegs, seg)) + rayPosZ ) * wood_ray_seg_length_z;\n        vec3 pt1 = vec3(0.0);\n        vec3 pt2 = vec3(cos(rayTheta), sin(rayTheta), 0.0);\n        vec3 p1 = p;\n        p1.z -= rayPosZ;\n        p1.z /=  wood_ray_ellipse_z2x;\n        vec3 v1 = pt2 - pt1;\n        vec3 v2 = pt1 - p1;\n        v2 = cross(v1, v2);\n        float dist = length(v2) / length(v1);\n        float invRsq = 1.0 / ( wood_ray_ellipse_radius_x * wood_ray_ellipse_radius_x);\n        weight += wyvillsq( (dist * dist) * invRsq );\n    }\n    return weight;\n}\nvec3 DarkenColorWithPores(vec3 p, vec3 diffColor, float woodWeight)\n{\n    float poresWeight = Weight2DNeighborImpulses(p, woodWeight);\n    float a = wood_pore_color_power - 1.0;\n    float b = 1.0;\n    float y = a * poresWeight + b;\n    return pow(abs(diffColor), vec3(y));\n}\nvec3 DarkenColorWithRays(vec3 p, vec3 diffColor)\n{\n    float raysWeight = Weight3DRayImpulses(p);\n    float a = wood_ray_color_power - 1.0;\n    float b = 1.0;\n    float y = a * raysWeight + b;\n    return pow(abs(diffColor), vec3(y));\n}\nfloat ComputeWoodWeight(float earlyWoodRatio)\n{\n    float woodWeight = 0.0;\n    if (wood_pore_type == 0)\n        woodWeight = 1.0;\n    else if (wood_pore_type == 1)\n        woodWeight = earlyWoodRatio;\n    else if (wood_pore_type == 2)\n        woodWeight = 1.0 - earlyWoodRatio;\n    else\n        woodWeight = -1.0;\n    return woodWeight;\n}\n#if defined( PRISMWOODBUMP )\nfloat ComputeEarlyWoodRatioAA(float radiusLength, float invUnitExt)\n{\n    float transPixels = min(wood_fall_rise.x, wood_fall_rise.y) * wood_ring_thickness * invUnitExt;\n    float samplesf = clamp(4.0 / transPixels, 1.0, 4.0);\n    int samples = int(samplesf);\n    float inverseSamples = 1.0 / float(samples);\n    vec2 rdelta = vec2(dFdx(radiusLength), dFdy(radiusLength)) * inverseSamples;\n    float earlywoodRatio = 0.0;\n    for (int i = 0; i < 4; ++i)\n    {\n        if (i >= samples) break;\n        for (int j = 0; j < 4; ++j)\n        {\n            if (j >= samples) break;\n            float r = radiusLength + dot(vec2(i, j), rdelta);\n            earlywoodRatio += ComputeEarlyWoodRatio(r);\n        }\n    }\n    return earlywoodRatio * (inverseSamples * inverseSamples);\n}\nfloat LatewoodDepthVariation(float invUnitExt)\n{\n    float transPixels = min(wood_fall_rise.x, wood_fall_rise.y) * wood_ring_thickness * invUnitExt;\n    return clamp(transPixels * 0.5, 0.0, 1.0);\n}\nfloat LatewoodHeightVariation(float earlyWoodRatio, float latewoodBumpDepth,\n                              float depthVar)\n{\n    return ( 1.0 - earlyWoodRatio ) * latewoodBumpDepth * depthVar;\n}\nfloat PoreDepthVariation(float woodWeight, float invUnitExt)\n{\n    float porePixels = woodWeight * wood_pore_radius * invUnitExt;\n    return clamp(porePixels, 0.0, 1.0);\n}\nfloat PoreHeightVariation(float earlyWoodRatio, float poresWeight, float poreDepth,\n                          float depthVar)\n{\n    return poresWeight * (-1.0 * poreDepth) * depthVar;\n}\nvoid ComputeTangents(vec3 normal, out vec3 u, out vec3 v)\n{\n    float scale = normal.z < 0.0 ? -1.0 : 1.0;\n    vec3 temp = scale * normal;\n    float e    = temp.z;\n    float h    = 1.0/(1.0 + e);\n    float hvx  = h   *  temp.y;\n    float hvxy = hvx * -temp.x;\n    u = vec3(e + hvx * temp.y, hvxy,                -temp.x);\n    v = vec3(hvxy,             e + h * temp.x * temp.x, -temp.y);\n    u *= scale;\n    v *= scale;\n}\nvec3 WoodBumpHeight(float heightLeft, float heightRight, float heightBack, float heightFront)\n{\n    const float epsilon = 0.001;\n    float heightDeltaX = heightRight - heightLeft;\n    vec3 Tu = vec3(2.0 * epsilon, 0.0, heightDeltaX);\n    float heightDeltaY = heightFront - heightBack;\n    vec3 Tv = vec3(0.0, 2.0 * epsilon, heightDeltaY);\n    return cross(Tu, Tv);\n}\nvec3 SelectNormal(vec3 N, vec3 bumpN, vec3 V)\n{\n    float bumpNdotV = dot(bumpN, V);\n    if(bumpNdotV > 0.0)\n        return bumpN;\n    else return N;\n}\nfloat MinInverseUnitExtent(vec3 p)\n{\n    return 1.0 / max(max(length(dFdx(p.xy)), length(dFdy(p.xy))), 0.000001);\n}\nfloat HeightVariation(vec3 pos)\n{\n    vec3 p = Distort(pos);\n    float radiusLength = length(p.xy);\n    if (wood_growth_perlin_enable)\n        radiusLength = DistortRadiusLength(radiusLength);\n    float invUnitExt = MinInverseUnitExtent(p);\n    float earlyWoodRatio = ComputeEarlyWoodRatioAA(radiusLength, invUnitExt);\n    float woodWeight = ComputeWoodWeight(earlyWoodRatio);\n    float poresWeight = Weight2DNeighborImpulses(p, woodWeight);\n    float depthVar = PoreDepthVariation(woodWeight, invUnitExt);\n    float poreHeightVariation = -1.0 * poresWeight * wood_pore_depth * depthVar;\n    float latewoodHeightVariation = 0.0;\n    if (wood_use_latewood_bump)\n    {\n        float latewoodDepthVar = LatewoodDepthVariation(invUnitExt);\n        latewoodHeightVariation = (1.0 - earlyWoodRatio) * wood_latewood_bump_depth * latewoodDepthVar;\n    }\n    float sumHeightVariation = poreHeightVariation + latewoodHeightVariation;\n    return sumHeightVariation;\n}\n#endif\nvec3 NoiseWood(vec3 p, inout float roughness)\n{\n    p = Distort(p);\n    float radiusLength = length(p.xy);\n    if(wood_growth_perlin_enable)\n        radiusLength = DistortRadiusLength(radiusLength);\n#if defined( PRISMWOODBUMP )\n    float invUnitExt = MinInverseUnitExtent( p );\n    float earlyWoodRatio = ComputeEarlyWoodRatioAA(radiusLength, invUnitExt);\n#else\n    float earlyWoodRatio = ComputeEarlyWoodRatio(radiusLength);\n#endif\n    vec3 earlyColor = wood_early_color;\n    if (wood_earlycolor_perlin_enable)\n        earlyColor = DistortEarlyColor(earlyColor, radiusLength);\n    vec3 lateColor;\n    if (wood_use_manual_late_color)\n        lateColor = wood_manual_late_color;\n    else\n        lateColor = pow(abs(earlyColor), vec3(wood_late_color_power));\n    if(wood_latecolor_perlin_enable)\n        lateColor = DistortLateColor(lateColor, radiusLength);\n    vec3 diffAlbedo = earlyWoodRatio * earlyColor + (1.0 - earlyWoodRatio) * lateColor;\n    if(wood_diffuse_perlin_enable)\n        diffAlbedo = DistortDiffuseColor(diffAlbedo, p);\n    if (wood_use_pores)\n    {\n        float woodWeight = ComputeWoodWeight(earlyWoodRatio);\n        diffAlbedo = DarkenColorWithPores(p, diffAlbedo, woodWeight);\n    }\n    if (wood_use_rays)\n        diffAlbedo = DarkenColorWithRays(p, diffAlbedo);\n    if(wood_use_groove_roughness)\n        roughness = LayerRoughnessVar(roughness, earlyWoodRatio);\n    return clamp(diffAlbedo, vec3(0.0), vec3(1.0));\n}\n#if defined(PRISMWOODBUMP)\nvoid getFinalWoodContext(\n    inout vec3 N, vec3 V, inout vec3 Tu, inout vec3 Tv, vec3 p,\n    vec3 geoNormal, vec3 tNormal, mat3 normalMatrix\n) {\n    vec3 offsetTuLeft = p - 0.001 * Tu;\n    vec3 offsetTuRight = p + 0.001 * Tu;\n    vec3 offsetTvLeft = p - 0.001 * Tv;\n    vec3 offsetTvRight = p + 0.001 * Tv;\n    float heightVariationTuLeft = HeightVariation(offsetTuLeft);\n    float heightVariationTuRight = HeightVariation(offsetTuRight);\n    float heightVariationTvLeft = HeightVariation(offsetTvLeft);\n    float heightVariationTvRight = HeightVariation(offsetTvRight);\n    vec3 bumpHeight = WoodBumpHeight(heightVariationTuLeft, heightVariationTuRight, heightVariationTvLeft, heightVariationTvRight);\n    vec3 newNormal = normalize(bumpHeight.x * Tu + bumpHeight.y * Tv + bumpHeight.z * vtNormal);\n    vec3 newNormalView = normalize(vNormalMatrix * newNormal);\n    vec3 selectedNormal = SelectNormal(geoNormal, newNormalView, V);\n    ComputeTangents(selectedNormal, Tu, Tv);\n    Tu = normalize(Tu);\n    Tv = normalize(Tv);\n    N = faceforward(selectedNormal, -V, selectedNormal);\n}\n#endif\n#endif\n";

var prism_glazing = "\nvec3 TransmitAdjust(vec3 transmission, vec3 f0) \n{ \n   vec3 limit = max(1.0 - f0, 0.00001); \n   return clamp(transmission, vec3(0.0, 0.0, 0.0), limit) / limit; \n} \nfloat ColorToIlluminance(in vec3 color) \n{ \n   const vec3 rgb2grey = vec3(0.299, 0.587, 0.114); \n   float illuminance = dot(rgb2grey, color); \n   return illuminance; \n} \nvoid applyPrismGlazingOpacity(\n    inout vec4 color,\n    vec3 transmissionF,\n    float transmissionAlpha,\n    float NdotV,\n    float glazingIlluminace) \n{\n    const float third = 1.0/3.0; \n    float transSurface = exp(-(transmissionAlpha + (transmissionAlpha < 0.0025 ? 0.0 : 0.25)) * NdotV * PI); \n    float opacity = 1.0- dot((1.0 - transmissionF), vec3(third,third,third)) * transSurface * glazingIlluminace; \n    opacity = clamp(opacity, 0.01, 0.99);\n    color.a *= opacity;\n} \n";

var prismTransparency = "void applyPrismTransparency(\n    inout vec4 color,\n    vec3 transparentColor,\n    float transparentIor\n) {\n    float fsLevel = max(max(color.r, color.g), color.b);\n    color = vec4(color.rgb/fsLevel, fsLevel);\n    float transLevel = min(min(transparentColor.r, transparentColor.g), transparentColor.b);\n    transLevel = min( (1.0 - surface_roughness), transLevel );\n    float transAlpha = (1.0 - transLevel) * 0.4 + surface_roughness * 0.55;\n    vec3 tr_g_color = sqrt(transparentColor);\n    vec4 transColor = vec4(0.5 * vec3(tr_g_color), transAlpha);\n    float strength = 1.0 - (1.0 - fsLevel) * (1.0 - fsLevel);\n    color = mix(transColor, color, strength);\n    color.a = max(color.a, 0.05);\n    if (transparentIor == 1.0 && tr_g_color == vec3(1.0)) {\n        color.a = 0.0;\n    }\n}";

var normalMapChunk = "#if defined(USE_SURFACE_NORMAL_MAP) || defined( USE_LAYERED_NORMAL_MAP ) || defined( USE_TILING_NORMAL )\nvoid heightMapTransform(\n    sampler2D bumpTexture,\n    vec2 uv,\n    mat3 transform,\n    vec2 bumpScale,\n    inout vec3 T,\n    inout vec3 B,\n    inout vec3 N\n) {\n    vec2 st = (transform * vec3(uv, 1.0)).xy;\n    mat3 mtxTangent = mat3(T, B, N);\n    T = normalize(mtxTangent * (transform * vec3(1.0, 0.0, 0.0)));\n    B = normalize(mtxTangent * (transform * vec3(0.0, 1.0, 0.0)));\n    const float oneThird = 1.0 / 3.0;\n    vec3 avg = vec3(oneThird, oneThird, oneThird);\n    vec2 offset = fwidth(st);\n    float h0 = dot(texture2D(bumpTexture, st).xyz, avg);\n    float hx = dot(texture2D(bumpTexture, st + vec2(offset.x, 0.0)).xyz, avg);\n    float hy = dot(texture2D(bumpTexture, st + vec2(0.0, offset.y)).xyz, avg);\n    vec2 diff = vec2(h0 - hx, h0 - hy) / offset;\n    N = normalize(\n        N + (\n            diff.x * T * bumpScale.x +\n            diff.y * B * bumpScale.y\n        )\n    );\n}\nvoid normalMapTransform(\n    sampler2D bumpTexture,\n    vec2 uv,\n    mat3 transform,\n    vec2 bumpScale,\n    inout vec3 T,\n    inout vec3 B,\n    inout vec3 N\n) {\n    vec2 st = (transform * vec3(uv, 1.0)).xy;\n    vec3 mapN =  2.0 * texture2D(bumpTexture, st).xyz - 1.0;\n    mapN.xy *= bumpScale.x;\n    mapN.z *= bumpScale.y;\n    vec3 v = vec3(mapN.y, -mapN.x, 0.0);\n    float c = -mapN.z;\n    mat3 skewV = mat3(\n        0.0, v.z, -v.y,\n        -v.z, 0.0, v.x,\n        v.y, -v.x, 0.0\n    );\n    mat3 rot = mat3(1.0) + skewV + skewV*skewV * 1.0/(1.0-c);\n    N *= rot;\n    T *= rot;\n    B *= rot;\n}\n#endif\n";

var decl_point_size = "uniform float point_size;";

var point_size = "gl_PointSize = point_size;";

var wide_lines_decl = "\n#ifdef WIDE_LINES\nattribute vec3 prev;\nattribute vec3 next;\nattribute float side;\nuniform vec2 view_size;\nvec2 to2d(vec4 i) {\n  return i.xy / i.w;\n}\n#endif\n";

var wide_lines_vert = "\n#ifdef WIDE_LINES\nvec4 mvpPosition = projectionMatrix * mvPosition; \nmat3 vectorMatrix = mat3(modelViewMatrix);\nvec2 _pos = to2d(mvpPosition) * view_size;\nvec2 _prev = to2d(projectionMatrix * vec4(mvPosition.xyz + vectorMatrix * (prev * 0.01), 1.0)) * view_size;\nvec2 _next = to2d(projectionMatrix * vec4(mvPosition.xyz - vectorMatrix * (next * 0.01), 1.0)) * view_size;\nvec2 dir1 = _pos - _next;\nvec2 dir2 = _prev - _pos;\ndir2 = (length(dir2) > 0.0000001) ? normalize(dir2) : vec2(0.0, 0.0);\ndir1 = (length(dir1) > 0.0000001) ? normalize(dir1) : dir2;\nvec2 dir_sharp = normalize(dir1 + dir2);\nvec2 dir = normalize(dir1 + dir_sharp);\nvec2 offset = vec2(-dir.y, dir.x);\nfloat len = 1.0 / cross(vec3(offset, 0), vec3(dir1, 0)).z;\noffset *= len;\noffset /= view_size;\noffset *= side;\noffset *= mvpPosition.w;\nmvpPosition.xy += offset;\ngl_Position = mvpPosition;\n#endif\n";

var hsv = "vec3 rgb2hsv(vec3 color)\n{\n    float delta;\n    float colorMax, colorMin;\n    float h,s,v;\n    vec3 hsv;\n    colorMax = max(color.r,color.g);\n    colorMax = max(colorMax,color.b);\n    colorMin = min(color.r,color.g);\n    colorMin = min(colorMin,color.b);\n    v = colorMax;\n    if(colorMax != 0.0)\n    {\n        s = (colorMax - colorMin)/colorMax;\n    }\n    else\n    {\n        s = 0.0;\n    }\n    if(s != 0.0)\n    {\n        delta = colorMax-colorMin;\n        if (color.r == colorMax)\n        {\n            h = (color.g-color.b)/delta;\n        }\n        else if (color.g == colorMax)\n        {\n            h = 2.0 + (color.b-color.r) / delta;\n        }\n        else\n        {\n            h = 4.0 + (color.r-color.g)/delta;\n        }\n        h /= 6.0;\n        if( h < 0.0)\n        {\n            h +=1.0;\n        }\n    }\n    else\n    {\n        h = 0.0;\n    }\n    hsv = vec3(h,s,v);\n    return hsv;\n}\nvec3 hsv2rgb(vec3 hsv)\n{\n    vec3 color;\n    float f,p,q,t;\n    float h,s,v;\n    float i,hi;\n    {\n        h = hsv.x*6.0;\n        s = hsv.y;\n        v = hsv.z;\n        i = floor(h);\n        f = h-i;\n        p = v * (1.0 - s);\n        q = v * (1.0 - (s * f));\n        t = v * (1.0 - (s * (1.0 - f)));\n        float r,g,b;\n        if (i == 0.0)\n        {\n            r = v;\n            g = t;\n            b = p;\n        }\n        else if (i == 1.0)\n        {\n            r = q;\n            g = v;\n            b = p;\n        }\n        else if (i == 2.0)\n        {\n            r = p;\n            g = v;\n            b = t;\n        }\n        else if (i == 3.0)\n        {\n            r = p;\n            g = q;\n            b = v;\n        }\n        else if (i == 4.0)\n        {\n            r = t;\n            g = p;\n            b = v;\n        }\n        else\n        {\n            r = v;\n            g = p;\n            b = q;\n        }\n        color = vec3(r,g,b);\n    }\n    return color;\n}";

/*
 * Reusable sets of uniforms that can be merged with other uniforms in specific shaders.
 */
var CutPlanesUniforms = {
    "cutplanes": { type: "v4v", value: [] },
    "hatchParams": { type: "v2", value: new THREE$1.Vector2(1.0, 10.0) },
    "hatchTintColor": { type: "c", value: new THREE$1.Color(0xFFFFFF) },
    "hatchTintIntensity": { type: "f", value: 1.0 }
};
var IdUniforms = {
    "dbId": { type: "v3", value: new THREE$1.Vector3(0, 0, 0) },
    "modelId": { type: "v3", value: new THREE$1.Vector3(0, 0, 0) }
};
var ThemingUniform = {
    "themingColor": { type: "v4", value: new THREE$1.Vector4(0, 0, 0, 0) }
};
// Uniforms shared by material shader chunks and ShadowMapShader
// Included by ShadowMapUniforms below.
var ShadowMapCommonUniforms = {
    "shadowESMConstant": { type: "f", value: 0.0 }
};
// Uniforms needed by material shaders to apply shadow mapping.
var ShadowMapUniforms = THREE$1.UniformsUtils.merge([{
    "shadowMap": { type: "t", value: null },
    "shadowMapSize": { type: "v2", value: new THREE$1.Vector2(0, 0) },
    "shadowBias": { type: "f", value: 0.0 },
    "shadowDarkness": { type: "f", value: 0.0 },
    "shadowMatrix": { type: "m4", value: new THREE$1.Matrix4() },
    "shadowLightDir": { type: "v3", value: new THREE$1.Vector3() }
}, ShadowMapCommonUniforms]);
// Uniform for point-set point size
var PointSizeUniforms = {
    "point_size": { type: "f", value: 1.0 }
};
// Uniform for wide lines shader
var WideLinesUniforms = {
    "view_size": { type: "v2", value: new THREE$1.Vector2(640, 480) }
};
// Uniforms used for reconstructing positions from depth-texture in post-passes. (depth_texture.glsl)
var DepthTextureUniforms = {
    "tDepth": { type: "t", value: null },
    "projInfo": { type: "v4", value: new THREE$1.Vector4() },
    "isOrtho": { type: "f", value: 0.0 },
    "worldMatrix_mainPass": { type: "m4", value: new THREE$1.Matrix4() }
};
/*
 * Chunks are code snippets that can be included in specific shaders
 * using the three.js-style include directive:
 *
 *      #include<name_of_chunk>
 *
 * During runtime this directive can be expanded into the corresponding
 * code snippet using the `resolve` method available below.
 */
var chunks = {};
// We include default three.js chunks, too
for (var name$1 in THREE$1.ShaderChunk) {
    chunks[name$1] = THREE$1.ShaderChunk[name$1];
}
chunks['pack_depth'] = pack_depth;
chunks['depth_texture'] = depth_texture;
chunks['tonemap'] = tonemap;
chunks['ordered_dither'] = ordered_dither;
chunks['cutplanes'] = cutplanes;
chunks['pack_normals'] = pack_normals;
chunks['hatch_pattern'] = hatch_pattern;
chunks['env_sample'] = env_sample;
chunks['id_decl_vert'] = id_decl_vert;
chunks['id_vert'] = id_vert;
chunks['id_decl_frag'] = id_decl_frag;
chunks['id_frag'] = id_frag;
chunks['final_frag'] = final_frag;
chunks['theming_decl_frag'] = theming_decl_frag;
chunks['theming_frag'] = theming_frag;
chunks['instancing_decl_vert'] = instancing_decl_vert;
chunks['shadowmap_decl_common'] = shadowmap_decl_common;
chunks['shadowmap_decl_vert'] = shadowmap_decl_vert;
chunks['shadowmap_vert'] = shadowmap_vert;
chunks['shadowmap_decl_frag'] = shadowmap_decl_frag;
chunks['float3_average'] = float3_average;
chunks['line_decl_common'] = line_decl_common;
chunks['prism_wood'] = prismWood;
chunks['prism_glazing'] = prism_glazing;
chunks['prism_transparency'] = prismTransparency;
chunks['normal_map'] = normalMapChunk;
chunks['decl_point_size'] = decl_point_size;
chunks['point_size'] = point_size;
chunks['wide_lines_decl'] = wide_lines_decl;
chunks['wide_lines_vert'] = wide_lines_vert;
chunks['hsv'] = hsv;
/*
 * Macros are simple JavaScript functions that can be evaluated from
 * within the shader code using a similar syntax as the include directive:
 *
 *      #name_of_macro<first_param, second_param, third_param, ...>
 *
 * All parameters are simply passed to the JavaScript code as strings,
 * i.e., they are not parsed in any way.
 *
 * We use this as a way to call the various Prism helper methods (such as
 * GetPrismMapsDefinitionChunk below) without having to compose the shader
 * code from lists of strings.
 */
var macros = {};
// If any map type is defined, then do whatever "content" is;
// typically it's "#define USE_MAP". In other words, if any map
// is defined, then USE_MAP will also be defined. This constant
// is then checked and determines whether a UV variable is defined, etc.
function GetPrismMapsDefinitionChunk(flag) {
    var def = ["#if defined( USE_SURFACE_ALBEDO_MAP )" + " || defined( USE_SURFACE_ROUGHNESS_MAP )" + " || defined( USE_SURFACE_CUTOUT_MAP )" + " || defined( USE_SURFACE_ANISOTROPY_MAP )" + " || defined( USE_SURFACE_ROTATION_MAP )" + " || defined( USE_OPAQUE_ALBEDO_MAP )" + " || defined( USE_OPAQUE_F0_MAP )" + " || defined( USE_OPAQUE_LUMINANCE_MODIFIER_MAP )" + " || defined( USE_LAYERED_BOTTOM_F0_MAP )" + " || defined( USE_LAYERED_F0_MAP )" + " || defined( USE_LAYERED_DIFFUSE_MAP )" + " || defined( USE_LAYERED_FRACTION_MAP )" + " || defined( USE_LAYERED_ROUGHNESS_MAP )" + " || defined( USE_LAYERED_ANISOTROPY_MAP )" + " || defined( USE_LAYERED_ROTATION_MAP )" + " || defined( USE_METAL_F0_MAP )" + " || defined( USE_SURFACE_NORMAL_MAP )" + " || defined( USE_LAYERED_NORMAL_MAP )", "#define " + flag, "#endif"].join("\n");
    return def;
}
macros['prism_check'] = GetPrismMapsDefinitionChunk;
// Set up code for texture access. If USE_SURFACE_ALBEDO_MAP is defined, for example, this texture access code gets executed.
// If it's not defined, then a simply copy occurs, e.g. "surfaceAlbedo = surface_albedo;" from the variableName and mapType.
function GetPrismMapSampleChunk(mapType, variableName, isFloat, linearize) {
    var suffix = isFloat ? "_v3" : "";
    var declare = isFloat ? "vec3 " : "";
    var average = isFloat ? variableName + " = average(" + variableName + suffix + ");" : "";
    var colorLinearization = linearize ? variableName + suffix + " = SRGBToLinear(" + variableName + suffix + ");" : "";
    var shader = ["#if defined( USE_" + mapType.toUpperCase() + "_MAP )",
    // note: the tiling system needs to modify the uv of the texture per tile, so we use the modified "uv" here, not vUv.
    "vec2 uv_" + mapType + "_map = (" + mapType + "_map_texMatrix * vec3(uv, 1.0)).xy;", mapType.toUpperCase() + "_CLAMP_TEST;", declare + variableName + suffix + " = texture2D(" + mapType + "_map, uv_" + mapType + "_map).xyz;", colorLinearization, "if(" + mapType + "_map_invert) " + variableName + suffix + " = vec3(1.0) - " + variableName + suffix + ";", average, "#else", variableName + " = " + mapType + ";", "#endif"].join("\n");
    return shader;
}
macros['prism_sample_texture'] = function (mapType, varName, isFloat, linearize) {
    return GetPrismMapSampleChunk(mapType, varName, isFloat === 'true', linearize === 'true');
};
function GetPrismMapUniformChunk(mapName) {
    var mtxName = mapName + "_texMatrix";
    var mapInvt = mapName + "_invert";
    var macroName = "USE_" + mapName;
    var uniforms = ["#if defined( " + macroName.toUpperCase() + " )", "uniform sampler2D " + mapName + ";", "uniform mat3 " + mtxName + ";", "uniform bool " + mapInvt + ";", "#endif"].join("\n");
    return uniforms;
}
macros['prism_uniforms'] = GetPrismMapUniformChunk;
function GetPrismBumpMapUniformChunk(mapName) {
    var mtxName = mapName + "_texMatrix";
    var mapScale = mapName + "_bumpScale";
    var mapType = mapName + "_bumpmapType";
    var macroName = "USE_" + mapName;
    var uniforms = ["#if defined( " + macroName.toUpperCase() + " )", "uniform sampler2D " + mapName + ";", "uniform mat3 " + mtxName + ";", "uniform vec2 " + mapScale + ";", "uniform int " + mapType + ";", "#endif"].join("\n");
    return uniforms;
}
macros['prism_bump_uniforms'] = GetPrismBumpMapUniformChunk;
// Precompile regexes for the macros
var _regExCache = {};
for (name$1 in macros) {
    _regExCache[name$1] = new RegExp('#' + name$1 + ' *<([\\w\\d., ]*)>', 'g');
}
/**
 * Recursively resolves include directives and macros.
 * @param {string} source Original shader code.
 * @returns {string} Shader code with all includes resolved.
 */
var resolve = function resolve(source) {
    for (var name in macros) {
        var re = _regExCache[name];
        source = source.replace(re, function (match, parens) {
            var params = parens.split(',').map(function (param) {
                return param.trim();
            });
            return macros[name].apply(null, params);
        });
    }
    var pattern = /#include *<([\w\d.]+)>/g;
    var func = function func(match, include) {
        if (!chunks[include]) {
            throw new Error('Cannot resolve #include<' + include + '>');
        }
        return resolve(chunks[include]);
    };
    return source.replace(pattern, func);
};
// The chunks don't have to be exported anymore, but we keep them
// for backwards compatibility (they're still referenced in LegacyNamespace.js)
var PackDepthShaderChunk = chunks['pack_depth'];
var TonemapShaderChunk = chunks['tonemap'];
var OrderedDitheringShaderChunk = chunks['ordered_dither'];
var CutPlanesShaderChunk = chunks['cutplanes'];
var PackNormalsShaderChunk = chunks['pack_normals'];
var HatchPatternShaderChunk = chunks['hatch_pattern'];
var EnvSamplingShaderChunk = chunks['env_sample'];
var IdVertexDeclaration = chunks['id_decl_vert'];
var IdVertexShaderChunk = chunks['id_vert'];
var IdFragmentDeclaration = chunks['id_decl_frag'];
var IdOutputShaderChunk = chunks['id_frag'];
var FinalOutputShaderChunk = chunks['final_frag'];
var ThemingFragmentDeclaration = chunks['theming_decl_frag'];
var ThemingFragmentShaderChunk = chunks['theming_frag'];
var InstancingVertexDeclaration = chunks['instancing_decl_vert'];
var ShadowMapDeclareCommonUniforms = chunks['shadowmap_decl_common'];
var ShadowMapVertexDeclaration = chunks['shadowmap_decl_vert'];
var ShadowMapVertexShaderChunk = chunks['shadowmap_vert'];
var ShadowMapFragmentDeclaration = chunks['shadowmap_decl_frag'];
var PointSizeDeclaration = chunks['decl_point_size'];
var PointSizeShaderChunk = chunks['point_size'];
var ShaderChunks = {
    IdUniforms: IdUniforms,
    ThemingUniform: ThemingUniform,
    CutPlanesUniforms: CutPlanesUniforms,
    ShadowMapCommonUniforms: ShadowMapCommonUniforms,
    ShadowMapUniforms: ShadowMapUniforms,
    PointSizeUniforms: PointSizeUniforms,
    WideLinesUniforms: WideLinesUniforms,
    DepthTextureUniforms: DepthTextureUniforms,
    PackDepthShaderChunk: PackDepthShaderChunk,
    TonemapShaderChunk: TonemapShaderChunk,
    OrderedDitheringShaderChunk: OrderedDitheringShaderChunk,
    CutPlanesShaderChunk: CutPlanesShaderChunk,
    PackNormalsShaderChunk: PackNormalsShaderChunk,
    HatchPatternShaderChunk: HatchPatternShaderChunk,
    EnvSamplingShaderChunk: EnvSamplingShaderChunk,
    IdVertexDeclaration: IdVertexDeclaration,
    IdVertexShaderChunk: IdVertexShaderChunk,
    IdFragmentDeclaration: IdFragmentDeclaration,
    IdOutputShaderChunk: IdOutputShaderChunk,
    FinalOutputShaderChunk: FinalOutputShaderChunk,
    ThemingFragmentDeclaration: ThemingFragmentDeclaration,
    ThemingFragmentShaderChunk: ThemingFragmentShaderChunk,
    InstancingVertexDeclaration: InstancingVertexDeclaration,
    ShadowMapDeclareCommonUniforms: ShadowMapDeclareCommonUniforms,
    ShadowMapVertexDeclaration: ShadowMapVertexDeclaration,
    ShadowMapVertexShaderChunk: ShadowMapVertexShaderChunk,
    ShadowMapFragmentDeclaration: ShadowMapFragmentDeclaration,
    PointSizeDeclaration: PointSizeDeclaration,
    PointSizeShaderChunk: PointSizeShaderChunk,
    GetPrismMapSampleChunk: GetPrismMapSampleChunk,
    GetPrismMapUniformChunk: GetPrismMapUniformChunk,
    resolve: resolve
};

var basic_vert = "#include<id_decl_vert>\n#include<decl_point_size>\n#include<common>\n#include<map_pars_vertex>\n#include<lightmap_pars_vertex>\n#include<envmap_pars_vertex>\n#include<color_pars_vertex>\n#include<morphtarget_pars_vertex>\n#include<skinning_pars_vertex>\n#include<logdepthbuf_pars_vertex>\n#include<wide_lines_decl>\n#if NUM_CUTPLANES > 0\nvarying vec3 vWorldPosition;\n#endif\nvoid main() {\n#include<map_vertex>\n#include<lightmap_vertex>\n#include<color_vertex>\n#include<skinbase_vertex>\n#ifdef USE_ENVMAP\n#include<morphnormal_vertex>\n#include<skinnormal_vertex>\n#include<defaultnormal_vertex>\n#endif\n#include<morphtarget_vertex>\n#include<skinning_vertex>\n#include<default_vertex>\n#include<wide_lines_vert>\n#include<logdepthbuf_vertex>\n#include<worldpos_vertex>\n#if NUM_CUTPLANES > 0\n    vec4 _worldPosition = modelMatrix * vec4( position, 1.0 );\n    vWorldPosition = _worldPosition.xyz;\n#endif\n#include<envmap_vertex>\n#include<id_vert>\n#include<point_size>\n}\n";

var basic_frag = "uniform vec3 diffuse;\nuniform float opacity;\n#include<common>\n#include<color_pars_fragment>\n#include<map_pars_fragment>\n#include<alphamap_pars_fragment>\n#include<lightmap_pars_fragment>\n#include<envmap_pars_fragment>\n#include<fog_pars_fragment>\n#include<specularmap_pars_fragment>\n#include<logdepthbuf_pars_fragment>\n#if NUM_CUTPLANES > 0\nvarying highp vec3 vWorldPosition;\n#endif\n#include<cutplanes>\n#include<id_decl_frag>\n#include<theming_decl_frag>\nvoid main() {\n#if NUM_CUTPLANES > 0\n    checkCutPlanes(vWorldPosition);\n#endif\n    vec3 outgoingLight = vec3( 0.0 );\n    vec4 diffuseColor = vec4( diffuse, opacity );\n#include<logdepthbuf_fragment>\n#include<map_fragment>\n#include<color_fragment>\n#include<alphamap_fragment>\n#include<alphatest_fragment>\n#include<specularmap_fragment>\n    outgoingLight = diffuseColor.rgb;\n#include<lightmap_fragment>\n#include<envmap_fragment>\n#include<linear_to_gamma_fragment>\n#include<fog_fragment>\n    gl_FragColor = vec4( outgoingLight, diffuseColor.a );\n#include<theming_frag>\n#include<final_frag>\n}\n";

//Replacement for the THREE BasicMaterial adding cut plane support
var BasicShader = {
    uniforms: THREE$1.UniformsUtils.merge([THREE$1.UniformsLib["common"], THREE$1.UniformsLib["fog"], THREE$1.UniformsLib["shadowmap"], ShaderChunks.CutPlanesUniforms, ShaderChunks.IdUniforms, ShaderChunks.ThemingUniform, ShaderChunks.PointSizeUniforms, ShaderChunks.WideLinesUniforms]),
    vertexShader: basic_vert,
    fragmentShader: basic_frag
};
THREE$1.ShaderLib['firefly_basic'] = BasicShader;

var screen_quad_uv_vert = "varying vec2 vUv;\nvoid main() {\n    vUv = uv;\n    gl_Position = projectionMatrix * modelViewMatrix * vec4( position, 1.0 );\n}\n";

var blend_frag = "uniform sampler2D tDiffuse;\nuniform sampler2D tAO;\nuniform int useAO;\nuniform float aoOpacity;\nuniform sampler2D tOverlay;\nuniform int useOverlay;\nuniform vec2 resolution;\nuniform int objID;\nuniform vec4 objIDv4;\nuniform sampler2D tID;\n#if defined(USE_MODEL_ID)\nuniform vec2 modelIDv2;\nuniform sampler2D tID2;\n#endif\nuniform float highlightIntensity;\nuniform vec3 selectionColor;\nuniform int highlightRange;\nuniform int objIDStart;\nuniform int objIDEnd;\n#ifdef IS_2D\nuniform float expand2dSelection;\n#endif\nvarying vec2 vUv;\n#include<tonemap>\nbool isSelected(vec3 C) {\n    float minS = min(selectionColor.r, min(selectionColor.g, selectionColor.b));\n    float maxS = max(selectionColor.r, max(selectionColor.g, selectionColor.b));\n    float satS = maxS - minS;\n    float minC = min(C.r, min(C.g, C.b));\n    float maxC = max(C.r, max(C.g, C.b));\n    float satC = maxC - minC;\n    if (satC < .01 || satS < .01)\n        return false;\n    vec3 S = (selectionColor - minS) / satS;\n    vec3 H = (C - minC) / satC;\n    vec3 D = H - S;\n    float eps = .15;\n    return (abs(D.r) + abs(D.g) + abs(D.b) < eps)\n        || (maxC >= (1.0 - eps) && D.r >= -eps && D.g >= -eps && D.b >= -eps);\n}\nvec4 overlayEdgeDetect(vec2 vUv) {\n#define IS_SELECTION(C) isSelected((C).rgb)\n#ifdef IS_2D\n#define MAX_ALPHA(c)\n#define SUM_ALPHA(c, w) sumAlpha += c.a * w; sumWeight += w;\n#else\n#define MAX_ALPHA(c) maxAlpha = max(maxAlpha, c.a);\n#define SUM_ALPHA(c, w) \n#endif\n#define CHECK_EDGE_ALPHA(I, J, W)     { vec4 c = texture2D( tOverlay, vUv+resolution*vec2((I),(J)) ); MAX_ALPHA(c) if (c.a > 0.0 && IS_SELECTION(c)) { hasEdge++; SUM_ALPHA(c, W) selectionPixel = c; } }\n#ifndef IS_2D\n#define CHECK_EDGE_SELECTION(I, J) { vec4 c = texture2D( tOverlay, vUv+resolution*vec2((I),(J)) ); MAX_ALPHA(c) if (c.a <= 0.0) hasEdge++; }\n#endif\n    int hasEdge = 0;\n    vec4 center = texture2D(tOverlay, vUv);\n    vec4 selectionPixel = vec4(0.0);\n#ifdef IS_2D\n    float sumAlpha = 0.0, sumWeight = 0.0;\n#else\n    float maxAlpha = 0.0;\n    bool paintOutline = false;\n#endif\n    if (center.a <= 0.0) {\n        CHECK_EDGE_ALPHA(-1.0,-1.0, 1.0);\n        CHECK_EDGE_ALPHA( 0.0,-1.0, 2.0);\n        CHECK_EDGE_ALPHA( 1.0,-1.0, 1.0);\n        CHECK_EDGE_ALPHA(-1.0, 0.0, 2.0);\n        CHECK_EDGE_ALPHA( 1.0, 0.0, 2.0);\n        CHECK_EDGE_ALPHA(-1.0, 1.0, 1.0);\n        CHECK_EDGE_ALPHA( 0.0, 1.0, 2.0);\n        CHECK_EDGE_ALPHA( 1.0, 1.0, 1.0);\n        if (hasEdge != 0) {\n#ifdef IS_2D\n            center.a = -clamp(expand2dSelection - 1.0 + sumAlpha / sumWeight, 0.0, 1.0);\n            center.rgb = center.a < 0.0 ? selectionPixel.rgb : center.rgb;\n#else\n            center = selectionPixel;\n            paintOutline = true;\n#endif\n        }\n    }\n    else if (center.a > 0.0 && IS_SELECTION(center)) {\n#ifdef IS_2D\n        center.a = -clamp(center.a + expand2dSelection, 0.0, 1.0);\n#else\n        CHECK_EDGE_SELECTION(-1.0,-1.0);\n        CHECK_EDGE_SELECTION( 0.0,-1.0);\n        CHECK_EDGE_SELECTION( 1.0,-1.0);\n        CHECK_EDGE_SELECTION(-1.0, 0.0);\n        CHECK_EDGE_SELECTION( 1.0, 0.0);\n        CHECK_EDGE_SELECTION(-1.0, 1.0);\n        CHECK_EDGE_SELECTION( 0.0, 1.0);\n        CHECK_EDGE_SELECTION( 1.0, 1.0);\n        if (hasEdge != 0)\n            paintOutline = true;\n        else\n            center.a = -center.a;\n#endif\n    }\n#ifndef IS_2D\n    if (paintOutline) {\n        float maxComponent = max(center.r, max(center.g, center.b));\n        center.rgb /= maxComponent;\n        center.rgb = sqrt(center.rgb);\n        center.a = 0.5 + 0.5 * maxAlpha * 0.125 * float(hasEdge);\n    }\n#endif\n    return center;\n}\nvec4 sampleColor() {\n    return texture2D( tDiffuse, vUv );\n}\nfloat sampleAO() {\n    return (useAO != 0) ? sqrt(texture2D(tAO, vUv).r) : 1.0;\n}\nvoid applyHighlighting(inout vec3 rgb) {\n#ifdef IS_2D\n    rgb = mix(rgb, vec3(1.0,1.0,0.0), highlightIntensity * 0.25);\n#else\n    rgb += highlightIntensity * 0.20;\n#endif\n}\nvoid main() {\n    vec4 texel = sampleColor();\n    float ao = sampleAO();\n    ao = 1.0 - (1.0 - ao) * aoOpacity;\n    texel.rgb *= ao;\n    if (useOverlay != 0) {\n        vec4 overlay = overlayEdgeDetect(vUv);\n        if (overlay.a < 0.0) {\n            overlay.a = -overlay.a;\n#ifdef IS_2D\n            overlay.a *= 0.75;\n#else\n            if (overlay.a >= 0.99) {\n                overlay.a = 0.75;\n                texel.rgb = vec3(luminance_post(texel.rgb));\n            }\n#endif\n        }\n        texel.rgb = mix(texel.rgb, sqrt(overlay.rgb), overlay.a);\n    }\n    if (highlightRange == 0) {\n        if (objID != 0) {\n            vec4 idAtPixel = texture2D(tID, vUv);\n#if defined(USE_MODEL_ID)\n            vec4 modelAtPixel = texture2D(tID2, vUv);\n            idAtPixel.a = modelAtPixel.b;\n            vec4 idDelta = abs(idAtPixel.rgba - objIDv4.rgba);\n            vec2 modelDelta = abs(modelAtPixel.rg - modelIDv2.rg);\n#else\n            vec4 idDelta = vec4(abs(idAtPixel.rgb - objIDv4.rgb), 0.0);\n            vec2 modelDelta = vec2(0.0, 0.0);\n#endif\n            if (max(max(modelDelta.r, modelDelta.g), max(max(idDelta.r, idDelta.g), max(idDelta.b, idDelta.a))) < 1e-3) {\n                applyHighlighting(texel.rgb);\n            }\n        }\n    } else {\n        vec4 idAtPixel = texture2D(tID, vUv);\n        int dbId = int(idAtPixel.r * 255.0 + idAtPixel.g * 255.0 * 256.0 + idAtPixel.b * 255.0 * 256.0 * 256.0);\n        if (dbId >= objIDStart && dbId <= objIDEnd) {\n            applyHighlighting(texel.rgb);\n        }\n    }\n    gl_FragColor = texel;\n}\n";

// Shader that composes a final frame from the color target, SAO target, and overlays target.
// defines: {
//     USE_MODEL_ID
// }
var BlendShader = {
    uniforms: {
        "tDiffuse": { type: "t", value: null },
        "tAO": { type: "t", value: null },
        "useAO": { type: "i", value: 0 },
        "aoOpacity": { type: "f", value: 1.0 },
        "tOverlay": { type: "t", value: null },
        "useOverlay": { type: "i", value: 0 },
        "tID": { type: "t", value: null },
        "objID": { type: "i", value: 0 },
        "objIDv4": { type: "v4", value: new THREE$1.Vector4(0, 0, 0, 0) },
        // #if defined(USE_MODEL_ID)
        "tID2": { type: "t", value: null },
        "modelIDv2": { type: "v2", value: new THREE$1.Vector2(0, 0) },
        // #endif
        "highlightIntensity": { type: "f", value: 1.0 },
        "selectionColor": { type: "c", value: new THREE$1.Color(0, 0, 0) },
        "expand2dSelection": { type: "f", value: 0.5 },
        "resolution": { type: "v2", value: new THREE$1.Vector2(1 / 1024, 1 / 512) },
        //Enable these if the forward pass renders in HDR-linear target and the Blend shader is doing the tone mapping
        //"exposureBias" : { type:"f", value: 1.0 },
        //"toneMapMethod" : { type:"i", value: 0 }
        "highlightRange": { type: "i", value: 0 },
        "objIDStart": { type: "i", value: 0 },
        "objIDEnd": { type: "i", value: 0 }
    },
    vertexShader: screen_quad_uv_vert,
    fragmentShader: blend_frag
};

var cel_frag = "#extension GL_OES_standard_derivatives : enable\n#include<depth_texture>\nuniform sampler2D tDiffuse;\nuniform sampler2D tID;\nuniform vec2 resolution;\nuniform float cameraNear;\nuniform float cameraFar;\nuniform sampler2D tFill;\nuniform sampler2D tPaper;\nuniform int style;\nuniform int idEdges;\nuniform int normalEdges;\nuniform int depthEdges;\nuniform float brightness;\nuniform float contrast;\nuniform int grayscale;\nuniform int preserveColor;\nuniform float levels;\nuniform float repeats;\nuniform float rotation;\nuniform sampler2D tGraphite1;\nuniform sampler2D tGraphite2;\nuniform sampler2D tGraphite3;\nuniform sampler2D tGraphite4;\nuniform sampler2D tGraphite5;\nuniform sampler2D tGraphite6;\nuniform sampler2D tGraphite7;\nuniform sampler2D tGraphite8;\nvarying vec2 vUv;\nvec4 recoverNZ(vec4 nrmz) {\n    float z = sqrt(1.0 - dot(nrmz.xy, nrmz.xy));\n    nrmz.w = -(nrmz.z + cameraNear) / (cameraFar - cameraNear);\n    nrmz.z = z;\n    return nrmz;\n}\n#include<tonemap>\n#include<hsv>\nvec3 quantize(vec3 c) {\n    float L = max(c.r, max(c.g, c.b));\n    c *= floor(L * (levels-1.0) + 0.5) / (L * (levels-1.0));\n    return c;\n}\nvec3 quantizeRGB(vec3 c) {\n    c *= c;\n    c *= floor(c * levels * 0.9999) / (levels-1.0);\n    return sqrt(c);\n}\nvec3 clampHue(vec3 c, float hues, float sats, float vals) {\n    vec3 hsv = rgb2hsv(c);\n    hsv.x = floor(hsv.x * hues + 0.5) / hues;\n    hsv.y = floor(hsv.y * sats + 0.5) / sats;\n    hsv.z = floor(hsv.z * vals + 0.5) / vals;\n    vec3 col = hsv2rgb(hsv);\n    return col;\n}\nvec3 reconstructCSFaceNormal(vec3 C) {\n    return normalize(cross(dFdy(C), dFdx(C)));\n}\nvec3 getPosition(ivec2 ssP, float depth) {\n    vec3 P;\n    P = reconstructCSPosition(vec2(ssP) + vec2(0.5), depth);\n    return P;\n}\nint isObjectEdge() {\n    vec4 MM = texture2D(tID, vUv);\n    vec4 LL = texture2D(tID, vUv + vec2(-1.0, -1.0) * resolution);\n    if (MM != LL) return 1;\n    vec4 LM = texture2D(tID, vUv + vec2( 0.0, -1.0) * resolution);\n    if (MM != LM) return 1;\n    vec4 LR = texture2D(tID, vUv + vec2( 1.0, -1.0) * resolution);\n    if (MM != LR) return 1;\n    vec4 ML = texture2D(tID, vUv + vec2(-1.0,  0.0) * resolution);\n    if (MM != ML) return 1;\n    vec4 MR = texture2D(tID, vUv + vec2( 1.0,  0.0) * resolution);\n    if (MM != MR) return 1;\n    vec4 UL = texture2D(tID, vUv + vec2(-1.0,  1.0) * resolution);\n    if (MM != UL) return 1;\n    vec4 UM = texture2D(tID, vUv + vec2( 0.0,  1.0) * resolution);\n    if (MM != UM) return 1;\n    vec4 UR = texture2D(tID, vUv + vec2( 1.0,  1.0) * resolution);\n    if (MM != UR) return 1;\n    return (MM.x + MM.y + MM.z + MM.w) >= 4.0 ? 0 : -1;\n}\nconst float r = 1.0;\nfloat normalDiff(vec3 n1, vec3 n2) {\n    float d = dot(n1.xyz, n2.xyz);\n    return acos(clamp(d, -1.0, 1.0));\n}\nint isNormalDepthEdge() {\n    ivec2 ssC = ivec2(gl_FragCoord.xy);\n    vec4 MM = texture2D(tDepth, vUv);\n    vec4 LL = texture2D(tDepth, vUv + vec2(-r, -r) * resolution);\n    vec4 LM = texture2D(tDepth, vUv + vec2( 0.0, -r) * resolution);\n    vec4 LR = texture2D(tDepth, vUv + vec2( r, -r) * resolution);\n    vec4 ML = texture2D(tDepth, vUv + vec2(-r,  0.0) * resolution);\n    vec4 MR = texture2D(tDepth, vUv + vec2( r,  0.0) * resolution);\n    vec4 UL = texture2D(tDepth, vUv + vec2(-r, r) * resolution);\n    vec4 UM = texture2D(tDepth, vUv + vec2( 0.0,  r) * resolution);\n    vec4 UR = texture2D(tDepth, vUv + vec2( r,  r) * resolution);\n    LL = recoverNZ(LL);\n    LM = recoverNZ(LM);\n    LR = recoverNZ(LR);\n    ML = recoverNZ(ML);\n    MM = recoverNZ(MM);\n    MR = recoverNZ(MR);\n    UL = recoverNZ(UL);\n    UM = recoverNZ(UM);\n    UR = recoverNZ(UR);\n    float dd = 0.0;\n    if ( depthEdges == 1 ) {\n        float G = (abs(UL.w - MM.w) + 2.0 * abs(UM.w - MM.w) + abs(UR.w - MM.w) + 2.0 * abs(ML.w - MM.w) + 2.0 * abs(MR.w - MM.w) + abs(LL.w - MM.w) + 2.0 * abs(LM.w - MM.w) + abs(LR.w - MM.w));\n        dd = abs(dFdx(G)) + abs(dFdy(G));\n    }\n    float Gn = 0.0;\n    if ( normalEdges == 1 ) {\n        float pLL = normalDiff(LL.xyz, MM.xyz);\n        float pLM = normalDiff(LM.xyz, MM.xyz);\n        float pLR = normalDiff(LR.xyz, MM.xyz);\n        float pML = normalDiff(ML.xyz, MM.xyz);\n        float pMM = normalDiff(MM.xyz, MM.xyz);\n        float pMR = normalDiff(MR.xyz, MM.xyz);\n        float pUL = normalDiff(UL.xyz, MM.xyz);\n        float pUM = normalDiff(UM.xyz, MM.xyz);\n        float pUR = normalDiff(UR.xyz, MM.xyz);\n        Gn = (abs(pUL - pMM) + 2.0 * abs(pUM - pMM) + abs(pUR - pMM) + 2.0 * abs(pML - pMM) + 2.0 * abs(pMR - pMM) + abs(pLL - pMM) + 2.0 * abs(pLM - pMM) + abs(pLR - pMM));\n    }\n    \n    return (dd > 0.004 || Gn > 2.0) ? 1 : 0;\n}\nvec3 computeGraphite( vec3 color, vec2 loc ) {\n    float lum = 0.299 * color.r + 0.587 * color.g + 0.114 * color.b;\n    float offset;\n    vec3 col1, col2;\n    if ( lum > 6.0/7.0 ) {\n        col1 = texture2D(tGraphite1, loc ).xyz;\n        col2 = texture2D(tGraphite2, loc ).xyz;\n        offset = 6.0/7.0;\n    } else if ( lum > 5.0/7.0 ) {\n        col1 = texture2D(tGraphite2, loc ).xyz;\n        col2 = texture2D(tGraphite3, loc ).xyz;\n        offset = 5.0/7.0;\n    } else if ( lum > 4.0/7.0 ) {\n        col1 = texture2D(tGraphite3, loc ).xyz;\n        col2 = texture2D(tGraphite4, loc ).xyz;\n        offset = 4.0/7.0;\n    } else if ( lum > 3.0/7.0 ) {\n        col1 = texture2D(tGraphite4, loc ).xyz;\n        col2 = texture2D(tGraphite5, loc ).xyz;\n        offset = 3.0/7.0;\n    } else if ( lum > 2.0/7.0 ) {\n        col1 = texture2D(tGraphite5, loc ).xyz;\n        col2 = texture2D(tGraphite6, loc ).xyz;\n        offset = 2.0/7.0;\n    } else if ( lum > 1.0/7.0 ) {\n        col1 = texture2D(tGraphite6, loc ).xyz;\n        col2 = texture2D(tGraphite7, loc ).xyz;\n        offset = 1.0/7.0;\n    } else {\n        col1 = texture2D(tGraphite7, loc ).xyz;\n        col2 = texture2D(tGraphite8, loc ).xyz;\n        offset = 0.0;\n    }\n    if ( col1.r == 0.0 && col2.r == 0.0 ) {\n        return vec3(lum,lum,lum);\n    }\n    float t = (lum-offset)*7.0;\n    return (col1 * t + col2 * (1.0 - t));\n}\nvec3 colorWithAdjustments() {\n    vec3 sceneRGB = texture2D(tDiffuse, vUv).xyz;\n    if ( brightness != 0.0 || contrast != 0.0) {\n        if ( brightness < 0.0 )\n        {\n            sceneRGB = sceneRGB * (1.0 + brightness);\n        }\n        else\n        {\n            sceneRGB = sceneRGB + ((1.0 - sceneRGB) * brightness);\n        }\n        float slant = tan(( clamp(contrast,-1.0,1.0) + 1.0) * 3.141592/4.001);\n        sceneRGB = (sceneRGB - 0.5) * slant + 0.5;\n        if ( preserveColor == 1 )\n        {\n            float maxval = max( sceneRGB.r, sceneRGB.g );\n            maxval = max( maxval, sceneRGB.b );\n            if ( maxval > 1.0 )\n            {\n                sceneRGB /= maxval;\n            }\n        }\n        sceneRGB = clamp(sceneRGB,0.0,1.0);\n    }\n    if ( grayscale == 1 ) {\n        sceneRGB.rgb = vec3(luminance_post(sceneRGB.rgb));\n    }\n    return sceneRGB;\n}\nvoid main() {\n    int foundEdge = 0;\n    foundEdge = ( idEdges == 1 && isObjectEdge() == 1 ) ? 1 : 0;\n    if ( foundEdge == 0 && (normalEdges == 1 || depthEdges == 1) ) {\n        foundEdge = isNormalDepthEdge();\n    }\n    vec2 loc = vec2((vUv.x-0.5)*(resolution.y/resolution.x),vUv.y-0.5)*repeats;\n    if ( style > 2 && rotation != 0.0 ) {\n        float rot = 3.14159*rotation;\n        float sinr = sin(rot);\n        float cosr = cos(rot);\n        loc = vec2(loc.x*cosr + -loc.y*sinr, loc.x*sinr + loc.y*cosr);\n    }\n    loc += vec2(0.5,0.5);\n    vec3 color;\n    if ( style == 2 ) {\n        if ( foundEdge == 1 ) {\n            gl_FragColor = vec4(0.0,0.0,0.0,1.0);\n        } else {\n            gl_FragColor = vec4(quantize(colorWithAdjustments()),1.0);\n        }\n    } else if ( style == 3 ) {\n        color = colorWithAdjustments();\n        vec3 graphColor = computeGraphite( color, loc );\n        if ( foundEdge == 1 ) {\n            gl_FragColor = vec4(0.16,0.16,0.16,1.0) + vec4(0.18 * graphColor,0.0);\n        } else {\n            gl_FragColor = vec4(graphColor,1.0);\n        }\n        return;\n    } else if ( style == 4 ) {\n        float fill = texture2D(tFill, loc ).r;\n        float paperStrength = 0.3;\n        vec3 paper = texture2D(tPaper, loc ).rgb;\n        paper = paperStrength * paper + (1.0-paperStrength)*vec3(1.0,1.0,1.0);\n        if ( foundEdge == 1 ) {\n            gl_FragColor = 0.75 * vec4(paper * fill, 1.0);\n        } else {\n            fill = pow(fill,1.6);\n            gl_FragColor = vec4(colorWithAdjustments() * (1.0 - fill) + paper * fill, 1.0);\n        }\n    } else {\n        if ( foundEdge == 1 ) {\n            gl_FragColor = vec4(0.0,0.0,0.0,1.0);\n        } else {\n            gl_FragColor = vec4(colorWithAdjustments(),1.0);\n        }\n        return;        \n    }\n}\n";

var CelShader = {
    uniforms: THREE$1.UniformsUtils.merge([ShaderChunks.DepthTextureUniforms, {
        "tDiffuse": { type: "t", value: null },
        "tID": { type: "t", value: null },
        "resolution": { type: "v2", value: new THREE$1.Vector2(1 / 1024, 1 / 512) },
        "cameraNear": { type: "f", value: 1 },
        "cameraFar": { type: "f", value: 100 },
        "tFill": { type: "t", value: null },
        "tPaper": { type: "t", value: null },
        "style": { type: "i", value: 0 },
        "idEdges": { type: "i", value: 1 },
        "normalEdges": { type: "i", value: 1 },
        "depthEdges": { type: "i", value: 1 },
        "brightness": { type: "f", value: 0.0 },
        "contrast": { type: "f", value: 0.0 },
        "grayscale": { type: "i", value: 0 },
        "preserveColor": { type: "i", value: 0.0 },
        "levels": { type: "f", value: 6.0 },
        "repeats": { type: "f", value: 3.0 },
        "rotation": { type: "f", value: 0.0 },
        "tGraphite1": { type: "t", value: null },
        "tGraphite2": { type: "t", value: null },
        "tGraphite3": { type: "t", value: null },
        "tGraphite4": { type: "t", value: null },
        "tGraphite5": { type: "t", value: null },
        "tGraphite6": { type: "t", value: null },
        "tGraphite7": { type: "t", value: null },
        "tGraphite8": { type: "t", value: null }
    }]),
    vertexShader: screen_quad_uv_vert,
    fragmentShader: cel_frag
};

var copy_frag = "uniform sampler2D tDiffuse;\nvarying vec2 vUv;\nvoid main() {\n    gl_FragColor = texture2D(tDiffuse, vUv);\n}\n";

//Trivial copy pass
var CopyShader = {
    uniforms: {
        "tDiffuse": { type: "t", value: null }
    },
    vertexShader: screen_quad_uv_vert,
    fragmentShader: copy_frag
};

var clear_frag = "uniform vec4 color;\nvoid main() {\n    gl_FragColor = color;\n}\n";

//Trivial clear pass - used to clear with stencil test
var ClearShader = {
    uniforms: {
        "color": { type: "v4", value: new THREE$1.Vector4(0, 0, 0, 0) }
    },
    vertexShader: screen_quad_uv_vert,
    fragmentShader: clear_frag
};

var highlight_frag = "\nuniform sampler2D tHighlight1;\nuniform sampler2D tHighlight0;\nuniform vec4 edgeColor;\nvarying vec2 vUv;\nvoid main() {\n    vec4 top = texture2D(tHighlight0, vUv);\n    vec4 base = texture2D(tHighlight1, vUv);\n    gl_FragColor = all(lessThan(abs(base - edgeColor), vec4(1.0e-2))) ?  base : (base * (1.0 - top.a) + top);\n}\n";

//Simple base to blend highlight targets
var HighlightShader = {
    uniforms: {
        "tHighlight0": { type: "t", value: null },
        "tHighlight1": { type: "t", value: null },
        "edgeColor": { type: "v4", value: new THREE$1.Vector4(1, 1, 1, 1) }
    },
    vertexShader: screen_quad_uv_vert,
    fragmentShader: highlight_frag
};

var fxaa_vert = "uniform vec2 uResolution;\nvarying vec2 vPos;\nvarying vec4 vPosPos;\nvoid main() {\n    vPos = uv;\n    vPosPos.xy = uv + vec2(-0.5, -0.5) * uResolution;\n    vPosPos.zw = uv + vec2( 0.5,  0.5) * uResolution;\n    gl_Position = projectionMatrix * modelViewMatrix * vec4( position, 1.0 );\n}\n";

var fxaa_frag = "#define FXAA_EDGE_SHARPNESS (8.0)\n#define FXAA_EDGE_THRESHOLD (0.125)\n#define FXAA_EDGE_THRESHOLD_MIN (0.05)\n#define FXAA_RCP_FRAME_OPT (0.50)\n#define FXAA_RCP_FRAME_OPT2 (2.0)\nuniform sampler2D tDiffuse;\nuniform highp vec2 uResolution;\nvarying vec2 vPos;\nvarying vec4 vPosPos;\nfloat FxaaLuma(vec3 rgb) {\n    return dot(rgb, vec3(0.299, 0.587, 0.114));\n}\nvoid main() {\n    float lumaNw = FxaaLuma(texture2D(tDiffuse, vPosPos.xy).rgb);\n    float lumaSw = FxaaLuma(texture2D(tDiffuse, vPosPos.xw).rgb);\n    float lumaNe = FxaaLuma(texture2D(tDiffuse, vPosPos.zy).rgb) + 1.0/384.0;\n    float lumaSe = FxaaLuma(texture2D(tDiffuse, vPosPos.zw).rgb);\n    vec3 rgbM = texture2D(tDiffuse, vPos.xy).rgb;\n    float lumaM = FxaaLuma(rgbM.rgb);\n    float lumaMax = max(max(lumaNe, lumaSe), max(lumaNw, lumaSw));\n    float lumaMin = min(min(lumaNe, lumaSe), min(lumaNw, lumaSw));\n    float lumaMaxSubMinM = max(lumaMax, lumaM) - min(lumaMin, lumaM);\n    float lumaMaxScaledClamped = max(FXAA_EDGE_THRESHOLD_MIN, lumaMax * FXAA_EDGE_THRESHOLD);\n    if (lumaMaxSubMinM < lumaMaxScaledClamped) {\n        gl_FragColor = vec4(rgbM, 1.0);\n        return;\n    }\n    float dirSwMinusNe = lumaSw - lumaNe;\n    float dirSeMinusNw = lumaSe - lumaNw;\n    vec2 dir1 = normalize(vec2(dirSwMinusNe + dirSeMinusNw, dirSwMinusNe - dirSeMinusNw));\n    vec3 rgbN1 = texture2D(tDiffuse, vPos.xy - dir1 * FXAA_RCP_FRAME_OPT*uResolution).rgb;\n    vec3 rgbP1 = texture2D(tDiffuse, vPos.xy + dir1 * FXAA_RCP_FRAME_OPT*uResolution).rgb;\n    float dirAbsMinTimesC = min(abs(dir1.x), abs(dir1.y)) * FXAA_EDGE_SHARPNESS;\n    vec2 dir2 = clamp(dir1.xy / dirAbsMinTimesC, -2.0, 2.0);\n    vec3 rgbN2 = texture2D(tDiffuse, vPos.xy - dir2 * FXAA_RCP_FRAME_OPT2*uResolution).rgb;\n    vec3 rgbP2 = texture2D(tDiffuse, vPos.xy + dir2 * FXAA_RCP_FRAME_OPT2*uResolution).rgb;\n    vec3 rgbA = rgbN1 + rgbP1;\n    vec3 rgbB = ((rgbN2 + rgbP2) * 0.25) + (rgbA * 0.25);\n    float lumaB = FxaaLuma(rgbB);\n    if ((lumaB < lumaMin) || (lumaB > lumaMax))\n        gl_FragColor = vec4(rgbA * 0.5, 1.0);\n    else\n        gl_FragColor = vec4(rgbB, 1.0);\n}\n";

/**
 * NVIDIA FXAA 3.11 by TIMOTHY LOTTES
 * "PC VERSION" Quality, ported to WebGL
 * https://gist.githubusercontent.com/bkaradzic/6011431/raw/92a3737404c0e764fa554077b16e07a46442da51/Fxaa3_11.h
 */
var FXAAShader = {
    uniforms: {
        "tDiffuse": { type: "t", value: null },
        "uResolution": { type: "v2", value: new THREE$1.Vector2(1 / 1024, 1 / 512) }
    },
    vertexShader: fxaa_vert,
    fragmentShader: fxaa_frag
};

var sao_blur_frag = "\n#define EDGE_SHARPNESS     (3.0)\n#define SCALE               (2)\n#define R                   (4)\n#define VALUE_TYPE        float\n#define VALUE_COMPONENTS   r\n#define VALUE_IS_KEY       0\n#define KEY_COMPONENTS     gb\n#if __VERSION__ >= 330\nconst float gaussian[R + 1] =\nfloat[](0.153170, 0.144893, 0.122649, 0.092902, 0.062970);\n#endif\nuniform sampler2D   tDiffuse;\nuniform vec2 size;\nuniform vec2 resolution;\nuniform vec2       axis;\nuniform float radius;\n#define  result         gl_FragColor.VALUE_COMPONENTS\n#define  keyPassThrough gl_FragColor.KEY_COMPONENTS\nfloat unpackKey(vec2 p) {\n    return p.x + p.y * (1.0 / 255.0);\n}\nvarying vec2 vUv;\nvoid main() {\n#   if __VERSION__ < 330\n    float gaussian[R + 1];\n#       if R == 3\n    gaussian[0] = 0.153170; gaussian[1] = 0.144893; gaussian[2] = 0.122649; gaussian[3] = 0.092902;\n#       elif R == 4\n    gaussian[0] = 0.153170; gaussian[1] = 0.144893; gaussian[2] = 0.122649; gaussian[3] = 0.092902; gaussian[4] = 0.062970;\n#       elif R == 6\n    gaussian[0] = 0.111220; gaussian[1] = 0.107798; gaussian[2] = 0.098151; gaussian[3] = 0.083953; gaussian[4] = 0.067458; gaussian[5] = 0.050920; gaussian[6] = 0.036108;\n#       endif\n#   endif\n    ivec2 axisi = ivec2(axis);\n    ivec2 ssC = ivec2(gl_FragCoord.xy);\n    vec4 temp = texture2D(tDiffuse, vUv);\n    gl_FragColor.gb = temp.KEY_COMPONENTS;\n    gl_FragColor.a = temp.a;\n    VALUE_TYPE sum = temp.VALUE_COMPONENTS;\n    if (temp.a == 0.0) {\n        result = sum;\n        return;\n    }\n    float key = unpackKey(keyPassThrough);\n    float BASE = gaussian[0];\n    float totalWeight = BASE;\n    sum *= totalWeight;\n    float scale = 1.5 / radius;\n    int r = -4; {\n        vec2 ssUV = vec2(ssC + axisi * (r * SCALE))*resolution;\n        temp = texture2D(tDiffuse, ssUV);\n        float      tapKey = unpackKey(temp.KEY_COMPONENTS);\n        VALUE_TYPE value  = temp.VALUE_COMPONENTS;\n        float weight = 0.3 + gaussian[4];\n        float dz = tapKey - key;\n        weight *= max(0.0, 1.0 - (EDGE_SHARPNESS * 2000.0) * abs(dz) * scale);\n        sum += value * weight;\n        totalWeight += weight;\n    }\n    r = -3; {\n        vec2 ssUV = vec2(ssC + axisi * (r * SCALE))*resolution;\n        temp = texture2D(tDiffuse, ssUV);\n        float      tapKey = unpackKey(temp.KEY_COMPONENTS);\n        VALUE_TYPE value  = temp.VALUE_COMPONENTS;\n        float weight = 0.3 + gaussian[3];\n        float dz = tapKey - key;\n        weight *= max(0.0, 1.0 - (EDGE_SHARPNESS * 2000.0) * abs(dz) * scale);\n        sum += value * weight;\n        totalWeight += weight;\n    }\n    r = -2; {\n        vec2 ssUV = vec2(ssC + axisi * (r * SCALE))*resolution;\n        temp = texture2D(tDiffuse, ssUV);\n        float      tapKey = unpackKey(temp.KEY_COMPONENTS);\n        VALUE_TYPE value  = temp.VALUE_COMPONENTS;\n        float weight = 0.3 + gaussian[2];\n        float dz = tapKey - key;\n        weight *= max(0.0, 1.0 - (EDGE_SHARPNESS * 2000.0) * abs(dz) * scale);\n        sum += value * weight;\n        totalWeight += weight;\n    }\n    r=-1; {\n        vec2 ssUV = vec2(ssC + axisi * (r * SCALE))*resolution;\n        temp = texture2D(tDiffuse, ssUV);\n        float      tapKey = unpackKey(temp.KEY_COMPONENTS);\n        VALUE_TYPE value  = temp.VALUE_COMPONENTS;\n        float weight = 0.3 + gaussian[1];\n        float dz = tapKey - key;\n        weight *= max(0.0, 1.0 - (EDGE_SHARPNESS * 2000.0) * abs(dz) * scale);\n        sum += value * weight;\n        totalWeight += weight;\n    }\n    r = 1; {\n        vec2 ssUV = vec2(ssC + axisi * (r * SCALE))*resolution;\n        temp = texture2D(tDiffuse, ssUV);\n        float      tapKey = unpackKey(temp.KEY_COMPONENTS);\n        VALUE_TYPE value  = temp.VALUE_COMPONENTS;\n        float weight = 0.3 + gaussian[1];\n        float dz = tapKey - key;\n        weight *= max(0.0, 1.0 - (EDGE_SHARPNESS * 2000.0) * abs(dz) * scale);\n        sum += value * weight;\n        totalWeight += weight;\n    }\n    r = 2; {\n        vec2 ssUV = vec2(ssC + axisi * (r * SCALE))*resolution;\n        temp = texture2D(tDiffuse, ssUV);\n        float      tapKey = unpackKey(temp.KEY_COMPONENTS);\n        VALUE_TYPE value  = temp.VALUE_COMPONENTS;\n        float weight = 0.3 + gaussian[2];\n        float dz = tapKey - key;\n        weight *= max(0.0, 1.0 - (EDGE_SHARPNESS * 2000.0) * abs(dz) * scale);\n        sum += value * weight;\n        totalWeight += weight;\n    }\n    r = 3; {\n        vec2 ssUV = vec2(ssC + axisi * (r * SCALE))*resolution;\n        temp = texture2D(tDiffuse, ssUV);\n        float      tapKey = unpackKey(temp.KEY_COMPONENTS);\n        VALUE_TYPE value  = temp.VALUE_COMPONENTS;\n        float weight = 0.3 + gaussian[3];\n        float dz = tapKey - key;\n        weight *= max(0.0, 1.0 - (EDGE_SHARPNESS * 2000.0) * abs(dz) * scale);\n        sum += value * weight;\n        totalWeight += weight;\n    }\n    r = 4; {\n        vec2 ssUV = vec2(ssC + axisi * (r * SCALE))*resolution;\n        temp = texture2D(tDiffuse, ssUV);\n        float      tapKey = unpackKey(temp.KEY_COMPONENTS);\n        VALUE_TYPE value  = temp.VALUE_COMPONENTS;\n        float weight = 0.3 + gaussian[4];\n        float dz = tapKey - key;\n        weight *= max(0.0, 1.0 - (EDGE_SHARPNESS * 2000.0) * abs(dz) * scale);\n        sum += value * weight;\n        totalWeight += weight;\n    }\n    const float epsilon = 0.0001;\n    result = sum / (totalWeight + epsilon);\n}\n";

// Bilateral separable blur pass for SAO shader.
// Derived from http://g3d.cs.williams.edu/websvn/filedetails.php?repname=g3d&path=%2FG3D10%2Fdata-files%2Fshader%2FAmbientOcclusion%2FAmbientOcclusion_blur.pix
// but without the normals being used in the bilateral filter.
var SAOBlurShader = {
    uniforms: {
        tDiffuse: { type: "t", value: null },
        size: { type: "v2", value: new THREE$1.Vector2(512, 512) },
        resolution: { type: "v2", value: new THREE$1.Vector2(1.0 / 512, 1.0 / 512) },
        axis: { type: "v2", value: new THREE$1.Vector2(1, 0) },
        // Width of AO effect in native geometry units (meters or whatever).
        // Same value as passed into SAOShader.js
        radius: { type: "f", value: 50.0 }
    },
    vertexShader: screen_quad_uv_vert,
    fragmentShader: sao_blur_frag
};

var fragmentShader = "\n#include <depth_texture>\n#define USE_MIPMAP 1\nuniform float cameraNear;\nuniform float cameraFar;\nuniform vec2 size;\nuniform vec2 resolution;\nuniform float lumInfluence;\nvarying vec2 vUv;\n#define NUM_SAMPLES (17)\n#define LOG_MAX_OFFSET (3)\n#define MAX_MIP_LEVEL (5)\n#define NUM_SPIRAL_TURNS (5)\n#define MIN_RADIUS (3.0)\nuniform float           projScale;\n#ifdef USE_MIPMAP\nuniform sampler2D tDepth_mip1;\nuniform sampler2D tDepth_mip2;\nuniform sampler2D tDepth_mip3;\nuniform sampler2D tDepth_mip4;\nuniform sampler2D tDepth_mip5;\n#endif\nuniform float radius;\nuniform float bias;\nuniform float intensity;\nvec2 tapLocation(int sampleNumber, float spinAngle, out float ssR){\n    float alpha = float(float(sampleNumber) + 0.5) * (1.0 / float(NUM_SAMPLES));\n    float angle = alpha * (float(NUM_SPIRAL_TURNS) * 6.28) + spinAngle;\n    ssR = alpha;\n    return vec2(cos(angle), sin(angle));\n}\nfloat CSZToKey(float z) {\n    return clamp( (z+cameraNear) / (cameraNear-cameraFar), 0.0, 1.0);\n}\nvoid packKey(float key, out vec2 p) {\n    float temp = floor(key * 255.0);\n    p.x = temp * (1.0 / 255.0);\n    p.y = key * 255.0 - temp;\n}\n#include <pack_depth>\nfloat unpackDepthNearFar( const in vec4 rgba_depth ) {\n    float depth = unpackDepth( rgba_depth );\n    if (depth == 0.0)\n        return -cameraFar * 1.0e10;\n    return depth * (cameraNear - cameraFar) - cameraNear;\n}\nvec3 reconstructCSFaceNormal(vec3 C) {\n    return normalize(cross(dFdy(C), dFdx(C)));\n}\nvec3 reconstructNonUnitCSFaceNormal(vec3 C) {\n    return cross(dFdy(C), dFdx(C));\n}\nvec3 getPosition(ivec2 ssP, float depth) {\n    vec3 P;\n    P = reconstructCSPosition(vec2(ssP) + vec2(0.5), depth);\n    return P;\n}\nvec3 getOffsetPosition(ivec2 ssC, vec2 unitOffset, float ssR) {\n    ivec2 ssP = ivec2(ssR * unitOffset) + ssC;\n    vec3 P;\n    vec2 screenUV = (vec2(ssP) + vec2(0.5)) * resolution;\n#ifdef USE_MIPMAP\n    int mipLevel = int(max(0.0, min(floor(log2(ssR)) - float(LOG_MAX_OFFSET), float(MAX_MIP_LEVEL))));\n    if (mipLevel == 0) {\n        P.z = texture2D(tDepth, screenUV).z;\n        if (P.z == 0.0) P.z = -cameraFar * 1.0e10;\n    }\n    else if (mipLevel == 1)\n        P.z = unpackDepthNearFar(texture2D(tDepth_mip1, screenUV));\n    else if (mipLevel == 2)\n        P.z = unpackDepthNearFar(texture2D(tDepth_mip2, screenUV));\n    else if (mipLevel == 3)\n        P.z = unpackDepthNearFar(texture2D(tDepth_mip3, screenUV));\n    else if (mipLevel == 4)\n        P.z = unpackDepthNearFar(texture2D(tDepth_mip4, screenUV));\n    else if (mipLevel == 5)\n        P.z = unpackDepthNearFar(texture2D(tDepth_mip5, screenUV));\n#else\n    P.z = texture2D(tDepth, screenUV).z;\n    if (P.z == 0.0) P.z = -cameraFar * 1.0e10;\n#endif\n    P = reconstructCSPosition(vec2(ssP) + vec2(0.5), P.z);\n    return P;\n}\nfloat sampleAO(in ivec2 ssC, in vec3 C, in vec3 n_C, in float ssDiskRadius, in int tapIndex, in float randomPatternRotationAngle) {\n    float ssR;\n    vec2 unitOffset = tapLocation(tapIndex, randomPatternRotationAngle, ssR);\n    ssR = max(0.75, ssR * ssDiskRadius);\n    vec3 Q = getOffsetPosition(ssC, unitOffset, ssR);\n    vec3 v = Q - C;\n    float vv = dot(v, v);\n    float vn = dot(v, n_C);\n    const float epsilon = 0.001;\n    float angAdjust = mix(1.0, max(0.0, 1.5 * n_C.z), 0.35);\n#define HIGH_QUALITY\n#ifdef HIGH_QUALITY\n    float f = max(1.0 - vv / (radius * radius), 0.0); return angAdjust * f * max((vn - bias) / sqrt(epsilon + vv), 0.0);\n#else\n    float f = max(radius * radius - vv, 0.0); return angAdjust * f * f * f * max((vn - bias) / (epsilon + vv), 0.0);\n#endif\n}\nconst bool useNoise = true;\nfloat getRandomAngle(vec2 pos) {\n    float dt= dot(pos ,vec2(12.9898,78.233));\n    return 6.28318 * fract(sin(mod(dt,3.14)) * 43758.5453);\n}\nvoid main() {\n    ivec2 ssC = ivec2(gl_FragCoord.xy);\n    vec4 nrmz = texture2D(tDepth, vUv);\n    if (nrmz.z == 0.0) {\n        gl_FragColor.r = 1.0;\n        gl_FragColor.a = 0.0;\n        packKey(1.0, gl_FragColor.gb);\n        return;\n    }\n    vec3 C = getPosition(ssC, nrmz.z);\n    packKey(CSZToKey(C.z), gl_FragColor.gb);\n    float ssDiskRadius = -projScale * radius / mix(C.z, -1.0, isOrtho);\n    float A;\n    if (ssDiskRadius <= MIN_RADIUS) {\n        A = 1.0;\n    } else {\n        float sum = 0.0;\n        float randomPatternRotationAngle = getRandomAngle(vUv);\n        vec3 n_C = vec3(nrmz.x, nrmz.y, sqrt(1.0 - dot(nrmz.xy, nrmz.xy)));\n        sum += sampleAO(ssC, C, n_C, ssDiskRadius, 0, randomPatternRotationAngle);\n        sum += sampleAO(ssC, C, n_C, ssDiskRadius, 1, randomPatternRotationAngle);\n        sum += sampleAO(ssC, C, n_C, ssDiskRadius, 2, randomPatternRotationAngle);\n        sum += sampleAO(ssC, C, n_C, ssDiskRadius, 3, randomPatternRotationAngle);\n        sum += sampleAO(ssC, C, n_C, ssDiskRadius, 4, randomPatternRotationAngle);\n        sum += sampleAO(ssC, C, n_C, ssDiskRadius, 5, randomPatternRotationAngle);\n        sum += sampleAO(ssC, C, n_C, ssDiskRadius, 6, randomPatternRotationAngle);\n        sum += sampleAO(ssC, C, n_C, ssDiskRadius, 7, randomPatternRotationAngle);\n        sum += sampleAO(ssC, C, n_C, ssDiskRadius, 8, randomPatternRotationAngle);\n        sum += sampleAO(ssC, C, n_C, ssDiskRadius, 9, randomPatternRotationAngle);\n        sum += sampleAO(ssC, C, n_C, ssDiskRadius, 10, randomPatternRotationAngle);\n        sum += sampleAO(ssC, C, n_C, ssDiskRadius, 11, randomPatternRotationAngle);\n        sum += sampleAO(ssC, C, n_C, ssDiskRadius, 12, randomPatternRotationAngle);\n        sum += sampleAO(ssC, C, n_C, ssDiskRadius, 13, randomPatternRotationAngle);\n        sum += sampleAO(ssC, C, n_C, ssDiskRadius, 14, randomPatternRotationAngle);\n        sum += sampleAO(ssC, C, n_C, ssDiskRadius, 15, randomPatternRotationAngle);\n        sum += sampleAO(ssC, C, n_C, ssDiskRadius, 16, randomPatternRotationAngle);\n        float intensityDivR6 = intensity / pow(radius, 6.0);\n#ifdef HIGH_QUALITY\n        A = pow(max(0.0, 1.0 - sqrt(sum * (3.0 / float(NUM_SAMPLES)))), intensity);\n#else\n        A = max(0.0, 1.0 - sum * intensityDivR6 * (5.0 / float(NUM_SAMPLES)));\n        A = (pow(A, 0.2) + 1.2 * A*A*A*A) / 2.2;\n#endif\n        if (abs(dFdx(C.z)) < 0.02) {\n            A -= dFdx(A) * (mod(float(ssC.x), 2.0) - 0.5);\n        }\n        if (abs(dFdy(C.z)) < 0.02) {\n            A -= dFdy(A) * (mod(float(ssC.y), 2.0) - 0.5);\n        }\n        A = mix(1.0, A, clamp(ssDiskRadius - MIN_RADIUS,0.0,1.0));\n    }\n    gl_FragColor.r = A;\n    gl_FragColor.a = 1.0;\n}\n";

/* Scalable Ambient Obscurance implementation based on:
   {http://graphics.cs.williams.edu/papers/SAOHPG12/} */
// latest code as of 3/1/2016 found at
// http://g3d.cs.williams.edu/websvn/filedetails.php?repname=g3d&path=%2FG3D10%2Fdata-files%2Fshader%2FAmbientOcclusion%2FAmbientOcclusion_AO.pix
var SAOShader = {
    uniforms: THREE$1.UniformsUtils.merge([ShaderChunks.DepthTextureUniforms, {
        "size": { type: "v2", value: new THREE$1.Vector2(512, 512) },
        "resolution": { type: "v2", value: new THREE$1.Vector2(1 / 512, 1 / 512) },
        "cameraNear": { type: "f", value: 1 },
        "cameraFar": { type: "f", value: 100 },
        "radius": { type: "f", value: 10.0 },
        "bias": { type: "f", value: 0.1 },
        "projScale": { type: "f", value: 500 },
        //"clipInfo":     { type: "v3", value: new THREE.Vector3(100, 99, -100) }, /* zf*zn, zn-zf, zf */
        "intensity": { type: "f", value: 0.4 },
        "tDepth_mip1": { type: "t", value: null },
        "tDepth_mip2": { type: "t", value: null },
        "tDepth_mip3": { type: "t", value: null },
        "tDepth_mip4": { type: "t", value: null },
        "tDepth_mip5": { type: "t", value: null }
    }]),
    vertexShader: screen_quad_uv_vert,
    fragmentShader: fragmentShader
};

var normals_vert = "varying vec3 vNormal;\nvarying float depth;\n#if NUM_CUTPLANES > 0\nvarying vec3 vWorldPosition;\n#endif\n#include<pack_normals>\n#include<instancing_decl_vert>\nvoid main() {\n#ifdef UNPACK_NORMALS\n    vec3 objectNormal = decodeNormal(normal);\n#else\n    vec3 objectNormal = normal;\n#endif\n#ifdef FLIP_SIDED\n    objectNormal = -objectNormal;\n#endif\n    objectNormal = getInstanceNormal(objectNormal);\n    vec3 instPos = getInstancePos(position);\n    vec3 transformedNormal = normalMatrix * objectNormal;\n    vNormal = normalize( transformedNormal );\n#if NUM_CUTPLANES > 0\n    vec4 worldPosition = modelMatrix * vec4( instPos, 1.0 );\n    vWorldPosition = worldPosition.xyz;\n#endif\n    vec4 mvPosition = modelViewMatrix * vec4( instPos, 1.0 );\n    depth = mvPosition.z;\n    vec4 p_Position = projectionMatrix * mvPosition;\n    gl_Position = p_Position;\n}\n";

var normals_frag = "varying highp vec3 vNormal;\nvarying highp float depth;\n#if NUM_CUTPLANES > 0\nvarying vec3 vWorldPosition;\n#endif\n#include<cutplanes>\nvoid main() {\n#if NUM_CUTPLANES > 0\n    checkCutPlanes(vWorldPosition);\n#endif\n    vec3 n = vNormal;\n    n = n * ( -1.0 + 2.0 * float( gl_FrontFacing ) );\n    n = normalize( n );\n    gl_FragColor = vec4(n.x, n.y, depth, 1.0);\n}\n";

// Also known as the depthShader, this shader computes and stores the x and y camera-space normal components and the depth.
//
// The z component of the normal can be derived, since we know it is a positive number and x^2 + y^2 + z^2 = 1.
// The depth is returned in camera space (before projection), so is relative to the world's space. It will need to be
// multiplied by the projection matrix to get the z-depth. For a perspective camera, visible values will be negative
// numbers; for an orthographic camera this is not necessarily the case.
var NormalsShader = {
    uniforms: {
        //"opacity" : { type: "f", value: 1.0 }
        "cutplanes": { type: "v4v", value: [] }
    },
    vertexShader: normals_vert,
    fragmentShader: normals_frag
};

var edge_vert = "\n#if NUM_CUTPLANES > 0\nvarying vec3 vWorldPosition;\n#endif\n#include<instancing_decl_vert>\nvoid main() {\n    vec3 instPos = getInstancePos(position);\n#if NUM_CUTPLANES > 0\n    vec4 worldPosition = modelMatrix * vec4( instPos, 1.0 );\n    vWorldPosition = worldPosition.xyz;\n#endif\n    vec4 mvPosition = modelViewMatrix * vec4( instPos, 1.0 );\n    vec4 p_Position = projectionMatrix * mvPosition;\n    gl_Position = p_Position;\n}";

var edge_frag = "\n#if NUM_CUTPLANES > 0\nvarying vec3 vWorldPosition;\n#endif\n#include<cutplanes>\nuniform vec4 color;\nvoid main() {\n#if NUM_CUTPLANES > 0\n    checkCutPlanes(vWorldPosition);\n#endif\n    gl_FragColor = color;\n}";

//Used for egde topology rendering
var EdgeShader = {
    uniforms: {
        "color": { type: "v4", value: new THREE$1.Vector4(0, 0, 0, 0.3) },
        "cutplanes": { type: "v4v", value: [] }
    },
    vertexShader: edge_vert,
    fragmentShader: edge_frag
};

var line_vert = "\n#include<line_decl_common>\nattribute vec3 fields1;\nattribute vec3 fields2;\nattribute vec4 color4b;\nattribute vec4 dbId4b;\nattribute vec4 flags4b;\nattribute vec4 layerVp4b;\n#ifdef HAS_ELLIPTICALS\nattribute vec3 extraParams;\n#endif\n#ifdef USE_INSTANCING\nattribute vec4 instFlags4b;\n#endif\nuniform mat4 mvpMatrix;\nuniform float pixelsPerUnit;\nuniform float aaRange;\nuniform float viewportId;\nuniform float swap;\n#ifdef HAS_LAYERS\nuniform sampler2D tLayerMask;\n#endif\n#ifdef SELECTION_RENDERER\nuniform sampler2D tSelectionTexture;\nuniform vec2 vSelTexSize;\n#endif\n#ifdef SELECTION_RENDERER\nuniform vec4 selectionColor;\n#endif\nvec2 centralVertex;\nvec2 offsetPosition;\nvec2 cos_sin(const float angle) { return vec2(cos(angle), sin(angle)); }\nvoid min_max(inout vec2 minPt, inout vec2 maxPt, const vec2 p) {\n    minPt = min(minPt, p);\n    maxPt = max(maxPt, p);\n}\n#if defined(USE_INSTANCING)\nfloat getVertexId() { return instFlags4b.x; }\n#else\nfloat getVertexId() { return flags4b.x; }\n#endif\nbool isStartVertex() { return (getVertexId() < VBB_SEG_END_RIGHT); }\nbool isLeftVertex()  { float id = getVertexId(); return ((id == VBB_SEG_END_LEFT || id == VBB_SEG_START_LEFT)); }\nstruct SegmentData { float angle, distAlong, distTotal, lineWidthHalf, lineType; };\nvoid decodeSegmentData(out SegmentData seg) {\n    seg.angle         = fields1.z;\n    seg.distAlong     = fields2.x;\n    seg.distTotal     = fields2.z;\n    seg.lineWidthHalf = fields2.y;\n    seg.lineType      = flags4b.z;\n}\nvoid strokeLineSegment() {\n    SegmentData seg; decodeSegmentData(seg);\n    float isStartCapVertex = isStartVertex() ? -1.0 :  1.0;\n    float isLeftSide       = isLeftVertex( ) ?  1.0 : -1.0;\n    float angleTransverse = seg.angle + isLeftSide * HALF_PI;\n    float lwAdjustment = fsHalfWidth + aaRange;\n    vec2 transverseOffset = cos_sin(angleTransverse) * lwAdjustment;\n    offsetPosition.xy += transverseOffset;\n    float distanceFromStart = max(isStartCapVertex, 0.0) * seg.distAlong;\n    vec2 along = distanceFromStart * cos_sin(seg.angle);\n    offsetPosition.xy += along;\n    centralVertex.xy  += along;\n    vec2 moveOffset = isStartCapVertex * isLeftSide * vec2(-transverseOffset.y, transverseOffset.x);\n    offsetPosition.xy -= moveOffset;\n    centralVertex.xy  -= moveOffset;\n    fsMultipurpose.x = (isStartCapVertex * lwAdjustment) + distanceFromStart;\n    fsMultipurpose.y = seg.distAlong;\n    fsMultipurpose.z = seg.distTotal;\n    fsMultipurpose.w = seg.lineType;\n    if (seg.lineWidthHalf < 0.0)\n        fsHalfWidth = -fsHalfWidth;\n}\n#ifdef HAS_TRIANGLE_GEOMS\nstruct TriangleData { vec2 p0, p1, p2; };\nvoid decodeTriangleData(out TriangleData tri) {\n    tri.p1 = vec2(fields1.z, fields2.x);\n    tri.p2 = fields2.yz;\n}\nvoid strokeOneTriangle() {\n    TriangleData tri; decodeTriangleData(tri);\n    fsHalfWidth = 0.0;\n    fsMultipurpose.z = 0.0;\n    float vertexId = getVertexId();\n    if (vertexId == VBB_SEG_END_RIGHT)\n        offsetPosition.xy = tri.p1;\n    else if (vertexId == VBB_SEG_END_LEFT)\n        offsetPosition.xy = tri.p2;\n}\n#endif\n#ifdef HAS_RASTER_QUADS\nstruct TexQuadData { float angle; vec2 size; };\nvoid decodeTexQuadData(out TexQuadData quad) {\n    quad.angle     = fields1.z;\n    quad.size   = fields2.xy;\n}\nvoid strokeTexQuad() {\n    TexQuadData quad; decodeTexQuadData(quad);\n    vec2 corner = vec2(isLeftVertex() ? -1.0 : 1.0, isStartVertex() ? -1.0 : 1.0);\n    vec2 p      = 0.5 * corner * quad.size;\n    vec2 rot    = cos_sin(quad.angle);\n    vec2 offset = vec2(p.x * rot.x - p.y * rot.y, p.x * rot.y + p.y * rot.x);\n    offsetPosition.xy += offset;\n    fsMultipurpose.xy = max(vec2(0.0), corner);\n    fsMultipurpose.z = 1.0;\n    fsHalfWidth = 0.0;\n}\n#endif\n#if defined(HAS_CIRCLES) || defined(HAS_ELLIPTICALS)\nstruct ArcData { vec2 c; float start, end, major, minor, tilt; };\nvoid decodeArcData(out ArcData arc) {\n    arc.c     = fields1.xy;\n    arc.start = fields1.z;\n    arc.end   = fields2.x;\n    arc.major = fields2.z;\n#if defined(HAS_ELLIPTICALS)\n    arc.minor = extraParams.x;\n    arc.tilt  = extraParams.y;\n#endif\n}\nvoid strokeArc(const ArcData arc) {\n    float isStart = isStartVertex() ? -1.0 : 1.0;\n    float isLeft  = isLeftVertex()  ? -1.0 : 1.0;\n    vec2 minPt;\n    vec2 maxPt;\n    vec2 angles = vec2(arc.start, arc.end);\n    vec2 endsX = vec2(arc.c.x) + arc.major * cos(angles);\n    vec2 endsY = vec2(arc.c.y) + arc.minor * sin(angles);\n    minPt = maxPt = vec2(endsX.x, endsY.x);\n    min_max(minPt, maxPt, vec2(endsX.y, endsY.y));\n    if (arc.end > arc.start) {\n        if (arc.start < PI_0_5 && arc.end > PI_0_5) {\n            min_max(minPt, maxPt, vec2(arc.c.x, arc.c.y + arc.minor));\n        }\n        if (arc.start < PI && arc.end > PI) {\n            min_max(minPt, maxPt, vec2(arc.c.x - arc.major, arc.c.y));\n        }\n        if (arc.start < PI_1_5 && arc.end > PI_1_5) {\n            min_max(minPt, maxPt, vec2(arc.c.x, arc.c.y - arc.minor));\n        }\n    } else {\n        min_max(minPt, maxPt, vec2(arc.c.x + arc.major, arc.c.y));\n        if (arc.start < PI_0_5 || arc.end > PI_0_5) {\n            min_max(minPt, maxPt, vec2(arc.c.x, arc.c.y + arc.minor));\n        }\n        if (arc.start < PI || arc.end > PI) {\n            min_max(minPt, maxPt, vec2(arc.c.x - arc.major, arc.c.y));\n        }\n        if (arc.start < PI_1_5 || arc.end > PI_1_5) {\n            min_max(minPt, maxPt, vec2(arc.c.x, arc.c.y - arc.minor));\n        }\n    }\n    minPt -= fsHalfWidth + aaRange;\n    maxPt += fsHalfWidth + aaRange;\n    offsetPosition.x = (isStart < 0.0) ? minPt.x : maxPt.x;\n    offsetPosition.y = (isLeft < 0.0)  ? minPt.y : maxPt.y;\n    fsMultipurpose.x = arc.start;\n    fsMultipurpose.y = -arc.major;\n    fsMultipurpose.z = arc.end;\n    fsMultipurpose.w = arc.minor;\n}\n#endif\n#if defined(HAS_CIRCLES)\nvoid strokeCircularArc() {\n    ArcData arc; decodeArcData(arc);\n    float r = arc.major;\n    if (r * pixelsPerUnit < 0.125)\n        r = 0.25 * aaRange;\n    arc.major = arc.minor = r;\n    strokeArc(arc);\n}\n#endif\n#if defined(HAS_ELLIPTICALS)\nvoid strokeEllipticalArc() {\n    ArcData arc; decodeArcData(arc);\n    strokeArc(arc);\n}\n#endif\nstruct CommonAttribs { vec2 pos; vec4 color; vec2 layerTC, vpTC; float lineWidthHalf, geomType, ghosting; };\nvoid decodeCommonAttribs(out CommonAttribs attribs) {\n    attribs.pos           = fields1.xy;\n    attribs.color         = color4b;\n    attribs.geomType      = flags4b.y;\n    attribs.layerTC       = layerVp4b.xy / 255.0;\n    attribs.vpTC          = layerVp4b.zw / 255.0;\n    attribs.lineWidthHalf = fields2.y;\n    attribs.ghosting      = flags4b.w;\n}\nvoid strokeIndexedTriangle() {\n    fsHalfWidth = 0.0;\n    fsMultipurpose.z = 0.0;\n}\n#ifdef SELECTION_RENDERER\nbool isSelected(const CommonAttribs attribs) {\n    vec3 oid = dbId4b.rgb;\n    float id01 = oid.r + oid.g * 256.0;\n    float t = (id01 + 0.5) * (1.0 / 4096.0);\n    float flrt = floor(t);\n    float texU = t - flrt;\n    float id23 = oid.b * (65536.0 / 4096.0) + flrt;\n    t = (id23 + 0.5) / vSelTexSize.y;\n    float texV = fract(t);\n    vec4 selBit = texture2D(tSelectionTexture, vec2(texU, texV));\n    return selBit.r == 1.0;\n}\n#endif\nbool isLayerOff(const CommonAttribs attribs) {\n#ifdef HAS_LAYERS\n    vec4 layerBit = texture2D(tLayerMask, attribs.layerTC);\n    return (layerBit.r == 0.0);\n#else\n    return false;\n#endif\n}\nvec4 getColor(const CommonAttribs attribs) {\n    if (isLayerOff(attribs)) { return vec4(0.0); }\n#ifdef SELECTION_RENDERER\n    if (isSelected(attribs)) { return selectionColor; }\n    return vec4(0.0);\n#else\n    return attribs.color;\n#endif\n}\nvoid main() {\n    CommonAttribs attribs; decodeCommonAttribs(attribs);\n    fsColor = getColor(attribs);\n    if (swap != 0.0 ) {\n        if ( fsColor.r == 0.0 && fsColor.g == 0.0 && fsColor.b == 0.0 )\n            fsColor.rgb = vec3(1.0,1.0,1.0);\n        else if ( fsColor.r == 1.0 && fsColor.g == 1.0 && fsColor.b == 1.0 )\n            fsColor.rgb = vec3(0.0,0.0,0.0);\n    }\n    centralVertex = offsetPosition = attribs.pos;\n    float lineWeight = attribs.lineWidthHalf;\n    if (lineWeight > 0.0) {\n        if(lineWeight < 0.5 / pixelsPerUnit) {\n            lineWeight = 0.5 / pixelsPerUnit;\n        }\n    }\n    else {\n        lineWeight = abs(lineWeight) / pixelsPerUnit;\n    }\n    fsHalfWidth = lineWeight;\n    dbId = dbId4b / 255.0;\n    fsVpTC     = attribs.vpTC;\n    fsGhosting = attribs.ghosting;\n    if      (attribs.geomType == VBB_GT_LINE_SEGMENT)     strokeLineSegment();\n#ifdef HAS_CIRCLES\n    else if (attribs.geomType == VBB_GT_ARC_CIRCULAR)     strokeCircularArc();\n#endif\n#ifdef HAS_ELLIPTICALS\n    else if (attribs.geomType == VBB_GT_ARC_ELLIPTICAL)   strokeEllipticalArc();\n#endif\n#ifdef HAS_RASTER_QUADS\n    else if (attribs.geomType == VBB_GT_TEX_QUAD)         strokeTexQuad();\n#endif\n#ifdef HAS_TRIANGLE_GEOMS\n    else if (attribs.geomType == VBB_GT_ONE_TRIANGLE)     strokeOneTriangle();\n#endif\n    else if (attribs.geomType == VBB_GT_TRIANGLE_INDEXED) strokeIndexedTriangle();\n    fsOffsetDirection = offsetPosition - centralVertex;\n    gl_Position = mvpMatrix * modelMatrix * vec4( offsetPosition.xy, 0.0, 1.0 );\n}\n";

var line_frag = "\n#include<line_decl_common>\nuniform highp float pixelsPerUnit;\nuniform highp float aaRange;\nuniform float opacity;\nuniform highp float viewportId;\nuniform highp float swap;\n#ifdef HAS_RASTER_QUADS\nuniform sampler2D tRaster;\n#endif\n#ifdef HAS_LINESTYLES\nuniform sampler2D tLineStyle;\nuniform vec2 vLineStyleTexSize;\n#endif\n#if defined(MRT_ID_BUFFER) || defined(MODEL_COLOR)\nuniform vec3 modelId;\n#endif\nfloat curveGaussian(float r, float invWidth) {\n    float amt = clamp(r * invWidth, 0.0, 1.0);\n    float exponent = amt * 2.0;\n    return exp(-exponent*exponent);\n}\n#ifdef HAS_LINESTYLES\nfloat getLinePatternPixel(int i, int j) {\n    return texture2D(tLineStyle, (vec2(i, j) + 0.5) / vLineStyleTexSize).x * 255.0;\n}\nfloat getPatternLength(int whichPattern) {\n    float p1 = getLinePatternPixel(0, whichPattern);\n    float p2 = getLinePatternPixel(1, whichPattern);\n    return (p2 * 256.0 + p1);\n}\n#endif\nvoid fillLineSegment() {\n    float radius = abs(fsHalfWidth);\n    float parametricDistance = fsMultipurpose.x;\n    float segmentLength      = fsMultipurpose.y;\n    float totalDistance      = fsMultipurpose.z;\n#ifdef HAS_LINESTYLES\n    int whichPattern         = int(fsMultipurpose.w);\n    if (whichPattern > 0) {\n        const float TEX_TO_UNIT = 1.0 / 96.0;\n        float LTSCALE = 1.0;\n        float patternScale;\n        if (fsHalfWidth < 0.0) {\n            patternScale = LTSCALE;\n        } else {\n            patternScale = LTSCALE * TEX_TO_UNIT * pixelsPerUnit;\n        }\n        float patLen = patternScale * getPatternLength(whichPattern);\n        float phase = mod((totalDistance + parametricDistance) * pixelsPerUnit, patLen);\n        bool onPixel = true;\n        float radiusPixels = radius * pixelsPerUnit;\n        for (int i=2; i<MAX_LINESTYLE_LENGTH; i+=2) {\n            float on = getLinePatternPixel(i, whichPattern);\n            if (on == 1.0) on = 0.0;\n            on *= patternScale;\n            onPixel = true;\n            phase -= on;\n            if (phase < 0.0) {\n                break;\n            }\n            else if (phase <= radiusPixels) {\n                onPixel = false;\n                break;\n            }\n            float off = getLinePatternPixel(i+1, whichPattern);\n            if (off <= 1.0) off = 0.0;\n            off *= patternScale;\n            onPixel = false;\n            phase -= off;\n            if (phase < -radiusPixels)\n                discard;\n            if (phase <= 0.0)\n                break;\n        }\n        if (!onPixel && (abs(phase) <= radiusPixels)) {\n            segmentLength = 0.0;\n            parametricDistance = phase / pixelsPerUnit;\n        }\n    }\n#endif\n    float dist;\n    float offsetLength2 = dot(fsOffsetDirection, fsOffsetDirection);\n    float ltz = max(0.0, sign(-parametricDistance));\n    float gtsl = max(0.0, sign(parametricDistance - segmentLength));\n    float d = (ltz + gtsl) * (parametricDistance - gtsl * segmentLength);\n    dist = sqrt(max(0.0, offsetLength2 + d*d));\n    float range =  dist - radius;\n    if (range > aaRange) {\n        discard;\n    }\n    gl_FragColor = fsColor;\n    gl_FragColor.a *= curveGaussian(range+aaRange, pixelsPerUnit);\n}\n#ifdef HAS_CIRCLES\nvoid fillCircularArc() {\n    float dist   = length(fsOffsetDirection);\n    vec2 angles  = fsMultipurpose.xz;\n    float radius = abs(fsMultipurpose.y);\n    float range  =  abs(dist - radius);\n    range -= fsHalfWidth;\n    if (range > aaRange) {\n        discard;\n    }\n    vec2 direction = fsOffsetDirection;\n    float angle = atan(direction.y, direction.x);\n    if (angles.x > angles.y) {\n        if (angle > angles.x && angle < PI) {\n            angle -= TAU;\n        }\n        angles.x -= TAU;\n        if (angle < angles.x ) {\n            angle += TAU;\n        }\n    }\n    else if (angle < 0.0)\n        angle += TAU;\n    if (angle > angles.x && angle < angles.y) {\n        gl_FragColor = fsColor;\n        gl_FragColor.a *= curveGaussian(range+aaRange, pixelsPerUnit);\n    }\n    else {\n        discard;\n    }\n}\n#endif\n#ifdef HAS_ELLIPTICALS\nfloat EllipticalApprox(\n        const int iters,\n        inout float t0, inout float t1,\n        const vec2 y,   out   vec2 x,\n        const vec2 e,   const vec2 ey, const vec2 esqr\n        ) {\n    vec2 r;\n    for (int i = 0; i < 10; ++i) {\n        if(i >= iters) break;\n        float t = mix(t0, t1, 0.5);\n        r = ey / (vec2(t) + esqr);\n        vec2 rsq = r * r;\n        float f = rsq.x + rsq.y - 1.0;\n        if(f > 0.0) { t0 = t; } else { t1 = t; }\n    }\n    x = e * r;\n    return distance(x, y);\n}\nfloat DistancePointEllipseSpecial (vec2 e, vec2 y, out vec2 x, float width, float aaRange) {\n    float dist;\n    vec2 esqr = e * e;\n    vec2 ey   = e * y;\n    float t0 = -esqr[1] + ey[1];\n    float t1 = -esqr[1] + length(ey);\n    dist = EllipticalApprox(6, t0, t1, y, x, e, ey, esqr);\n    if (dist > max(2.0 * (width + aaRange), e[0] * 0.05))\n        return dist;\n    dist = EllipticalApprox(6, t0, t1, y, x, e, ey, esqr);\n    float ecc = 1.0 +  0.1 * e[0] / e[1];\n    if (dist > max(ecc * (width + aaRange), e[0] * 0.001))\n        return dist;\n    if (dist < (width - aaRange) / ecc)\n        return dist;\n    dist = EllipticalApprox(10, t0, t1, y, x, e, ey, esqr);\n    return dist;\n}\nfloat DistancePointEllipse(vec2 e, vec2 y, out vec2 locX, float width, float aaRange) {\n    vec2 locE, locY;\n    float diff = sign(e[0] - e[1]);\n    vec2 swizzle = vec2(max(diff, 0.0), -min(diff, 0.0));\n    locE.x = dot(e, swizzle.xy);\n    locE.y = dot(e, swizzle.yx);\n    locY.x = dot(y, swizzle.xy);\n    locY.y = dot(y, swizzle.yx);\n    vec2 refl = sign(locY);\n    locY *= refl;\n    vec2 x;\n    float distance = DistancePointEllipseSpecial(locE, locY, x, width, aaRange);\n    x *= refl;\n    locX.x = dot(x, swizzle.xy);\n    locX.y = dot(x, swizzle.yx);\n    return distance;\n}\nvoid fillEllipticalArc() {\n    vec2 angles = fsMultipurpose.xz;\n    vec2 radii  = abs(fsMultipurpose.yw);\n    vec2 dir    = fsOffsetDirection;\n    vec2 pos;\n    float range = DistancePointEllipse(radii, dir, pos, fsHalfWidth, aaRange);\n    range -= fsHalfWidth;\n    if (range > aaRange)\n        discard;\n    float ar = radii[0] / radii[1];\n    float angle = atan(ar * pos.y, pos.x);\n    if (angles.x > angles.y) {\n        if (angle > angles.x && angle < PI) {\n            angle -= TAU;\n        }\n        angles.x -= TAU;\n        if (angle < angles.x ) {\n            angle += TAU;\n        }\n    }\n    else if (angle < 0.0)\n        angle += TAU;\n    if (angle > angles.x && angle < angles.y) {\n        gl_FragColor = fsColor;\n        gl_FragColor.a *= curveGaussian(range+aaRange, pixelsPerUnit);\n    }\n    else {\n        discard;\n    }\n}\n#endif\n#ifdef HAS_RASTER_QUADS\nvoid fillTexQuad() { gl_FragColor = texture2D(tRaster, fsMultipurpose.xy); }\n#endif\nvoid fillTriangle() { gl_FragColor = fsColor; }\nvoid main() {\n    if (fsColor == vec4(0.0)) {\n        discard;\n    }\n    if (fsHalfWidth == 0.0) {\n#ifdef HAS_RASTER_QUADS\n        if (fsMultipurpose.z != 0.0)\n            fillTexQuad();\n        else\n#endif\n            fillTriangle();\n    }\n    else if (fsMultipurpose.y < 0.0) {\n#ifdef HAS_CIRCLES\n#ifdef HAS_ELLIPTICALS\n        if (abs(fsMultipurpose.y) == fsMultipurpose.w)\n#endif\n            fillCircularArc();\n#endif\n#ifdef HAS_ELLIPTICALS\n#ifdef HAS_CIRCLES\n        else\n#endif\n            fillEllipticalArc();\n#endif\n    }\n    else\n        fillLineSegment();\n#ifdef MRT_NORMALS\n    gl_FragData[1] = vec4(0.0);\n#endif\n    float writeId = 1.0;\n    if (fsGhosting != 0.0 || \n            ((viewportId != 0.0) && (abs(fsVpTC.x * 255.0 + fsVpTC.y) >= 0.5 && abs(fsVpTC.x * 255.0 + fsVpTC.y - viewportId) >= 0.5))) {\n        writeId = 0.0;\n        gl_FragColor.a *= opacity * ((swap == 1.0) ? 0.21 : 0.1);\n    } else {\n        gl_FragColor.a *= opacity;\n    }\n#include<id_frag>\n}\n";

var LineShader = {
    uniforms: {
        "pixelsPerUnit": { type: "f", value: 1.0 },
        "aaRange": { type: "f", value: 0.5 },
        "tLayerMask": { type: "t", value: null },
        "tLineStyle": { type: "t", value: null },
        "vLineStyleTexSize": { type: "v2", value: new THREE$1.Vector2(13, 70) },
        "tRaster": { type: "t", value: null },
        "tSelectionTexture": { type: "t", value: null },
        "vSelTexSize": { type: "v2", value: new THREE$1.Vector2(4096, 1) },
        "displayPixelRatio": { type: "f", value: 1.0 },
        "opacity": { type: "f", value: 1.0 },
        "selectionColor": { type: "v4", value: new THREE$1.Vector4(0, 0, 1, 1) },
        "modelId": { type: "v3", value: new THREE$1.Vector3(0, 0, 0) },
        "viewportId": { type: "f", value: 0.0 },
        "swap": { type: "f", value: 0.0 }
    },
    attributes: {
        "fields1": 0,
        "fields2": 0,
        "color4b": 0,
        "dbId4b": 0,
        "flags4b": 0,
        "layerVp4b": 0,
        "extraParams": 0,
        "instFlags4b": 0
    },
    defines: {},
    vertexShader: line_vert,
    fragmentShader: line_frag
};

var occlusion_vert = "\n#include<instancing_decl_vert>\nvarying vec4 finalColor;\nuniform vec3 color;\nuniform float opacity;\nvoid main() {\n    gl_Position = projectionMatrix * (viewMatrix * vec4(getInstancePos(position), 1.0));\n    finalColor = vec4(color, opacity);\n}\n";

var occlusion_frag = "precision lowp float;\nvarying vec4 finalColor;\nvoid main() {\n    gl_FragColor = finalColor;\n}\n";

//Simple shader for occlusion testing
var OcclusionShader = {
    uniforms: {
        "color": { type: "v3", value: new THREE$1.Vector3(0, 0, 0) },
        "opacity": { type: "f", value: 1.0 }
    },
    rawShader: true,
    vertexShader: occlusion_vert,
    fragmentShader: occlusion_frag
};

/** Create ShaderMaterial instance using a given shader specification
 *
 *   @param {Object} shader - Shader specification E.g., CopyShader. Must provide vertexShader and fragmentShader.
 *                            May provide uniforms, defines, and attributes. See CopyShader for example.
 *   @returns {THREE.ShaderMaterial}
 */
var createShaderMaterial = function createShaderMaterial(shader) {
    var params = {
        vertexShader: shader.vertexShader,
        fragmentShader: shader.fragmentShader
    };
    // only add these fields if the shader actually needs them, because keys with undefined values
    // would cause errors in THREE.Material
    if (shader.uniforms) params.uniforms = THREE$1.UniformsUtils.clone(shader.uniforms);
    if (shader.defines) params.defines = Object.assign({}, shader.defines);
    if (shader.extensions) params.extensions = Object.assign({}, shader.extensions);
    // Note that these are shared, because they are usually not modified afterwards
    if (shader.attributes) params.attributes = shader.attributes;
    return new THREE$1.ShaderMaterial(params);
};
/** Add custom macro to given material. Note that macro modification requires expensive shader recompile.
 *   @param {THREE.Material} material
 *   @param {string}         macroName
 *   @param {string}         [macroValue=""]
 **/
var setMacro = function setMacro(material, macroName, macroValue) {
    // default to "" (for simple toggles)
    macroValue = macroValue || "";
    // create defines object if needed
    if (!material.defines) {
        material.defines = {};
    }
    // change macro and trigger update if needed
    if (material.defines[macroName] != macroValue) {
        material.defines[macroName] = macroValue;
        material.needsUpdate = true;
    }
};
/** Remove custom macro to given material. Note that macro modification requires expensive shader recompile.
 *   @param {THREE.Material} material
 *   @param {string}         macroName
 **/
var removeMacro = function removeMacro(material, macroName) {
    // skip material update if nothing changed
    if (material.defines || material.defines[macroName]) {
        // Note that we cannot just assign undefined here, because this would
        // produce a "#define <MACRONAME> undefined" string in the shader (see FireFlyWebGlProgram.js)
        // Fortunately, removing macros doesn't happen per-frame, and it requires shader-recompile anyway.
        delete material.defines[macroName];
        material.needsUpdate = true;
    }
};
var ShaderUtils = {
    createShaderMaterial: createShaderMaterial,
    setMacro: setMacro,
    removeMacro: removeMacro
};

var ShaderPass = function ShaderPass(shader, textureID) {
    this.textureID = textureID !== undefined ? textureID : "tDiffuse";
    this.material = ShaderUtils.createShaderMaterial(shader);
    // share uniforms with material
    this.uniforms = this.material.uniforms;
    this.renderToScreen = false;
    this.enabled = true;
    this.clear = false;
    this.camera = new THREE$1.OrthographicCamera(-1, 1, 1, -1, 0, 1);
    //this.quad = new THREE.Mesh( new THREE.PlaneGeometry( 2, 2 ), this.material );
    //Instead of using a screen quad we use a large triangle -- this is slightly
    //faster (~6% measured in our specific case), due to better cache coherency. See this article:
    //http://michaldrobot.com/2014/04/01/gcn-execution-patterns-in-full-screen-passes/
    var triangle = new THREE$1.BufferGeometry();
    var p = new Float32Array(9);
    p[0] = -1;
    p[1] = -1;
    p[2] = 0;
    p[3] = 3;
    p[4] = -1;
    p[5] = 0;
    p[6] = -1;
    p[7] = 3;
    p[8] = 0;
    var uv = new Float32Array(6);
    uv[0] = 0;
    uv[1] = 0;
    uv[2] = 2;
    uv[3] = 0;
    uv[4] = 0;
    uv[5] = 2;
    var n = new Float32Array(9);
    n[0] = 0;
    n[1] = 0;
    n[2] = 1;
    n[3] = 0;
    n[4] = 0;
    n[5] = 1;
    n[6] = 0;
    n[7] = 0;
    n[8] = 1;
    triangle.addAttribute("position", new THREE$1.BufferAttribute(p, 3));
    triangle.addAttribute("normal", new THREE$1.BufferAttribute(n, 3));
    triangle.addAttribute("uv", new THREE$1.BufferAttribute(uv, 2));
    this.quad = new THREE$1.Mesh(triangle, this.material);
    this.scene = new THREE$1.Scene();
    this.scene.add(this.quad);
};
ShaderPass.prototype = {
    // note: delta is not used
    render: function render(renderer, writeBuffer, readBuffer, delta) {
        if (this.uniforms[this.textureID]) {
            this.uniforms[this.textureID].value = readBuffer.texture || readBuffer;
        }
        if (this.renderToScreen || !writeBuffer) {
            renderer.render(this.scene, this.camera);
        } else {
            renderer.render(this.scene, this.camera, writeBuffer, this.clear);
        }
    }
};

var gaussian_vert = "varying vec2 vUv;\nvoid main() {\n#if defined(HORIZONTAL) && defined(FLIP_UV)\n    vUv = vec2(uv.x, 1.0-uv.y);\n#else\n    vUv = vec2(uv.x, uv.y);\n#endif\n    gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);\n}\n";

var gaussian_frag = "uniform sampler2D tDiffuse;\nuniform vec4 uColor;\nvarying vec2 vUv;\n#ifdef HORIZONTAL\n#define GET_UV(X) vec2(vUv.x + KERNEL_SCALE_H*(X), vUv.y)\n#else\n#define GET_UV(Y) vec2(vUv.x, vUv.y + KERNEL_SCALE_V*(Y))\n#endif\n#define PI 3.14159265358979\n#define SIGMA ((KERNEL_RADIUS+KERNEL_RADIUS+1.0) / 6.0)\n#define SIGMASQ2 (2.0 * SIGMA * SIGMA)\n#define GAUSSIAN(X) ( (1.0 / sqrt(PI * SIGMASQ2)) * exp(-(X)*(X)/SIGMASQ2) )\nvoid main() {\n    vec4 texColSum = vec4(0.0);\n    float gaussSum = 0.0;\n    for (float x=-KERNEL_RADIUS; x<=KERNEL_RADIUS; x+=1.0) {\n        float gauss = GAUSSIAN(x);\n        vec4 texCol = texture2D(tDiffuse, GET_UV(x));\n#ifdef HAS_ALPHA\n        texCol.rgb *= texCol.a;\n#endif\n        texColSum += texCol * gauss;\n        gaussSum += gauss;\n    }\n#ifdef HAS_ALPHA\n    texColSum.rgb /= (texColSum.a == 0.0 ? 0.0001 : texColSum.a);\n#endif\n#ifdef HORIZONTAL\n    gl_FragColor = texColSum/gaussSum;\n#else\n    gl_FragColor = texColSum/gaussSum * uColor;\n#endif\n}\n";

var GaussianShader = {
    uniforms: {
        tDiffuse: { type: "t", value: null },
        uColor: { type: "v4", value: new THREE$1.Vector4(1.0, 1.0, 1.0, 1.0) }
    },
    // defines: {
    //     KERNEL_SCALE_H:  1.0 / 64.0,
    //     KERNEL_SCALE_V:  1.0 / 64.0,
    //     KERNEL_RADIUS: 7.0
    // },
    vertexShader: gaussian_vert,
    fragmentShader: gaussian_frag
};
var GaussianPass = function GaussianPass(width, height, radius, scale, params) {
    var _width = width;
    var _height = height;
    var _blurRadius = radius || 3.0;
    var _pixelScale = scale || 1.0;
    var _blurPassH, _blurPassV;
    var _tmptarget;
    var _params = {
        hasAlpha: params.hasAlpha || false,
        blending: params.blending || false,
        flipUV: params.flipUV || false
    };
    // PUBLIC FUNCTIONS
    this.render = function (renderer, writeBuffer, readBuffer) {
        _blurPassH.render(renderer, _tmptarget, readBuffer); // from readBuffer to intermediary tmp
        _blurPassV.render(renderer, writeBuffer, _tmptarget); // tmp out to write
    };
    this.setSize = function (width, height) {
        this.cleanup();
        _width = width;
        _height = height;
        _tmptarget = new THREE$1.WebGLRenderTarget(width, height, {
            minFilter: THREE$1.LinearFilter,
            magFilter: THREE$1.LinearFilter,
            format: params.format !== undefined ? params.format : THREE$1.RGBAFormat,
            type: params.type !== undefined ? params.type : THREE$1.UnsignedByteType,
            stencilBuffer: false
        });
        _tmptarget.generateMipmaps = false;
        _blurPassH.material.defines.KERNEL_SCALE_H = _blurPassV.material.defines.KERNEL_SCALE_H = (_pixelScale / _width).toFixed(4);
        _blurPassH.material.defines.KERNEL_SCALE_V = _blurPassV.material.defines.KERNEL_SCALE_V = (_pixelScale / _height).toFixed(4);
        _blurPassH.material.needsUpdate = _blurPassV.material.needsUpdate = true;
    };
    this.cleanup = function () {
        if (_tmptarget) _tmptarget.dispose();
    };
    this.setColor = function (color) {
        _blurPassV.material.uniforms.uColor.value.x = color.r;
        _blurPassV.material.uniforms.uColor.value.y = color.g;
        _blurPassV.material.uniforms.uColor.value.z = color.b;
    };
    this.setAlpha = function (alpha) {
        _blurPassV.material.uniforms.uColor.value.w = alpha;
    };
    // INITIALIZATION
    // init shader passes
    _blurPassH = new ShaderPass(GaussianShader);
    _blurPassV = new ShaderPass(GaussianShader);
    // init target
    this.setSize(width, height);
    _blurPassH.material.blending = _blurPassV.material.blending = THREE$1.NoBlending;
    _blurPassH.material.depthWrite = _blurPassV.material.depthWrite = false;
    _blurPassH.material.depthTest = _blurPassV.material.depthTest = false;
    _blurPassH.material.defines.HORIZONTAL = 1;
    _blurPassH.material.defines.KERNEL_RADIUS = _blurPassV.material.defines.KERNEL_RADIUS = _blurRadius.toFixed(1);
    if (_params.blending) {
        _blurPassV.material.transparent = true;
        _blurPassV.material.blending = THREE$1.NormalBlending;
    }
    if (_params.hasAlpha) _blurPassH.material.defines.HAS_ALPHA = _blurPassV.material.defines.HAS_ALPHA = "";
    if (_params.flipUV) _blurPassH.material.defines.FLIP_UV = "";
};

var userAgent = typeof navigator !== "undefined" ? navigator.userAgent.toLowerCase() : "";
var isIOSDevice = function isIOSDevice() {
    return userAgent.match(/ip(ad|hone|od)/);
};
var isAndroidDevice = function isAndroidDevice() {
    return userAgent.indexOf("android") !== -1;
};
var isMobileDevice = function isMobileDevice() {
    return isIOSDevice() || isAndroidDevice();
};
var isChrome = function isChrome() {
    return userAgent.indexOf("chrome") !== -1;
};
var isSafari = function isSafari() {
    return userAgent.indexOf("safari") !== -1 && userAgent.indexOf("chrome") === -1;
};
var isFirefox = function isFirefox() {
    return userAgent.indexOf("firefox") !== -1;
};
var isMac = function isMac() {
    return userAgent.indexOf("mac os") !== -1;
};
var isWindows = function isWindows() {
    return userAgent.indexOf("win32") !== -1 || userAgent.indexOf("windows") !== -1;
};
var isNodeJS = function isNodeJS() {
    return typeof navigator === "undefined";
};
var rescueFromPolymer = function () {
    if (isSafari()) {
        return function (object) {
            if (!window.Polymer) {
                return object;
            }
            for (var p in object) {
                if (p.indexOf("__impl") !== -1) {
                    return object[p];
                }
            }
            return object;
        };
    } else {
        return function (o) {
            return o;
        };
    }
}();
//Maps a relative resource path (like a pack file or texture)
//to an absolute URL (possibly signed).
var pathToURL = function pathToURL(path) {
    if (path.indexOf("://") !== -1 || path.indexOf("urn:") === 0) {
        return path;
    }
    if (typeof window === "undefined") return path;
    var rootRelPath = window.location.pathname;
    //chop off the index.html part
    var lastSlash = rootRelPath.lastIndexOf("/");
    rootRelPath = rootRelPath.substr(0, lastSlash + 1);
    var absPath = window.location.protocol + "//" + window.location.host + rootRelPath + path;
    return absPath;
};
// A list of resources that record the URL and necessary auxilary information (such as ACM headers and / or
// session id) required to get the resource. This bag of collection will be passed from JS to native code so
// all viewer consumable resources could be downloaded on native side for offline viewing.
// avp.assets = isAndroidDevice() ? [] : null;
exports.assets = [];
var clearAssets = function clearAssets() {
    exports.assets = null;
};
/**
 * Fired when the viewer receives and parses the initial model manifest.
 * @event WGS#MODEL_ROOT_LOADED_EVENT
 * @property {object} svf - Parsed SVF/F2D JSON.
 * @property {object} model - Model data.
 */
var MODEL_ROOT_LOADED_EVENT = 'svfLoaded';
/**
 * Fired when a model is removed from the viewer.
 * @event Autodesk.Viewing.Viewer3D#MODEL_UNLOADED_EVENT
 * @property {object} model - Model data.
 */
var MODEL_UNLOADED_EVENT = 'modelUnloaded';
/**
 * Fired when something in the view changes that may expose missing geometry.
 * @event WGS#LOAD_MISSING_GEOMETRY
 * @property {boolean} [delay] - A flag used to aggregate multiple events during user interactions.
 *                               Defaults to true.
 */
var LOAD_MISSING_GEOMETRY = 'loadMissingGeometry';
/**
 * Fired when fragments are loaded on demand
 * @event WGS#FRAGMENTS_LOADED_EVENT
 * @property {Model}    model - The model that loaded the fragment
 * @property {function} getFragIds - A function used to return the list of fragment ids loaded
 * @property {Object}   data - Data used to generate the fragment ids
 */
var FRAGMENTS_LOADED_EVENT = 'fragmentLoaded';
/**
 * Fired when fragments are loaded on demand
 * @event WGS#FILE_LOAD_STARTED
 * @property {Loader}   loader - The loader that is starting to load a file
 */
var FILE_LOAD_STARTED = 'fileLoadStarted';
/**
 * Fired when fragments are loaded on demand
 * @event WGS#GEOMETRY_DOWNLOAD_COMPLETE
 * @property {Model}    model - The model that loaded the fragment
 * @property {boolean}  memoryLimited - Set to true if the model was loaded in memory limited mode
 */
var GEOMETRY_DOWNLOAD_COMPLETE = 'geometryDownloadComplete';
/**
 * Fired when the instance tree is successfully created.
 * @event Autodesk.Viewing.Viewer3D#OBJECT_TREE_CREATED_EVENT
 * @property {object} svf - Parsed SVF/F2D JSON.
 * @property {object} model - Model data.
 */
var OBJECT_TREE_CREATED_EVENT = 'propertyDbLoaded';
/**
 * Fired when there's an error while parsing the instance tree.
 * @event Autodesk.Viewing.Viewer3D#OBJECT_TREE_UNAVAILABLE_EVENT
 * @property {object} svf - Parsed SVF/F2D JSON.
 * @property {object} model - Model data.
 */
var OBJECT_TREE_UNAVAILABLE_EVENT = 'propertyDbUnavailable';
/**
 * Fired when the model/drawing textures finish loading.
 * @event Autodesk.Viewing.Viewer3D#TEXTURES_LOADED_EVENT
 * @property {object} model - Model data.
 */
var TEXTURES_LOADED_EVENT = 'texturesLoaded';
// If true, will use a different code path where data structures are
// optimized for using less memory.
exports.memoryOptimizedLoading = true;
var setMemoryOptimizedLoading = function setMemoryOptimizedLoading(optimized) {
    exports.memoryOptimizedLoading = optimized;
};
var GPU_MEMORY_LIMIT = (isMobileDevice() ? 64 : 256) * 1024 * 1024;
var GPU_OBJECT_LIMIT = isMobileDevice() ? 2500 : 10000;
// Overhead for geometry buffer. 240 bytes by the BufferGeometry object, 112 bytes for
// each of the index and vertex buffer arrays. The buffer used by the index and vertex
// buffer arrays is shared by multiple geometry objects, so we don't include the 64
// byte overhead for that.
var GEOMETRY_OVERHEAD = 464;
// This is the threshold of the projected screen pixel for culling.
var PIXEL_CULLING_THRESHOLD = 1;
var PAGEOUT_SUCCESS = 0;
var PAGEOUT_FAIL = 1;
var PAGEOUT_NONE = 2;
var RENDER_NORMAL = 0; // === RenderQueue.NORMAL !!!
// === RenderQueue.NORMAL !!!
var RENDER_HIGHLIGHTED1 = 1; // === RenderQueue.HIGHLIGHTED !!!
// === RenderQueue.HIGHLIGHTED !!!
var RENDER_HIGHLIGHTED2 = 2; // === RenderQueue.HIGHLIGHTED !!!
// === RenderQueue.HIGHLIGHTED !!!
var RENDER_HIDDEN = 3; // === RenderQueue.HIDDEN !!!
// === RenderQueue.HIDDEN !!!
var RENDER_SHADOWMAP = 4;
var RENDER_FINISHED = 5;
var GROUND_UNFINISHED = 0;
var GROUND_FINISHED = 1;
var GROUND_RENDERED = 2;
// FragmentList flags
// visibility/highlight bitmask flags
// NOTE: This is confusing and it should be fixed, but when the MESH_VISIBLE bit is off, the mesh
// will draw in ghosted mode. To completely skip drawing a mesh, set the HIDE flag.
var MESH_VISIBLE = 1;
var MESH_HIGHLIGHTED = 2;
var MESH_HIDE = 4;
var MESH_ISLINE = 8;
var MESH_MOVED = 16; // indicates if an animation matrix is set
// indicates if an animation matrix is set
var MESH_TRAVERSED = 0x20; // only used for paging: drawn fragments are tagged and then skipped by forEach() until the flag is being reset (e.g. on scene/camera changes)
// only used for paging: drawn fragments are tagged and then skipped by forEach() until the flag is being reset (e.g. on scene/camera changes)
var MESH_DRAWN = 0x40; // only used for paging: drawn fragments are tagged. At the end of all render passes flag is copied to MESH_TRAVERSED.
// only used for paging: drawn fragments are tagged. At the end of all render passes flag is copied to MESH_TRAVERSED.
var MESH_RENDERFLAG = 0x80;
var MESH_ISPOINT = 0x100; // indicates that the mesh is vertex-only
// indicates that the mesh is vertex-only
var MESH_ISWIDELINE = 0x200; // indicates that the mesh is wide line
// Values to use for the id buffer source
// indicates that the mesh is wide line
var DB_ID = 0;
var FRAGMENT_ID = 1;
// Values for resetting the iterator
var RESET_NORMAL = 0;
var RESET_REDRAW = 1;
var RESET_RELOAD = 2;
var POSTPROC_STYLE_OFF = 0;
var POSTPROC_STYLE_EDGING = 1;
var POSTPROC_STYLE_CEL = 2;
var POSTPROC_STYLE_GRAPHITE = 3;
var POSTPROC_STYLE_PENCIL = 4;

var groundreflection_draw_frag = "uniform sampler2D tDiffuse;\nvarying vec2 vUv;\nvoid main() {\n    vec4 texel = texture2D( tDiffuse, vUv );\n    gl_FragColor = texel;\n}\n";

// var GroundReflectionCompShader = {
//     uniforms: {
//         tDiffuse: { type: "t", value: null },
//         tBackground: { type: "t", value: null },
//         uColor: { type: "v4", value: new THREE.Vector4(1.0, 1.0, 1.0, 1.0) }
//     },
//
//     vertexShader: screen_quad_uv_vert,
//     fragmentShader: groundreflection_comp_frag
// };
var GroundReflectionDrawShader = {
    uniforms: {
        tDiffuse: { type: "t", value: null }
    },
    vertexShader: screen_quad_uv_vert,
    fragmentShader: groundreflection_draw_frag
};
var GroundReflection = function GroundReflection(renderer, width, height, params) {
    var _renderer = renderer;
    var _gl = _renderer.getContext();
    var _width = width || 512;
    var _height = height || 512;
    var _gaussianPass, _drawPass;
    var _groundPlane, _groundCenter;
    var _reflCamera;
    var _isGroundCulled = false;
    var _clearColor = new THREE$1.Color(0, 0, 0);
    var _clearPass,
        _useClearPass = false;
    var _envMapBg = false;
    this.inTarget = undefined;
    this.outTarget = undefined;
    var _needClear = true;
    var _status = GROUND_UNFINISHED;
    // param defaults
    var _params = {
        color: new THREE$1.Color(1.0, 1.0, 1.0),
        alpha: 0.3,
        texScale: 0.5,
        blurRadius: 2,
        blurTexScale: 0.5,
        fadeAngle: Math.PI / 18
    };
    // PRIVATE FUNCTIONS
    var getReflectionMatrix = function getReflectionMatrix(plane) {
        var N = plane.normal;
        var C = plane.constant;
        return new THREE$1.Matrix4().set(1 - 2 * N.x * N.x, -2 * N.y * N.x, -2 * N.x * N.z, -2 * C * N.x, -2 * N.x * N.y, 1 - 2 * N.y * N.y, -2 * N.y * N.z, -2 * C * N.y, -2 * N.x * N.z, -2 * N.y * N.z, 1 - 2 * N.z * N.z, -2 * C * N.z, 0, 0, 0, 1);
    };
    // PUBLIC FUNCTIONS
    // note: currently scale is not used
    this.setTransform = function (center, upDir, scale) {
        _groundCenter = center;
        _groundPlane.normal = upDir;
        _groundPlane.constant = -center.dot(upDir);
    };
    this.cleanup = function () {
        if (_gaussianPass) _gaussianPass.cleanup();
        if (this.inTarget) this.inTarget.dispose();
        if (this.outTarget) this.outTarget.dispose();
    };
    this.setSize = function (width, height) {
        _width = width;
        _height = height;
        this.cleanup();
        // init targets
        this.inTarget = new THREE$1.WebGLRenderTarget(_width * _params.texScale, _height * _params.texScale, {
            magFilter: THREE$1.LinearFilter,
            minFilter: THREE$1.LinearFilter,
            format: THREE$1.RGBAFormat,
            stencilBuffer: false
        });
        this.inTarget.generateMipmaps = false;
        // outTarget is where we're rendering the ground reflection image (without anything else)
        // and that we will merge with the regular rendering by putting it on a quad.
        this.outTarget = new THREE$1.WebGLRenderTarget(_width * _params.texScale, _height * _params.texScale, {
            magFilter: THREE$1.LinearFilter,
            minFilter: THREE$1.LinearFilter,
            format: THREE$1.RGBAFormat,
            stencilBuffer: false
        });
        this.outTarget.generateMipmaps = false;
        // init gaussian pass
        if (!_gaussianPass) _gaussianPass = new GaussianPass(_width * _params.texScale * _params.blurTexScale, _height * _params.texScale * _params.blurTexScale, _params.blurRadius, 1.0, {
            hasAlpha: true,
            blending: true,
            flipUV: true
        });else _gaussianPass.setSize(_width * _params.texScale * _params.blurTexScale, _height * _params.texScale * _params.blurTexScale);
    };
    this.updateCamera = function (camera) {
        // do not render if camera cannot see top of plane
        var camTarget;
        if (camera.isPerspective) {
            // For perspective camera, see if camera location -> point on plane
            // dotted with the plane's normal is positive. If so, camera is below
            // plane and ground can be culled.
            camTarget = _groundCenter.clone();
        } else {
            // For orthographic camera, see if camera direction (target - position) 
            // dotted with the plane's normal is positive. If so, camera is below
            // plane and ground can be culled.
            camTarget = camera.target.clone();
        }
        var camDir = camera.position.clone().sub(camTarget).normalize();
        var camAngle = Math.PI / 2 - camDir.angleTo(_groundPlane.normal);
        _isGroundCulled = camAngle < 0;
        if (_isGroundCulled) return;
        // fade out
        if (_params.fadeAngle > 0) {
            var fadeAmount = Math.min(_params.fadeAngle, camAngle) / _params.fadeAngle;
            _gaussianPass.setAlpha(fadeAmount * _params.alpha);
        }
        // construct reflected camera
        var reflMatrix = getReflectionMatrix(_groundPlane);
        _reflCamera = camera.clone();
        _reflCamera.applyMatrix(reflMatrix);
        // MAGIC: scale negative Y and flip UV gives us correct result without messing with face winding
        _reflCamera.projectionMatrix.elements[5] *= -1;
        _reflCamera.matrixWorldNeedsUpdate = true;
        // copy worldUpTransform
        if (camera.worldUpTransform) _reflCamera.worldUpTransform = camera.worldUpTransform.clone();else _reflCamera.worldUpTransform = new THREE$1.Matrix4();
    };
    this.renderIntoReflection = function (scene) {
        if (_isGroundCulled) return;
        _renderer.render(scene, _reflCamera, this.inTarget);
        // THREE.log("GR render in");
    };
    this.prepareGroundReflection = function () {
        var qScenes;
        var qSceneCount = 0;
        var qSceneIdx = 0;
        var MAX_PROCESS_FRAMES = 100;
        var maxScenesPerFrame = 0;
        return function (groundShadow, viewerImpl, forceDraw, minScenesPerFrame, maxTime, ratio) {
            var modelQueue = viewerImpl.modelQueue();
            // if the ground reflection is finished, leave
            if (_status !== GROUND_UNFINISHED || modelQueue.isEmpty()) {
                // this call did not render it, so make sure the rendered status is set to finished.
                _status = GROUND_FINISHED;
                return maxTime;
            }
            // This will happen once the linear render list is replaced
            // by the BVH.
            if (qScenes != modelQueue.getGeomScenes()) _needClear = true;
            // Get a separate set of scenes (render batches) for us to traverse. Everything gets traversed.
            if (_needClear) {
                _needClear = false;
                // if it's not visible, don't bother
                // TODO this should really be tested once when making command list - if culled, don't even
                // do anything with reflection or with displaying ground plane.
                this.updateCamera(viewerImpl.camera);
                if (this.isGroundCulled()) {
                    _status = GROUND_FINISHED;
                    return maxTime;
                }
                this.clear();
                qScenes = modelQueue.getGeomScenes();
                qSceneCount = qScenes.length;
                qSceneIdx = 0;
                if (minScenesPerFrame) {
                    maxScenesPerFrame = Math.max(Math.ceil(qSceneCount / MAX_PROCESS_FRAMES), minScenesPerFrame);
                } else {
                    maxScenesPerFrame = qSceneCount;
                }
                _status = GROUND_UNFINISHED;
            } else if (_status !== GROUND_UNFINISHED) {
                // finished, or just finished rendering last frame, or not visible;
                // set status to definitively finished.
                _status = GROUND_FINISHED;
                return maxTime;
            } else if (minScenesPerFrame === 0) {
                // render rest of scene, time permitting
                maxScenesPerFrame = qSceneCount;
            }
            // progressive draw into reflection
            var startTime, budget;
            if (maxTime) {
                startTime = performance.now();
                ratio = ratio === undefined ? 1.0 : ratio;
                budget = ratio * maxTime;
            }
            // TODO this is a bug in the old system: we should really use the BVH iterator here,
            // so that (a) it's draw with frustum culling (should be faster) and (b) transparency is
            // done properly from back to front. Need to get system to work properly before undertaking
            // this task.
            var retval;
            var i = 0;
            while (i < maxScenesPerFrame && qSceneIdx < qSceneCount) {
                // Note that we'll always render at least one batch here, regardless of time.
                // Not sure this is necessary, but it does avoid something going bad that causes
                // the timer to always fail and so get us caught in an infinite loop of calling
                // this method again and again.
                var qScene = qScenes[qSceneIdx++];
                if (qScene) {
                    i++;
                    // passing forceVisible to WebGLRenderer.projectObject()
                    qScene.forceVisible = true;
                    // Note we render everything in the scene (render batch) to the ground plane,
                    // so we don't have to worry about frustum culling, etc. - just blast through.
                    this.renderIntoReflection(qScene);
                    qScene.forceVisible = false;
                    // check time, if used
                    if (maxTime) {
                        var timeElapsed = performance.now() - startTime;
                        // is time up and we're not done?
                        if (budget < timeElapsed && qSceneIdx < qSceneCount) {
                            // couldn't finish render in time
                            _status = GROUND_UNFINISHED;
                            retval = maxTime - timeElapsed;
                            break;
                        }
                    }
                }
            }
            // Did we finish? We only reach this path if the maxObj limit is reached.
            if (qSceneIdx < qSceneCount) {
                _status = GROUND_UNFINISHED;
                // return time left, or 1, meaning we're not done.
                retval = maxTime ? maxTime - performance.now() + startTime : 1;
            }
            // Should we create an intermediate result for display?
            // Yes, if we're done rendering (retval is undefined), or if we're forcing it
            // because progressive rendering is on and this is the first tick's result.
            if (retval === undefined || forceDraw) {
                // We just finished, great, do the post-process
                this.postprocess(viewerImpl.camera, viewerImpl.matman());
                if (groundShadow && groundShadow.enabled) {
                    viewerImpl.renderGroundShadow(this.outTarget);
                }
                this.renderReflection(viewerImpl.camera, viewerImpl.renderer().getColorTarget());
                // We give back a sign that it was *this* call that actually finished up.
                if (retval === undefined) _status = GROUND_RENDERED;
                return maxTime ? maxTime - performance.now() + startTime : 1;
            } else {
                return retval;
            }
        };
    }();
    // The way the reflection pass works is that we render the reflection
    // and blur it, etc. and the result is in outTarget. This method then
    // merges the color buffer and the reflection image by rendering the
    // reflection image on a screen-fillinq quad (well, a triangle) and
    // setting depth range so that the depth value is 0.999999+, i.e., at
    // the back of the scene.
    // This sort of merge draw means the color target can be left as-is,
    // no ping-ponging need occur, the reflection is put right into it.
    this.renderReflection = function (camera, target) {
        if (_isGroundCulled) return;
        // Shove the quad with the reflection image to the back of the color buffer.
        // NOTE: depthRange does not appear to work on Chrome on Windows. See
        // _drawPass.scene.position.z for further corrective measure.
        // Also see https://jira.autodesk.com/browse/LMV-1262
        _gl.depthRange(0.999999, 1);
        _drawPass.render(_renderer, target, this.outTarget);
        // restore default range
        _gl.depthRange(0, 1);
        // THREE.log("GR render out");
    };
    this.toggleEnvMapBackground = function (value) {
        _envMapBg = value;
        _clearPass.uniforms.envMapBackground.value = value;
    };
    this.postprocess = function (camera) {
        if (_isGroundCulled) return;
        // clear outTarget with bg color
        if (_useClearPass || _envMapBg) {
            _clearPass.uniforms['uCamDir'].value = camera.worldUpTransform ? camera.getWorldDirection().clone().applyMatrix4(camera.worldUpTransform) : camera.getWorldDirection();
            _clearPass.uniforms['uCamUp'].value = camera.worldUpTransform ? camera.up.clone().applyMatrix4(camera.worldUpTransform) : camera.up;
            _clearPass.uniforms['uResolution'].value.set(_width, _height);
            _clearPass.uniforms['uHalfFovTan'].value = Math.tan(THREE$1.Math.degToRad(camera.fov * 0.5));
            _clearPass.render(_renderer, this.outTarget);
            _renderer.clearTarget(this.outTarget, false, true, false);
        } else {
            _renderer.setClearColor(_clearColor, 1.0);
            _renderer.clearTarget(this.outTarget, true, true, false);
        }
        // blur inTarget with alpha blending over bg in outTarget
        _gaussianPass.render(_renderer, this.outTarget, this.inTarget);
        // THREE.log("GR postprocess");
    };
    this.clear = function () {
        // clear with bgColor otherwise there'll be outline problem
        // using the cheaper flat clear color in this case
        _renderer.setClearColor(_clearColor, 0);
        _renderer.clearTarget(this.inTarget, true, true, false);
        _renderer.clearBlend();
        // THREE.log("GR clear");
    };
    // params are normalized clamped THREE.Vector3
    this.setClearColors = function (colorTop, colorBot, skipClearPass) {
        if (!colorBot) {
            _clearColor.copy(colorTop);
            _useClearPass = false;
        } else {
            _clearColor.setRGB(0.5 * (colorTop.x + colorBot.x), 0.5 * (colorTop.y + colorBot.y), 0.5 * (colorTop.z + colorBot.z));
            // same logic as RenderContext.setClearColors
            _useClearPass = !colorTop.equals(colorBot) && !skipClearPass;
            //!av.isAndroidDevice() &&
            //!av.isIOSDevice();
        }
        if (_useClearPass) {
            _clearPass.uniforms.color1.value.copy(colorTop);
            _clearPass.uniforms.color2.value.copy(colorBot);
        }
    };
    this.setEnvRotation = function (rotation) {
        _clearPass.material.envRotationSin = Math.sin(rotation);
        _clearPass.material.envRotationCos = Math.cos(rotation);
    };
    this.isGroundCulled = function () {
        return _isGroundCulled;
    };
    this.getStatus = function () {
        return _status;
    };
    this.setDirty = function () {
        _needClear = true;
        _status = GROUND_UNFINISHED;
    };
    this.setColor = function (color) {
        _gaussianPass.setColor(_params.color);
        _params.color.set(color);
    };
    this.setAlpha = function (alpha) {
        _gaussianPass.setAlpha(_params.alpha);
        _params.alpha = alpha;
    };
    // INITIALIZATION
    if (params) {
        for (var i in _params) {
            _params[i] = params[i] !== undefined ? params[i] : _params[i];
        }
    }
    // init passes
    _drawPass = new ShaderPass(GroundReflectionDrawShader);
    _drawPass.material.blending = THREE$1.NoBlending;
    _drawPass.material.depthTest = true;
    _drawPass.material.depthWrite = false;
    // Put the screen-filling quad at the back of the view volume.
    // This is slightly dangerous, it could go "too far", so we put it at
    // -0.999999 to keep it from being on the razor's edge.
    // See https://jira.autodesk.com/browse/LMV-1262
    _drawPass.scene.position.z = -0.999999;
    if (params.clearPass) {
        _clearPass = params.clearPass;
    } else {
        _clearPass = new ShaderPass(BackgroundShader);
        _clearPass.material.blending = THREE$1.NoBlending;
        _clearPass.material.depthWrite = false;
        _clearPass.material.depthTest = false;
    }
    // init targets
    this.setSize(_width, _height);
    _gaussianPass.setAlpha(_params.color);
    _gaussianPass.setAlpha(_params.alpha);
    // init plane
    _groundPlane = new THREE$1.Plane(new THREE$1.Vector3(0, 1, 0), 0);
    _groundCenter = new THREE$1.Vector3(0, 0, 0);
};

var addLineNumbers = function addLineNumbers(code) {
    var lines = code.split('\n');
    for (var i = 0; i < lines.length; i++) {
        lines[i] = i + 1 + ': ' + lines[i];
    }
    return lines.join('\n');
};
var DEBUG_SHADERS = false;
var WebGLShader = function WebGLShader(gl, type, code) {
    var shader = gl.createShader(type);
    gl.shaderSource(shader, code);
    gl.compileShader(shader);
    if (DEBUG_SHADERS) {
        if (gl.getShaderParameter(shader, gl.COMPILE_STATUS) === false) {
            THREE$1.error('THREE.WebGLShader: Shader couldn\'t compile.');
        }
        if (gl.getShaderInfoLog(shader) !== '') {
            THREE$1.warn('THREE.WebGLShader: gl.getShaderInfoLog()', gl.getShaderInfoLog(shader), addLineNumbers(code));
        }
    }
    // --enable-privileged-webgl-extension
    // THREE.log( type, gl.getExtension( 'WEBGL_debug_shaders' ).getTranslatedShaderSource( shader ) );
    return shader;
};

var phong_vert = "varying vec3 vViewPosition;\n#ifndef FLAT_SHADED\nvarying vec3 vNormal;\n#endif\n#if defined( USE_MAP ) || defined( USE_SPECULARMAP )\nvarying vec2 vUv;\nuniform mat3 texMatrix;\n#endif\n#if defined( USE_BUMPMAP ) || defined( USE_NORMALMAP )\nvarying vec2 vUvBump;\nuniform mat3 texMatrixBump;\n#endif\n#if defined( USE_ALPHAMAP )\nvarying vec2 vUvAlpha;\nuniform mat3 texMatrixAlpha;\n#endif\n#if defined( USE_ENVMAP )\n#if ! defined( USE_BUMPMAP ) && ! defined( USE_NORMALMAP )\nuniform float refractionRatio;\n#endif\n#endif\n#if MAX_SPOT_LIGHTS > 0 || NUM_CUTPLANES > 0\nvarying vec3 vWorldPosition;\n#endif\n#ifdef USE_COLOR\nvarying vec3 vColor;\n#endif\n#ifdef USE_LOGDEPTHBUF\n#ifdef USE_LOGDEPTHBUF_EXT\nvarying float vFragDepth;\n#endif\nuniform float logDepthBufFC;\n#endif\n#ifdef MRT_NORMALS\nvarying float depth;\n#endif\n#include<pack_normals>\n#include<instancing_decl_vert>\n#include<id_decl_vert>\n#include<wide_lines_decl>\n#include<shadowmap_decl_vert>\nvoid main() {\n#if defined( USE_MAP ) || defined( USE_SPECULARMAP )\n    vUv = (texMatrix * vec3(uv, 1.0)).xy;\n#endif\n#if defined( USE_BUMPMAP ) || defined( USE_NORMALMAP )\n    vUvBump = (texMatrixBump * vec3(uv, 1.0)).xy;\n#endif\n#if defined( USE_ALPHAMAP )\n    vUvAlpha = (texMatrixAlpha * vec3(uv, 1.0)).xy;\n#endif\n#ifdef USE_COLOR\n#ifdef GAMMA_INPUT\n    vColor = color * color;\n#else\n    vColor = color;\n#endif\n#endif\n#ifdef UNPACK_NORMALS\n    vec3 objectNormal = decodeNormal(normal);\n#else\n    vec3 objectNormal = normal;\n#endif\n#ifdef FLIP_SIDED\n    objectNormal = -objectNormal;\n#endif\n    objectNormal = getInstanceNormal(objectNormal);\n    vec3 instPos = getInstancePos(position);\n    vec3 transformedNormal = normalMatrix * objectNormal;\n#ifndef FLAT_SHADED\n    vNormal = normalize( transformedNormal );\n#endif\n    vec4 mvPosition = modelViewMatrix * vec4( instPos, 1.0 );\n    gl_Position = projectionMatrix * mvPosition;\n#include<wide_lines_vert>\n    vViewPosition = -mvPosition.xyz;\n#if MAX_SPOT_LIGHTS > 0 || NUM_CUTPLANES > 0\n    vec4 worldPosition = modelMatrix * vec4( instPos, 1.0 );\n    vWorldPosition = worldPosition.xyz;\n#endif\n#ifdef USE_LOGDEPTHBUF\n    if (projectionMatrix[3][3] == 0.0) {\n        gl_Position.z = log2(max(1.0e-6, gl_Position.w + 1.0)) * logDepthBufFC;\n#ifdef USE_LOGDEPTHBUF_EXT\n        vFragDepth = 1.0 + gl_Position.w;\n#else\n        gl_Position.z = (gl_Position.z - 1.0) * gl_Position.w;\n#endif\n    } else {\n#ifdef USE_LOGDEPTHBUF_EXT\n        vFragDepth = 1.0 + vViewPosition.z;\n#else\n#endif\n    }\n#endif\n#ifdef MRT_NORMALS\n    depth = mvPosition.z;\n#endif\n#include<shadowmap_vert>\n#include<id_vert>\n}\n";

var phong_frag = "uniform vec3 diffuse;\nuniform float opacity;\nuniform vec3 emissive;\nuniform vec3 specular;\nuniform float shininess;\n#include<env_sample>\n#ifdef USE_COLOR\nvarying vec3 vColor;\n#endif\n#ifdef GAMMA_INPUT\nvec3 InputToLinear(vec3 c) {\n    return c * c;\n}\nfloat InputToLinear(float c) {\n    return c * c;\n}\n#else\nvec3 InputToLinear(vec3 c) {\n    return c;\n}\nfloat InputToLinear(float c) {\n    return c;\n}\n#endif\n#if defined( USE_MAP ) || defined( USE_SPECULARMAP )\nvarying vec2 vUv;\n#endif\n#if defined( USE_BUMPMAP ) || defined( USE_NORMALMAP )\nvarying vec2 vUvBump;\n#endif\n#if defined( USE_ALPHAMAP )\nvarying vec2 vUvAlpha;\n#endif\n#ifdef USE_MAP\nuniform sampler2D map;\n#endif\n#if TONEMAP_OUTPUT > 0\nuniform float exposureBias;\n#include<tonemap>\n#endif\n#if defined(IRR_RGBM) || defined(ENV_RGBM) || defined(ENV_GAMMA) || defined(IRR_GAMMA)\nuniform float envMapExposure;\n#endif\n#ifdef USE_FOG\nuniform vec3 fogColor;\nuniform float fogNear;\nuniform float fogFar;\n#endif\n#include<id_decl_frag>\n#include<theming_decl_frag>\n#include<shadowmap_decl_frag>\n#ifdef USE_ENVMAP\nuniform float reflMipIndex;\nuniform float reflectivity;\nuniform samplerCube envMap;\n#if defined( USE_BUMPMAP ) || defined( USE_NORMALMAP )\nuniform float refractionRatio;\n#endif\nvec3 sampleReflection(vec3 dir, float mipIndex) {\n    vec3 adjDir = adjustLookupVector(dir);\n#ifdef ENV_GAMMA\n#ifdef HAVE_TEXTURE_LOD\n    vec4 envTexColor = textureCubeLodEXT( envMap, adjDir, mipIndex );\n#else\n    vec4 envTexColor = textureCube( envMap, adjDir, mipIndex );\n#endif\n    return GammaDecode(envTexColor, envMapExposure);\n#elif defined(ENV_RGBM)\n#ifdef HAVE_TEXTURE_LOD\n    vec4 envTexColor = textureCubeLodEXT( envMap, adjDir, mipIndex );\n#else\n    vec4 envTexColor = textureCube( envMap, adjDir, mipIndex );\n#endif\n    return RGBMDecode(envTexColor, envMapExposure);\n#else\n    vec4 envTexColor = textureCube( envMap, adjDir );\n    vec3 cubeColor = envTexColor.xyz;\n#ifdef GAMMA_INPUT\n    cubeColor *= cubeColor;\n#endif\n    return cubeColor;\n#endif\n}\n#endif\nuniform vec3 ambientLightColor;\n#if MAX_DIR_LIGHTS > 0\nuniform vec3 directionalLightColor[ MAX_DIR_LIGHTS ];\nuniform vec3 directionalLightDirection[ MAX_DIR_LIGHTS ];\n#endif\n#if MAX_POINT_LIGHTS > 0\nuniform vec3 pointLightColor[ MAX_POINT_LIGHTS ];\nuniform vec3 pointLightPosition[ MAX_POINT_LIGHTS ];\nuniform float pointLightDistance[ MAX_POINT_LIGHTS ];\n#endif\n#if MAX_SPOT_LIGHTS > 0\nuniform vec3 spotLightColor[ MAX_SPOT_LIGHTS ];\nuniform vec3 spotLightPosition[ MAX_SPOT_LIGHTS ];\nuniform vec3 spotLightDirection[ MAX_SPOT_LIGHTS ];\nuniform float spotLightAngleCos[ MAX_SPOT_LIGHTS ];\nuniform float spotLightExponent[ MAX_SPOT_LIGHTS ];\nuniform float spotLightDistance[ MAX_SPOT_LIGHTS ];\n#endif\n#ifdef USE_IRRADIANCEMAP\nuniform samplerCube irradianceMap;\n#endif\n#if MAX_SPOT_LIGHTS > 0 || NUM_CUTPLANES > 0\nvarying highp vec3 vWorldPosition;\n#endif\nvarying highp vec3 vViewPosition;\n#ifndef FLAT_SHADED\nvarying highp vec3 vNormal;\n#endif\n#ifdef USE_BUMPMAP\nuniform sampler2D bumpMap;\nuniform float bumpScale;\nvec2 dHdxy_fwd() {\n    vec2 dSTdx = dFdx( vUvBump );\n    vec2 dSTdy = dFdy( vUvBump );\n    float Hll = bumpScale * GET_BUMPMAP(vUvBump).x;\n    float dBx = bumpScale * GET_BUMPMAP(vUvBump + dSTdx).x - Hll;\n    float dBy = bumpScale * GET_BUMPMAP(vUvBump + dSTdy).x - Hll;\n    return vec2( dBx, dBy );\n}\nvec3 perturbNormalArb( vec3 surf_pos, vec3 surf_norm, vec2 dHdxy ) {\n    vec3 vSigmaX = dFdx( surf_pos );\n    vec3 vSigmaY = dFdy( surf_pos );\n    vec3 vN = surf_norm;\n    vec3 R1 = cross( vSigmaY, vN );\n    vec3 R2 = cross( vN, vSigmaX );\n    float fDet = dot( vSigmaX, R1 );\n    vec3 vGrad = sign( fDet ) * ( dHdxy.x * R1 + dHdxy.y * R2 );\n    return normalize( abs( fDet ) * surf_norm - vGrad );\n}\n#endif\n#ifdef USE_NORMALMAP\nuniform sampler2D normalMap;\nuniform vec2 normalScale;\nvec3 perturbNormal2Arb( vec3 eye_pos, vec3 surf_norm ) {\n    vec3 q0 = dFdx( eye_pos.xyz );\n    vec3 q1 = dFdy( eye_pos.xyz );\n    vec2 st0 = dFdx( vUvBump.st );\n    vec2 st1 = dFdy( vUvBump.st );\n    vec3 S = normalize(  q0 * st1.t - q1 * st0.t );\n    vec3 T = normalize( -q0 * st1.s + q1 * st0.s );\n    vec3 N = normalize( surf_norm );\n    vec3 mapN = GET_NORMALMAP(vUvBump).xyz * 2.0 - 1.0;\n    mapN.xy = normalScale * mapN.xy;\n    mat3 tsn = mat3( S, T, N );\n    return normalize( tsn * mapN );\n}\n#endif\n#ifdef USE_SPECULARMAP\nuniform sampler2D specularMap;\n#endif\n#ifdef USE_ALPHAMAP\nuniform sampler2D alphaMap;\n#endif\n#include<hatch_pattern>\n#ifdef USE_LOGDEPTHBUF\nuniform float logDepthBufFC;\n#ifdef USE_LOGDEPTHBUF_EXT\n#extension GL_EXT_frag_depth : enable\nvarying highp float vFragDepth;\n#endif\n#endif\nvec3 Schlick_v3(vec3 v, float cosHV) {\n    float facing = max(1.0 - cosHV, 0.0);\n    float facing2 = facing * facing;\n    return v + (1.0 - v) * facing * facing2 * facing2;\n}\nfloat Schlick_f(float v, float cosHV) {\n    float facing = max(1.0 - cosHV, 0.0);\n    float facing2 = facing * facing;\n    return v + ( 1.0 - v ) * facing2 * facing2 * facing;\n}\n#include<cutplanes>\nvoid main() {\n#if NUM_CUTPLANES > 0\n    checkCutPlanes(vWorldPosition);\n#endif\n    gl_FragColor = vec4( vec3 ( 1.0 ), opacity );\n#ifdef USE_MAP\n    vec4 texelColor = GET_MAP(vUv);\n#ifdef MAP_INVERT\n    texelColor.xyz = 1.0-texelColor.xyz;\n#endif\n#ifdef GAMMA_INPUT\n    texelColor.xyz *= texelColor.xyz;\n#endif\n    gl_FragColor = gl_FragColor * texelColor;\n#endif\n#ifdef USE_ALPHAMAP\n    vec4 texelAlpha = GET_ALPHAMAP(vUvAlpha);\n    gl_FragColor.a *= texelAlpha.r;\n#endif\n#ifdef ALPHATEST\n    if ( gl_FragColor.a < ALPHATEST ) discard;\n#endif\n    float specularStrength;\n#ifdef USE_SPECULARMAP\n    vec4 texelSpecular = GET_SPECULARMAP(vUv);\n    specularStrength = texelSpecular.r;\n#else\n    specularStrength = 1.0;\n#endif\n#ifndef FLAT_SHADED\n    vec3 normal = normalize( vNormal );\n#ifdef DOUBLE_SIDED\n    normal = normal * ( -1.0 + 2.0 * float( gl_FrontFacing ) );\n#endif\n#else\n    vec3 fdx = dFdx( vViewPosition );\n    vec3 fdy = dFdy( vViewPosition );\n    vec3 normal = normalize( cross( fdx, fdy ) );\n#endif\n    vec3 geomNormal = normal;\n#ifdef USE_NORMALMAP\n    normal = perturbNormal2Arb( -vViewPosition, normal );\n#elif defined( USE_BUMPMAP )\n    normal = perturbNormalArb( -vViewPosition, normal, dHdxy_fwd() );\n#endif\n    vec3 viewDirection;\n    if (projectionMatrix[3][3] == 0.0) {\n        viewDirection = normalize( vViewPosition );\n    } else {\n        viewDirection = vec3(0.0, 0.0, 1.0);\n    }\n    vec3 totalDiffuse = vec3( 0.0 );\n    vec3 totalSpecular = vec3( 0.0 );\n    float shininessB = shininess * 4.0;\n#if MAX_POINT_LIGHTS > 0\n    vec3 pointDiffuse  = vec3( 0.0 );\n    vec3 pointSpecular = vec3( 0.0 );\n    for ( int i = 0; i < MAX_POINT_LIGHTS; i ++ ) {\n        vec4 lPosition = viewMatrix * vec4( pointLightPosition[ i ], 1.0 );\n        vec3 lVector = lPosition.xyz + vViewPosition.xyz;\n        float lDistance = 1.0;\n        if ( pointLightDistance[ i ] > 0.0 )\n            lDistance = 1.0 - min( ( length( lVector ) / pointLightDistance[ i ] ), 1.0 );\n        lVector = normalize( lVector );\n        float dotProduct = dot( normal, lVector );\n        float pointDiffuseWeight = max( dotProduct, 0.0 );\n        pointDiffuse  += InputToLinear(diffuse) * InputToLinear(pointLightColor[ i ]) * pointDiffuseWeight * lDistance;\n        vec3 pointHalfVector = normalize( lVector + viewDirection );\n        float pointDotNormalHalf = max( dot( normal, pointHalfVector ), 0.0 );\n        float pointSpecularWeight = specularStrength * max( pow( pointDotNormalHalf, shininessB ), 0.0 );\n        float specularNormalization = shininessB * 0.125 + 0.25;\n        vec3 schlick = Schlick_v3(InputToLinear(specular), dot( lVector, pointHalfVector ) );\n        pointSpecular += schlick * InputToLinear(pointLightColor[ i ]) * pointSpecularWeight * pointDiffuseWeight * lDistance * specularNormalization ;\n    }\n    totalDiffuse += pointDiffuse;\n    totalSpecular += pointSpecular;\n#endif\n#if MAX_SPOT_LIGHTS > 0\n    vec3 spotDiffuse  = vec3( 0.0 );\n    vec3 spotSpecular = vec3( 0.0 );\n    for ( int i = 0; i < MAX_SPOT_LIGHTS; i ++ ) {\n        vec4 lPosition = viewMatrix * vec4( spotLightPosition[ i ], 1.0 );\n        vec3 lVector = lPosition.xyz + vViewPosition.xyz;\n        float lDistance = 1.0;\n        if ( spotLightDistance[ i ] > 0.0 )\n            lDistance = 1.0 - min( ( length( lVector ) / spotLightDistance[ i ] ), 1.0 );\n        lVector = normalize( lVector );\n        float spotEffect = dot( spotLightDirection[ i ], normalize( spotLightPosition[ i ] - vWorldPosition ) );\n        if ( spotEffect > spotLightAngleCos[ i ] ) {\n            spotEffect = max( pow( spotEffect, spotLightExponent[ i ] ), 0.0 );\n            float dotProduct = dot( normal, lVector );\n            float spotDiffuseWeight = max( dotProduct, 0.0 );\n            spotDiffuse += InputToLinear(diffuse) * InputToLinear(spotLightColor[ i ]) * spotDiffuseWeight * lDistance * spotEffect;\n            vec3 spotHalfVector = normalize( lVector + viewDirection );\n            float spotDotNormalHalf = max( dot( normal, spotHalfVector ), 0.0 );\n            float spotSpecularWeight = specularStrength * max( pow( spotDotNormalHalf, shininessB ), 0.0 );\n            float specularNormalization = shininessB * 0.125 + 0.25;\n            vec3 schlick = Schlick_v3(InputToLinear(specular), dot( lVector, spotHalfVector ) );\n            spotSpecular += schlick * InputToLinear(spotLightColor[ i ]) * spotSpecularWeight * spotDiffuseWeight * lDistance * specularNormalization * spotEffect;\n        }\n    }\n    totalDiffuse += spotDiffuse;\n    totalSpecular += spotSpecular;\n#endif\n#if MAX_DIR_LIGHTS > 0\n    vec3 dirDiffuse  = vec3( 0.0 );\n    vec3 dirSpecular = vec3( 0.0 );\n    for( int i = 0; i < MAX_DIR_LIGHTS; i ++ ) {\n        vec4 lDirection = viewMatrix * vec4( directionalLightDirection[ i ], 0.0 );\n        vec3 dirVector = normalize( lDirection.xyz );\n        float dotProduct = dot( normal, dirVector );\n        float dirDiffuseWeight = max( dotProduct, 0.0 );\n        dirDiffuse  += InputToLinear(diffuse) * InputToLinear(directionalLightColor[ i ]) * dirDiffuseWeight;\n        vec3 dirHalfVector = normalize( dirVector + viewDirection );\n        float dirDotNormalHalf = max( dot( normal, dirHalfVector ), 0.0 );\n        float dirSpecularWeight = specularStrength * max( pow( dirDotNormalHalf, shininessB ), 0.0 );\n        float specularNormalization = shininessB * 0.125 + 0.25;\n        vec3 schlick = Schlick_v3(InputToLinear(specular), dot( dirVector, dirHalfVector ));\n        dirSpecular += schlick * InputToLinear(directionalLightColor[ i ]) * dirSpecularWeight * dirDiffuseWeight * specularNormalization;\n    }\n    totalDiffuse += dirDiffuse;\n    totalSpecular += dirSpecular;\n#endif\n#ifdef USE_IRRADIANCEMAP\n    vec3 worldNormal = mat3(viewMatrixInverse) * normal;\n    vec3 indirectDiffuse = sampleIrradianceMap(worldNormal, irradianceMap, envMapExposure);\n    indirectDiffuse = applyEnvShadow(indirectDiffuse, worldNormal);\n    totalDiffuse += InputToLinear(diffuse) * indirectDiffuse;\n#endif\n#ifdef METAL\n    gl_FragColor.xyz = gl_FragColor.xyz * ( InputToLinear(emissive) + totalDiffuse + ambientLightColor * InputToLinear(diffuse) + totalSpecular );\n#else\n    gl_FragColor.xyz = gl_FragColor.xyz * ( InputToLinear(emissive) + totalDiffuse + ambientLightColor * InputToLinear(diffuse) ) + totalSpecular;\n#endif\n#ifdef USE_COLOR\n    gl_FragColor = gl_FragColor * vec4( vColor, 1.0 );\n#endif\n#if defined(USE_ENVMAP)\n    vec3 reflectVec;\n#if defined( USE_BUMPMAP ) || defined( USE_NORMALMAP )\n#ifdef ENVMAP_MODE_REFLECTION\n    reflectVec = reflect( -viewDirection, normal );\n#else \n    reflectVec = refract( -viewDirection, normal, refractionRatio );\n#endif\n#else\n    reflectVec = reflect( -viewDirection, normal );\n#endif\n    reflectVec = mat3(viewMatrixInverse) * reflectVec;\n    float reflectScale = 1.0;\n    vec3 cubeColor = sampleReflection(reflectVec, reflMipIndex);\n    cubeColor *= reflectScale;\n    float facing = dot( viewDirection, geomNormal );\n    if (facing < -1e-2)\n        facing = 1.0;\n    else\n        facing = max(1e-6, facing);\n    vec3 schlickRefl;\n#ifdef METAL\n    schlickRefl = InputToLinear(specular);\n#else\n    schlickRefl = Schlick_v3(InputToLinear(specular), facing);\n    gl_FragColor.a = mix(gl_FragColor.a, Schlick_f(gl_FragColor.a, facing), reflectivity);\n    float invSchlick = (1.0 - facing * 0.5);\n    float invSchlick2 = invSchlick * invSchlick;\n    float norm_factor = 1.0 - invSchlick * invSchlick2 * invSchlick2;\n    norm_factor = (28.0 / 23.0) * norm_factor;\n    gl_FragColor.xyz *= norm_factor * (1.0 - InputToLinear(specular));\n#endif\n    gl_FragColor.xyz += cubeColor.xyz * specularStrength * schlickRefl.xyz;\n#ifdef CLEARCOAT\n    vec3 reflectVecClearcoat = reflect( -viewDirection, geomNormal );\n    reflectVecClearcoat = mat3(viewMatrixInverse) * reflectVecClearcoat;\n    vec3 cubeColorClearcoat = sampleReflection(reflectVecClearcoat, 0.0);\n    float schlickClearcoat = Schlick_f(InputToLinear(reflectivity), facing);\n    gl_FragColor.xyz = mix(gl_FragColor.xyz, cubeColorClearcoat * schlickClearcoat, 0.5);\n#endif\n#endif\n#if TONEMAP_OUTPUT == 1\n    gl_FragColor.xyz = toneMapCanonOGS_WithGamma_WithColorPerserving(exposureBias * gl_FragColor.xyz);\n#elif TONEMAP_OUTPUT == 2\n    gl_FragColor.xyz = toneMapCanonFilmic_WithGamma( exposureBias * gl_FragColor.xyz );\n#endif\n#ifdef USE_FOG\n    float depth = gl_FragCoord.z / gl_FragCoord.w;\n    float fogFactor = smoothstep( fogNear, fogFar, depth );\n    gl_FragColor = mix( gl_FragColor, vec4( fogColor, gl_FragColor.w ), fogFactor );\n#endif\n#include<theming_frag>\n#include<final_frag>\n}\n";

var PhongShader = {
    uniforms: THREE$1.UniformsUtils.merge([THREE$1.UniformsLib["common"], THREE$1.UniformsLib["bump"], THREE$1.UniformsLib["normalmap"], THREE$1.UniformsLib["lights"], THREE$1.UniformsLib["fog"], ShaderChunks.CutPlanesUniforms, ShaderChunks.IdUniforms, ShaderChunks.ThemingUniform, ShaderChunks.ShadowMapUniforms, ShaderChunks.WideLinesUniforms, {
        "emissive": { type: "c", value: new THREE$1.Color(0x000000) },
        "specular": { type: "c", value: new THREE$1.Color(0x111111) },
        "shininess": { type: "f", value: 30 },
        "reflMipIndex": { type: "f", value: 0 },
        "texMatrix": { type: "m3", value: new THREE$1.Matrix3() },
        "texMatrixBump": { type: "m3", value: new THREE$1.Matrix3() },
        "texMatrixAlpha": { type: "m3", value: new THREE$1.Matrix3() },
        "irradianceMap": { type: "t", value: null },
        "exposureBias": { type: "f", value: 1.0 },
        "envMapExposure": { type: "f", value: 1.0 },
        "envRotationSin": { type: "f", value: 0.0 },
        "envRotationCos": { type: "f", value: 1.0 }
    }]),
    vertexShader: phong_vert,
    fragmentShader: phong_frag
};
THREE$1.ShaderLib['firefly_phong'] = PhongShader;

//Utility logic for listing vertex data from LmvBufferGeometry interleaved buffers
//Uh, for being able to run both in worker and in main viewer JS
var LmvVector3 = typeof self !== 'undefined' && self.LmvVector3 ? self.LmvVector3 : THREE$1.Vector3;
//These functions work for both workers side interleaved buffer structures
//and main thread side LmvBufferGeometry instances. The difference in naming
//if the index attribute on both sides is super annoying and should be cleaned up.
/** Works for BufferGeometry as well as THREE.BufferGeometry. Supports interleaved and non-interleaved buffers.
 *   @param {BufferGeometry|THREE.BufferGeometry} geom
 *   @returns {number}
 */
function getVertexCount(geom) {
    if (geom.vb) {
        // interleaved
        return geom.vb.length / geom.vbstride;
    }
    // no interleaved buffer. Return count from position attribute or 0
    return geom.attributes.positions ? geom.attributes.positions.count : 0;
}
var _p;
function enumMeshVertices(geometry, callback, matrix) {
    var attributes = geometry.attributes;
    var positions = geometry.vb || attributes.position.array;
    var stride = geometry.vb ? geometry.vbstride : 3;
    // Get the offset to positions in the buffer. Be careful, 2D buffers
    // don't use the 'position' attribute for positions. Reject those.
    var poffset;
    if (geometry.vblayout) {
        if (!geometry.vblayout.position) return; // No positions, what to do??
        poffset = geometry.vblayout.position.offset;
    } else if (!attributes.position) return; // No positions, what to do??
    else poffset = attributes.position.itemOffset || 0;
    var vcount = positions.length / stride;
    if (!_p) _p = new LmvVector3();
    var pi = poffset;
    for (var i = 0; i < vcount; i++, pi += stride) {
        _p.set(positions[pi], positions[pi + 1], positions[pi + 2]);
        if (matrix) _p.applyMatrix4(matrix);
        callback(_p, i);
    }
}
var vA;
var vB;
var vC;
var nA;
var nB;
var nC;
function enumMeshTriangles(geometry, callback) {
    var attributes = geometry.attributes;
    var a, b, c;
    if (!vA) {
        vA = new LmvVector3();
        vB = new LmvVector3();
        vC = new LmvVector3();
        nA = new LmvVector3();
        nB = new LmvVector3();
        nC = new LmvVector3();
    }
    var positions = geometry.vb || attributes.position.array;
    var normals = geometry.vb || attributes.normal && attributes.normal.array;
    var stride = geometry.vb ? geometry.vbstride : 3;
    // Get the offset to positions in the buffer. Be careful, 2D buffers
    // don't use the 'position' attribute for positions. Reject those.
    var poffset;
    if (geometry.vblayout) {
        if (!geometry.vblayout.position) return; // No positions, what to do??
        poffset = geometry.vblayout.position.offset;
    } else if (!attributes.position) return; // No positions, what to do??
    else poffset = attributes.position.itemOffset || 0;
    var noffset = 0;
    var nattr = geometry.vblayout ? geometry.vblayout.normal : attributes.normal || null;
    if (nattr) {
        noffset = nattr.offset || nattr.itemOffset;
    } else {
        normals = null;
    }
    if (nattr && (nattr.itemSize !== 3 || nattr.bytesPerItem !== 4)) {
        //console.log("Normals are packed, will be skipped from enumMeshTriangles. Use packNormals=false load option.");
        normals = null;
    }
    var indices = geometry.ib || geometry.indices || (attributes.index ? attributes.index.array : null);
    if (indices) {
        var offsets = geometry.offsets;
        if (!offsets || offsets.length === 0) {
            offsets = [{ start: 0, count: indices.length, index: 0 }];
        }
        for (var oi = 0, ol = offsets.length; oi < ol; ++oi) {
            var start = offsets[oi].start;
            var count = offsets[oi].count;
            var index = offsets[oi].index;
            for (var i = start, il = start + count; i < il; i += 3) {
                a = index + indices[i];
                b = index + indices[i + 1];
                c = index + indices[i + 2];
                var pa = a * stride + poffset;
                var pb = b * stride + poffset;
                var pc = c * stride + poffset;
                vA.x = positions[pa];
                vA.y = positions[pa + 1];
                vA.z = positions[pa + 2];
                vB.x = positions[pb];
                vB.y = positions[pb + 1];
                vB.z = positions[pb + 2];
                vC.x = positions[pc];
                vC.y = positions[pc + 1];
                vC.z = positions[pc + 2];
                if (normals) {
                    var na = a * stride + noffset;
                    var nb = b * stride + noffset;
                    var nc = c * stride + noffset;
                    nA.x = normals[na];
                    nA.y = normals[na + 1];
                    nA.z = normals[na + 2];
                    nB.x = normals[nb];
                    nB.y = normals[nb + 1];
                    nB.z = normals[nb + 2];
                    nC.x = normals[nc];
                    nC.y = normals[nc + 1];
                    nC.z = normals[nc + 2];
                    callback(vA, vB, vC, a, b, c, nA, nB, nC);
                } else {
                    callback(vA, vB, vC, a, b, c);
                }
            }
        }
    } else {
        var vcount = geometry.vb ? geometry.vb.length / geometry.vbstride : positions.length / 3;
        for (var _i = 0; _i < vcount; _i++) {
            a = 3 * _i;
            b = 3 * _i + 1;
            c = 3 * _i + 2;
            var pa = a * stride + poffset;
            var pb = b * stride + poffset;
            var pc = c * stride + poffset;
            vA.x = positions[pa];
            vA.y = positions[pa + 1];
            vA.z = positions[pa + 2];
            vB.x = positions[pb];
            vB.y = positions[pb + 1];
            vB.z = positions[pb + 2];
            vC.x = positions[pc];
            vC.y = positions[pc + 1];
            vC.z = positions[pc + 2];
            if (normals) {
                var na = a * stride + noffset;
                var nb = b * stride + noffset;
                var nc = c * stride + noffset;
                nA.x = normals[na];
                nA.y = normals[na + 1];
                nA.z = normals[na + 2];
                nB.x = normals[nb];
                nB.y = normals[nb + 1];
                nB.z = normals[nb + 2];
                nC.x = normals[nc];
                nC.y = normals[nc + 1];
                nC.z = normals[nc + 2];
                callback(vA, vB, vC, a, b, c, nA, nB, nC);
            } else {
                callback(vA, vB, vC, a, b, c);
            }
        }
    }
}
var vP;
var vQ;
function enumMeshLines(geometry, callback) {
    var attributes = geometry.attributes;
    var a, b;
    if (!vP) {
        vP = new LmvVector3();
        vQ = new LmvVector3();
    }
    var istep = 2;
    if (geometry.lineWidth) {
        istep = 6;
    }
    var indices = geometry.ib || geometry.indices || (attributes.index ? attributes.index.array : null);
    if (indices) {
        var positions = geometry.vb ? geometry.vb : attributes.position.array;
        var stride = geometry.vb ? geometry.vbstride : 3;
        var offsets = geometry.offsets;
        if (!offsets || offsets.length === 0) {
            offsets = [{ start: 0, count: indices.length, index: 0 }];
        }
        for (var oi = 0, ol = offsets.length; oi < ol; ++oi) {
            var start = offsets[oi].start;
            var count = offsets[oi].count;
            var index = offsets[oi].index;
            for (var i = start, il = start + count; i < il; i += istep) {
                a = index + indices[i];
                b = index + indices[i + 1];
                vP.x = positions[a * stride];
                vP.y = positions[a * stride + 1];
                vP.z = positions[a * stride + 2];
                vQ.x = positions[b * stride];
                vQ.y = positions[b * stride + 1];
                vQ.z = positions[b * stride + 2];
                callback(vP, vQ, a, b);
            }
        }
    } else {
        var positions = geometry.vb ? geometry.vb : attributes.position.array;
        var stride = geometry.vb ? geometry.vbstride : 3;
        for (var _i2 = 0, _il = positions.length; _i2 < _il; _i2 += istep) {
            a = _i2;
            b = _i2 + 1;
            vP.x = positions[a * stride];
            vP.y = positions[a * stride + 1];
            vP.z = positions[a * stride + 2];
            vQ.x = positions[b * stride];
            vQ.y = positions[b * stride + 1];
            vQ.z = positions[b * stride + 2];
            callback(vP, vQ, a, b);
        }
    }
}
var VertexEnumerator = {
    getVertexCount: getVertexCount,
    enumMeshVertices: enumMeshVertices,
    enumMeshTriangles: enumMeshTriangles,
    enumMeshLines: enumMeshLines
};

/**
 * @author mrdoob / http://mrdoob.com/
 * @author *kile / http://kile.stravaganza.org/
 * @author philogb / http://blog.thejit.org/
 * @author mikael emtinger / http://gomo.se/
 * @author egraether / http://egraether.com/
 * @author WestLangley / http://github.com/WestLangley
 */
/* Pruned version of THREE.Vector3, for use in the LMV web worker */
var LmvVector3$1 = function LmvVector3(x, y, z) {
    this.x = x || 0;
    this.y = y || 0;
    this.z = z || 0;
};
LmvVector3$1.prototype = {
    constructor: LmvVector3$1,
    set: function set(x, y, z) {
        this.x = x;
        this.y = y;
        this.z = z;
        return this;
    },
    setX: function setX(x) {
        this.x = x;
        return this;
    },
    setY: function setY(y) {
        this.y = y;
        return this;
    },
    setZ: function setZ(z) {
        this.z = z;
        return this;
    },
    setComponent: function setComponent(index, value) {
        switch (index) {
            case 0:
                this.x = value;
                break;
            case 1:
                this.y = value;
                break;
            case 2:
                this.z = value;
                break;
            default:
                throw new Error('index is out of range: ' + index);
        }
    },
    getComponent: function getComponent(index) {
        switch (index) {
            case 0:
                return this.x;
            case 1:
                return this.y;
            case 2:
                return this.z;
            default:
                throw new Error('index is out of range: ' + index);
        }
    },
    clone: function clone() {
        return new this.constructor(this.x, this.y, this.z);
    },
    copy: function copy(v) {
        this.x = v.x;
        this.y = v.y;
        this.z = v.z;
        return this;
    },
    add: function add(v, w) {
        if (w !== undefined) {
            console.warn('THREE.Vector3: .add() now only accepts one argument. Use .addVectors( a, b ) instead.');
            return this.addVectors(v, w);
        }
        this.x += v.x;
        this.y += v.y;
        this.z += v.z;
        return this;
    },
    addScalar: function addScalar(s) {
        this.x += s;
        this.y += s;
        this.z += s;
        return this;
    },
    addVectors: function addVectors(a, b) {
        this.x = a.x + b.x;
        this.y = a.y + b.y;
        this.z = a.z + b.z;
        return this;
    },
    addScaledVector: function addScaledVector(v, s) {
        this.x += v.x * s;
        this.y += v.y * s;
        this.z += v.z * s;
        return this;
    },
    sub: function sub(v, w) {
        if (w !== undefined) {
            console.warn('THREE.Vector3: .sub() now only accepts one argument. Use .subVectors( a, b ) instead.');
            return this.subVectors(v, w);
        }
        this.x -= v.x;
        this.y -= v.y;
        this.z -= v.z;
        return this;
    },
    subScalar: function subScalar(s) {
        this.x -= s;
        this.y -= s;
        this.z -= s;
        return this;
    },
    subVectors: function subVectors(a, b) {
        this.x = a.x - b.x;
        this.y = a.y - b.y;
        this.z = a.z - b.z;
        return this;
    },
    multiply: function multiply(v, w) {
        if (w !== undefined) {
            console.warn('THREE.Vector3: .multiply() now only accepts one argument. Use .multiplyVectors( a, b ) instead.');
            return this.multiplyVectors(v, w);
        }
        this.x *= v.x;
        this.y *= v.y;
        this.z *= v.z;
        return this;
    },
    multiplyScalar: function multiplyScalar(scalar) {
        this.x *= scalar;
        this.y *= scalar;
        this.z *= scalar;
        return this;
    },
    multiplyVectors: function multiplyVectors(a, b) {
        this.x = a.x * b.x;
        this.y = a.y * b.y;
        this.z = a.z * b.z;
        return this;
    },
    applyMatrix3: function applyMatrix3(m) {
        var x = this.x;
        var y = this.y;
        var z = this.z;
        var e = m.elements;
        this.x = e[0] * x + e[3] * y + e[6] * z;
        this.y = e[1] * x + e[4] * y + e[7] * z;
        this.z = e[2] * x + e[5] * y + e[8] * z;
        return this;
    },
    applyMatrix4: function applyMatrix4(m) {
        // input: THREE.Matrix4 affine matrix
        var x = this.x,
            y = this.y,
            z = this.z;
        var e = m.elements;
        this.x = e[0] * x + e[4] * y + e[8] * z + e[12];
        this.y = e[1] * x + e[5] * y + e[9] * z + e[13];
        this.z = e[2] * x + e[6] * y + e[10] * z + e[14];
        return this;
    },
    applyProjection: function applyProjection(m) {
        // input: THREE.Matrix4 projection matrix
        var x = this.x,
            y = this.y,
            z = this.z;
        var e = m.elements;
        var d = 1 / (e[3] * x + e[7] * y + e[11] * z + e[15]); // perspective divide
        this.x = (e[0] * x + e[4] * y + e[8] * z + e[12]) * d;
        this.y = (e[1] * x + e[5] * y + e[9] * z + e[13]) * d;
        this.z = (e[2] * x + e[6] * y + e[10] * z + e[14]) * d;
        return this;
    },
    applyQuaternion: function applyQuaternion(q) {
        var x = this.x;
        var y = this.y;
        var z = this.z;
        var qx = q.x;
        var qy = q.y;
        var qz = q.z;
        var qw = q.w;
        // calculate quat * vector
        var ix = qw * x + qy * z - qz * y;
        var iy = qw * y + qz * x - qx * z;
        var iz = qw * z + qx * y - qy * x;
        var iw = -qx * x - qy * y - qz * z;
        // calculate result * inverse quat
        this.x = ix * qw + iw * -qx + iy * -qz - iz * -qy;
        this.y = iy * qw + iw * -qy + iz * -qx - ix * -qz;
        this.z = iz * qw + iw * -qz + ix * -qy - iy * -qx;
        return this;
    },
    transformDirection: function transformDirection(m) {
        // input: THREE.Matrix4 affine matrix
        // vector interpreted as a direction
        var x = this.x,
            y = this.y,
            z = this.z;
        var e = m.elements;
        this.x = e[0] * x + e[4] * y + e[8] * z;
        this.y = e[1] * x + e[5] * y + e[9] * z;
        this.z = e[2] * x + e[6] * y + e[10] * z;
        this.normalize();
        return this;
    },
    divide: function divide(v) {
        this.x /= v.x;
        this.y /= v.y;
        this.z /= v.z;
        return this;
    },
    divideScalar: function divideScalar(scalar) {
        if (scalar !== 0) {
            var invScalar = 1 / scalar;
            this.x *= invScalar;
            this.y *= invScalar;
            this.z *= invScalar;
        } else {
            this.x = 0;
            this.y = 0;
            this.z = 0;
        }
        return this;
    },
    min: function min(v) {
        if (this.x > v.x) {
            this.x = v.x;
        }
        if (this.y > v.y) {
            this.y = v.y;
        }
        if (this.z > v.z) {
            this.z = v.z;
        }
        return this;
    },
    max: function max(v) {
        if (this.x < v.x) {
            this.x = v.x;
        }
        if (this.y < v.y) {
            this.y = v.y;
        }
        if (this.z < v.z) {
            this.z = v.z;
        }
        return this;
    },
    clamp: function clamp(min, max) {
        // This function assumes min < max, if this assumption isn't true it will not operate correctly
        if (this.x < min.x) {
            this.x = min.x;
        } else if (this.x > max.x) {
            this.x = max.x;
        }
        if (this.y < min.y) {
            this.y = min.y;
        } else if (this.y > max.y) {
            this.y = max.y;
        }
        if (this.z < min.z) {
            this.z = min.z;
        } else if (this.z > max.z) {
            this.z = max.z;
        }
        return this;
    },
    clampScalar: function () {
        var min, max;
        return function clampScalar(minVal, maxVal) {
            if (min === undefined) {
                min = new LmvVector3$1();
                max = new LmvVector3$1();
            }
            min.set(minVal, minVal, minVal);
            max.set(maxVal, maxVal, maxVal);
            return this.clamp(min, max);
        };
    }(),
    floor: function floor() {
        this.x = Math.floor(this.x);
        this.y = Math.floor(this.y);
        this.z = Math.floor(this.z);
        return this;
    },
    ceil: function ceil() {
        this.x = Math.ceil(this.x);
        this.y = Math.ceil(this.y);
        this.z = Math.ceil(this.z);
        return this;
    },
    round: function round() {
        this.x = Math.round(this.x);
        this.y = Math.round(this.y);
        this.z = Math.round(this.z);
        return this;
    },
    roundToZero: function roundToZero() {
        this.x = this.x < 0 ? Math.ceil(this.x) : Math.floor(this.x);
        this.y = this.y < 0 ? Math.ceil(this.y) : Math.floor(this.y);
        this.z = this.z < 0 ? Math.ceil(this.z) : Math.floor(this.z);
        return this;
    },
    negate: function negate() {
        this.x = -this.x;
        this.y = -this.y;
        this.z = -this.z;
        return this;
    },
    dot: function dot(v) {
        return this.x * v.x + this.y * v.y + this.z * v.z;
    },
    lengthSq: function lengthSq() {
        return this.x * this.x + this.y * this.y + this.z * this.z;
    },
    length: function length() {
        return Math.sqrt(this.x * this.x + this.y * this.y + this.z * this.z);
    },
    lengthManhattan: function lengthManhattan() {
        return Math.abs(this.x) + Math.abs(this.y) + Math.abs(this.z);
    },
    normalize: function normalize() {
        return this.divideScalar(this.length());
    },
    setLength: function setLength(l) {
        var oldLength = this.length();
        if (oldLength !== 0 && l !== oldLength) {
            this.multiplyScalar(l / oldLength);
        }
        return this;
    },
    lerp: function lerp(v, alpha) {
        this.x += (v.x - this.x) * alpha;
        this.y += (v.y - this.y) * alpha;
        this.z += (v.z - this.z) * alpha;
        return this;
    },
    lerpVectors: function lerpVectors(v1, v2, alpha) {
        this.subVectors(v2, v1).multiplyScalar(alpha).add(v1);
        return this;
    },
    cross: function cross(v, w) {
        if (w !== undefined) {
            console.warn('THREE.Vector3: .cross() now only accepts one argument. Use .crossVectors( a, b ) instead.');
            return this.crossVectors(v, w);
        }
        var x = this.x,
            y = this.y,
            z = this.z;
        this.x = y * v.z - z * v.y;
        this.y = z * v.x - x * v.z;
        this.z = x * v.y - y * v.x;
        return this;
    },
    crossVectors: function crossVectors(a, b) {
        var ax = a.x,
            ay = a.y,
            az = a.z;
        var bx = b.x,
            by = b.y,
            bz = b.z;
        this.x = ay * bz - az * by;
        this.y = az * bx - ax * bz;
        this.z = ax * by - ay * bx;
        return this;
    },
    projectOnVector: function () {
        var v1, dot;
        return function projectOnVector(vector) {
            if (v1 === undefined) v1 = new LmvVector3$1();
            v1.copy(vector).normalize();
            dot = this.dot(v1);
            return this.copy(v1).multiplyScalar(dot);
        };
    }(),
    projectOnPlane: function () {
        var v1;
        return function projectOnPlane(planeNormal) {
            if (v1 === undefined) v1 = new LmvVector3$1();
            v1.copy(this).projectOnVector(planeNormal);
            return this.sub(v1);
        };
    }(),
    reflect: function () {
        // reflect incident vector off plane orthogonal to normal
        // normal is assumed to have unit length
        var v1;
        return function reflect(normal) {
            if (v1 === undefined) v1 = new LmvVector3$1();
            return this.sub(v1.copy(normal).multiplyScalar(2 * this.dot(normal)));
        };
    }(),
    distanceTo: function distanceTo(v) {
        return Math.sqrt(this.distanceToSquared(v));
    },
    distanceToSquared: function distanceToSquared(v) {
        var dx = this.x - v.x;
        var dy = this.y - v.y;
        var dz = this.z - v.z;
        return dx * dx + dy * dy + dz * dz;
    },
    setEulerFromRotationMatrix: function setEulerFromRotationMatrix(m, order) {
        console.error('THREE.Vector3: .setEulerFromRotationMatrix() has been removed. Use Euler.setFromRotationMatrix() instead.');
    },
    setEulerFromQuaternion: function setEulerFromQuaternion(q, order) {
        console.error('THREE.Vector3: .setEulerFromQuaternion() has been removed. Use Euler.setFromQuaternion() instead.');
    },
    getPositionFromMatrix: function getPositionFromMatrix(m) {
        console.warn('THREE.Vector3: .getPositionFromMatrix() has been renamed to .setFromMatrixPosition().');
        return this.setFromMatrixPosition(m);
    },
    getScaleFromMatrix: function getScaleFromMatrix(m) {
        console.warn('THREE.Vector3: .getScaleFromMatrix() has been renamed to .setFromMatrixScale().');
        return this.setFromMatrixScale(m);
    },
    getColumnFromMatrix: function getColumnFromMatrix(index, matrix) {
        console.warn('THREE.Vector3: .getColumnFromMatrix() has been renamed to .setFromMatrixColumn().');
        return this.setFromMatrixColumn(index, matrix);
    },
    setFromMatrixPosition: function setFromMatrixPosition(m) {
        this.x = m.elements[12];
        this.y = m.elements[13];
        this.z = m.elements[14];
        return this;
    },
    setFromMatrixScale: function setFromMatrixScale(m) {
        var sx = this.set(m.elements[0], m.elements[1], m.elements[2]).length();
        var sy = this.set(m.elements[4], m.elements[5], m.elements[6]).length();
        var sz = this.set(m.elements[8], m.elements[9], m.elements[10]).length();
        this.x = sx;
        this.y = sy;
        this.z = sz;
        return this;
    },
    setFromMatrixColumn: function setFromMatrixColumn(index, matrix) {
        var offset = index * 4;
        var me = matrix.elements;
        this.x = me[offset];
        this.y = me[offset + 1];
        this.z = me[offset + 2];
        return this;
    },
    equals: function equals(v) {
        return v.x === this.x && v.y === this.y && v.z === this.z;
    },
    fromArray: function fromArray(array, offset) {
        if (offset === undefined) offset = 0;
        this.x = array[offset];
        this.y = array[offset + 1];
        this.z = array[offset + 2];
        return this;
    },
    toArray: function toArray(array, offset) {
        if (array === undefined) array = [];
        if (offset === undefined) offset = 0;
        array[offset] = this.x;
        array[offset + 1] = this.y;
        array[offset + 2] = this.z;
        return array;
    },
    fromAttribute: function fromAttribute(attribute, index, offset) {
        if (offset === undefined) offset = 0;
        index = index * attribute.itemSize + offset;
        this.x = attribute.array[index];
        this.y = attribute.array[index + 1];
        this.z = attribute.array[index + 2];
        return this;
    }
};

/**
 * @author bhouston / http://exocortex.com
 * @author WestLangley / http://github.com/WestLangley
 */
/* Pruned version of THREE.Box3, for use in the LMV web worker */
var LmvBox3 = function LmvBox3(min, max) {
    this.min = min !== undefined ? min : new LmvVector3$1(Infinity, Infinity, Infinity);
    this.max = max !== undefined ? max : new LmvVector3$1(-Infinity, -Infinity, -Infinity);
};
LmvBox3.prototype = {
    constructor: LmvBox3,
    set: function set(min, max) {
        this.min.copy(min);
        this.max.copy(max);
        return this;
    },
    setFromPoints: function setFromPoints(points) {
        this.makeEmpty();
        for (var i = 0, il = points.length; i < il; i++) {
            this.expandByPoint(points[i]);
        }
        return this;
    },
    setFromArray: function setFromArray(array, offset) {
        this.min.x = array[offset];
        this.min.y = array[offset + 1];
        this.min.z = array[offset + 2];
        this.max.x = array[offset + 3];
        this.max.y = array[offset + 4];
        this.max.z = array[offset + 5];
        return this;
    },
    copyToArray: function copyToArray(array, offset) {
        array[offset] = this.min.x;
        array[offset + 1] = this.min.y;
        array[offset + 2] = this.min.z;
        array[offset + 3] = this.max.x;
        array[offset + 4] = this.max.y;
        array[offset + 5] = this.max.z;
    },
    setFromCenterAndSize: function () {
        var v1 = new LmvVector3$1();
        return function (center, size) {
            var halfSize = v1.copy(size).multiplyScalar(0.5);
            this.min.copy(center).sub(halfSize);
            this.max.copy(center).add(halfSize);
            return this;
        };
    }(),
    clone: function clone() {
        return new this.constructor().copy(this);
    },
    copy: function copy(box) {
        this.min.copy(box.min);
        this.max.copy(box.max);
        return this;
    },
    makeEmpty: function makeEmpty() {
        this.min.x = this.min.y = this.min.z = Infinity;
        this.max.x = this.max.y = this.max.z = -Infinity;
        return this;
    },
    empty: function empty() {
        // this is a more robust check for empty than ( volume <= 0 ) because volume can get positive with two negative axes
        return this.max.x < this.min.x || this.max.y < this.min.y || this.max.z < this.min.z;
    },
    center: function center(optionalTarget) {
        var result = optionalTarget || new LmvVector3$1();
        return result.addVectors(this.min, this.max).multiplyScalar(0.5);
    },
    size: function size(optionalTarget) {
        var result = optionalTarget || new LmvVector3$1();
        return result.subVectors(this.max, this.min);
    },
    expandByPoint: function expandByPoint(point) {
        this.min.min(point);
        this.max.max(point);
        return this;
    },
    expandByVector: function expandByVector(vector) {
        this.min.sub(vector);
        this.max.add(vector);
        return this;
    },
    expandByScalar: function expandByScalar(scalar) {
        this.min.addScalar(-scalar);
        this.max.addScalar(scalar);
        return this;
    },
    containsPoint: function containsPoint(point) {
        if (point.x < this.min.x || point.x > this.max.x || point.y < this.min.y || point.y > this.max.y || point.z < this.min.z || point.z > this.max.z) {
            return false;
        }
        return true;
    },
    containsBox: function containsBox(box) {
        if (this.min.x <= box.min.x && box.max.x <= this.max.x && this.min.y <= box.min.y && box.max.y <= this.max.y && this.min.z <= box.min.z && box.max.z <= this.max.z) {
            return true;
        }
        return false;
    },
    getParameter: function getParameter(point, optionalTarget) {
        // This can potentially have a divide by zero if the box
        // has a size dimension of 0.
        var result = optionalTarget || new LmvVector3$1();
        return result.set((point.x - this.min.x) / (this.max.x - this.min.x), (point.y - this.min.y) / (this.max.y - this.min.y), (point.z - this.min.z) / (this.max.z - this.min.z));
    },
    isIntersectionBox: function isIntersectionBox(box) {
        // using 6 splitting planes to rule out intersections.
        if (box.max.x < this.min.x || box.min.x > this.max.x || box.max.y < this.min.y || box.min.y > this.max.y || box.max.z < this.min.z || box.min.z > this.max.z) {
            return false;
        }
        return true;
    },
    clampPoint: function clampPoint(point, optionalTarget) {
        var result = optionalTarget || new LmvVector3$1();
        return result.copy(point).clamp(this.min, this.max);
    },
    distanceToPoint: function () {
        var v1 = new LmvVector3$1();
        return function (point) {
            var clampedPoint = v1.copy(point).clamp(this.min, this.max);
            return clampedPoint.sub(point).length();
        };
    }(),
    intersect: function intersect(box) {
        this.min.max(box.min);
        this.max.min(box.max);
        return this;
    },
    union: function union(box) {
        this.min.min(box.min);
        this.max.max(box.max);
        return this;
    },
    applyMatrix4: function () {
        var points = [new LmvVector3$1(), new LmvVector3$1(), new LmvVector3$1(), new LmvVector3$1(), new LmvVector3$1(), new LmvVector3$1(), new LmvVector3$1(), new LmvVector3$1()];
        return function (matrix) {
            // NOTE: I am using a binary pattern to specify all 2^3 combinations below
            points[0].set(this.min.x, this.min.y, this.min.z).applyMatrix4(matrix); // 000
            points[1].set(this.min.x, this.min.y, this.max.z).applyMatrix4(matrix); // 001
            points[2].set(this.min.x, this.max.y, this.min.z).applyMatrix4(matrix); // 010
            points[3].set(this.min.x, this.max.y, this.max.z).applyMatrix4(matrix); // 011
            points[4].set(this.max.x, this.min.y, this.min.z).applyMatrix4(matrix); // 100
            points[5].set(this.max.x, this.min.y, this.max.z).applyMatrix4(matrix); // 101
            points[6].set(this.max.x, this.max.y, this.min.z).applyMatrix4(matrix); // 110
            points[7].set(this.max.x, this.max.y, this.max.z).applyMatrix4(matrix); // 111
            this.makeEmpty();
            this.setFromPoints(points);
            return this;
        };
    }(),
    translate: function translate(offset) {
        this.min.add(offset);
        this.max.add(offset);
        return this;
    },
    equals: function equals(box) {
        return box.min.equals(this.min) && box.max.equals(this.max);
    }
};

var getVertexCount$1 = VertexEnumerator.getVertexCount;
var enumMeshTriangles$1 = VertexEnumerator.enumMeshTriangles;
var enumMeshVertices$1 = VertexEnumerator.enumMeshVertices;
function remapVertices(geom, boundingBox) {
    //de-duplicate vertices based on position only (ignoring normals)
    var remap = [];
    var uniqueV = {};
    var boxScale = 1.0;
    if (geom.boundingBox || boundingBox) {
        var bbox = new LmvBox3().copy(geom.boundingBox || boundingBox);
        var sz = bbox.size();
        boxScale = Math.max(sz.x, Math.max(sz.y, sz.z));
    }
    var SCALE = (1 << 16) / boxScale; //snap scale, assuming unit mesh
    function getVertexIndex(v, i) {
        var x = 0 | v.x * SCALE;
        var y = 0 | v.y * SCALE;
        var z = 0 | v.z * SCALE;
        var mx = uniqueV[x];
        if (!mx) {
            uniqueV[x] = mx = {};
        }
        var my = mx[y];
        if (!my) {
            mx[y] = my = {};
        }
        var mz = my[z];
        if (mz === undefined) {
            my[z] = mz = i;
        }
        return mz;
    }
    function remapcb(v, i) {
        var vidx = getVertexIndex(v, i);
        remap[i] = vidx;
    }
    enumMeshVertices$1(geom, remapcb);
    return remap;
}
function transformVertices(geom, toWorld) {
    var vbuf = new Float32Array(3 * getVertexCount$1(geom));
    function cb(v, i) {
        vbuf[3 * i] = v.x;
        vbuf[3 * i + 1] = v.y;
        vbuf[3 * i + 2] = v.z;
    }
    enumMeshVertices$1(geom, cb, toWorld);
    return vbuf;
}
function createWireframe(geom, toWorld, boundingBox, wantAllTriangleEdges) {
    if (geom.isLines) return;
    if (geom.iblines) return;
    //find unique vertices
    var remap = remapVertices(geom, boundingBox);
    //get vertices in world space -- we need this for
    //correct angle calculations
    var worldVerts = transformVertices(geom, toWorld);
    //loop over all triangles, keeping track of
    //edges that seem important
    var seenEdges = {};
    var edgeIB = [];
    var _v1 = new LmvVector3$1();
    var _v2 = new LmvVector3$1();
    var _v3 = new LmvVector3$1();
    var _n1 = new LmvVector3$1();
    var _n2 = new LmvVector3$1();
    function getV(i, v) {
        v.x = worldVerts[3 * i];
        v.y = worldVerts[3 * i + 1];
        v.z = worldVerts[3 * i + 2];
    }
    function getNormal(i1, i2, i3, n) {
        getV(i1, _v1);
        getV(i2, _v2);
        getV(i3, _v3);
        _v2.sub(_v1);
        _v3.sub(_v1);
        _v2.cross(_v3);
        n.copy(_v2).normalize();
    }
    function doOneEdge(i1orig, i2orig, opp1orig) {
        var i1 = remap[i1orig];
        var i2 = remap[i2orig];
        var opp1 = remap[opp1orig];
        //Ignore degenerates
        if (i1 === i2 || i1 === opp1 || i2 === opp1) return;
        var reversed = false;
        if (i1 > i2) {
            var tmp = i1;
            i1 = i2;
            i2 = tmp;
            reversed = true;
        }
        var e1 = seenEdges[i1];
        if (e1) {
            var opp2orig = e1[i2];
            if (opp2orig === undefined) {
                e1[i2] = reversed ? -opp1orig - 1 : opp1orig;
            } else {
                //We now know two triangles that share this edge,
                //we can check if it's important
                if (!wantAllTriangleEdges) {
                    //Use original indices, so that we
                    //can do the math with the correct winding order
                    getNormal(i1orig, i2orig, opp1orig, _n1);
                    if (opp2orig < 0) {
                        getNormal(i2, i1, remap[-opp2orig - 1], _n2);
                    } else {
                        getNormal(i1, i2, remap[opp2orig], _n2);
                    }
                    var dot = _n1.dot(_n2);
                    if (Math.abs(dot) < 0.25) {
                        edgeIB.push(i1orig);
                        edgeIB.push(i2orig);
                    }
                } else {
                    edgeIB.push(i1orig);
                    edgeIB.push(i2orig);
                }
                delete e1[i2];
            }
        } else {
            seenEdges[i1] = {};
            seenEdges[i1][i2] = opp1orig;
        }
    }
    function tricb(vA, vB, vC, iA, iB, iC) {
        doOneEdge(iA, iB, iC);
        doOneEdge(iB, iC, iA);
        doOneEdge(iC, iA, iB);
    }
    //find edges that have neighboring triangles at sharp angle
    enumMeshTriangles$1(geom, tricb);
    //process remaining edges (outer edges that only have one triangle)
    for (var i1 in seenEdges) {
        for (var i2 in seenEdges[i1]) {
            edgeIB.push(parseInt(i1));
            edgeIB.push(parseInt(i2));
        }
    }
    if (edgeIB.length > 1) {
        geom.iblines = new Uint16Array(edgeIB.length);
        geom.iblines.set(edgeIB);
    }
    /*
        for (var i=0; i<geom.ib.length; i++) {
            geom.ib[i] = remap[geom.ib[i]];
        }
        */
}
var DeriveTopology = {
    createWireframe: createWireframe
};

var inverseMatrix;
var ray;
var vA$1;
var vB$1;
var vC$1;
function init_three() {
    if (!inverseMatrix) {
        inverseMatrix = new THREE$1.Matrix4();
        ray = new THREE$1.Ray();
        vA$1 = new THREE$1.Vector3();
        vB$1 = new THREE$1.Vector3();
        vC$1 = new THREE$1.Vector3();
    }
}
function meshRayCast(mesh, raycaster, intersects) {
    init_three();
    var geometry = mesh.geometry;
    if (!geometry) return;
    var material = mesh.material;
    var side = material ? material.side : THREE$1.FrontSide;
    inverseMatrix.getInverse(mesh.matrixWorld);
    ray.copy(raycaster.ray).applyMatrix4(inverseMatrix);
    var precision = raycaster.precision;
    var intersectionPoint, distance;
    VertexEnumerator.enumMeshTriangles(geometry, function (vA, vB, vC, a, b, c) {
        if (side === THREE$1.BackSide) {
            intersectionPoint = ray.intersectTriangle(vC, vB, vA, true);
        } else {
            intersectionPoint = ray.intersectTriangle(vA, vB, vC, side !== THREE$1.DoubleSide);
        }
        if (intersectionPoint === null) return;
        intersectionPoint.applyMatrix4(mesh.matrixWorld);
        distance = raycaster.ray.origin.distanceTo(intersectionPoint);
        if (distance < precision || distance < raycaster.near || distance > raycaster.far) return;
        intersects.push({
            distance: distance,
            point: intersectionPoint,
            face: new THREE$1.Face3(a, b, c, THREE$1.Triangle.normal(vA, vB, vC)),
            faceIndex: null,
            fragId: mesh.fragId,
            dbId: mesh.dbId
        });
    });
}
function lineRayCast(mesh, raycaster, intersects) {
    init_three();
    var geometry = mesh.geometry;
    if (!geometry) return;
    var precision = raycaster.linePrecision;
    if (mesh.isWideLine && mesh.geometry.lineWidth) {
        precision = mesh.geometry.lineWidth;
    }
    var precisionSq = precision * precision;
    inverseMatrix.getInverse(mesh.matrixWorld);
    ray.copy(raycaster.ray).applyMatrix4(inverseMatrix);
    var interSegment = new THREE$1.Vector3();
    var interRay = new THREE$1.Vector3();
    if (geometry instanceof THREE$1.BufferGeometry) {
        VertexEnumerator.enumMeshLines(geometry, function (vStart, vEnd) {
            var distance, distSq;
            ray.distanceSqToSegment(vStart, vEnd, interRay, interSegment);
            interSegment.applyMatrix4(mesh.matrixWorld);
            interRay.applyMatrix4(mesh.matrixWorld);
            distSq = interSegment.distanceToSquared(interRay);
            if (distSq > precisionSq) return;
            distance = raycaster.ray.origin.distanceTo(interSegment);
            if (distance < raycaster.near || distance > raycaster.far) return;
            intersects.push({
                distance: distance,
                // What do we want? intersection point on the ray or on the segment??
                // point: raycaster.ray.at( distance ),
                point: interSegment,
                face: null,
                faceIndex: null,
                fragId: mesh.fragId,
                dbId: mesh.dbId
            });
        });
    }
}
/// c.f. THREE.PointCloud.prototype.raycast()
function pointRayCast(mesh, raycaster, intersects) {
    init_three();
    var geometry = mesh.geometry;
    if (!geometry) return;
    inverseMatrix.getInverse(mesh.matrixWorld);
    ray.copy(raycaster.ray).applyMatrix4(inverseMatrix);
    var precision = raycaster.precision;
    var pickRadius = raycaster.params.PointCloud.threshold;
    if (!pickRadius) pickRadius = 1;
    pickRadius *= Math.max(3, geometry.pointSize); // small point sizes are too hard to pick!
    pickRadius /= 4;
    if (geometry instanceof THREE$1.BufferGeometry) {
        VertexEnumerator.enumMeshVertices(geometry, function (point) {
            // points are drawn as squares, but treat them as circles
            // to save having to calculate the orientation
            var distanceToRay = ray.distanceToPoint(point);
            if (distanceToRay > pickRadius) {
                return;
            }
            var intersectionPoint = ray.closestPointToPoint(point);
            if (intersectionPoint === null) return;
            intersectionPoint.applyMatrix4(mesh.matrixWorld);
            var distance = raycaster.ray.origin.distanceTo(intersectionPoint);
            if (distance < precision || distance < raycaster.near || distance > raycaster.far) {
                return;
            }
            intersects.push({
                distance: distance,
                point: point,
                face: null,
                faceIndex: null,
                fragId: mesh.fragId,
                dbId: mesh.dbId
            });
        });
    } else {
        // not implemented - other geometry types
    }
}
function rayCast(mesh, raycaster, intersects) {
    if (mesh.isLine || mesh.isWideLine) lineRayCast(mesh, raycaster, intersects);else if (mesh.isPoint) pointRayCast(mesh, raycaster, intersects);else meshRayCast(mesh, raycaster, intersects);
}
function intersectObjectRec(object, raycaster, intersects, recursive) {
    if (object instanceof THREE$1.Mesh) rayCast(object, raycaster, intersects); //use our extended impl in case of Mesh.
    else object.raycast(raycaster, intersects); //fall back to normal THREE.js impl
    if (recursive === true) {
        var children = object.children;
        for (var i = 0, l = children.length; i < l; i++) {
            intersectObjectRec(children[i], raycaster, intersects, true);
        }
    }
}
var descSort = function descSort(a, b) {
    return a.distance - b.distance;
};
function intersectObject(object, raycaster, intersects, recursive) {
    intersectObjectRec(object, raycaster, intersects, recursive);
    intersects.sort(descSort);
}
var VBIntersector = {
    meshRayCast: meshRayCast,
    lineRayCast: lineRayCast,
    rayCast: rayCast,
    intersectObject: intersectObject
};

/**
 * Maintains a list of buffer geometries and running totals of their memory usage, etc.
 * Each geometry gets an integer ID to be used as reference in packed fragment lists.
 * @param {number} numObjects Number of objects (may be 0 if not known in advance).
 * @param {boolean} is2d True for 2D datasets.
 * @param {boolean} [disableStreaming] Set to true for small models to enforce full GPU upload.
 * @constructor
 */
function GeometryList(numObjects, is2d, disableStreaming) {
    // array of BufferGeometry instances. Indexed by svfid.
    this.geoms = [null]; //keep index 0 reserved for invalid id
    this.numGeomsInMemory = 0; // total number of geoms added via addGeometry(..) (may be <this.geoms.length)
    this.geomMemory = 0; // total memory in bytes of all geoms
    this.gpuMeshMemory = 0; // total memory in bytes of all geoms, exluding those that we draw from system memory
    this.gpuNumMeshes = 0; // total number of geoms etries that we fully upload to GPU for drawing
    this.geomPolyCount = 0; // summed number of polygons, where geometries with mulitple instances are counted only once.
    this.instancePolyCount = 0; // summed number of polygons, counted per instance
    this.is2d = is2d;
    // 6 floats per geometry
    this.geomBoxes = new Float32Array(Math.max(1, numObjects + 1) * 6);
    // If false, we use a heuristic to determine which shapes are uploaded to GPU and which
    // ones we draw from CPU memory using (slower) streaming draw.
    this.disableStreaming = !!disableStreaming;
}
GeometryList.prototype.getGeometry = function (svfid) {
    return this.geoms[svfid];
};
/**
 * Determines for a geometry whether to store it on CPU or GPU.
 * @param {THREE.BufferGeometry} geometry
 * @param {number}               numInstances
 * @param {number}               gpuNumMeshes
 * @param {number}               gpuMeshMemory
 */
GeometryList.prototype.chooseMemoryType = function (geometry, numInstances, gpuNumMeshes, gpuMeshMemory) {
    // Define GPU memory limits for heuristics below
    var GPU_MEMORY_LOW = GPU_MEMORY_LIMIT;
    var GPU_MEMORY_HIGH = 2 * GPU_MEMORY_LOW;
    var GPU_MESH_MAX = GPU_OBJECT_LIMIT;
    if (this.isf2d) GPU_MEMORY_HIGH *= 2; //there isn't much in terms of textures in 2d drawings, so we can afford to more room for geometry
    //this.disableStreaming = true;
    //Heuristically determine if we want to load this mesh onto the GPU
    //or use streaming draw from system memory
    if (this.disableStreaming || gpuMeshMemory < GPU_MEMORY_LOW && gpuNumMeshes < GPU_MESH_MAX) {
        //We are below the lower limits, so the mesh automatically is
        //assigned to retained mode
        geometry.streamingDraw = false;
        geometry.streamingIndex = false;
    } else if (gpuMeshMemory >= GPU_MEMORY_HIGH) {
        //We are above the upper limit, so mesh is automatically
        //assigned to streaming draw
        geometry.streamingDraw = true;
        geometry.streamingIndex = true;
    } else {
        //Between the lower and upper limits,
        //Score mesh importance based on its size
        //and number of instances it has. If the score
        //is high, we will prefer to put the mesh on the GPU
        //so that we don't schlep it across the bus all the time.
        var weightScore;
        if (!this.is2d) {
            weightScore = geometry.byteSize * (numInstances || 1);
        } else {
            //In the case of 2D, there are no instances, so we just keep
            //piling into the GPU until we reach the "high" mark.
            weightScore = 100001;
        }
        if (weightScore < 100000) {
            geometry.streamingDraw = true;
            geometry.streamingIndex = true;
        }
    }
};
/**
 * Stores geometry in this.geoms, updates overall GPU/CPU statistics (this.geometry etc.),
 * changes the geometry object:
 *      - Sets geometry.streamingDraw/streamingIndex (to control whether to draw the mesh from system mem or GPU)
 *      - Sets geometry.svfid, so that each geom knows its index.
 *      - Deletes the bbox and bsphere to safe memory
 * Assumptions:
 *      - It is not expected to be called multiple times for the same svfid. This would mess up some statistics.
 * @param {LmvBufferGeometry} geometry - Must not be null. A geometry cannot be added
 *      to more than one GeometryList. (see below why)
 * @param {number} numInstances - default 1 if undef.
 * @param {number} svfid - Geometry will be stored in this.geoms[svfid].
 *      If undef or <=0, geometry is appended at the end of this.geoms.
 */
GeometryList.prototype.addGeometry = function (geometry, numInstances, svfid) {
    this.chooseMemoryType(geometry, numInstances, this.gpuNumMeshes, this.gpuMeshMemory);
    // track overall GPU workload
    var size = geometry.byteSize + GEOMETRY_OVERHEAD;
    if (!geometry.streamingDraw) {
        if (isMobileDevice()) size += geometry.byteSize;
        this.gpuMeshMemory += geometry.byteSize;
        this.gpuNumMeshes += 1;
    }
    this.numGeomsInMemory++;
    // if no svfid is defined
    if (svfid === undefined || svfid <= 0) svfid = this.geoms.length;
    // store geometry (may increase array length)
    this.geoms[svfid] = geometry;
    // resize this.geombboxes if necessary
    var fill = this.geomBoxes.length / 6 | 0;
    if (fill < this.geoms.length) {
        var end = this.geoms.length * 3 / 2 | 0;
        var nb = new Float32Array(6 * end);
        nb.set(this.geomBoxes);
        // Make all of the new bounds empty
        var empty = new THREE$1.Box3();
        empty.makeEmpty();
        while (fill < end) {
            nb[fill * 6] = empty.min.x;
            nb[fill * 6 + 1] = empty.min.y;
            nb[fill * 6 + 2] = empty.min.z;
            nb[fill * 6 + 3] = empty.max.x;
            nb[fill * 6 + 4] = empty.max.y;
            nb[fill++ * 6 + 5] = empty.max.z;
        }
        this.geomBoxes = nb;
    }
    // copy geometry bbox to this.geomBoxes
    var bb = geometry.boundingBox;
    if (!bb) {
        if (!geometry.hash) {
            console.error("Mesh without bbox and without hash should not be.");
        }
        this.geomBoxes[svfid * 6] = -0.5;
        this.geomBoxes[svfid * 6 + 1] = -0.5;
        this.geomBoxes[svfid * 6 + 2] = -0.5;
        this.geomBoxes[svfid * 6 + 3] = 0.5;
        this.geomBoxes[svfid * 6 + 4] = 0.5;
        this.geomBoxes[svfid * 6 + 5] = 0.5;
    } else {
        this.geomBoxes[svfid * 6] = bb.min.x;
        this.geomBoxes[svfid * 6 + 1] = bb.min.y;
        this.geomBoxes[svfid * 6 + 2] = bb.min.z;
        this.geomBoxes[svfid * 6 + 3] = bb.max.x;
        this.geomBoxes[svfid * 6 + 4] = bb.max.y;
        this.geomBoxes[svfid * 6 + 5] = bb.max.z;
    }
    //Free the bbx objects if we don't want them.
    if (exports.memoryOptimizedLoading && !this.is2d) {
        geometry.boundingBox = null;
        geometry.boundingSphere = null;
    }
    // track system-side memory
    this.geomMemory += size;
    // track polygon count
    //TODO: Asssignment into the svf is temporary until the dependencies
    //are unentangled
    var ib = geometry.attributes['index'].array || geometry.ib;
    var polyCount = geometry.isLines ? ib.length / 2 : ib.length / 3;
    this.geomPolyCount += polyCount;
    this.instancePolyCount += polyCount * (numInstances || 1);
    // Record the count that can be decrease properly when geometry removed.
    geometry.polyCount = polyCount;
    geometry.instanceCount = numInstances || 1;
    geometry.svfid = svfid;
    geometry.lockCount = 0;
    return svfid;
};
/**
 * Removes the geometry with svfid 'idx' from the list.
 * Note: Unlike addGeometry, this method only updates this.numGeomsInMemory. All other statistics keep the same.
 * @param {int} idx - Geometry ID.
 * @returns {int} Size of the removed geometry, or 0.
 */
GeometryList.prototype.removeGeometry = function (idx, renderer) {
    // if there is no geom assigned, just return 0
    var geometry = this.getGeometry(idx);
    if (!geometry || geometry.lockCount > 0) {
        return 0;
    }
    var size = geometry.byteSize + GEOMETRY_OVERHEAD;
    renderer && renderer.deallocateGeometry(geometry);
    if (!geometry.streamingDraw) {
        if (isMobileDevice()) size += geometry.byteSize;
        this.gpuMeshMemory -= geometry.byteSize;
        this.gpuNumMeshes -= 1;
    }
    // remove geometry from the list
    this.geoms[idx] = null;
    // decrease its related counts
    this.geomMemory -= size;
    this.numGeomsInMemory--;
    this.geomPolyCount -= geometry.polyCount;
    this.instancePolyCount -= geometry.instanceCount * geometry.polyCount;
    return size;
};
/**
 * Locks the geometry with svfid 'idx'.
 * Locked geometry will not be removed when paging out.
 * Use sparingly if on demand loading is enabled.
 * @param {int} idx - Geometry ID.
 * @returns {boolean} True if the geometry was in memory and was locked.
 */
GeometryList.prototype.lockGeometry = function (idx) {
    var geometry = this.getGeometry(idx);
    if (!geometry) {
        return false;
    }
    ++geometry.lockCount;
    return true;
};
/**
 * Unlocks the geometry with svfid 'idx'.
 * Locked geometry will not be removed when paging out.
 * Call once for each time you call lockGeometry.
 * @param {int} idx - Geometry ID.
 * @returns {boolean} True if the geometry was in memory and was locked.
 */
GeometryList.prototype.unlockGeometry = function (idx) {
    var geometry = this.getGeometry(idx);
    if (!geometry || geometry.lockCount <= 0) {
        return false;
    }
    --geometry.lockCount;
    return true;
};
/**
 * Gets the lock count for the geometry with svfid 'idx'.
 * Geometry is locked if the lock count is > 0.
 * Locked geometry will not be removed when paging out.
 * @param {int} idx - Geometry ID.
 * @returns {int} The lock count of the geometry, or -1 if the geometry is not in memory.
 */
GeometryList.prototype.getLockCount = function (idx) {
    var geometry = this.getGeometry(idx);
    if (!geometry) {
        return -1;
    }
    return geometry.lockCount;
};
/**
 * Returns bounding box of a geometry.
 * @param {number} geomid - Geometry ID.
 * @param {THREE.Box3|LmvBox3} dst - Set to empty is there is no geometry of this id.
 */
GeometryList.prototype.getModelBox = function (geomid, dst) {
    // return empty box if geomid is out of bounds. If the id is in bounds
    // then the stored bbox is empty if the geometry hasn't been loaded 
    if (this.geomBoxes.length / 6 <= geomid) {
        dst.makeEmpty();
        return;
    }
    // extract bbox values from Float32Array this.geomboxes
    var off = geomid * 6;
    var bb = this.geomBoxes;
    dst.min.x = bb[off];
    dst.min.y = bb[off + 1];
    dst.min.z = bb[off + 2];
    dst.max.x = bb[off + 3];
    dst.max.y = bb[off + 4];
    dst.max.z = bb[off + 5];
};
// Tell renderer to release all GPU buffers. 
// renderer: instaneof FireFlyWebGLRenderer
GeometryList.prototype.dispose = function (renderer) {
    if (!renderer) return;
    for (var i = 0, iEnd = this.geoms.length; i < iEnd; i++) {
        if (this.geoms[i]) renderer.deallocateGeometry(this.geoms[i]);
    }
};
GeometryList.prototype.printStats = function () {
    THREE$1.log("Total geometry size: " + this.geomMemory / (1024 * 1024) + " MB");
    THREE$1.log("Number of meshes: " + this.geoms.length);
    THREE$1.log("Num Meshes on GPU: " + this.gpuNumMeshes);
    THREE$1.log("Net GPU geom memory used: " + this.gpuMeshMemory);
};

// Rearranged logically, base 3. X is 1's digit, Y is 10's digit, Z is 100's digit.
// low/medium/high value is 0/1/2. So the center of the 3x3x3 space is == 111 base 3 == 13.
// old 64-position code, which is what the comment indices are based on
// var pos = ((this.eye.x < box.min.x) ?  1 : 0)   // 1 = left
//         + ((this.eye.x > box.max.x) ?  2 : 0)   // 2 = right
//         + ((this.eye.y < box.min.y) ?  4 : 0)   // 4 = bottom
//         + ((this.eye.y > box.max.y) ?  8 : 0)   // 8 = top
//         + ((this.eye.z < box.min.z) ? 16 : 0)   // 16 = front
//         + ((this.eye.z > box.max.z) ? 32 : 0);  // 32 = back
var _boxIndexList = [[1, 5, 4, 7, 3, 2, 6], [0, 3, 2, 1, 5, 4, 6], [0, 3, 2, 6, 5, 4, 6], [0, 4, 7, 3, 2, 1, 6], [0, 3, 2, 1, -1, -1, 4], [0, 3, 2, 6, 5, 1, 6], [0, 4, 7, 6, 2, 1, 6], [0, 3, 7, 6, 2, 1, 6], [0, 3, 7, 6, 5, 1, 6], [0, 1, 5, 4, 7, 3, 6], [0, 1, 5, 4, -1, -1, 4], [0, 1, 2, 6, 5, 4, 6], [0, 4, 7, 3, -1, -1, 4], [-1, -1, -1, -1, -1, -1, 0], [1, 2, 6, 5, -1, -1, 4], [0, 4, 7, 6, 2, 3, 6], [2, 3, 7, 6, -1, -1, 4], [1, 2, 3, 7, 6, 5, 6], [0, 1, 5, 6, 7, 3, 6], [0, 1, 5, 6, 7, 4, 6], [0, 1, 2, 6, 7, 4, 6], [0, 4, 5, 6, 7, 3, 6], [4, 5, 6, 7, -1, -1, 4], [1, 2, 6, 7, 4, 5, 6], [0, 4, 5, 6, 2, 3, 6], [2, 3, 7, 4, 5, 6, 6], [1, 2, 3, 7, 4, 5, 6] //42 back, top, right
];
//Encapsulates frustum-box intersection logic
var FrustumIntersector = function FrustumIntersector() {
    this.frustum = new THREE$1.Frustum();
    this.viewProj = new THREE$1.Matrix4();
    this.viewDir = [0, 0, 1];
    this.ar = 1.0;
    this.viewport = new THREE$1.Vector3(1, 1, 1);
    this.areaConv = 1;
    this.areaCullThreshold = 1; // The pixel size of the object projected on screen, will be culled if less than this value.
    this.eye = new THREE$1.Vector3();
};
// Put the result values as properties of FrustumIntersector
// TODO should merge this with code below
Object.defineProperty(FrustumIntersector, 'OUTSIDE', { value: 0 });
Object.defineProperty(FrustumIntersector, 'INTERSECTS', { value: 1 });
Object.defineProperty(FrustumIntersector, 'CONTAINS', { value: 2 });
Object.defineProperty(FrustumIntersector, 'CONTAINMENT_UNKNOWN', { value: -1 });
FrustumIntersector.prototype.reset = function (camera) {
    this.viewProj.multiplyMatrices(camera.projectionMatrix, camera.matrixWorldInverse);
    this.frustum.setFromMatrix(this.viewProj);
    var vm = camera.matrixWorldInverse.elements;
    this.ar = camera.aspect;
    this.viewDir[0] = -vm[2];
    this.viewDir[1] = -vm[6];
    this.viewDir[2] = -vm[10];
    this.eye.x = camera.position.x;
    this.eye.y = camera.position.y;
    this.eye.z = camera.position.z;
    this.areaConv = camera.clientWidth * camera.clientHeight / 4;
};
FrustumIntersector.prototype.projectedArea = function () {
    var points;
    var tmpBox;
    function init_three() {
        if (!points) {
            points = [new THREE$1.Vector3(), new THREE$1.Vector3(), new THREE$1.Vector3(), new THREE$1.Vector3(), new THREE$1.Vector3(), new THREE$1.Vector3(), new THREE$1.Vector3(), new THREE$1.Vector3()];
            tmpBox = new THREE$1.Box2();
        }
    }
    function applyProjection(p, m) {
        var x = p.x,
            y = p.y,
            z = p.z;
        var e = m.elements;
        var w = e[3] * x + e[7] * y + e[11] * z + e[15];
        //This is the difference between this function and
        //the normal THREE.Vector3.applyProjection. We avoid
        //inverting the positions of points behind the camera,
        //otherwise our screen area computation can result in
        //boxes getting clipped out when they are in fact partially visible.
        if (w < 0) w = -w;
        var d = 1.0 / w;
        p.x = (e[0] * x + e[4] * y + e[8] * z + e[12]) * d;
        p.y = (e[1] * x + e[5] * y + e[9] * z + e[13]) * d;
        //We also don't need the Z
        //p.z = ( e[ 2 ] * x + e[ 6 ] * y + e[ 10 ] * z + e[ 14 ] ) * d;
    }
    return function (box) {
        if (box.empty()) return 0;
        init_three();
        var matrix = this.viewProj;
        // NOTE: I am using a binary pattern to specify all 2^3 combinations below
        points[0].set(box.min.x, box.min.y, box.min.z); // 000
        points[1].set(box.min.x, box.min.y, box.max.z); // 001
        points[2].set(box.min.x, box.max.y, box.min.z); // 010
        points[3].set(box.min.x, box.max.y, box.max.z); // 011
        points[4].set(box.max.x, box.min.y, box.min.z); // 100
        points[5].set(box.max.x, box.min.y, box.max.z); // 101
        points[6].set(box.max.x, box.max.y, box.min.z); // 110
        points[7].set(box.max.x, box.max.y, box.max.z); // 111
        for (var i = 0; i < 8; i++) {
            applyProjection(points[i], matrix);
        }tmpBox.makeEmpty();
        tmpBox.setFromPoints(points);
        // Clamp both min and max value between [-1.0, 1.0]
        if (tmpBox.min.x < -1.0) tmpBox.min.x = -1.0;
        if (tmpBox.min.x > 1.0) tmpBox.min.x = 1.0;
        if (tmpBox.min.y < -1.0) tmpBox.min.y = -1.0;
        if (tmpBox.min.y > 1.0) tmpBox.min.y = 1.0;
        if (tmpBox.max.x > 1.0) tmpBox.max.x = 1.0;
        if (tmpBox.max.x < -1.0) tmpBox.max.x = -1.0;
        if (tmpBox.max.y > 1.0) tmpBox.max.y = 1.0;
        if (tmpBox.max.y < -1.0) tmpBox.max.y = -1.0;
        return (tmpBox.max.x - tmpBox.min.x) * (tmpBox.max.y - tmpBox.min.y);
    };
}();
// A more precise estimator, based on https://github.com/erich666/jgt-code/blob/master/Volume_04/Number_2/Schmalstieg1999/bboxarea.cxx
// Schmalstieg, Dieter, and Robert F. Tobler, "Fast Projected Area Computation for Three-Dimensional Bounding Boxes," journal of graphics tools, 4(2):37-43, 1999.
// Note: this code assumes that the silhouette corners will all project to be in front of the viewer. We do Take
// corrective action if this is not the case, but it's of a "well, negate the value" nature, not a true clip fix.
// It is assumed that frustum culling has already been applied, so that such cases should be rare.
// So, for example, a long terrain tile below the viewer may get the corners behind the viewer transformed to be some
// semi-arbitrary corner locations in front. ProjectedArea has the same problem. Since this method is used just to get
// a rough idea of the importance of a fragment, we don't spend a lot of time on fixing this. If a corner is detected
// as behind the eye, we could instead return an area of 4, i.e., it fills the screen.
FrustumIntersector.prototype.projectedBoxArea = function () {
    var points, pointsSwap;
    var sizeClippedPolygon;
    function init_three() {
        if (!points) {
            // maximum of 6 points in silhouette, plus 4 points, one for each clip edge
            points = [];
            pointsSwap = [];
            for (var i = 0; i < 10; i++) {
                points.push(new THREE$1.Vector3());
                pointsSwap.push(new THREE$1.Vector3());
            }
        }
    }
    // TODO: same as projectedArea - should this implementation be a derived class? How to do that in javascript?
    function applyProjection(p, m) {
        var x = p.x,
            y = p.y,
            z = p.z;
        var e = m.elements;
        var w = e[3] * x + e[7] * y + e[11] * z + e[15];
        //This is the difference between this function and
        //the normal THREE.Vector3.applyProjection. We avoid
        //inverting the positions of points behind the camera,
        //otherwise our screen area computation can result in
        //boxes getting clipped out when they are in fact partially visible.
        if (w < 0) w = -w;
        var d = 1.0 / w;
        p.x = (e[0] * x + e[4] * y + e[8] * z + e[12]) * d;
        p.y = (e[1] * x + e[5] * y + e[9] * z + e[13]) * d;
        //We also don't need the Z
        //p.z = ( e[ 2 ] * x + e[ 6 ] * y + e[ 10 ] * z + e[ 14 ] ) * d;
    }
    // Optimized to clip against -1 to 1 NDC in X and Y.
    // NOTE: this modifies the clipPolygon being passed in, as the
    // code takes four passes (for each edge of the screen) and ping-pongs
    // the data between clipPolygon (really, the "points" array) and pointsSwap, a temporary buffer.
    // Doing so saves us from having to copy data or duplicate code.
    function clip(clipPolygon, sizePolygon) {
        var polygonSource = clipPolygon;
        var polygonDest = pointsSwap;
        var polygonSwap;
        var prevPt, thisPt, prevIn, thisIn;
        var numPt, numClip;
        var newSizePolygon;
        var testInside = function testInside(pt) {
            switch (numClip) {
                case 0:
                    return pt.x >= -1;
                case 1:
                    return pt.x <= 1;
                case 2:
                    return pt.y >= -1;
                case 3:
                    return pt.y <= 1;
            }
        };
        var savePoint = function savePoint(pt) {
            polygonDest[newSizePolygon].x = pt.x;
            polygonDest[newSizePolygon++].y = pt.y;
        };
        var saveIntersect = function saveIntersect() {
            var ptx, pty;
            switch (numClip) {
                case 0:
                    ptx = -1;
                    pty = prevPt.y + (thisPt.y - prevPt.y) * (ptx - prevPt.x) / (thisPt.x - prevPt.x);
                    break;
                case 1:
                    ptx = 1;
                    pty = prevPt.y + (thisPt.y - prevPt.y) * (ptx - prevPt.x) / (thisPt.x - prevPt.x);
                    break;
                case 2:
                    pty = -1;
                    ptx = prevPt.x + (thisPt.x - prevPt.x) * (pty - prevPt.y) / (thisPt.y - prevPt.y);
                    break;
                case 3:
                    pty = 1;
                    ptx = prevPt.x + (thisPt.x - prevPt.x) * (pty - prevPt.y) / (thisPt.y - prevPt.y);
                    break;
            }
            polygonDest[newSizePolygon].x = ptx;
            polygonDest[newSizePolygon++].y = pty;
        };
        // If polygon size <= 2, it will have no area, so don't care. We need this test to avoid
        // access polygonSource[-1] when size === 0.
        for (numClip = 0; numClip < 4 && sizePolygon > 2; numClip++) {
            newSizePolygon = 0;
            prevPt = polygonSource[sizePolygon - 1];
            prevIn = testInside(prevPt);
            for (numPt = 0; numPt < sizePolygon; numPt++) {
                thisPt = polygonSource[numPt];
                thisIn = testInside(thisPt);
                if (prevIn) {
                    if (thisIn) {
                        // edge is entirely in - save point
                        savePoint(thisPt);
                    } else {
                        // edge is exiting - save intersection
                        saveIntersect();
                    }
                } else {
                    // edge starts out
                    if (thisIn) {
                        // edge is entering - save intersection and point
                        saveIntersect();
                        savePoint(thisPt);
                    }
                    //else {
                    // edge is still out - save nothing
                    //}
                }
                prevPt = thisPt;
                prevIn = thisIn;
            }
            // swap for next round
            sizePolygon = newSizePolygon;
            polygonSwap = polygonSource;
            polygonSource = polygonDest;
            polygonDest = polygonSwap;
        }
        sizeClippedPolygon = sizePolygon;
        return polygonSource;
    }
    // if not specified, perform clip
    return function (box, doNotClip) {
        if (box.empty()) return 0;
        init_three();
        var matrix = this.viewProj;
        //compute the array index to classify eye with respect to the 6 defining planes
        //of the bbox, 0-26
        var pos;
        if (this.eye.x >= box.min.x) {
            pos = this.eye.x > box.max.x ? 2 : 1;
        } else {
            pos = 0;
        }
        if (this.eye.y >= box.min.y) {
            pos += this.eye.y > box.max.y ? 6 : 3;
        }
        if (this.eye.z >= box.min.z) {
            pos += this.eye.z > box.max.z ? 18 : 9;
        }
        // 13 indicates eye location is inside box, index 1+3+9, so return full screen area
        if (pos === 13) {
            return 4;
        }
        var num = _boxIndexList[pos][6]; //look up number of vertices in outline
        //generate 8 corners of the bbox, as needed
        // run through "num" points and create and transform just those
        var i;
        for (i = 0; i < num; i++) {
            var idx = _boxIndexList[pos][i];
            // tricksiness here: order is (though this is left-handed; we use right-handed)
            // (min[0],min[1],min[2]); //     7+------+6
            // (max[0],min[1],min[2]); //     /|     /|
            // (max[0],max[1],min[2]); //    / |    / |
            // (min[0],max[1],min[2]); //   / 4+---/--+5  
            // (min[0],min[1],max[2]); // 3+------+2 /    y   z
            // (max[0],min[1],max[2]); //  | /    | /     |  /
            // (max[0],max[1],max[2]); //  |/     |/      |/
            // (min[0],max[1],max[2]); // 0+------+1      *---x
            points[i].set((idx + 1) % 4 < 2 ? box.min.x : box.max.x, idx % 4 < 2 ? box.min.y : box.max.y, idx < 4 ? box.min.z : box.max.z);
            applyProjection(points[i], matrix);
        }
        var sum = 0;
        // always clip if needed; TODO: make more efficient, i.e., don't alloc each time.
        if (doNotClip) {
            sum = (points[num - 1].x - points[0].x) * (points[num - 1].y + points[0].y);
            for (i = 0; i < num - 1; i++) {
                sum += (points[i].x - points[i + 1].x) * (points[i].y + points[i + 1].y);
            }
        } else {
            var clippedPolygon = clip(points, num);
            // see if clipped polygon has anything returned at all; if not, area is 0
            if (sizeClippedPolygon >= 3) {
                sum = (clippedPolygon[sizeClippedPolygon - 1].x - clippedPolygon[0].x) * (clippedPolygon[sizeClippedPolygon - 1].y + clippedPolygon[0].y);
                for (i = 0; i < sizeClippedPolygon - 1; i++) {
                    sum += (clippedPolygon[i].x - clippedPolygon[i + 1].x) * (clippedPolygon[i].y + clippedPolygon[i + 1].y);
                }
            }
        }
        // avoid winding order left-handed/right-handed headaches by taking abs(); fixes clockwise loops
        return Math.abs(sum * 0.5); //return computed value corrected by 0.5
    };
}();
FrustumIntersector.prototype.estimateDepth = function (bbox) {
    var e = this.viewProj.elements;
    // Take center of box and find its distance from the eye.
    var x = (bbox.min.x + bbox.max.x) / 2.0;
    var y = (bbox.min.y + bbox.max.y) / 2.0;
    var z = (bbox.min.z + bbox.max.z) / 2.0;
    // not used: var w = e[3] * x + e[7] * y + e[11] * z + e[15];
    var d = 1.0 / (e[3] * x + e[7] * y + e[11] * z + e[15]);
    return (e[2] * x + e[6] * y + e[10] * z + e[14]) * d;
};
FrustumIntersector.prototype.intersectsBox = function () {
    //Copied from three.js and modified to return separate
    //value for full containment versus intersection.
    //Return values: 0 -> outside, 1 -> intersects, 2 -> contains
    var p1, p2;
    function init_three() {
        if (!p1) {
            p1 = new THREE$1.Vector3();
            p2 = new THREE$1.Vector3();
        }
    }
    return function (box) {
        init_three();
        var planes = this.frustum.planes;
        var contained = 0;
        for (var i = 0; i < 6; i++) {
            var plane = planes[i];
            p1.x = plane.normal.x > 0 ? box.min.x : box.max.x;
            p2.x = plane.normal.x > 0 ? box.max.x : box.min.x;
            p1.y = plane.normal.y > 0 ? box.min.y : box.max.y;
            p2.y = plane.normal.y > 0 ? box.max.y : box.min.y;
            p1.z = plane.normal.z > 0 ? box.min.z : box.max.z;
            p2.z = plane.normal.z > 0 ? box.max.z : box.min.z;
            var d1 = plane.distanceToPoint(p1);
            var d2 = plane.distanceToPoint(p2);
            // if both outside plane, no intersection
            if (d1 < 0 && d2 < 0) {
                return FrustumIntersector.OUTSIDE;
            }
            if (d1 > 0 && d2 > 0) {
                contained++;
            }
        }
        return contained == 6 ? FrustumIntersector.CONTAINS : FrustumIntersector.INTERSECTS;
    };
}();
// KLUDGE - TODO Cleve
Object.defineProperty(FrustumIntersector, 'OUTSIDE', { value: 0 });
Object.defineProperty(FrustumIntersector, 'INTERSECTS', { value: 1 });
Object.defineProperty(FrustumIntersector, 'CONTAINS', { value: 2 });
Object.defineProperty(FrustumIntersector, 'CONTAINMENT_UNKNOWN', { value: -1 });
var OUTSIDE = 0;
var INTERSECTS = 1;
var CONTAINS = 2;
var CONTAINMENT_UNKNOWN = -1;

var _tmpBox;
function init_three$1() {
    if (!_tmpBox) _tmpBox = new THREE$1.Box3();
}
/**
 * Represents a subset of objects from a larger list, for e.g. a draw call batch
 * to send to the renderer. It's like a small view into an ordered FragmentList.
 *
 * frags     -- FragmentList of all available meshes (1:1 correspondance with LMV fragments)
 * fragOrder -- Array of indices, pointing into the array of fragments
 * start     -- start index in the array of indices
 * count     -- how many mesh indices (after start index) are contained in the subset.
 * @constructor
 */
function RenderBatch(frags, fragOrder, start, count) {
    this.frags = frags;
    this.indices = fragOrder; // may be a typed array (usually, Int32Array) or generic Array containing 
    // the actual typed array in index 0, see getIndices(). May be null, which means indices[i]==i.
    this.start = start;
    this.count = count;
    this.lastItem = start; // Defines the (exclusive) range end used in this.forEach(). If a batch is complete, i.e. all fragments are added, 
    // we usually have this.lastItem = this.start + this.count. But it may be smaller if dynamic adding is being used.
    // The final value of this.lastItem is set from outside by the creator (see e.g., ModelIteratorLinear or ModelIteratorBVH)
    // NOTE: this.lastItem must be set before this.forEach() has any effect.
    //Compatibility with THREE.Scene. Optional override material (instanceof THREE.ShaderMaterial) temporarily used by renderers.
    this.overrideMaterial = null;
    //Whether sort by material ID has been done
    this.sortDone = false;
    this.numAdded = 0; // number of added batches since last material sort
    this.avgFrameTime = undefined; // Average time spent for rendering this batch. Maintained externally by RenderScene.renderSome()
    this.nodeIndex = undefined; // Optional: Unique index of this RenderBatch (used by modelIteratorBVH/ConsolidationIterator)
    // Summed worldBoxes 
    this.boundingBox = new THREE$1.Box3();
    this.boundingBoxHidden = new THREE$1.Box3(); //bbox counting hidden/ghosted
    //Tells the renderer whether to sort by Z before drawing.
    //We only set this for RenderBatches containing transparent objects.
    this.sortObjects = false;
    this.sortDone = false;
    this.sortByShaderDone = false;
    // Only internally (re)used by this.sortByDepth() to avoid reallocation.
    this.depths = null; // Float32Array, depths[i] stores the last computed depth for the framgent with fragId==this.indices[this.startIndex + i]. see this.sortByDepth().
    this.indicesView = null; // array view into this.indices, reduced to the range [this.start, this.start+this.count]
    //Tells the renderer whether to do per-mesh frustum culling.
    //In some cases when we know the whole batch is completely
    //contained in the viewing frustum, we turn this off.
    this.frustumCulled = true;
    //Used by ground shadow code path
    this.forceVisible = false;
    // FragmentList do not always contain THREE.Meshes for each shape. They may also just contain plain BufferGeometry 
    // and THREE.ShaderMaterial. In this case, the renderer must handle the this batch using immediate mode rendering.
    // (see FragmentList.getVizmesh() and WebGLRenderer.render() for details)
    this.renderImmediate = !frags.useThreeMesh;
    //Set per frame during scene traversal
    this.renderImportance = 0.0;
    // make sure that static temp-variable _tmpBox exists (used to reduce new Box allocations in several methods below)
    init_three$1();
}
RenderBatch.prototype.getIndices = function () {
    // Note that isArray returns false for typed arrays like Int32Array. 
    // isArray() is used to here to check whether indices is
    //  a) a typed array itself or
    //  b) a generic array containing the actual typed array in index 0.
    return Array.isArray(this.indices) ? this.indices[0] : this.indices;
};
// Sorts 
RenderBatch.prototype.sortByMaterial = function () {
    //Render batch must be complete before we can sort it
    if (this.numAdded < this.count) return;
    var frags = this.frags;
    var indices = this.getIndices();
    if (!indices) {
        THREE$1.warn("Only indexed RenderSubsets can be sorted.");
        return;
    }
    // apply sort only to the range used by this batch
    var tmp = indices.subarray(this.start, this.start + this.count);
    Array.prototype.sort.call(tmp, function (a, b) {
        var ma = frags.getMaterialId(a);
        var mb = frags.getMaterialId(b);
        if (ma === undefined) return mb ? 1 : 0;
        if (mb === undefined) return -1;
        return ma - mb;
    });
    //indices.set(tmp, this.start); // not needed because tmp already points to the same buffer
    // indicate that indices are sorted by material and no batches have beend added since then.
    this.numAdded = 0;
    this.sortDone = true;
};
//Sorts meshes in the render batch by shader ID, to avoid
//unnecessary shader switching in the renderer when looping over a batch.
//This can only be performed once the RenderBatch is full/complete and
//all shaders are known.
RenderBatch.prototype.sortByShader = function () {
    //Render batch must be complete before we can sort it
    if (!this.sortDone || this.sortByShaderDone) return;
    var frags = this.frags;
    var indices = this.getIndices();
    var tmp = indices.subarray(this.start, this.start + this.count);
    Array.prototype.sort.call(tmp, function (a, b) {
        var ma = frags.getMaterial(a);
        var mb = frags.getMaterial(b);
        var pd = ma.program.id - mb.program.id;
        if (pd) return pd;
        return ma.id - mb.id;
    });
    //indices.set(tmp, this.start);
    this.numAdded = 0;
    this.sortByShaderDone = true;
};
// Sorts this.indices by increasing depth for the current view.
// Input: frustumIn instanceof FrustumIntersector
RenderBatch.prototype.sortByDepth = function () {
    var frags;
    var indices;
    var frustum;
    var bbox;
    var depths; // just a pointer to this.depths 
    // use frustum to calculate depth per fragment
    function calDepth(fragId, i) {
        if (!frags.getGeometry(fragId)) depths[i] = -Infinity;else {
            frags.getWorldBounds(fragId, bbox);
            depths[i] = frustum.estimateDepth(bbox);
        }
    }
    //function sortCB(a, b) {
    //    return depths[b] - depths[a];
    //}
    return function (frustumIn) {
        frags = this.frags;
        indices = this.getIndices();
        frustum = frustumIn;
        bbox = _tmpBox;
        if (!indices) {
            THREE$1.warn("Only indexed RenderSubsets can be sorted.");
            return;
        }
        // init indicesView as a view to the relevant range in this.indices, i.e., the range [start, start+count)
        if (!this.indicesView || this.indicesView.length < this.count) this.indicesView = indices.subarray(this.start, this.start + this.count);
        // allocate this.depth to store a depth value for each fragment index in indicesView
        if (!this.depths || this.depths.length < this.count) this.depths = new Float32Array(this.count);
        depths = this.depths;
        // For each fragId indicesView[i], compute the depth and store it in depth[i]
        this.forEachNoMesh(calDepth);
        // Does not work, this call sorts on depths[indicesViews[i]], not depths[i],
        // where 'i' is an index into both the depths and indicesViews lists.
        //Array.prototype.sort.call(this.indicesView, sortCB);
        // Insertion sort appears to be about 7x or more faster
        // for lists of 64 or less objects vs. defining a sort() function.
        // Asking if there's a faster way. Traian mentioned quicksort > 8
        // objects; I might give this a try.
        var tempDepth, tempIndex;
        for (var j = 1; j < depths.length; j++) {
            var k = j;
            while (k > 0 && depths[k - 1] < depths[k]) {
                // swap elem at position k one position backwards (for indicesView and depths)
                tempDepth = depths[k - 1];
                depths[k - 1] = depths[k];
                depths[k] = tempDepth;
                tempIndex = this.indicesView[k - 1];
                this.indicesView[k - 1] = this.indicesView[k];
                this.indicesView[k] = tempIndex;
                k--;
            }
        }
        //indices.set(this.indicesView, this.start); // Not needed because indicesView is already a view into this range
    };
}();
//Use only for incremental adding to linearly ordered (non-BVH) scenes!
RenderBatch.prototype.onFragmentAdded = function () {
    return function (fragId) {
        // update bbox
        this.frags.getWorldBounds(fragId, _tmpBox);
        this.boundingBox.union(_tmpBox);
        // mark 
        this.sortDone = false;
        //NOTE: This only works with trivial fragment ordering (linear render queues).
        //Otherwise the item index does not necessarily match the fragId due to the 
        //reordering jump table (this.indices).
        if (this.lastItem <= fragId) {
            this.lastItem = fragId + 1;
            if (this.visibleStats !== undefined) this.visibleStats = 0; // reset visibility, since a new fragment might change it
            this.numAdded++;
        }
    };
}();
/**
 * Iterates over fragments.
 * @param {function} callback - function(mesh, id) called for each fragment geometry.
 *      - mesh: instanceof THREE.Mesh (as obtained from FragmentList.getVizmesh)
 *      - id:   fragment id
 * @param {number} drawMode - Optional flag (see FragmentList.js), e.g., globals.MESH_VISIBLE. If specified, we only traverse fragments for which this flag is set.
 * @param {bool} includeEmpty - Default: false, i.e. fragments are skipped if they have no mesh available via getVizmesh().
 */
RenderBatch.prototype.forEach = function (callback, drawMode, includeEmpty) {
    var indices = this.getIndices();
    var frags = this.frags;
    var sortByShaderPossible = !this.sortByShaderDone;
    //var showPF = (frags.showPF === undefined ) ? -1 : frags.showPF;
    var i, idx, iEnd, m;
    //If the most likely rendering flags are true, use a shortened version of the for-loop.
    var i, iEnd, idx, m;
    if (!drawMode && !includeEmpty && !sortByShaderPossible) {
        for (i = this.start, iEnd = this.lastItem; i < iEnd; i++) {
            idx = indices ? indices[i] : i;
            // for debug only, if the PF is to be displayed, then check if this fragment is in the designated PF
            //if ((showPF !== -1) && (showPF !== frags.fragments.packIds[idx])) {
            //    continue;
            //}
            var m = frags.getVizmesh(idx, this.renderImportance);
            if (m && m.geometry) {
                callback(m, idx);
            }
        }
    } else {
        for (i = drawMode == MESH_RENDERFLAG && this.hasOwnProperty("drawStart") ? this.drawStart : this.start, iEnd = this.lastItem; i < iEnd; i++) {
            idx = indices ? indices[i] : i;
            // for debug only, if the PF is to be displayed, then check if this fragment is in the designated PF
            //if ((showPF !== -1) && (showPF !== frags.fragments.packIds[idx])) {
            //    continue;
            //}
            var m = frags.getVizmesh(idx, this.renderImportance);
            if (sortByShaderPossible && (!m || !m.material || !m.material.program || m.geometry_proxy)) sortByShaderPossible = false;
            // if drawMode is given, iterate vizflags that match
            if ((includeEmpty || m && m.geometry) && (!drawMode || frags.isFlagSet(idx, drawMode))) {
                callback(m, idx);
            }
        }
    }
    //If all materials shaders are already available, we can sort by shader
    //to minimize shader switches during rendering.  This sort will only
    //execute once and changing materials later will break the sorted order again.
    if (sortByShaderPossible) this.sortByShader();
};
/**
 * Iterates over fragments. Like forEach(), but takes a different callback.
 * @param {function} callback - function(fragId, idx) called for each fragment geometry.
 *      - fragId:   fragment id
 *      - idx:      running index from 0 .. (lastItem-start)
 * @param {number} drawMode - Optional flag (see FragmentList.js), e.g., globals.MESH_VISIBLE. If specified, we only traverse fragments for which this flag is set.
 * @param {bool} includeEmpty - Default: false, i.e. fragments are skipped if they have no mesh available via getVizmesh().
 */
RenderBatch.prototype.forEachNoMesh = function (callback, drawMode, includeEmpty) {
    var indices = this.getIndices();
    var frags = this.frags;
    for (var i = this.start, iEnd = this.lastItem; i < iEnd; i++) {
        var fragId = indices ? indices[i] : i;
        // get geometry - in this case just to check if it is available
        var geometry;
        if (frags.useThreeMesh) {
            var m = frags.getVizmesh(fragId);
            if (m) geometry = m.geometry;
        } else {
            geometry = frags.getGeometry(fragId);
        }
        // if drawMode is given, iterate vizflags that match
        if ((includeEmpty || geometry) && (!drawMode || frags.isFlagSet(fragId, drawMode))) {
            callback(fragId, i - this.start);
        }
    }
};
/**
 * Checks if given ray hits a bounding box of any of the fragments.
 * @param {THREE.RayCaster} raycaster
 * @param {Object[]}        intersects - An object array that contains intersection result objects.
 *                                       Each result r stores properties like r.point, r.fragId, r.dbId. (see VBIntersector.js for details)
 * @param {number[]}       [dbIdFilter] - Array of dbIds. If specieed, only fragments with dbIds inside the filter are checked.
 */
RenderBatch.prototype.raycast = function () {
    return function (raycaster, intersects, dbIdFilter) {
        //Assumes bounding box is up to date.
        if (raycaster.ray.isIntersectionBox(this.boundingBox) === false) return;
        var self = this;
        var tmpBox = _tmpBox;
        // traverse all visible meshes
        this.forEach(function (m, fragId) {
            // Don't intersect hidden objects
            if (self.frags.isFlagSet(fragId, MESH_HIDE)) return;
            //Check the dbIds filter if given
            if (dbIdFilter && dbIdFilter.length) {
                //Theoretically this can return a list of IDs (for 2D meshes)
                //but this code will not be used for 2D geometry intersection.
                var dbId = 0 | self.frags.getDbIds(fragId);
                //dbIDs will almost always have just one integer in it, so
                //indexOf should be fast enough.
                if (dbIdFilter.indexOf(dbId) === -1) return;
            }
            // raycast worldBox first.
            self.frags.getWorldBounds(fragId, tmpBox);
            // Expand bounding box a bit, to take into account axis aligned lines
            tmpBox.expandByScalar(0.5);
            if (raycaster.ray.isIntersectionBox(tmpBox)) {
                // worldbox was hit. do raycast with actucal geometry.
                VBIntersector.rayCast(m, raycaster, intersects);
            }
        }, MESH_VISIBLE);
    };
}();
/**
 * Computes/updates the members:
 *      - this.boundingBox
 *      - this.boundingBoxHidden (bbox of ghosted fragments)
 */
RenderBatch.prototype.calculateBounds = function () {
    // pointers to make some objects available for the callback below.
    var vizflags;
    var bounds;
    var boundsH;
    var frags;
    var tmpBox;
    // adds box of a fragment to bounds or bounds, depennding on its vizflags.
    function cb(fragId) {
        frags.getWorldBounds(fragId, tmpBox);
        var f = vizflags[fragId];
        if (f & 1 /*MESH_VISIBLE*/) bounds.union(tmpBox);else boundsH.union(tmpBox); //mesh is "ghosted"
    }
    return function () {
        // init boxes for visible and ghosted meshes
        this.boundingBox.makeEmpty();
        this.boundingBoxHidden.makeEmpty();
        // make members and tempBox accessible for cb
        vizflags = this.frags.vizflags;
        bounds = this.boundingBox;
        boundsH = this.boundingBoxHidden;
        frags = this.frags;
        tmpBox = _tmpBox;
        this.forEachNoMesh(cb, 0, this.frags.onDemandLoadingEnabled());
    };
}();
/**
 * Sets the globals.MESH_RENDERFLAG for a single fragment, depeneding on the drawMode and the other flags of the fragment.
 * @param {number} drawMode - One of the modes defined in Viewer3DImpl.js, e.g. globals.RENDER_NORMAL
 * @param {number} vizflags - vizflags bitmask.
 * @param {number} idx - index into vizflags, for which we want to determine the MESH_RENDERFLAG.
 * @returns {bool} Final, evaluated visibility.
 */
RenderBatch.prototype.evalVisbility = function (drawMode, vizflags, idx) {
    var v;
    var vfin = vizflags[idx] & ~MESH_RENDERFLAG;
    switch (drawMode) {
        case RENDER_HIDDEN:
            v = !(vfin & MESH_VISIBLE); //visible (bit 0 on)
            break;
        case RENDER_HIGHLIGHTED1:
        case RENDER_HIGHLIGHTED2:
            v = vfin & MESH_HIGHLIGHTED; //highlighted (bit 1 on)
            break;
        default:
            v = (vfin & (MESH_VISIBLE | MESH_HIGHLIGHTED | MESH_HIDE)) == 1; //visible but not highlighted, and not a hidden line (bit 0 on, bit 1 off, bit 2 off)
            break;
    }
    //Store evaluated visibility into bit 7 of the vizflags
    //to use for immediate rendering
    vizflags[idx] = vfin | (v ? MESH_RENDERFLAG : 0);
    return v;
};
/**
 * Checks if fragment is outside the frustum.
 * @param {bool} checkCull - indicates if culling is enabled. If false, return value is always false.
 * @param {FrustumIntersector} frustum
 * @param {FragmentList} frags
 * @param {number} idx - index into frags.
 * @returns {bool} True if the given fragment is outside the frustum and culling is enabled.
 */
function evalCulling(checkCull, frustum, frags, idx) {
    var culled = false;
    frags.getWorldBounds(idx, _tmpBox);
    if (checkCull && !frustum.intersectsBox(_tmpBox)) {
        culled = true;
    }
    //This code path disabled because it was found to slow things down overall.
    /*
    else {
        // Check whether the projected area is smaller than a threshold,
        // if yes, do not render it.
        var area = frustum.projectedBoxArea(_tmpBox, !checkCull);
        area *= frustum.areaConv;
        if (area < frustum.areaCullThreshold) {
            culled = true;
        }
    }
    */
    return culled;
}
/**
 * Updates visibility for all fragments of this RenderBatch.
 * This means:
 *  1. It returns true if all meshes are hidden (false otherwise)
 *
 *  2. If the whole batch box is outside the frustum, nothing else is done.
 *     (using this.boundingBox or this.boundingBoxHidden, depending on drawMode)
 *
 *  3. For all each checked fragment with fragId fid and mesh m, the final visibility is stored...
 *      a) In the m.visible flag.
 *      b) In the MESH_RENDERFLAG of the vizflags[fid]
 *     This is only done for fragments with geometry.
 *
 *  4. If a custom callback is specified (fragIdCb), this callback is triggered for all fragments
 *     for which mesh or mesh.geometry is missing.
 * @param {number} drawMode - One of the modes defined in Viewer3DImpl.js, e.g. globals.RENDER_NORMAL
 * @param {FrustumIntersector} frustum
 * @param {function=} fragIdCb - callback that is called for all empty fragments. It is used for on-demand-loading.
 * @returns {bool} True if all meshes are hidden (false otherwise).
 */
RenderBatch.prototype.applyVisibility = function () {
    var frags, vizflags, frustum, drawMode, fragIdCb, checkCull, allHidden;
    // Callback to apply visibility for a single fragment
    //
    // Input: Geometry and index of a fragment, i.e.
    //  m:   instanceof THREE.Mesh (see FragmentList.getVizmesh). May be null.
    //  idx: index of the fragment in the fragment list. 
    //
    // What is does:
    //  1. bool m.visible is updated based on flags and frustum check (if m!=null)
    //  2. The MESH_RENDERFLAG flag is updated for this fragment, i.e., is true for meshes with m.visible==true
    //  3. If there is no geometry and there is a custom callback (checkCull) 
    //  4. Set allHidden to false if any mesh passes as visible.
    function applyVisCB(m, idx) {
        // if there's no mesh or no geometry, just call the custom callback.
        // [HB:] I think it would be clearer to remove the frags.useThreeMesh condition here.
        //       It's not really intuitive that for (m==0) the callback is only called for frags.useThreeMesh.
        //       Probably the reason is just that this code section has just been implemented for the useThreeMesh
        //       case and the other one was irrelevant.
        if (!m && frags.useThreeMesh || !m.geometry) {
            // if a custom callback is specified, call it with the fragId
            if (fragIdCb) fragIdCb(idx);
            return;
        }
        // apply frustum check for this fragment
        var culled = evalCulling(checkCull, frustum, frags, idx);
        // if outside, set m.visbile and the MESH_RENDERFLAG of the fragment to false
        if (culled) {
            if (m) {
                m.visible = false;
            } else {
                THREE$1.warn("Unexpected null mesh");
            }
            // unset MESH_RENDERFLAG
            vizflags[idx] = vizflags[idx] & ~MESH_RENDERFLAG;
            return;
        }
        // frustum check passed. But it might still be invisible due to vizflags and/or drawMode. 
        // Note that evalVisbility also updates the MESH_RENDERFLAG already.
        var v = this.evalVisbility(drawMode, vizflags, idx);
        if (m) m.visible = !!v;
        // Set to false if any mesh passes as visible
        allHidden = allHidden && !v;
    }
    // Similar to applyVisCB above, but without geometry param, so that we don't set any m.visible property.
    function applyVisCBNoMesh(idx) {
        // if no geometry is assigned, just call custom cb (if specified) and stop here.
        if (!frags.getGeometryId(idx)) {
            // [HB:] Actually, this callback is only used if fragIdCb is not set. So, the check below will
            //       always be false.
            if (fragIdCb) fragIdCb(idx);
            return;
        }
        // apply frustum check for this fragment
        var culled = evalCulling(checkCull, frustum, frags, idx);
        // if culled, set visflags MESH_RENDERFLAG to false 
        if (culled) {
            vizflags[idx] = vizflags[idx] & ~MESH_RENDERFLAG;
            return;
        }
        // frustum check passed. But it might still be invisible due to vizflags and/or drawMode. 
        // Note that evalVisbility also updates the MESH_RENDERFLAG already.
        var v = this.evalVisbility(drawMode, vizflags, idx);
        // Set to false if any mesh passes as visible
        allHidden = allHidden && !v;
    }
    return function (drawModeIn, frustumIn, fragIdCbIn) {
        //Used when parts of the same scene
        //have to draw in separate passes (e.g. during isolate).
        //Consider maintaining two render queues instead if the
        //use cases get too complex, because this approach
        //is not very scalable as currently done (it traverses
        //the entire scene twice, plus the flag flipping for each item).
        allHidden = true;
        frustum = frustumIn;
        drawMode = drawModeIn;
        fragIdCb = fragIdCbIn;
        //Check if the entire render batch is contained inside
        //the frustum. This will save per-object checks.
        var containment = frustum.intersectsBox(drawMode === RENDER_HIDDEN ? this.boundingBoxHidden : this.boundingBox);
        if (containment === FrustumIntersector.OUTSIDE) return allHidden; //nothing to draw
        vizflags = this.frags.vizflags;
        frags = this.frags;
        checkCull = containment !== FrustumIntersector.CONTAINS;
        // The main difference between applyVisCB and applyVisCBNoMesh is that applyVisCB also updates mesh.visible for each mesh.
        // This does only make sense when using THREE.Mesh. Otherwise, the mesh containers are volatile anyway (see FragmentList.getVizmesh)
        //
        // [HB:] If frags.useThreeMesh is false, it does never make sense to use the cb version with mesh. So, it's not really clear
        //       here why the check condition is not just (!frags.useThreeMesh).
        if (!fragIdCbIn && !frags.useThreeMesh) {
            // Use callback that does not set mesh.visible
            this.forEachNoMesh(applyVisCBNoMesh.bind(this), null);
        } else {
            // Use callback that also sets mesh.visible.
            // Skip fragments without geometry unless a custom callback is defined (fragIdCB)
            this.forEach(applyVisCB.bind(this), null, fragIdCb);
        }
        return allHidden;
    };
}();

//Finds a precanned BufferAttribute corresponding to the given
//attribute data, so that we don't have to allocate the same exact
//one over and over and over.
var bufattrs = {};
function findBufferAttribute(attributeName, attributeData, numInstances) {
    //Note .array could be undefined in case we are using
    //an interleaved buffer.
    var attr;
    if (attributeData.array) {
        attr = new THREE$1.BufferAttribute(attributeData.array, attributeData.itemSize);
    } else {
        var id = attributeName + "|" + attributeData.bytesPerItem + "|" + attributeData.normalize + "|" + attributeData.isPattern + "|" + attributeData.divisor + "|" + attributeData.offset;
        attr = bufattrs[id];
        if (attr) return attr;
        attr = new THREE$1.BufferAttribute(undefined, attributeData.itemSize);
        bufattrs[id] = attr;
    }
    attr.bytesPerItem = attributeData.bytesPerItem;
    attr.normalize = attributeData.normalize;
    attr.isPattern = attributeData.isPattern;
    if (numInstances) {
        attr.divisor = attributeData.divisor;
    }
    if (attributeData.array) {
        //Is the data for the attribute specified separately
        //from the interleaved VB?
    } else if (attributeData.hasOwnProperty("offset")) {
        //If the attribute is in the interleaved VB, it has
        //an offset into it.
        attr.itemOffset = attributeData.offset;
    } else {
        THREE$1.warn("VB attribute is neither interleaved nor separate. Something is wrong with the buffer specificaiton.");
    }
    return attr;
}
var attrKeys = {};
function findAttributesKeys(geometry) {
    var key = "";
    for (var p in geometry.attributes) {
        key += p + "|";
    }var res = attrKeys[key];
    if (res) return res;
    res = Object.keys(geometry.attributes);
    attrKeys[key] = res;
    return res;
}
var indexAttr16;
var indexAttr32;
var BufferGeometry$1;
var idcounter = 1;
function initBufferGeometry() {
    indexAttr16 = new THREE$1.BufferAttribute(undefined, 1);
    indexAttr16.bytesPerItem = 2;
    indexAttr32 = new THREE$1.BufferAttribute(undefined, 1);
    indexAttr32.bytesPerItem = 4;
    BufferGeometry$1 = function BufferGeometry$$1() {
        //Avoid calling the superclass constructor for performance reasons.
        //Skips the creation of a uuid and defining an accessor for the .id property.
        //THREE.BufferGeometry.call(this);
        //Null those out since we don't need them.
        this.uuid = null;
        this.name = null;
        this.id = idcounter++;
        this.attributes = {};
        this.attributesKeys = [];
        this.drawcalls = [];
        this.offsets = this.drawcalls; // backwards compatibility
        this.boundingBox = null;
        this.boundingSphere = null;
        this.numInstances = undefined;
        this.streamingDraw = false;
        this.streamingIndex = false;
        this.svfid = undefined;
        this.vb = null;
        this.vbbuffer = undefined;
        this.ib = null;
        this.ibbuffer = undefined;
        this.iblines = null;
        this.iblinesbuffer = undefined;
        this.vaos = undefined;
        this.vbNeedsUpdate = false;
        this.vbstride = 0;
        this.byteSize = 0;
        this.attributesKeys = undefined;
        // Note:
        //  1. Although __webglInit would also be undefined without this assignment, it is still essential
        //     for performance reasons, because it makes this property known to the JIT compiler. Otherwise,
        //     it would be attached to each buffer later in WebGLRenderer - which would waste performance.
        //  2. It is essential to use "undefined" and not "false" here. The reason is that WebGLRenderer
        //     only checks in the form "__webglInit === undefined", i.e., setting it to "false" here would have
        //     the same effect like setting it to "true" and would finally cause a memory leak.
        this.__webglInit = undefined;
    };
    BufferGeometry$1.prototype = Object.create(THREE$1.BufferGeometry.prototype);
    BufferGeometry$1.prototype.constructor = BufferGeometry$1;
}
function createBufferGeometry() {
    if (!BufferGeometry$1) initBufferGeometry();
    return new BufferGeometry$1();
}
//Converts a mesh description passed back from worker threads into a renderable three.js
//compatible BufferGeometry.
//Sets various extra flags we need.
function meshToGeometry(mdata) {
    var mesh = mdata.mesh;
    var geometry = createBufferGeometry();
    if (isNodeJS()) {
        //Used by SVF post-processing tools
        geometry.packId = mdata.packId;
        geometry.meshIndex = mdata.meshIndex;
    }
    geometry.byteSize = 0;
    geometry.vb = mesh.vb;
    geometry.vbbuffer = undefined;
    geometry.vbNeedsUpdate = true;
    geometry.byteSize += mesh.vb.byteLength;
    geometry.hash = mdata.hash;
    geometry.vbstride = mesh.vbstride;
    if (mesh.isLines) geometry.isLines = mesh.isLines;
    if (mesh.isWideLines) {
        geometry.isWideLines = true;
        geometry.lineWidth = mesh.lineWidth;
    }
    if (mesh.isPoints) {
        geometry.isPoints = mesh.isPoints;
        geometry.pointSize = mesh.pointSize;
    }
    if (mdata.is2d) geometry.is2d = true;
    geometry.numInstances = mesh.numInstances;
    for (var attributeName in mesh.vblayout) {
        var attributeData = mesh.vblayout[attributeName];
        //geometry.addAttribute(attributeName, findBufferAttribute(attributeData, geometry.numInstances));
        geometry.attributes[attributeName] = findBufferAttribute(attributeName, attributeData, geometry.numInstances);
    }
    //Index buffer setup
    if (!exports.memoryOptimizedLoading) {
        var iAttr = new THREE$1.BufferAttribute(mesh.indices, 1);
        iAttr.bytesPerItem = mesh.indices instanceof Uint32Array ? 4 : 2;
        geometry.addAttribute("index", iAttr);
    } else {
        geometry.attributes.index = mesh.indices instanceof Uint32Array ? indexAttr32 : indexAttr16;
        geometry.ib = mesh.indices;
        geometry.ibbuffer = undefined;
        if (mesh.iblines) {
            geometry.attributes.indexlines = mesh.iblines instanceof Uint32Array ? indexAttr32 : indexAttr16;
            geometry.iblines = mesh.iblines;
            geometry.iblinesbuffer = undefined;
        }
    }
    geometry.attributesKeys = findAttributesKeys(geometry);
    geometry.byteSize += mesh.indices.byteLength;
    //TODO: Not sure chunking into list of smaller offset/counts
    //is required for LMV data since it's already broken up.
    //if (mesh.indices.length > 65535)
    // Works fine now. Left in for debugging.
    //if (mesh.vb.length / mesh.vbstride > 65535)
    //    THREE.warn("Mesh with " + (mesh.vb.length / mesh.vbstride) + " > 65535 vertices. It will fail to draw.");
    //TODO: This is a transient object that gets freed once the geometry
    //is added to the GeometryList. We can save on the object creation
    //eventually when we do micro optimizations.
    geometry.boundingBox = new THREE$1.Box3().copy(mesh.boundingBox);
    geometry.boundingSphere = new THREE$1.Sphere().copy(mesh.boundingSphere);
    //MEM
    geometry.drawcalls = null;
    geometry.offsets = null;
    mdata.geometry = geometry;
    mdata.mesh = null;
}
var BufferGeometryUtils = {
    meshToGeometry: meshToGeometry,
    createBufferGeometry: createBufferGeometry
};

/**
 * A GeomMergeTask is used for mesh consolidation. It fills vertex buffer and id buffer of a consolidated mesh
 * based on a set of compatible input meshes.
 *
 * GeomMergeTask is shared by main wgs script and worker script, so that the same code can be used for single-threaded
 * and multi-threaded consolidation.
 */
// unique task ids
var _nextTaskId = 1;
function createTaskId() {
    return _nextTaskId++;
}
function GeomMergeTask() {
    // Interleaved vertex buffers as Float32Array.
    this.vb = null;
    // floats per vertex
    this.vbstride = 0;
    // offsets in floats where to find position/normal in vertex buffer
    this.posOffset = 0;
    this.normalOffset = 0;
    // matrices per src-geom (Float32Array with 16 floats per matrix)
    this.matrices = null;
    this.ranges = null;
    // must be an Uint32Array that we can efficiently hand-over to the worker
    this.dbIds = null;
    // unique task-id used to find BufferGeometry when a merged vb is returned from worker
    this.id = createTaskId();
}
/**
 *  Packs a Vector3 normal vector into 2 components. This is a CPU-side implementation of PackNormalsShaderChunk
 *  (see ShaderChunks.js)
 *
 *   @param {THREE.Vector3|LmvVector3} normal - InOut normal vector.
 *
 *  Note that 'normal' must be normalized!
 */
function encodeNormal(normal) {
    normal.x = 0.5 * (1.0 + Math.atan2(normal.y, normal.x) / Math.PI);
    normal.y = 0.5 * (1.0 + normal.z);
    normal.z = 0.0; // not used for result
}
/**
 * @param {THREE.Vector3|LmvVector3} normal - InOut normal vector. Input z is ignored.
 */
function decodeNormal(normal) {
    var angX = 2.0 * normal.x - 1.0;
    var angY = 2.0 * normal.y - 1.0;
    var scthX = Math.sin(angX * Math.PI);
    var scthY = Math.cos(angX * Math.PI);
    var scphiX = Math.sqrt(1.0 - angY * angY);
    var scphiY = angY;
    normal.x = scthY * scphiX;
    normal.y = scthX * scphiX;
    normal.z = scphiY;
}
/**
 *  Writes a dbId into 4 subsequent bytes of an Uint8Array. (4th is only for alignment and always 0)
 *   @param {Number}     dbId
 *   @param {Uint8Array} bufferUint8 - view into the vertex buffer that we write to.
 *   @param {Number}     writeIndex  - Index into the uint8 array where we write the first byte.
 */
function writeIdToBuffer(dbId, bufferUint8, writeIndex) {
    bufferUint8[writeIndex++] = dbId & 0xff;
    bufferUint8[writeIndex++] = dbId >> 8 & 0xff;
    bufferUint8[writeIndex++] = dbId >> 16 & 0xff;
    bufferUint8[writeIndex] = 0; // dbIds are only vec3 in the shader
}
// We don't have THREE.Matrix3 in a worker, so that we cannot use getNormalTransform()
function getNormalMatrix(matrix, dstMatrix) {
    // eliminate translation part
    dstMatrix.copy(matrix);
    dstMatrix[12] = 0;
    dstMatrix[13] = 0;
    dstMatrix[14] = 0;
    // tranpose of inverse
    return dstMatrix.getInverse(dstMatrix).transpose();
}
/**
 *  Transforms positions and normals of a vertex buffer range.
 *
 *  NOTE: Only interleaved buffers with packed normals are supported.
 *
 *   @param {GeomInfo}      geom
 *   @param {Uint16Array}   vbUint16     - additional uint16-view to interleaved vertex-buffer
 *   @param {LmvMatrix4}    matrix
 *   @param {Number}        [rangeStart] - First vertex to transform. (default: 0)
 *   @param {Number}        [rangeEnd]   - End of vertex range.       (default: #vertices)
 *   @param {LmvMatrix4}    tmpMatrix    - reused tmp matrix
 *   @param {LmvVector3}    tmpVec       - reused tmp vector
 */
var transformVertexRange = function transformVertexRange(geom, vbUint16, matrix, rangeStart, rangeEnd, tmpMatrix, tmpVec) {
    // transform positions
    var posOffset = geom.posOffset;
    for (var i = rangeStart; i < rangeEnd; i++) {
        // read vertex position i
        var offset = i * geom.vbstride + posOffset;
        tmpVec.set(geom.vb[offset], geom.vb[offset + 1], geom.vb[offset + 2]);
        tmpVec.applyMatrix4(matrix);
        // write vertex position i
        geom.vb[offset] = tmpVec.x;
        geom.vb[offset + 1] = tmpVec.y;
        geom.vb[offset + 2] = tmpVec.z;
    }
    // transform normals (if available)
    if (geom.normalOffset !== -1) {
        // To transform normals, we need an Uint16-view to the data.
        // Packed normals are 2-component Uint16-vectors.
        var uint16PerVertex = geom.vbstride * 2; // Multiply by 2, because vbstride and itemOffset
        var uint16NormalOffset = geom.normalOffset * 2; // are counting 32Bit floats.
        var maxUint16 = 0xFFFF;
        // compute normal transform
        var normalMatrix = getNormalMatrix(matrix, tmpMatrix);
        // transform normal vectors
        for (i = rangeStart; i < rangeEnd; i++) {
            // read byte-normal of vertex i
            var normalIndex = i * uint16PerVertex + uint16NormalOffset;
            tmpVec.set(vbUint16[normalIndex], vbUint16[normalIndex + 1], 0.0);
            // decode to vec3 with components in [0,1]
            tmpVec.divideScalar(maxUint16);
            decodeNormal(tmpVec);
            // Note that normalMatrix is a LmvMatrix4 (although we only use 3x3 matrix)
            tmpVec.applyMatrix4(normalMatrix);
            // Note that encodeNormal requires normalized values. Although a decodedNormal is
            // always normalized, the normalMatrix may involve a scaling.
            tmpVec.normalize();
            // encode back to 2-component uint16
            encodeNormal(tmpVec);
            tmpVec.multiplyScalar(maxUint16);
            // write back to vertex buffer
            vbUint16[normalIndex] = tmpVec.x;
            vbUint16[normalIndex + 1] = tmpVec.y;
        }
    }
};
// read matrix i from Float32 array to target LmvMatrix4
function getMatrix(index, array, target) {
    // TypedArray.set does not support a srcOffset parameter. So we have to use manual copy here.
    var offset = 16 * index;
    for (var i = 0; i < 16; i++) {
        target.elements[i] = array[i + offset];
    }
}
/**
 *  Run merge task. This can be done using Vector/Matrix types from THREE (in main) or LmvVector/LmvMatrix (worker).
 *  To define which types to use while keeping the code independent, a preallocated matrix/vector must be provided.
 *
 *  @param {LmvMatrix4|THREE.Matrix4} matrix
 *  @param {LmvVector3|THREE.Vector3} vector
 *  @returns {Object} - merge result r, containing
 *                        {number}       r.id:        task id
 *                        {Float32Array} r.vb:        merged interleaved vertex buffer
 *                        {Uint8Array}   r.vertexIds: buffer for separate per-vertex id attribute
 */
GeomMergeTask.prototype.run = function (matrix, vec) {
    var vb = this.vb;
    var vertexCount = vb.length / this.vbstride;
    var tmpMatrix = matrix.clone();
    // create buffer for per-vertex ids of consolidated mesh
    var IDBytesPerVertex = 3;
    var dstIds = new Uint8Array(IDBytesPerVertex * vertexCount);
    // to transform normals, we need an Uint16-view to the interleaved vertex buffer.
    // packed normals are 2-component Uin16-vectors.
    var hasNormals = this.normalOffset !== -1;
    var vbUint16 = hasNormals ? new Uint16Array(vb.buffer, vb.byteOffset, vb.length * 2) : null;
    // transform vertex-range and write ids. Each range corresponds to a source fragment geometry
    var ranges = this.ranges;
    var matrices = this.matrices;
    var numRanges = ranges.length - 1; // note that ranges contains an extra element for the last range end
    for (var j = 0; j < numRanges; j++) {
        // get vertex range corresponding to src geom i
        var rangeBegin = ranges[j];
        var rangeEnd = ranges[j + 1];
        // get matrix for src geom i
        getMatrix(j, matrices, matrix);
        // transform vertex positions and normals in this range
        transformVertexRange(this, vbUint16, matrix, rangeBegin, rangeEnd, tmpMatrix, vec);
        // assign dbId to all vertices of this range
        var dstIdsByteOffset = rangeBegin * IDBytesPerVertex;
        var rangeLength = rangeEnd - rangeBegin;
        var dbId = this.dbIds[j];
        for (var k = 0; k < rangeLength; k++) {
            writeIdToBuffer(dbId, dstIds, dstIdsByteOffset);
            dstIdsByteOffset += IDBytesPerVertex;
        }
    }
    // return result object. It contains everything we need to finish a single consolidated mesh.
    return {
        taskId: this.id,
        vb: this.vb,
        vertexIds: dstIds
    };
};

var getVertexCount$3 = VertexEnumerator.getVertexCount;
/** Computes ranges in consolidated vertex buffer:
 *  When merging geoms into a single vertex buffer, each source geometry geoms[i] will correspond to a range
 *  in the merged vertex buffer. These function computes these ranges. From the returned array, a range
 *  corresponding to src fragment i can be obtained by:
 *   - rangeBegin = ranges[i]
 *   - rangeEnd   = ranges[i+1] (exclusive)
 *  Note that ranges.length is #geoms + 1.
 *
 * @param {BufferGeometry} geoms - pointers to src fragment geoms to be merged.
 * @returns {Uint16Array}
 */
function createRangeArray(geoms) {
    var ranges = new Uint16Array(geoms.length + 1);
    var rangeStart = 0;
    for (var i = 0; i < geoms.length; i++) {
        ranges[i] = rangeStart;
        rangeStart += getVertexCount$3(geoms[i]);
    }
    // add end of final range
    ranges[i] = rangeStart;
    return ranges;
}
/**
 * Init merge task from src geometries.
 *
 * @param {BufferGeometry[]} geoms      - input geometries
 * @param {BufferGeometry}   targetGeom - consolidated geometry (just copied, not transformed yet)
 * @param {Float32Array}     matrices   - transforms per range (each matrix stored as 16 subsequent floats)
 * @param {Int32Array}       dbIds      - dbIds per src fragment - used by worker to build per-vertex id buffer
 * @constructor
 */
function createMergeTask(geoms, targetGeom, matrices, dbIds) {
    var ranges = createRangeArray(geoms);
    var task = new GeomMergeTask();
    // Interleaved vertex buffers as Float32Array
    task.vb = targetGeom.vb;
    // floats per vertex
    task.vbstride = targetGeom.vbstride;
    // offsets in floats where to find position/normal in vertex buffer
    task.posOffset = targetGeom.attributes.position.itemOffset;
    task.normalOffset = targetGeom.attributes.normal ? targetGeom.attributes.normal.itemOffset : -1; // -1 for "no normals"
    // matrices per src-geom (Float32Array with 16 floats per matrix)
    task.matrices = matrices;
    task.ranges = ranges;
    // must be an Uint32Array that we can efficiently hand-over to the worker
    task.dbIds = dbIds;
    return task;
}
/*
 * Writes the result of a GeomMergeTask back to a BufferGeometry.
 *  @param {Object}         mergeResult - returned by GeomMergeTask.run()
 *  @param {BufferGeometry} targetGeom  - BufferGeometry that will use the consolidated buffers
 */
function applyMergeResult(mergeResult, targetGeom) {
    targetGeom.vb = mergeResult.vb; // interleaved vertex-buffer  {Float32Array}
    targetGeom.attributes.id.array = mergeResult.vertexIds; // buffer with per-vertex ids {Uint32Array}
    targetGeom.needsUpdate = true;
}
/**
 * Helper class used to delegate a part of the geometry merging work to a worker thread.
 *   @param {Consolidation} consolidation - Consolidation.inProgress will be true as long as workers are running.
 */
var ParallelGeomMerge$1 = function ParallelGeomMerge(consolidation) {
    // Currently, we hardwire to just use 2 workers. With more workers, the single workers finished faster, but
    // for the overall time until all results are returned, I couldn't measure any benefit so far.
    var numWorkers = 2;
    // Track how many workers have to deliver their result before the consolidation is ready to use.
    var _workersRunning = 0;
    // indexed by task id. Contains BufferGeometries of consolidated meshes that are waiting for their merged vertex buffer.
    var _receiverGeoms = {};
    // MergeTask[] - one per addMergeTask() call
    var _tasks = [];
    // {Consolidation} - We set consolidation.inProgress as long as workers are running. This makes sure that
    //                   the consolidation is not used before it is fully finished.
    var _consolidation = consolidation;
    // workers
    var _workers = new Array(numWorkers);
    /**
     * Called in mergeGeometry (Consolidation.js) to delegate merge work to worker thread.
     * See MergeTask ctor for params.
     */
    this.addMergeTask = function (geoms, targetGeom, matrices, dbIds) {
        var task = createMergeTask(geoms, targetGeom, matrices, dbIds);
        _tasks.push(task);
        // remember which BufferGeometry will get the merged vertex buffer
        _receiverGeoms[task.id] = targetGeom;
    };
    /**
     * After adding merge tasks, this function passes all collected input to the workers and
     * starts them.
     */
    this.runTasks = function () {
        // init workers
        for (var i = 0; i < numWorkers; i++) {
            _workers[i] = ParallelGeomMerge.createWorker();
            _workers[i].addEventListenerWithIntercept(handleGeomMergeResult);
        }
        // subdivide task array into ranges, where each range is processed by a separate worker
        var numTasks = _tasks.length;
        var tasksPerWorker = Math.floor(numTasks / numWorkers);
        for (var r = 0; r < numWorkers; r++) {
            // define next range
            var lastCycle = r === numWorkers - 1;
            var rangeBegin = r * tasksPerWorker;
            var rangeEnd = lastCycle ? numTasks : rangeBegin + tasksPerWorker;
            var rangeLength = rangeEnd - rangeBegin;
            // array of tasks for this worker
            var tasks = [];
            // add all buffers and matrix arrays to transfer-list
            var transferList = new Array(4 * rangeLength);
            var index = 0;
            for (i = rangeBegin; i < rangeEnd; i++) {
                var task = _tasks[i];
                transferList[index++] = task.vb.buffer;
                transferList[index++] = task.matrices.buffer;
                transferList[index++] = task.ranges.buffer;
                transferList[index++] = task.dbIds.buffer;
                tasks.push(task);
            }
            // start worker task
            var msg = {
                operation: "MERGE_GEOMETRY",
                tasks: tasks
            };
            var worker = _workers[r];
            worker.doOperation(msg, transferList);
            _workersRunning++;
        }
        // mark consolidation as unusable until all workers are finished
        _consolidation.inProgress = true;
    };
    /**
     * Handles messages returned from worker threads
     * @param {Object} msg
     * @param {Object[]} msg.data - array of results per task, sent by ConsolidationWorker.
     *                              Each result contains interleaved vertex-buffer and vertex-id buffer for a
     *                              consolidated mesh. see doGeomMerge() function in ConsolidationWorker.js for details.
     */
    function handleGeomMergeResult(msg) {
        // get worker results. Note that sending consolidation results is currently the only supported
        // message that a consolidation worker may send.
        var results = msg.data;
        // for each returned vertex-buffer, find the corresponding consolidated mesh that should obtain it.
        for (var i = 0; i < results.length; i++) {
            var result = results[i];
            var taskId = result.taskId;
            // use task id to find receiving geometry
            var geom = _receiverGeoms[taskId];
            applyMergeResult(result, geom);
            // remove entry from list
            delete _receiverGeoms[taskId];
        }
        // Check if all workers are done
        _workersRunning--;
        if (_workersRunning === 0) {
            // all workers done. Signal that consolidation is ready to use.
            _consolidation.inProgress = false;
            // terminate workers
            for (i = 0; i < _workers.length; i++) {
                _workers[i].clearAllEventListenerWithIntercept();
                _workers[i].terminate();
                _workers[i] = null;
            }
        }
    }
};
// Run merge task immediately in the main thread
function runMergeSingleThreaded$1(geoms, mergedGeom, matrices, dbIds) {
    var task = createMergeTask(geoms, mergedGeom, matrices, dbIds);
    // run merge task - since we are in main, we can use THREE matrix/vectors for this
    var vec = new THREE$1.Vector3();
    var matrix = new THREE$1.Matrix4();
    var result = task.run(matrix, vec);
    applyMergeResult(result, mergedGeom);
}
var ParallelGeomMergeUtils = {
    ParallelGeomMerge: ParallelGeomMerge$1,
    runMergeSingleThreaded: runMergeSingleThreaded$1
};

var LineStyleDefs = [{
    id: "SOLID",
    name: "Solid",
    ascii_art: "_______________________________________",
    def: [1]
},
//Line types from acad.lin below. Definitions are kept the same
//as the original except the format is JSON-ified to avoid parsing .LIN
//
//  AutoCAD Linetype Definition file
//  Version 2.0
//  Copyright 1991, 1992, 1993, 1994, 1996 by Autodesk, Inc.
//
//List of line type definitions from ACAD.lin.
//[TS] The units for these items seem to be inches or drawing units with dot
// being represented by 0, i.e. pen width = 0. (see note about ISO patterns below)
{
    id: "BORDER",
    name: "Border",
    ascii_art: "__ __ . __ __ . __ __ . __ __ . __ __ .",
    def: [.5, -.25, .5, -.25, 0, -.25]
}, {
    id: "BORDER2",
    name: "Border (.5x)",
    ascii_art: "__ __ . __ __ . __ __ . __ __ . __ __ .",
    def: [.25, -.125, .25, -.125, 0, -.125]
}, {
    id: "BORDERX2",
    name: "Border (2x)",
    ascii_art: "____  ____  .  ____  ____  .  ___",
    def: [1.0, -.5, 1.0, -.5, 0, -.5]
}, {
    id: "CENTER",
    name: "Center",
    ascii_art: "____ _ ____ _ ____ _ ____ _ ____ _ ____",
    def: [1.25, -.25, .25, -.25]
}, {
    id: "CENTER2",
    name: "Center (.5x)",
    ascii_art: "___ _ ___ _ ___ _ ___ _ ___ _ ___",
    def: [.75, -.125, .125, -.125]
}, {
    id: "CENTERX2",
    name: "Center (2x)",
    ascii_art: "________  __  ________  __  _____",
    def: [2.5, -.5, .5, -.5]
}, {
    id: "DASHDOT",
    name: "Dash dot",
    ascii_art: "__ . __ . __ . __ . __ . __ . __ . __",
    def: [.5, -.25, 0, -.25]
}, {
    id: "DASHDOT2",
    name: "Dash dot (.5x)",
    ascii_art: "_._._._._._._._._._._._._._._.",
    def: [.25, -.125, 0, -.125]
}, {
    id: "DASHDOTX2",
    name: "Dash dot (2x)",
    ascii_art: "____  .  ____  .  ____  .  ___",
    def: [1.0, -.5, 0, -.5]
}, {
    id: "DASHED",
    name: "Dashed",
    ascii_art: "__ __ __ __ __ __ __ __ __ __ __ __ __ _",
    def: [.5, -.25]
}, {
    id: "DASHED2",
    name: "Dashed (.5x)",
    ascii_art: "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _",
    def: [.25, -.125]
}, {
    id: "DASHEDX2",
    name: "Dashed (2x)",
    ascii_art: "____  ____  ____  ____  ____  ___",
    def: [1.0, -.5]
}, {
    id: "DIVIDE",
    name: "Divide",
    ascii_art: "____ . . ____ . . ____ . . ____ . . ____",
    def: [.5, -.25, 0, -.25, 0, -.25]
}, {
    id: "DIVIDE2",
    name: "Divide (.5x)",
    ascii_art: "__..__..__..__..__..__..__..__.._",
    def: [.25, -.125, 0, -.125, 0, -.125]
}, {
    id: "DIVIDEX2",
    name: "Divide (2x)",
    ascii_art: "________  .  .  ________  .  .  _",
    def: [1.0, -.5, 0, -.5, 0, -.5]
}, {
    id: "DOT",
    name: "Dot",
    ascii_art: ". . . . . . . . . . . . . . . . . . . . . . . .",
    def: [0, -.25]
}, {
    id: "DOT2",
    name: "Dot (.5x)",
    ascii_art: "........................................",
    def: [0, -.125]
}, {
    id: "DOTX2",
    name: "Dot (2x)",
    ascii_art: ".  .  .  .  .  .  .  .  .  .  .  .  .  .",
    def: [0, -.5]
}, {
    id: "HIDDEN",
    name: "Hidden",
    ascii_art: "__ __ __ __ __ __ __ __ __ __ __ __ __ __",
    def: [.25, -.125]
}, {
    id: "HIDDEN2",
    name: "Hidden (.5x)",
    ascii_art: "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _",
    def: [.125, -.0625]
}, {
    id: "HIDDENX2",
    name: "Hidden (2x)",
    ascii_art: "____ ____ ____ ____ ____ ____ ____",
    def: [.5, -.25]
}, {
    id: "PHANTOM",
    name: "Phantom",
    ascii_art: "______  __  __  ______  __  __  ______",
    def: [1.25, -.25, .25, -.25, .25, -.25]
}, {
    id: "PHANTOM2",
    name: "Phantom (.5x)",
    ascii_art: "___ _ _ ___ _ _ ___ _ _ ___ _ _",
    def: [.625, -.125, .125, -.125, .125, -.125]
}, {
    id: "PHANTOMX2",
    name: "Phantom (2x)",
    ascii_art: "____________    ____    ____   _",
    def: [2.5, -.5, .5, -.5, .5, -.5]
},
//
//  ISO 128 (ISO/DIS 12011) linetypes
//
//  The size of the line segments for each defined ISO line, is
//  defined for an usage with a pen width of 1 mm. To use them with
//  the other ISO predefined pen widths, the line has to be scaled
//  with the appropriate value (e.g. pen width 0,5 mm -> ltscale 0.5).
//
//[TS] Added pen_width and unit properties to make this explicit
{
    id: "ACAD_ISO02W100",
    name: "ISO dash",
    ascii_art: "__ __ __ __ __ __ __ __ __ __ __ __ __",
    def: [12, -3],
    pen_width: 1,
    unit: "mm"
}, {
    id: "ACAD_ISO03W100",
    name: "ISO dash space",
    ascii_art: "__    __    __    __    __    __",
    def: [12, -18],
    pen_width: 1,
    unit: "mm"
}, {
    id: "ACAD_ISO04W100",
    name: "ISO long-dash dot",
    ascii_art: "____ . ____ . ____ . ____ . _",
    def: [24, -3, .5, -3],
    pen_width: 1,
    unit: "mm"
}, {
    id: "ACAD_ISO05W100",
    name: "ISO long-dash double-dot",
    ascii_art: "____ .. ____ .. ____ .",
    def: [24, -3, .5, -3, .5, -3],
    pen_width: 1,
    unit: "mm"
}, {
    id: "ACAD_ISO06W100",
    name: "ISO long-dash triple-dot",
    ascii_art: "____ ... ____ ... ____",
    def: [24, -3, .5, -3, .5, -3, .5, -3],
    pen_width: 1,
    unit: "mm"
}, {
    id: "ACAD_ISO07W100",
    name: "ISO dot",
    ascii_art: ". . . . . . . . . . . . . . . . . . . .",
    def: [.5, -3],
    pen_width: 1,
    unit: "mm"
}, {
    id: "ACAD_ISO08W100",
    name: "ISO long-dash short-dash",
    ascii_art: "____ __ ____ __ ____ _",
    def: [24, -3, 6, -3],
    pen_width: 1,
    unit: "mm"
}, {
    id: "ACAD_ISO09W100",
    name: "ISO long-dash double-short-dash",
    ascii_art: "____ __ __ ____",
    def: [24, -3, 6, -3, 6, -3],
    pen_width: 1,
    unit: "mm"
}, {
    id: "ACAD_ISO10W100",
    name: "ISO dash dot",
    ascii_art: "__ . __ . __ . __ . __ . __ . __ . ",
    def: [12, -3, .5, -3],
    pen_width: 1,
    unit: "mm"
}, {
    id: "ACAD_ISO11W100",
    name: "ISO double-dash dot",
    ascii_art: "__ __ . __ __ . __ __ . __ _",
    def: [12, -3, 12, -3, .5, -3],
    pen_width: 1,
    unit: "mm"
}, {
    id: "ACAD_ISO12W100",
    name: "ISO dash double-dot",
    ascii_art: "__ . . __ . . __ . . __ . .",
    def: [12, -3, .5, -3, .5, -3],
    pen_width: 1,
    unit: "mm"
}, {
    id: "ACAD_ISO13W100",
    name: "ISO double-dash double-dot",
    ascii_art: "__ __ . . __ __ . . _",
    def: [12, -3, 12, -3, .5, -3, .5, -3],
    pen_width: 1,
    unit: "mm"
}, {
    id: "ACAD_ISO14W100",
    name: "ISO dash triple-dot",
    ascii_art: "__ . . . __ . . . __ . . . _",
    def: [12, -3, .5, -3, .5, -3, .5, -3],
    pen_width: 1,
    unit: "mm"
}, {
    id: "ACAD_ISO15W100",
    name: "ISO double-dash triple-dot",
    ascii_art: "__ __ . . . __ __ . .",
    def: [12, -3, 12, -3, .5, -3, .5, -3, .5, -3],
    pen_width: 1,
    unit: "mm"
},
//  Complex linetypes
//
//  Complex linetypes have been added to this file.
//  These linetypes were defined in LTYPESHP.LIN in
//  Release 13, and are incorporated in ACAD.LIN in
//  Release 14.
//  
//  These linetype definitions use LTYPESHP.SHX.
//
//[TS] These do not work, we can only render linear types.
{
    id: "FENCELINE1",
    name: "Fenceline circle",
    ascii_art: "----0-----0----0-----0----0-----0--",
    def: [.25, -.1, ["CIRC1", "ltypeshp.shx", "x=-.1", "s=.1"], -.1, 1] //TODO: Does not work
}, {
    id: "FENCELINE2",
    name: "Fenceline square",
    ascii_art: "----[]-----[]----[]-----[]----[]---",
    def: [.25, -.1, ["BOX", "ltypeshp.shx", "x=-.1", "s=.1"], -.1, 1] //TODO: Does not work
}, {
    id: "TRACKS",
    name: "Tracks",
    ascii_art: "-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-",
    def: [.15, ["TRACK1", "ltypeshp.shx", "s=.25"], .15] //TODO: Does not work
}, {
    id: "BATTING",
    name: "Batting",
    ascii_art: "SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS",
    def: [.0001, -.1, ["BAT", "ltypeshp.shx", "x=-.1", "s=.1"], -.2, ["BAT", "ltypeshp.shx", "r=180", "x=.1", "s=.1"], -.1] //TODO: Does not work
}, {
    id: "HOT_WATER_SUPPLY",
    name: "Hot water supply",
    ascii_art: "---- HW ---- HW ---- HW ----",
    def: [.5, -.2, ["HW", "STANDARD", "S=.1", "R=0.0", "X=-0.1", "Y=-.05"], -.2] //TODO: Does not work
}, {
    id: "GAS_LINE",
    name: "Gas line",
    ascii_art: "----GAS----GAS----GAS----GAS----GAS----GAS--",
    def: [.5, -.2, ["GAS", "STANDARD", "S=.1", "R=0.0", "X=-0.1", "Y=-.05"], -.25] //TODO: Does not work
}, {
    id: "ZIGZAG",
    name: "Zig zag",
    ascii_art: "/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/",
    def: [.0001, -.2, ["ZIG", "ltypeshp.shx", "x=-.2", "s=.2"], -.4, ["ZIG", "ltypeshp.shx", "r=180", "x=.2", "s=.2"], -.2] //TODO: Does not work
}];
var CreateLinePatternTexture = function CreateLinePatternTexture() {
    var h = LineStyleDefs.length;
    var w = 0;
    for (var i = 0; i < h; i++) {
        var ls = LineStyleDefs[i];
        if (ls.def.length > w) w = ls.def.length;
    }
    var pw = w + 3;
    var ph = h;
    var pot = 1;
    while (pot < pw) {
        pot *= 2;
    }pw = pot;
    pot = 1;
    while (pot < ph) {
        pot *= 2;
    }ph = pot;
    var tex = new Uint8Array(pw * ph);
    for (var j = 0; j < h; j++) {
        var off = j * pw;
        var ls = LineStyleDefs[j];
        //NOTE: The pattern scaling here just makes
        //the definitions in the texture consistent throughout in units of logical pixels (96 pixels per inch).
        //It does not apply scaling based on pen width or LTSCALE which should be done in shader.
        //Because we use a Byte texture, the maximum dash length at 96 dpi is about 2.5 inches, which
        //is enough for the patterns we have today. This can be easily fixed by changing to e.g. rgba8
        var dpi = 96;
        var unitScale = ls.unit && ls.unit == "mm" ? 1.0 / 25.4 : 1.0;
        var penWidth = ls.pen_width || 0;
        var segs = ls.def;
        var patLen = 0;
        for (var i = 0; i < segs.length; i++) {
            var len = Math.abs(segs[i]);
            var isDot = len <= penWidth * 0.5;
            //Is it a dot? (the ISO patterns define dot as segment with half a pen width)
            if (isDot) len = 0;
            var ilen = 0 | len * dpi * unitScale;
            patLen += ilen;
            //dot handling, set to 1 logical pixel in texture, since we need the 0 to indicate pattern end
            //the shader will interpret 1 as dot.
            tex[off + i + 2] = ilen ? ilen : 1;
        }
        //Two bytes to store total pattern length in the first two bytes of the texture row
        tex[off] = patLen % 256;
        tex[off + 1] = patLen / 256;
        //null terminate the pattern def in the texture so we know when to stop in the shader
        tex[off + segs.length + 2] = 0;
    }
    var lineStyleTex = new THREE$1.DataTexture(tex, pw, ph, THREE$1.LuminanceFormat, THREE$1.UnsignedByteType, THREE$1.UVMapping, THREE$1.ClampToEdgeWrapping, THREE$1.ClampToEdgeWrapping, THREE$1.NearestFilter, THREE$1.NearestFilter, 0);
    lineStyleTex.generateMipmaps = false;
    lineStyleTex.flipY = false;
    lineStyleTex.needsUpdate = true;
    return lineStyleTex;
};
var LineStyleDef = {
    LineStyleDefs: LineStyleDefs,
    CreateLinePatternTexture: CreateLinePatternTexture
};

var prism_vert = "varying vec3 vViewPosition;\nvarying vec3 vNormal;\n#if defined(PRISMWOOD) && !defined(NO_UVW)\nvarying vec3 vUvw;\n#if defined(PRISMWOODBUMP)\nvarying vec3 vtNormal;\nvarying mat3 mNormalMatrix;\n#endif\n#endif\n#if MAX_SPOT_LIGHTS > 0 || NUM_CUTPLANES > 0\nvarying vec3 vWorldPosition;\n#endif\n#prism_check<USE_MAP>\n#if defined(USE_MAP) || defined(USE_TILING)\nvarying vec2 vUv;\n#endif\n#ifdef USE_LOGDEPTHBUF\n#ifdef USE_LOGDEPTHBUF_EXT\nvarying float vFragDepth;\n#endif\nuniform float logDepthBufFC;\n#endif\n#ifdef MRT_NORMALS\nvarying float depth;\n#endif\n#include<pack_normals>\n#include<instancing_decl_vert>\n#include<id_decl_vert>\n#include<shadowmap_decl_vert>\n#if !defined(USE_MAP) && (MAX_DIR_LIGHTS > 0 || MAX_POINT_LIGHTS > 0 || MAX_SPOT_LIGHTS > 0) || defined( PRISMWOODBUMP )\nvarying vec3 vTangent;\nvarying vec3 vBitangent;\nvoid ComputeTangents(vec3 normal, out vec3 u, out vec3 v)\n{\n    float scale = normal.z < 0.0 ? -1.0 : 1.0;\n    vec3 temp = scale * normal;\n    float e    = temp.z;\n    float h    = 1.0/(1.0 + e);\n    float hvx  = h   *  temp.y;\n    float hvxy = hvx * -temp.x;\n    u = vec3(e + hvx * temp.y, hvxy,                -temp.x);\n    v = vec3(hvxy,             e + h * temp.x * temp.x, -temp.y);\n    u *= scale;\n    v *= scale;\n}\n#endif\nvoid main() {\n#if defined(USE_MAP) || defined(USE_TILING)\n    vUv = uv;\n#endif\n#ifdef UNPACK_NORMALS\n    vec3 objectNormal = decodeNormal(normal);\n#else\n    vec3 objectNormal = normal;\n#endif\n#ifdef FLIP_SIDED\n    objectNormal = -objectNormal;\n#endif\n    objectNormal = getInstanceNormal(objectNormal);\n    vec3 instPos = getInstancePos(position);\n#if defined(PRISMWOOD) && !defined(NO_UVW)\n#if defined(PRISMWOODBUMP)\n    vUvw = instPos;\n    vtNormal = normalize(objectNormal);\n    mNormalMatrix = normalMatrix;\n#else\n    vUvw = uvw;\n#endif\n#endif\n    vec3 transformedNormal = normalMatrix * objectNormal;\n    vNormal = normalize( transformedNormal );\n    vec4 mvPosition = modelViewMatrix * vec4( instPos, 1.0 );\n    gl_Position = projectionMatrix * mvPosition;\n    vViewPosition = -mvPosition.xyz;\n#if MAX_SPOT_LIGHTS > 0 || NUM_CUTPLANES > 0\n    vec4 worldPosition = modelMatrix * vec4( instPos, 1.0 );\n    vWorldPosition = worldPosition.xyz;\n#endif\n#if !defined(USE_MAP) && (MAX_DIR_LIGHTS > 0 || MAX_POINT_LIGHTS > 0 || MAX_SPOT_LIGHTS > 0) || defined ( PRISMWOODBUMP )\n    vec3 Tu, Tv;\n#if defined(PRISMWOODBUMP)\n    ComputeTangents(vtNormal, Tu, Tv);\n#else\n    ComputeTangents(vNormal, Tu, Tv);\n#endif\n    vTangent = Tu;\n    vBitangent = Tv;\n#endif\n#ifdef USE_LOGDEPTHBUF\n    if (projectionMatrix[3][3] == 0.0) {\n        gl_Position.z = log2(max(1.0e-6, gl_Position.w + 1.0)) * logDepthBufFC;\n#ifdef USE_LOGDEPTHBUF_EXT\n        vFragDepth = 1.0 + gl_Position.w;\n#else\n        gl_Position.z = (gl_Position.z - 1.0) * gl_Position.w;\n#endif\n    } else {\n#ifdef USE_LOGDEPTHBUF_EXT\n        vFragDepth = 1.0 + vViewPosition.z;\n#else\n#endif\n    }\n#endif\n#ifdef MRT_NORMALS\n    depth = mvPosition.z;\n#endif\n#include<id_vert>\n#include<shadowmap_vert>\n}\n";

var prism_frag = "\n#include<common>\n#define RECIPROCAL_PI 0.318309886\n#define ONE 0.00390625\nuniform float opacity;\nuniform vec3 surface_albedo;\nuniform float surface_roughness;\nuniform float surface_anisotropy;\nuniform float surface_rotation;\nuniform sampler2D importantSamplingRandomMap;\nuniform sampler2D importantSamplingSolidAngleMap;\n#if defined( PRISMOPAQUE )\nuniform vec3 opaque_albedo;\nuniform float opaque_f0;\nuniform vec3 opaque_luminance_modifier;\nuniform float opaque_luminance;\n#elif defined( PRISMMETAL )\nuniform vec3 metal_f0;\n#elif defined( PRISMLAYERED )\nuniform float layered_f0;\nuniform vec3 layered_diffuse;\nuniform float layered_fraction;\nuniform vec3 layered_bottom_f0;\nuniform float layered_roughness;\nuniform float layered_anisotropy;\nuniform float layered_rotation;\n#elif defined( PRISMTRANSPARENT )\nuniform float transparent_ior;\nuniform vec3 transparent_color;\nuniform float transparent_distance;\n#elif defined( PRISMGLAZING )\nuniform vec3 glazing_f0;\nuniform vec3 glazing_transmission_color;\nuniform float glazing_transmission_roughness;\n#elif defined( PRISMWOOD )\nuniform bool wood_fiber_cosine_enable;\nuniform int wood_fiber_cosine_bands;\nuniform vec4 wood_fiber_cosine_weights;\nuniform vec4 wood_fiber_cosine_frequencies;\nuniform bool wood_fiber_perlin_enable;\nuniform int wood_fiber_perlin_bands;\nuniform vec4 wood_fiber_perlin_weights;\nuniform vec4 wood_fiber_perlin_frequencies;\nuniform float wood_fiber_perlin_scale_z;\nuniform bool wood_growth_perlin_enable;\nuniform int wood_growth_perlin_bands;\nuniform vec4 wood_growth_perlin_weights;\nuniform vec4 wood_growth_perlin_frequencies;\nuniform float wood_latewood_ratio;\nuniform float wood_earlywood_sharpness;\nuniform float wood_latewood_sharpness;\nuniform float wood_ring_thickness;\nuniform bool wood_earlycolor_perlin_enable;\nuniform int wood_earlycolor_perlin_bands;\nuniform vec4 wood_earlycolor_perlin_weights;\nuniform vec4 wood_earlycolor_perlin_frequencies;\nuniform vec3 wood_early_color;\nuniform bool wood_use_manual_late_color;\nuniform vec3 wood_manual_late_color;\nuniform bool wood_latecolor_perlin_enable;\nuniform int wood_latecolor_perlin_bands;\nuniform vec4 wood_latecolor_perlin_weights;\nuniform vec4 wood_latecolor_perlin_frequencies;\nuniform float wood_late_color_power;\nuniform bool wood_diffuse_perlin_enable;\nuniform int wood_diffuse_perlin_bands;\nuniform vec4 wood_diffuse_perlin_weights;\nuniform vec4 wood_diffuse_perlin_frequencies;\nuniform float wood_diffuse_perlin_scale_z;\nuniform bool wood_use_pores;\nuniform int wood_pore_type;\nuniform float wood_pore_radius;\nuniform float wood_pore_cell_dim;\nuniform float wood_pore_color_power;\nuniform float wood_pore_depth;\nuniform bool wood_use_rays;\nuniform float wood_ray_color_power;\nuniform float wood_ray_seg_length_z;\nuniform float wood_ray_num_slices;\nuniform float wood_ray_ellipse_z2x;\nuniform float wood_ray_ellipse_radius_x;\nuniform bool wood_use_latewood_bump;\nuniform float wood_latewood_bump_depth;\nuniform bool wood_use_groove_roughness;\nuniform float wood_groove_roughness;\nuniform float wood_diffuse_lobe_weight;\nuniform sampler2D permutationMap;\nuniform sampler2D gradientMap;\nuniform sampler2D perm2DMap;\nuniform sampler2D permGradMap;\nuniform vec4 wood_ring_fraction;\nuniform vec2 wood_fall_rise;\n#endif\n#ifdef USE_TILING\nuniform mat4 tilingOverallTransform;\nuniform sampler2D TilingMap;\nuniform mat3 TilingMap_texMatrix;\nuniform vec4 uv2tile;\nuniform vec4 tile2uv;\nuniform vec2 tileAlignOffset;\nuniform mat4 tilingUVTransform;\n#ifdef USE_TILING_NORMAL\nuniform sampler2D TilingNormalMap;\nuniform mat3 TilingNormalMap_texMatrix;\n#endif\n#ifdef USE_TILING_RANDOM\nuniform sampler2D TilingRandomMap;\nuniform mat3 TilingRandomMap_texMatrix;\nuniform vec2 tilingRandomAxisS;\nuniform vec2 tilingRandomAxisT;\nuniform vec2 tilingRandomAlignmentOffset;\n#endif\n#endif\nuniform float envExponentMin;\nuniform float envExponentMax;\nuniform float envExponentCount;\n#include<env_sample>\n#if TONEMAP_OUTPUT > 0\nuniform float exposureBias;\n#include<tonemap>\n#endif\n#if MAX_SPOT_LIGHTS > 0 || NUM_CUTPLANES > 0\nvarying vec3 vWorldPosition;\n#endif\n#ifdef USE_LOGDEPTHBUF\nuniform float logDepthBufFC;\n#ifdef USE_LOGDEPTHBUF_EXT\n#extension GL_EXT_frag_depth : enable\nvarying highp float vFragDepth;\n#endif\n#endif\n#include<id_decl_frag>\n#include<theming_decl_frag>\n#include<shadowmap_decl_frag>\n#ifdef USE_FOG\nuniform vec3 fogColor;\nuniform float fogNear;\nuniform float fogFar;\n#endif\n#prism_check<USE_MAP>\n#if defined(USE_MAP) || defined(USE_TILING)\nvarying vec2 vUv;\n#endif\n#if defined(PRISMWOOD) && !defined(NO_UVW)\nvarying vec3 vUvw;\n#endif\n#prism_uniforms<surface_albedo_map>\n#prism_uniforms<surface_roughness_map>\n#prism_uniforms<surface_cutout_map>\n#prism_uniforms<surface_anisotropy_map>\n#prism_uniforms<surface_rotation_map>\n#prism_uniforms<opaque_albedo_map>\n#prism_uniforms<opaque_f0_map>\n#prism_uniforms<opaque_luminance_modifier_map>\n#prism_uniforms<layered_bottom_f0_map>\n#prism_uniforms<layered_f0_map>\n#prism_uniforms<layered_diffuse_map>\n#prism_uniforms<layered_fraction_map>\n#prism_uniforms<layered_roughness_map>\n#prism_uniforms<layered_anisotropy_map>\n#prism_uniforms<layered_rotation_map>\n#prism_uniforms<metal_f0_map>\n#prism_uniforms<glazing_f0_map>\n#prism_uniforms<glazing_transmission_roughness_map>\n#prism_uniforms<glazing_transmission_color_map>\n#prism_uniforms<wood_curly_distortion_map>\n#if defined( USE_WOOD_CURLY_DISTORTION_MAP )\nuniform bool wood_curly_distortion_enable;\nuniform float wood_curly_distortion_scale;\n#endif\n#prism_bump_uniforms<surface_normal_map>\n#prism_bump_uniforms<layered_normal_map>\nfloat SRGBToLinearComponent(float color) {\n    float result = color;\n    if (result<=0.04045)\n        result *= 0.07739938;\n    else\n        result = pow(abs((result+0.055)*0.947867298), 2.4);\n    return result;\n}\nvec3 SRGBToLinear(vec3 color) {\n    vec3 result = color;\n    result.x = SRGBToLinearComponent(result.x);\n    result.y = SRGBToLinearComponent(result.y);\n    result.z = SRGBToLinearComponent(result.z);\n    return result;\n}\n#if defined( USE_ENVMAP )\nuniform float envMapExposure;\nuniform samplerCube envMap;\n#endif\n#include<normal_map>\n#if !defined(USE_MAP) && (MAX_DIR_LIGHTS > 0 || MAX_POINT_LIGHTS > 0 || MAX_SPOT_LIGHTS > 0) || defined ( PRISMWOODBUMP )\nvarying vec3 vTangent;\nvarying vec3 vBitangent;\n#if defined( PRISMWOODBUMP )\nvarying vec3 vtNormal;\nvarying mat3 mNormalMatrix;\n#endif\n#endif\n#if defined( USE_ENVMAP )\nvec3 sampleReflection(vec3 N, vec3 V, float mipIndex) {\n    vec3 dir = (2.0 * dot(V, N)) * N - V;\n    dir = adjustLookupVector(mat3(viewMatrixInverse) * dir);\n#ifdef ENV_GAMMA\n#ifdef HAVE_TEXTURE_LOD\n    vec4 envTexColor = textureCubeLodEXT( envMap, dir, mipIndex );\n#else\n    vec4 envTexColor = textureCube( envMap, dir, mipIndex );\n#endif\n    return GammaDecode(envTexColor, envMapExposure);\n#elif defined(ENV_RGBM)\n#ifdef HAVE_TEXTURE_LOD\n    vec4 envTexColor = textureCubeLodEXT( envMap, dir, mipIndex );\n#else\n    vec4 envTexColor = textureCube( envMap, dir, mipIndex );\n#endif\n    return RGBMDecode(envTexColor, envMapExposure);\n#else\n    vec4 envTexColor = textureCube( envMap, dir );\n    vec3 cubeColor = envTexColor.xyz;\n#ifdef GAMMA_INPUT\n    cubeColor *= cubeColor;\n#endif\n    return cubeColor;\n#endif\n}\n#endif\n#include<hatch_pattern>\n#if defined( USE_ENVMAP ) && defined( USE_IRRADIANCEMAP )\nuniform samplerCube irradianceMap;\nvec3 sampleNormal(vec3 normal) {\n    vec3 worldNormal = mat3(viewMatrixInverse) * normal;\n    vec3 irradiance = sampleIrradianceMap(worldNormal, irradianceMap, envMapExposure);\n    irradiance = applyEnvShadow(irradiance, worldNormal);\n    return irradiance;\n}\n#endif\n#if MAX_DIR_LIGHTS > 0\nuniform vec3 directionalLightColor[ MAX_DIR_LIGHTS ];\nuniform vec3 directionalLightDirection[ MAX_DIR_LIGHTS ];\n#endif\n#if MAX_POINT_LIGHTS > 0\nuniform vec3 pointLightColor[ MAX_POINT_LIGHTS ];\nuniform vec3 pointLightPosition[ MAX_POINT_LIGHTS ];\nuniform float pointLightDistance[ MAX_POINT_LIGHTS ];\n#endif\n#if MAX_SPOT_LIGHTS > 0\nuniform vec3 spotLightColor[ MAX_SPOT_LIGHTS ];\nuniform vec3 spotLightPosition[ MAX_SPOT_LIGHTS ];\nuniform vec3 spotLightDirection[ MAX_SPOT_LIGHTS ];\nuniform float spotLightAngleCos[ MAX_SPOT_LIGHTS ];\nuniform float spotLightExponent[ MAX_SPOT_LIGHTS ];\nuniform float spotLightDistance[ MAX_SPOT_LIGHTS ];\n#endif\nfloat sqr(float x) {return x*x;}\nfloat aSqrd(float maxAlphaSqr, float cosTheta)\n{\n    if (abs(cosTheta) < 1e-10)\n    {\n        return 1e10;\n    }\n    float tan2 = 1.0/sqr(cosTheta) - 1.0;\n    return maxAlphaSqr * tan2;\n}\nvec3 Fresnel_Schlick(vec3 f0, float cosAngle)\n{\n    float x = 1.0 - cosAngle;\n    float x2 = x * x;\n    float x5 = x * x2 * x2;\n    return f0 + (1.0 - f0) * x5;\n}\nvec3 Fresnel_Rough(vec3 f0, float cosAngle, float alpha)\n{\n    float x = 1.0 - cosAngle;\n    float x2 = x * x;\n    float x5 = x * x2 * x2;\n    vec3 maxReflectance = mix(vec3(1.0), f0, vec3(min(0.7, alpha)) / 0.7);\n    return f0 + (maxReflectance - f0) * x5;\n}\nfloat IORToReflectance(float ior)\n{\n    return sqr((1.0 - ior)/(1.0 + ior));\n}\nvec2 RoughnessToAlpha(float roughness, float anisotropy)\n{\n    vec2 alpha = roughness * vec2(1.0, 1.0 - anisotropy);\n    alpha = alpha * alpha;\n    alpha = clamp(alpha, 0.001, 1.0);\n    return alpha;\n}\nfloat AlphaToPhong(float alpha)\n{\n    return max(0.0, 2.56/alpha - 7.0);\n}\nfloat ExponentToReflMipIndex(float exponent)\n{\n    float targetLog = log2(exponent);\n    float minLog = log2(envExponentMin);\n    float maxLog = log2(envExponentMax);\n    float deltaLog = clamp(targetLog - minLog, 0.0, maxLog - minLog);\n    float level = clamp((1.0-(deltaLog + 0.5) / envExponentCount), 0.0, 1.0) * 6.0;\n    return level;\n}\n#include<prism_wood>\n#if defined( ENABLEIMPORTANTSAMPLING ) && (defined( USE_SURFACE_ROTATION_MAP ) || defined( USE_SURFACE_ANISOTROPY_MAP ) || defined( USE_LAYERED_ROTATION_MAP ) || defined( USE_LAYERED_ANISOTROPY_MAP ))\n#define IMPORTANTSAMPLING\n#endif\n#if defined( IMPORTANTSAMPLING )\n#define SAMPLECOUNT 32\nvec2 Hammersley(int index)\n{\n    float u = (float(index) + 0.5) / 32.0;\n    float v = 0.5;\n    float noise = texture2D(importantSamplingRandomMap, vec2(u, v), 0.0).r;\n   return vec2(2.0 * PI * float(index/SAMPLECOUNT), noise);\n}\nvec3 ImportanceSampleAnisotropicGGX(int index, vec2 alpha, vec3 N, vec3 Tu, vec3 Tv)\n{\n    vec2 uniformSample2D = Hammersley(index);\n    float coef = sqrt(uniformSample2D.y / (1.0 - uniformSample2D.y));\n    float sinSigma, cosSigma;\n    sinSigma = sin(uniformSample2D.x);\n    cosSigma = cos(uniformSample2D.x);\n    vec3 H = coef * ((alpha.x * cosSigma) * Tu + (alpha.y * sinSigma) * Tv) + N;\n    H = normalize(H);\n    return H;\n}\nfloat ComputePDF(vec2 alpha, float NdotH, float HdotTu, float HdotTv, float VdotH)\n{\n    float factor1 = HdotTu / alpha.x;\n    float factor2 = HdotTv / alpha.y;\n    float factor3 = factor1 * factor1 + factor2 * factor2 + NdotH * NdotH;\n    float factor = factor3 * factor3 * alpha.x * alpha.y * VdotH * 4.0 * PI;\n    if (factor > 0.0)\n    {\n        return (NdotH / factor);\n    }\n    else\n    {\n        return 0.0;\n    }\n}\n#define INVFACESIZE 0.0078125\nfloat DirectionToSolidAngle(vec3 dir)\n{\n    dir = abs(dir);\n    float first = min(dir.x, dir.y);\n    float temp = max(dir.x, dir.y);\n    float second = min(temp, dir.z);\n    float third = max(temp, dir.z);\n    first /= third;\n    second /= third;\n    float u = (first+1.0)/2.0;\n    float v = (second + 1.0) / 2.0;\n    float solidAngle = texture2D(importantSamplingSolidAngleMap, vec2(u, v), 0.0).r * 0.000255;\n    return solidAngle;\n}\nfloat Smith_GGX(float value)\n{\n    return 2.0 / (1.0 + sqrt(1.0 + value));\n}\nvec2 RoughnessAnisotropyToAlpha(float roughness, float anisotropy)\n{\n    float aspect = sqrt(1.0 - 0.9 * anisotropy);\n    vec2 alpha = vec2(roughness * roughness / aspect, roughness * roughness * aspect);\n    return alpha;\n}\nvec3 ImportanceSamplingSpecular(float angle, vec3 reflectance, float roughness, float anisotropy, vec3 V, vec3 N, vec3 Tu, vec3 Tv)\n{\n    vec3 specular = vec3(0.0);\n    float radAngle;\n    if (anisotropy < 1e-10)\n    {\n        radAngle = 0.0;\n    }\n    else\n    {\n        radAngle = -PI * angle;\n    }\n    vec2 alpha = RoughnessAnisotropyToAlpha(roughness, anisotropy);\n    float alpha2 = max(alpha.x * alpha.x, alpha.y * alpha.y);\n    float NdotV = dot(N, V);\n    float alpha2NV = aSqrd(alpha2, NdotV);\n    vec2 sincosTheta;\n    sincosTheta.x = sin(radAngle);\n    sincosTheta.y = cos(radAngle);\n    vec3 Tu1, Tv1;\n    Tu1 = sincosTheta.y * Tu - sincosTheta.x * Tv;\n    Tv1 = sincosTheta.x * Tu + sincosTheta.y * Tv;\n    vec3 H;\n    vec3 sampleLightIntensity;\n    vec3 L;\n    float effectiveSample = 0.0;\n    for (int i = 0; i < SAMPLECOUNT; i++)\n    {\n        H = ImportanceSampleAnisotropicGGX(i, alpha, N, Tu1, Tv1);\n        float VdotH = dot(V, H);\n        L = 2.0 * VdotH * H - V;\n        float NdotH = dot(N, H);\n        float NdotL = dot(N, L);\n        if (NdotL >= 0.0 && NdotV > 0.0 && NdotH > 0.0)\n        {\n            float alpha2NL = aSqrd(alpha2, NdotL);\n            float HdotTu = dot(H, Tu1);\n            float HdotTv = dot(H, Tv1);\n            float pdf = ComputePDF(alpha, NdotH, HdotTu, HdotTv, VdotH);\n            float mipmapLevel = 0.0;\n            if (pdf > 0.0)\n            {\n                mipmapLevel = 0.3 * log2(1.0 / (float(SAMPLECOUNT) * pdf * DirectionToSolidAngle(L)));\n            }\n            mipmapLevel = clamp(mipmapLevel, 0.0, 4.0);\n            L = normalize(L);\n            sampleLightIntensity = sampleReflection(L, L, mipmapLevel).rgb;\n            float G = Smith_GGX(alpha2NL) * Smith_GGX(alpha2NV);\n            vec3 F = Fresnel_Schlick(reflectance, VdotH);\n            float factor = G * VdotH / (NdotH * NdotV);\n            if (factor >= 0.0)\n            {\n                specular += abs(sampleLightIntensity * F * factor);\n                effectiveSample += 1.0;\n            }\n        }\n    }\n    if (effectiveSample > 0.0)\n    {\n        specular /= effectiveSample;\n    }\n    return specular;\n}\n#endif\n#if MAX_DIR_LIGHTS > 0 || MAX_POINT_LIGHTS > 0 || MAX_SPOT_LIGHTS > 0\nvec3 DiffuseLobe(vec3 diffuseColor)\n{\n    return diffuseColor * RECIPROCAL_PI;\n}\nvec3 Rotate(vec3 vec, float angle)\n{\n    float s = sin(angle);\n    float c = cos(angle);\n    return vec3(vec.x * c - vec.y * s, vec.x * s + vec.y * c, vec.z);\n}\nfloat NDF_GGX(float alphaU, float alphaV, vec3 normal)\n{\n    float nx2 = sqr(normal.x);\n    float ny2 = sqr(normal.y);\n    float nz2 = sqr(normal.z);\n    float scale = 1.0/(alphaU * alphaV * PI);\n    return scale/sqr(nx2/sqr(alphaU) + ny2/sqr(alphaV) + nz2);\n}\nfloat G1_GGX(float aSqrd)\n{\n    return 2.0 / (1.0 + sqrt(1.0 + aSqrd));\n}\nvec3 MicrofacetLobe(\n        vec3 Hlocal, float NdotL, float NdotH, float NdotV, float VdotH,\n        float roughness, float anisotropy, float rotation, vec3 reflectance)\n{\n    vec2 alpha = RoughnessToAlpha(roughness, anisotropy);\n    Hlocal = Rotate(Hlocal, rotation);\n    vec3 F = Fresnel_Schlick(reflectance, VdotH);\n    float D = NDF_GGX(alpha.x, alpha.y, Hlocal);\n    float alpha2 = max(sqr(alpha.x), sqr(alpha.y));\n    float alpha2NL = aSqrd(alpha2, NdotL);\n    float alpha2NV = aSqrd(alpha2, NdotV);\n    float G = G1_GGX(alpha2NL) * G1_GGX(alpha2NV);\n    return max(F * D * G / (4.0 * NdotL * NdotV), vec3(0.0));\n}\n#if defined( PRISMOPAQUE )\nvec3 BRDF_Opaque(vec3 Hlocal, float NdotL, float NdotH, float NdotV, float VdotH,\n        vec3 surfaceAlbedo, float surfaceRoughness, float surfaceAnisotropy, float surfaceRotation,\n        float opaqueF0, vec3 opaqueAlbedo)\n{\n    vec3 diffuse = DiffuseLobe(opaqueAlbedo);\n    vec3 specular = surfaceAlbedo * MicrofacetLobe(\n            Hlocal, NdotL, NdotH, NdotV, VdotH,\n            surfaceRoughness, surfaceAnisotropy, surfaceRotation, vec3(opaqueF0));\n    return (specular+diffuse)*NdotL;\n}\n#elif defined( PRISMMETAL )\nvec3 BRDF_Metal(vec3 Hlocal, float NdotL, float NdotH, float NdotV, float VdotH,\n        vec3 surfaceAlbedo, float surfaceRoughness, float surfaceAnisotropy, float surfaceRotation,\n        vec3 metalF0)\n{\n    vec3 specular = surfaceAlbedo * MicrofacetLobe(\n            Hlocal, NdotL, NdotH, NdotV, VdotH,\n            surfaceRoughness, surfaceAnisotropy, surfaceRotation, metalF0);\n    return specular*NdotL;\n}\n#elif defined( PRISMLAYERED )\nvec3 BRDF_Layered(vec3 Hlocal, float NdotL, float NdotH, float NdotV, float VdotH,\n        vec3 Hlocal2, float N2dotL, float N2dotH, float N2dotV,\n        vec3 surfaceAlbedo, float surfaceRoughness, float surfaceAnisotropy, float surfaceRotation,\n        float layeredF0, vec3 layeredDiffuse, float layeredRoughness, float layeredAnisotropy,\n        float layeredRotation, vec3 bottom_f0, float layeredFraction)\n{\n    vec3 Fl = Fresnel_Schlick(vec3(layeredF0), NdotL);\n    vec3 Fv = Fresnel_Schlick(vec3(layeredF0), NdotV);\n    vec3 amount = (1.0 - Fl) * (1.0 - Fv);\n    vec3 topSpecular = surfaceAlbedo * MicrofacetLobe(\n            Hlocal, NdotL, NdotH, NdotV, VdotH,\n            surfaceRoughness, surfaceAnisotropy, surfaceRotation,\n            vec3(layeredF0));\n    vec3 topDiffuse = DiffuseLobe(layeredDiffuse);\n    vec3 botSpecular = MicrofacetLobe(\n            Hlocal2, N2dotL, N2dotH, N2dotV, VdotH,\n            layeredRoughness, layeredAnisotropy, layeredRotation,\n            bottom_f0);\n    return topSpecular*NdotL + amount * mix(topDiffuse*NdotL, botSpecular*N2dotL, layeredFraction);\n}\n#elif defined( PRISMTRANSPARENT )\nvec3 BRDF_Transparent(vec3 Hlocal, float NdotL, float NdotH, float NdotV, float VdotH,\n        vec3 surfaceAlbedo, float surfaceRoughness, float surfaceAnisotropy, float surfaceRotation)\n{\n    vec3 reflectance = vec3(IORToReflectance(transparent_ior));\n    vec3 specular = surfaceAlbedo * MicrofacetLobe(\n            Hlocal, NdotL, NdotH, NdotV, VdotH,\n            surfaceRoughness, surfaceAnisotropy, surfaceRotation, reflectance);\n    return specular*NdotL;\n}\n#elif defined( PRISMGLAZING )\nvec3 BRDF_Glazing(vec3 Hlocal, float NdotL, float NdotH, float NdotV, float VdotH,\n        vec3 surfaceAlbedo, float surfaceRoughness, float surfaceAnisotropy, float surfaceRotation,\n        vec3 glazingF0, vec3 glazingTransmissionColor, float glazingIlluminance)\n{\n    vec3 diffuse = DiffuseLobe(glazingTransmissionColor - vec3(glazingIlluminance, glazingIlluminance, glazingIlluminance));\n    vec3 specular = surfaceAlbedo * MicrofacetLobe(\n            Hlocal, NdotL, NdotH, NdotV, VdotH,\n            surfaceRoughness, surfaceAnisotropy, surfaceRotation, glazingF0);\n    return (specular+diffuse)*NdotL;\n}\n#elif defined( PRISMWOOD )\nvec3 BRDF_Wood(vec3 Hlocal, float NdotL, float NdotH, float NdotV, float VdotH,\n        vec3 surfaceAlbedo, float surfaceRoughness, vec3 woodDiffuse)\n{\n    vec3 diffuse = DiffuseLobe(woodDiffuse);\n    vec3 specular = surfaceAlbedo * MicrofacetLobe(\n            Hlocal, NdotL, NdotH, NdotV, VdotH,\n            surfaceRoughness, 0.0, 0.0, vec3(0.04));\n    return (specular+diffuse)*NdotL;\n}\n#endif\n#endif\n#if defined( USE_ENVMAP )\n#if defined( PRISMOPAQUE )\nvec3 Environment_Opaque(vec3 N, vec3 V, float NdotV, vec3 surfaceAlbedo, float surfaceRoughness,\n        float opaqueF0, vec3 opaqueAlbedo, float surfaceAnisotropy, float surfaceRotation, vec3 Tu, vec3 T)\n{\n    float alpha = RoughnessToAlpha(surfaceRoughness, 0.0).x;\n    vec3 F = Fresnel_Rough(vec3(opaqueF0), NdotV, alpha);\n#if defined( IMPORTANTSAMPLING )\n    vec3 specular = surfaceAlbedo * ImportanceSamplingSpecular(surfaceRotation, vec3(opaqueF0), surfaceRoughness, surfaceAnisotropy, V, N, Tu, Tv);\n#else\n    float exponent = AlphaToPhong(alpha);\n    float reflMipIndex = ExponentToReflMipIndex(exponent);\n    vec3 envSpecular = sampleReflection(N, V, reflMipIndex);\n    vec3 specular = F* surfaceAlbedo * envSpecular;\n#endif\n#if defined( USE_IRRADIANCEMAP )\n    vec3 envIrradiance = sampleNormal(N);\n#else\n    vec3 envIrradiance = vec3(1.0);\n#endif\n    vec3 diffuse = (1.0 - F) * opaqueAlbedo * envIrradiance;\n    vec3 luminanceModifier;\n#prism_sample_texture<opaque_luminance_modifier, luminanceModifier, false, true>\n    vec3 emission = luminanceModifier * opaque_luminance;\n    return diffuse + specular + emission;\n}\n#elif defined( PRISMMETAL )\nvec3 Environment_Metal(vec3 N, vec3 V, float NdotV, vec3 surfaceAlbedo, float surfaceRoughness, vec3 metalF0, float surfaceAnisotropy, float surfaceRotation, vec3 Tu, vec3 Tv)\n{\n#if defined( IMPORTANTSAMPLING )\n    vec3 specular = surfaceAlbedo * ImportanceSamplingSpecular(surfaceRotation, metalF0, surfaceRoughness, surfaceAnisotropy, V, N, Tu, Tv);\n#else\n    float alpha = RoughnessToAlpha(surfaceRoughness, 0.0).x;\n    float exponent = AlphaToPhong(alpha);\n    float reflMipIndex = ExponentToReflMipIndex(exponent);\n    vec3 F = Fresnel_Rough(metalF0, NdotV, alpha);\n    vec3 envSpecular = sampleReflection(N, V, reflMipIndex);\n    vec3 specular = F * surfaceAlbedo * envSpecular;\n#endif\n    return specular;\n}\n#elif defined( PRISMLAYERED )\nvec3 Environment_Layered(vec3 N, vec3 V, float NdotV, vec3 N2, float N2dotV, vec3 surfaceAlbedo, float surfaceRoughness,\n        float layeredF0, float surfaceAnisotropy, float surfaceRotation, vec3 Tu, vec3 Tv, vec3 layeredDiffuse, float layeredRoughness,\n        float layeredAnisotropy, float layeredRotation, vec3 bottom_f0, float layeredFraction)\n{\n    vec3 F = Fresnel_Schlick(vec3(layeredF0), NdotV);\n    float alpha = RoughnessToAlpha(surfaceRoughness, 0.0).x;\n#if defined( IMPORTANTSAMPLING )\n    vec3 topSpecular = surfaceAlbedo * ImportanceSamplingSpecular(surfaceRotation, vec3(layeredF0), surfaceRoughness, surfaceAnisotropy, V, N, Tu, Tv);\n#else\n    float exponent = AlphaToPhong(alpha);\n    float reflMipIndex = ExponentToReflMipIndex(exponent);\n    vec3 envSpecular = sampleReflection(N, V, reflMipIndex);\n    vec3 topSpecular = F * surfaceAlbedo * envSpecular;\n#endif\n    vec3 amount = (1.0 - F);\n#if defined( USE_IRRADIANCEMAP )\n    vec3 envIrradiance = sampleNormal(N);\n#else\n    vec3 envIrradiance = vec3(1.0);\n#endif\n    vec3 topDiffuse = layeredDiffuse * envIrradiance;\n#if defined( IMPORTANTSAMPLING )\n    vec3 botSpecular = ImportanceSamplingSpecular(layeredRotation, bottom_f0, layeredRoughness, layeredAnisotropy, V, N2, Tu, Tv);\n#else\n    alpha = RoughnessToAlpha(layeredRoughness, 0.0).x;\n    exponent = AlphaToPhong(alpha);\n    reflMipIndex = ExponentToReflMipIndex(exponent);\n    envSpecular = sampleReflection(N2, V, reflMipIndex);\n    F = Fresnel_Rough(bottom_f0, N2dotV, alpha);\n    vec3 botSpecular = F * envSpecular;\n#endif\n    return topSpecular + amount * mix(topDiffuse, botSpecular, layeredFraction);\n}\n#elif defined( PRISMTRANSPARENT )\nvec3 Environment_Transparent(vec3 N, vec3 V, float NdotV, vec3 surfaceAlbedo, float surfaceRoughness, float surfaceAnisotropy, float surfaceRotation, vec3 Tu, vec3 Tv)\n{\n    vec3 reflectance = vec3(IORToReflectance(transparent_ior));\n    float alpha = RoughnessToAlpha(surfaceRoughness, 0.0).x;\n    vec3 F = Fresnel_Rough(reflectance, NdotV, alpha);\n#if defined( IMPORTANTSAMPLING )\n    vec3 specular = surfaceAlbedo * ImportanceSamplingSpecular(surfaceRotation, reflectance, surfaceRoughness, surfaceAnisotropy, V, N, Tu, Tv);\n#else\n    float exponent = AlphaToPhong(alpha);\n    float reflMipIndex = ExponentToReflMipIndex(exponent);\n    vec3 envSpecular = sampleReflection(N, V, reflMipIndex);\n    vec3 specular = F * surfaceAlbedo * envSpecular;\n#endif\n#if defined( USE_IRRADIANCEMAP )\n    vec3 envIrradiance = sampleNormal(N);\n#else\n    vec3 envIrradiance = vec3(1.0);\n#endif\n    vec3 color = F * surfaceRoughness * transparent_color * envIrradiance;\n    return specular + color;\n}\n#elif defined( PRISMGLAZING )\nvec3 Environment_Glazing(vec3 N, vec3 V, float NdotV, vec3 surfaceAlbedo, float surfaceRoughness, float surfaceAnisotropy, float surfaceRotation, vec3 Tu, vec3 Tv,\n                         vec3 glazing_f0, vec3 transmissionF, float transmissionAlpha, vec3 glazingAdjustedColor, float glazingIlluminace)\n{\n    float surfaceAlpha = RoughnessToAlpha(surfaceRoughness, 0.0).x;\n    vec3 surfaceF = Fresnel_Rough(glazing_f0, NdotV, surfaceAlpha);\n#if defined( IMPORTANTSAMPLING )\n    vec3 specular = surfaceAlbedo * ImportanceSamplingSpecular(surfaceRotation, glazing_f0, surfaceRoughness, surfaceAnisotropy, V, N, Tu, Tv);\n#else\n    float exponent = AlphaToPhong(surfaceAlpha);\n    float reflMipIndex = ExponentToReflMipIndex(exponent);\n    vec3 envSpecular = sampleReflection(N, V, reflMipIndex);\n    vec3 specular = surfaceF * surfaceAlbedo * envSpecular;\n#endif\n#if defined( USE_IRRADIANCEMAP )\n    vec3 envIrradiance = sampleNormal(N);\n#else\n    vec3 envIrradiance = vec3(1.0);\n#endif\n    vec3 color = 0.5 * (1.0 - transmissionF) * (glazingAdjustedColor - vec3(glazingIlluminace, glazingIlluminace, glazingIlluminace)) * envIrradiance; \n    return specular + color;\n}\n#elif defined( PRISMWOOD )\nvec3 Environment_Wood(vec3 N, vec3 V, float NdotV, vec3 surfaceAlbedo, float surfaceRoughness, vec3 woodDiffuse, float surfaceAnisotropy, float surfaceRotation, vec3 Tu, vec3 Tv)\n{\n    float alpha = RoughnessToAlpha(surfaceRoughness, 0.0).x;\n    vec3 F = Fresnel_Rough(vec3(0.04), NdotV, alpha);\n#if defined( IMPORTANTSAMPLING )\n    vec3 specular = surfaceAlbedo * ImportanceSamplingSpecular(surfaceRotation, vec3(0.04), surfaceRoughness, surfaceAnisotropy, V, N, Tu, Tv);\n#else\n    float exponent = AlphaToPhong(alpha);\n    float reflMipIndex = ExponentToReflMipIndex(exponent);\n    vec3 envSpecular = sampleReflection(N, V, reflMipIndex);\n    vec3 specular = F * surfaceAlbedo * envSpecular;\n#endif\n#if defined( USE_IRRADIANCEMAP )\n    vec3 envIrradiance = sampleNormal(N);\n#else\n    vec3 envIrradiance = vec3(1.0);\n#endif\n    vec3 diffuse = (1.0 - F) * woodDiffuse * envIrradiance;\n    return diffuse + specular;\n}\n#endif\n#endif\n#if defined( PRISMTRANSPARENT )\n#include <prism_transparency>\n#elif defined( PRISMGLAZING )\n#include <prism_glazing>\n#endif\n#ifdef USE_TILING\nvec3 tilingTransform(vec2 uv, mat4 transform)\n{\n\treturn (transform * vec4(uv, 0.0, 1.0)).xyz;\n}\nvec4 tilingMapTest(sampler2D tilingSampler, mat3 transf, vec3 uv, vec4 uv2tile, vec4 tile2uv)\n{\n\tvec2 tileCoord = vec2(dot(uv2tile.xz, uv.xy), dot(uv2tile.yw, uv.xy));\n\tvec2 ijBase = floor(tileCoord);\n    vec2 fracC = fract(tileCoord);\n\tvec2 st = vec2(dot(tile2uv.xz, fracC), dot(tile2uv.yw, fracC));\n\tvec4 tileInfo = vec4(0.0, 0.0, 2.0, 2.0);\n\tvec2 iOffset = float(TILE_RANGE_X_MIN) * tile2uv.xy;\n\tvec2 jBaseOffset = float(TILE_RANGE_Y_MIN) * tile2uv.zw;\n\tfor( int i = TILE_RANGE_X_MIN; i <= TILE_RANGE_X_MAX; i++)\n\t{\n\t\tvec2 jOffset = jBaseOffset;\n\t\tfor( int j = TILE_RANGE_Y_MIN; j <= TILE_RANGE_Y_MAX; j++)\n\t\t{\n\t\t\tvec2 sampleUV = st + iOffset + jOffset;\n\t\t\tjOffset += tile2uv.zw;\n\t\t\tsampleUV = (transf * vec3(sampleUV, 1.0)).xy;\n\t\t\tvec4 tex = texture2D(tilingSampler, sampleUV);\n\t\t\tfloat d = max( min(tex.r, tex.g), min( max(tex.r, tex.g), tex.b));\n            if (d < tileInfo.z) {\n\t\t\t\ttileInfo.xy = vec2(float(i),float(j));\n\t\t\t\ttileInfo.w = tileInfo.z;\n\t\t\t\ttileInfo.z = d;\n\t\t\t} else {\n\t\t\t\ttileInfo.w = min(tileInfo.w, d);\n\t\t\t}\n\t\t}\n\t\tiOffset += tile2uv.xy;\n\t}\n\ttileInfo.zw = tileInfo.zw - 0.5;\n\tfloat w = clamp(tileInfo.z/max(fwidth(tileInfo.z), 0.000001) + 0.5, 0.0, 1.0);\n\tif ( w == 1.0 )\n\t\tdiscard;\n \tif (abs(tileInfo.w)<=abs(tileInfo.z))\n\t\tw = 0.0;\n\ttileInfo.w = 1.0 - w;\n\ttileInfo.xy -= ijBase;\n\treturn tileInfo;\n}\nvec2 tilingSubMaterialRelocate(vec3 uv, vec4 tileInfo, vec4 tile2uv)\n{\n\tvec2 offset = vec2(dot(tile2uv.xz, tileInfo.xy), dot(tile2uv.yw, tileInfo.xy));\n\treturn (uv.xy + offset);\n}\n#ifdef USE_TILING_RANDOM\nvec2 tilingRandom(vec2 uv, vec4 tileInfo, sampler2D randomSampler, mat3 transf, vec2 tileTextureAxisS, vec2 tileTextureAxisT, vec2 tile2TextureOffset)\n{\n    vec2 xti = (vec3(tileInfo.xy, 1.0) * transf).xy;\n    vec4 random = texture2D(randomSampler, xti);\n    vec2 randomOffset = vec2(tileTextureAxisS.x*random.z + tileTextureAxisT.x*random.w,\n        tileTextureAxisS.y*random.z + tileTextureAxisT.y*random.w) + tile2TextureOffset;\n    return uv + randomOffset;\n}\n#endif\nvoid tilingNormalOffset(\n    sampler2D bumpTexture,\n    vec2 uv,\n    mat3 transform,\n    inout vec3 T,\n    inout vec3 B,\n    inout vec3 N\n) {\n    vec2 st = (vec3(uv, 1.0) * transform).xy;\n    vec3 distort =  (2.0 * texture2D(bumpTexture, st).xyz - 1.0) - vec3(0.0,0.0,1.0);\n    mat3 mat = mat3(\n        T.x, B.x, N.x,\n        T.y, B.y, N.y,\n        T.z, B.z, N.z\n    );\n    N = normalize(N + (mat*distort));\n}\n#endif\nvarying vec3 vNormal;\nvarying vec3 vViewPosition;\n#include<cutplanes>\nvoid main() {\n#if NUM_CUTPLANES > 0\n    checkCutPlanes(vWorldPosition);\n#endif\n    vec3 N = normalize(vNormal);\n    vec3 Tu = vec3(0.0);\n    vec3 Tv = vec3(0.0);\n#if defined(USE_MAP) || defined(USE_TILING)\n    vec2 uv = vUv;\n#endif\n#ifdef USE_TILING\n    vec3 v_tilingOverallTransf = tilingTransform( vUv, tilingOverallTransform );\n    vec4 v_TilingMap = tilingMapTest( TilingMap, TilingMap_texMatrix, v_tilingOverallTransf, uv2tile, tile2uv );\n    uv = tilingSubMaterialRelocate( v_tilingOverallTransf, v_TilingMap, tile2uv ) + tileAlignOffset;\n#ifdef USE_TILING_NORMAL\n    vec2 uvNorm = uv;\n#endif\n#ifdef USE_TILING_RANDOM\n    uv = tilingRandom( uv, v_TilingMap, TilingRandomMap, TilingRandomMap_texMatrix, tilingRandomAxisS, tilingRandomAxisT, tilingRandomAlignmentOffset );\n#endif\n    uv = tilingTransform( uv, tilingUVTransform ).xy;\n#endif\n#if defined( USE_SURFACE_NORMAL_MAP ) || defined( USE_LAYERED_NORMAL_MAP ) || MAX_DIR_LIGHTS > 0 || MAX_POINT_LIGHTS > 0 || MAX_SPOT_LIGHTS > 0 || defined( PRISMWOODBUMP ) || defined( IMPORTANTSAMPLING )\n#if !defined(USE_MAP) || defined( PRISMWOODBUMP )\n    Tu = normalize(vTangent);\n    Tv = normalize(vBitangent);\n#else\n    vec3 q0 = dFdx( -vViewPosition );\n    vec3 q1 = dFdy( -vViewPosition );\n    vec2 st0 = dFdx( uv );\n    vec2 st1 = dFdy( uv );\n    Tu = normalize(  q0 * st1.t - q1 * st0.t );\n    Tv = normalize( -q0 * st1.s + q1 * st0.s );\n#endif\n#endif\n    vec3 V;\n    if (projectionMatrix[3][3] == 0.0) {\n        V = normalize( vViewPosition );\n    } else {\n        V = vec3(0.0, 0.0, 1.0);\n    }\n    N = faceforward(N, -V, N);\n#if defined(PRISMLAYERED)\n    vec3 N2 = N;\n#endif\n#ifndef FLAT_SHADED\n    vec3 normal = normalize( vNormal );\n#ifdef DOUBLE_SIDED\n    normal = normal * ( -1.0 + 2.0 * float( gl_FrontFacing ) );\n#endif\n#else\n    vec3 fdx = dFdx( vViewPosition );\n    vec3 fdy = dFdy( vViewPosition );\n    vec3 normal = normalize( cross( fdx, fdy ) );\n#endif\n#if defined( USE_SURFACE_NORMAL_MAP )\n    if (surface_normal_map_bumpmapType == 0)\n        heightMapTransform(surface_normal_map, uv, surface_normal_map_texMatrix, surface_normal_map_bumpScale, Tu, Tv, N);\n    else\n        normalMapTransform(surface_normal_map, uv, surface_normal_map_texMatrix, surface_normal_map_bumpScale, Tu, Tv, N);\n#endif\n#if defined( USE_LAYERED_NORMAL_MAP )\n    if (layered_normal_map_bumpmapType == 0)\n        heightMapTransform(layered_normal_map, uv, layered_normal_map_texMatrix, layered_normal_map_bumpScale, Tu, Tv, N2);\n    else\n        normalMapTransform(layered_normal_map, uv, layered_normal_map_texMatrix, layered_normal_map_bumpScale, Tu, Tv, N2);\n#endif\n#ifdef USE_TILING_NORMAL\n    tilingNormalOffset(TilingNormalMap, uvNorm, TilingNormalMap_texMatrix, Tu, Tv, N);\n#endif\n#if defined( PRISMWOOD )\n#ifdef NO_UVW\n    vec3 p = vec3(0.0);\n#elif defined( USE_WOOD_CURLY_DISTORTION_MAP )\n    vec3 p = DistortCurly(vUvw);\n#else\n    vec3 p = vUvw;\n#endif\n#if !defined( NO_UVW ) && defined( PRISMWOODBUMP )\n    getFinalWoodContext(\n        N, V, Tu, Tv, p,\n        normal, vtNormal, vNormalMatrix\n    );\n#endif\n#endif\n    float NdotV = clamp(dot(N, V), EPSILON, 1.0);\n#if defined(PRISMLAYERED)\n    float N2dotV = clamp(dot(N2, V), EPSILON, 1.0);\n#endif\n    vec3 surfaceAlbedo;\n#prism_sample_texture<surface_albedo, surfaceAlbedo, false, true>\n    float surfaceRoughness;\n#prism_sample_texture<surface_roughness, surfaceRoughness, true, false>\n    float surfaceAnisotropy;\n#prism_sample_texture<surface_anisotropy, surfaceAnisotropy, true, false>\n    float surfaceRotation;\n#prism_sample_texture<surface_rotation, surfaceRotation, true, false>\n#if defined(PRISMOPAQUE)\n    float opaqueF0;\n#prism_sample_texture<opaque_f0, opaqueF0, true, false>\n    vec3 opaqueAlbedo;\n#prism_sample_texture<opaque_albedo, opaqueAlbedo, false, true>\n#elif defined(PRISMMETAL)\n    vec3 metalF0;\n#prism_sample_texture<metal_f0, metalF0, false, true>\n#elif defined(PRISMLAYERED)\n    float layeredF0;\n#prism_sample_texture<layered_f0, layeredF0, true, false>\n    vec3 layeredDiffuse;\n#prism_sample_texture<layered_diffuse, layeredDiffuse, false, true>\n    float layeredRoughness;\n#prism_sample_texture<layered_roughness, layeredRoughness, true, false>\n    float layeredAnisotropy;\n#prism_sample_texture<layered_anisotropy, layeredAnisotropy, true, false>\n    float layeredRotation;\n#prism_sample_texture<layered_rotation, layeredRotation, true, false>\n    vec3 bottom_f0;\n#prism_sample_texture<layered_bottom_f0, bottom_f0, false, true>\n    float layeredFraction;\n#prism_sample_texture<layered_fraction, layeredFraction, true, false>\n#elif defined( PRISMGLAZING )\n    vec3 glazingTransmissionColor;\n#prism_sample_texture<glazing_transmission_color, glazingTransmissionColor, false, true>\n    vec3 glazingF0;\n#prism_sample_texture<glazing_f0, glazingF0, false, true>\n    float glazingTransmissionRoughness;\n#prism_sample_texture<glazing_transmission_roughness, glazingTransmissionRoughness, true, false>\n    vec3 glazingAdjustedColor = TransmitAdjust(glazingTransmissionColor, glazingF0);\n    float glazingIlluminace = ColorToIlluminance(glazingAdjustedColor);\n    float transmissionAlpha = RoughnessToAlpha(glazingTransmissionRoughness, 0.0).x;\n    vec3 transmissionF = Fresnel_Rough(glazingF0, NdotV, transmissionAlpha);\n#elif defined(PRISMWOOD)\n    vec3 woodDiffuse = NoiseWood(p, surfaceRoughness);\n#endif\n    vec3 outRadianceLight = vec3(0.0);\n#if MAX_DIR_LIGHTS > 0 || MAX_POINT_LIGHTS > 0 || MAX_SPOT_LIGHTS > 0\n    vec3 lightDirection[ MAX_DIR_LIGHTS + MAX_POINT_LIGHTS + MAX_SPOT_LIGHTS ];\n    vec3 lightColor[ MAX_DIR_LIGHTS + MAX_POINT_LIGHTS + MAX_SPOT_LIGHTS ];\n#if MAX_DIR_LIGHTS > 0\n    for( int i = 0; i < MAX_DIR_LIGHTS; i ++ ) {\n        vec4 lDirection = viewMatrix * vec4( directionalLightDirection[ i ], 0.0 );\n        lightDirection[i] = normalize( lDirection.xyz );\n        lightColor[i] = SRGBToLinear(directionalLightColor[ i ]);\n    }\n#endif\n#if MAX_POINT_LIGHTS > 0\n    for( int i = 0; i < MAX_POINT_LIGHTS; i ++ ) {\n        vec4 lPosition = viewMatrix * vec4( pointLightPosition[ i ], 1.0 );\n        vec3 lVector = lPosition.xyz + vViewPosition.xyz;\n        lightDirection[MAX_DIR_LIGHTS + i] = normalize( lVector );\n        float lDistance = 1.0;\n        if ( pointLightDistance[ i ] > 0.0 )\n            lDistance = 1.0 - min( ( length( lVector ) / pointLightDistance[ i ] ), 1.0 );\n        lightColor[MAX_DIR_LIGHTS + i] = SRGBToLinear(pointLightColor[ i ]) * lDistance;\n    }\n#endif\n#if MAX_SPOT_LIGHTS > 0\n    for( int i = 0; i < MAX_SPOT_LIGHTS; i ++ ) {\n        vec4 lPosition = viewMatrix * vec4( spotLightPosition[ i ], 1.0 );\n        vec3 lVector = lPosition.xyz + vViewPosition.xyz;\n        lightDirection[MAX_DIR_LIGHTS + MAX_POINT_LIGHTS + i] = normalize( lVector );\n        float lDistance = 1.0;\n        if ( spotLightDistance[ i ] > 0.0 )\n            lDistance = 1.0 - min( ( length( lVector ) / spotLightDistance[ i ] ), 1.0 );\n        float spotEffect = dot( spotLightDirection[ i ], normalize( spotLightPosition[ i ] - vWorldPosition ) );\n        if ( spotEffect > spotLightAngleCos[ i ] )\n            spotEffect = max( pow( spotEffect, spotLightExponent[ i ] ), 0.0 );\n        lightColor[MAX_DIR_LIGHTS + MAX_POINT_LIGHTS + i] = SRGBToLinear(spotLightColor[ i ]) * lDistance * spotEffect;\n    }\n#endif\n    for( int i = 0; i < MAX_DIR_LIGHTS + MAX_POINT_LIGHTS + MAX_SPOT_LIGHTS; i ++ ) {\n        vec3 L = lightDirection[i];\n        float NdotL = max(EPSILON, dot(N, L));\n        vec3 H = normalize(L + V);\n        float NdotH = dot(N, H);\n        float VdotH = dot(V, H);\n        float Hu = dot(H, Tu);\n        float Hv = dot(H, Tv);\n        vec3 Hlocal = vec3(Hu, Hv, NdotH);\n#if defined(PRISMLAYERED)\n        float N2dotL = dot(N2, L);\n        float N2dotH = dot(N2, H);\n        vec3 Hlocal2 = vec3(Hu, Hv, N2dotH);\n#endif\n        vec3 brdf = lightColor[i] *\n#if defined(PRISMOPAQUE)\n            BRDF_Opaque(Hlocal, NdotL, NdotH, NdotV, VdotH,\n                    surfaceAlbedo, surfaceRoughness, surfaceAnisotropy, surfaceRotation,\n                    opaqueF0, opaqueAlbedo);\n#elif defined(PRISMMETAL)\n            BRDF_Metal(Hlocal, NdotL, NdotH, NdotV, VdotH,\n                surfaceAlbedo, surfaceRoughness, surfaceAnisotropy, surfaceRotation,\n                metalF0);\n#elif defined(PRISMLAYERED)\n            BRDF_Layered(Hlocal, NdotL, NdotH, NdotV, VdotH, Hlocal2, N2dotL, N2dotH, N2dotV,\n                surfaceAlbedo, surfaceRoughness, surfaceAnisotropy, surfaceRotation,\n                layeredF0, layeredDiffuse, layeredRoughness, layeredAnisotropy,\n                layeredRotation, bottom_f0, layeredFraction);\n#elif defined(PRISMTRANSPARENT)\n            BRDF_Transparent(Hlocal, NdotL, NdotH, NdotV, VdotH, surfaceAlbedo, surfaceRoughness, surfaceAnisotropy, surfaceRotation);\n#elif defined(PRISMGLAZING)\n            BRDF_Glazing(Hlocal, NdotL, NdotH, NdotV, VdotH, surfaceAlbedo, surfaceRoughness, surfaceAnisotropy, surfaceRotation,\n                         glazingF0, glazingTransmissionColor, glazingIlluminace);\n#elif defined(PRISMWOOD)\n            BRDF_Wood(Hlocal, NdotL, NdotH, NdotV, VdotH, surfaceAlbedo, surfaceRoughness, woodDiffuse);\n#endif\n        outRadianceLight += max(vec3(0.0), brdf);\n    }\n#endif\n    vec3 outRadianceEnv = vec3(0.0);\n#if defined( USE_ENVMAP )\n    outRadianceEnv =\n#if defined(PRISMOPAQUE)\n        Environment_Opaque(N, V, clamp(NdotV, 0.0, 1.0), surfaceAlbedo, surfaceRoughness,\n                opaqueF0, opaqueAlbedo, surfaceAnisotropy, surfaceRotation, Tu, Tv);\n#elif defined(PRISMMETAL)\n        Environment_Metal(N, V, clamp(NdotV, 0.0, 1.0), surfaceAlbedo, surfaceRoughness, metalF0, surfaceAnisotropy, surfaceRotation, Tu, Tv);\n#elif defined(PRISMLAYERED)\n        Environment_Layered(N, V, clamp(NdotV, 0.0, 1.0), N2, clamp(N2dotV, 0.0, 1.0), surfaceAlbedo, surfaceRoughness,\n            layeredF0, surfaceAnisotropy, surfaceRotation, Tu, Tv, layeredDiffuse, layeredRoughness, layeredAnisotropy,\n            layeredRotation, bottom_f0, layeredFraction);\n#elif defined(PRISMTRANSPARENT)\n        Environment_Transparent(N, V, clamp(NdotV, 0.0, 1.0), surfaceAlbedo, surfaceRoughness, surfaceAnisotropy, surfaceRotation, Tu, Tv);\n#elif defined(PRISMGLAZING)\n        Environment_Glazing(N, V, clamp(NdotV, 0.0, 1.0), surfaceAlbedo, surfaceRoughness, surfaceAnisotropy, surfaceRotation, Tu, Tv,\n            glazingF0, transmissionF, transmissionAlpha, glazingAdjustedColor, glazingIlluminace);\n#elif defined(PRISMWOOD)\n        Environment_Wood(N, V, clamp(NdotV, 0.0, 1.0), surfaceAlbedo, surfaceRoughness, woodDiffuse, surfaceAnisotropy, surfaceRotation, Tu, Tv);\n#endif\n#endif\n    float surface_cutout = 1.0;\n#prism_sample_texture<surface_cutout, surface_cutout, true, false>\n#if defined( USE_SURFACE_CUTOUT_MAP )\n    if(surface_cutout < 0.01) discard;\n#endif\n    gl_FragColor = vec4( outRadianceLight + outRadianceEnv, opacity*surface_cutout );\n#if TONEMAP_OUTPUT == 1\n    gl_FragColor.xyz = toneMapCanonOGS_WithGamma_WithColorPerserving(exposureBias * gl_FragColor.xyz);\n#elif TONEMAP_OUTPUT == 2\n    gl_FragColor.xyz = toneMapCanonFilmic_WithGamma(exposureBias * gl_FragColor.xyz);\n#endif\n#ifdef USE_FOG\n    float depth = gl_FragCoord.z / gl_FragCoord.w;\n    float fogFactor = smoothstep( fogNear, fogFar, depth );\n    gl_FragColor = mix( gl_FragColor, vec4( fogColor, gl_FragColor.w ), fogFactor );\n#endif\n#if defined(PRISMTRANSPARENT)\n    applyPrismTransparency(gl_FragColor, transparent_color, transparent_ior);\n    gl_FragColor.a *= surface_cutout;\n#ifdef USE_TILING\n    gl_FragColor.a *= v_TilingMap.a;\n#endif\n#elif defined( PRISMGLAZING )\n    applyPrismGlazingOpacity(gl_FragColor, transmissionF, transmissionAlpha, NdotV, glazingIlluminace);\n#ifdef USE_TILING\n    gl_FragColor.a *= v_TilingMap.a;\n#endif\n#endif\n#include<theming_frag>\n#include<final_frag>\n}\n";

// This method sets up various uniforms for a given map, putting them
// in an array called "uniforms" which are accessed by the name, such
// as "uniforms[surface_albedo_map_texMatrix]".
function GetPrismMapUniforms(mapName) {
    var mtxName = mapName + "_texMatrix";
    var mapInvt = mapName + "_invert";
    var uniforms = {};
    uniforms[mapName] = { type: "t", value: null };
    uniforms[mtxName] = { type: "m3", value: new THREE$1.Matrix3() };
    uniforms[mapInvt] = { type: "i", value: 0 };
    return uniforms;
}
function GetPrismBumpMapUniforms(mapName) {
    var mtxName = mapName + "_texMatrix";
    var mapScale = mapName + "_bumpScale";
    var mapType = mapName + "_bumpmapType";
    var uniforms = {};
    uniforms[mapName] = { type: "t", value: null };
    uniforms[mtxName] = { type: "m3", value: new THREE$1.Matrix3() };
    uniforms[mapScale] = { type: "v2", value: new THREE$1.Vector2(1, 1) };
    uniforms[mapType] = { type: "i", value: 0 };
    return uniforms;
}
var PrismShader = {
    uniforms: THREE$1.UniformsUtils.merge([THREE$1.UniformsLib["common"], THREE$1.UniformsLib["lights"], THREE$1.UniformsLib["fog"], ShaderChunks.CutPlanesUniforms, ShaderChunks.IdUniforms, ShaderChunks.ThemingUniform, ShaderChunks.ShadowMapUniforms, GetPrismMapUniforms("surface_albedo_map"), GetPrismMapUniforms("surface_roughness_map"), GetPrismMapUniforms("surface_cutout_map"), GetPrismMapUniforms("surface_anisotropy_map"), GetPrismMapUniforms("surface_rotation_map"), GetPrismMapUniforms("opaque_albedo_map"), GetPrismMapUniforms("opaque_f0_map"), GetPrismMapUniforms("opaque_luminance_modifier_map"), GetPrismMapUniforms("layered_bottom_f0_map"), GetPrismMapUniforms("layered_f0_map"), GetPrismMapUniforms("layered_diffuse_map"), GetPrismMapUniforms("layered_fraction_map"), GetPrismMapUniforms("layered_roughness_map"), GetPrismMapUniforms("layered_anisotropy_map"), GetPrismMapUniforms("layered_rotation_map"), GetPrismMapUniforms("metal_f0_map"), GetPrismMapUniforms("wood_curly_distortion_map"), GetPrismMapUniforms("glazing_f0_map"), GetPrismMapUniforms("glazing_transmission_color_map"), GetPrismMapUniforms("glazing_transmission_roughness_map"), GetPrismBumpMapUniforms("surface_normal_map"), GetPrismBumpMapUniforms("layered_normal_map"), GetPrismMapUniforms("TilingMap"), GetPrismMapUniforms("TilingNormalMap"), GetPrismMapUniforms("TilingRandomMap"), {
        //Surface
        "surface_albedo": { type: "c", value: new THREE$1.Color(0x111111) },
        "surface_roughness": { type: "f", value: 1.0 },
        "surface_anisotropy": { type: "f", value: 1.0 },
        "surface_rotation": { type: "f", value: 1.0 },
        //Opaque
        "opaque_albedo": { type: "c", value: new THREE$1.Color(0x111111) },
        "opaque_f0": { type: "f", value: 1.0 },
        "opaque_luminance_modifier": { type: "c", value: new THREE$1.Color(0x111111) },
        "opaque_luminance": { type: "f", value: 1.0 },
        //Metal
        "metal_f0": { type: "c", value: new THREE$1.Color(0x111111) },
        //Layered
        "layered_f0": { type: "f", value: 1.0 },
        "layered_diffuse": { type: "c", value: new THREE$1.Color(0x000000) },
        "layered_fraction": { type: "f", value: 1.0 },
        "layered_bottom_f0": { type: "c", value: new THREE$1.Color(0x111111) },
        "layered_roughness": { type: "f", value: 1.0 },
        "layered_anisotropy": { type: "f", value: 1.0 },
        "layered_rotation": { type: "f", value: 1.0 },
        //Transparent
        "transparent_ior": { type: "f", value: 2.0 },
        "transparent_color": { type: "c", value: new THREE$1.Color(0x111111) },
        "transparent_distance": { type: "f", value: 1.0 },
        //Glazing
        "glazing_f0": { type: "c", value: new THREE$1.Color(0xffffff) },
        "glazing_transmission_roughness": { type: "f", value: 0.0 },
        "glazing_transmission_color": { type: "c", value: new THREE$1.Color(0xffffff) },
        //Wood
        "wood_fiber_cosine_enable": { type: "i", value: 1 },
        "wood_fiber_cosine_bands": { type: "i", value: 2 },
        "wood_fiber_cosine_weights": { type: "v4", value: new THREE$1.Vector4(2.5, 0.5, 1, 1) },
        "wood_fiber_cosine_frequencies": { type: "v4", value: new THREE$1.Vector4(15, 4, 1, 1) },
        "wood_fiber_perlin_enable": { type: "i", value: 1 },
        "wood_fiber_perlin_bands": { type: "i", value: 3 },
        "wood_fiber_perlin_weights": { type: "v4", value: new THREE$1.Vector4(3.0, 1.0, 0.2, 1) },
        "wood_fiber_perlin_frequencies": { type: "v4", value: new THREE$1.Vector4(40, 20, 3.5, 1) },
        "wood_fiber_perlin_scale_z": { type: "f", value: 0.3 },
        "wood_growth_perlin_enable": { type: "i", value: 1 },
        "wood_growth_perlin_bands": { type: "i", value: 3 },
        "wood_growth_perlin_weights": { type: "v4", value: new THREE$1.Vector4(1.0, 2, 1, 1) },
        "wood_growth_perlin_frequencies": { type: "v4", value: new THREE$1.Vector4(1, 5, 13, 1) },
        "wood_latewood_ratio": { type: "f", value: 0.238 },
        "wood_earlywood_sharpness": { type: "f", value: 0.395 },
        "wood_latewood_sharpness": { type: "f", value: 0.109 },
        "wood_ring_thickness": { type: "f", value: 0.75 },
        "wood_earlycolor_perlin_enable": { type: "i", value: 1 },
        "wood_earlycolor_perlin_bands": { type: "i", value: 2 },
        "wood_earlycolor_perlin_weights": { type: "v4", value: new THREE$1.Vector4(0.3, 0.5, 0.15, 1) },
        "wood_earlycolor_perlin_frequencies": { type: "v4", value: new THREE$1.Vector4(8, 3, 0.35, 1) },
        "wood_early_color": { type: "c", value: new THREE$1.Color(0.286, 0.157, 0.076) },
        "wood_use_manual_late_color": { type: "i", value: 0 },
        "wood_manual_late_color": { type: "c", value: new THREE$1.Color(0.62, 0.35, 0.127) },
        "wood_latecolor_perlin_enable": { type: "i", value: 1 },
        "wood_latecolor_perlin_bands": { type: "i", value: 1 },
        "wood_latecolor_perlin_weights": { type: "v4", value: new THREE$1.Vector4(0.75, 0.55, 1, 1) },
        "wood_latecolor_perlin_frequencies": { type: "v4", value: new THREE$1.Vector4(4.5, 0.05, 1, 1) },
        "wood_late_color_power": { type: "f", value: 1.25 },
        "wood_diffuse_perlin_enable": { type: "i", value: 1 },
        "wood_diffuse_perlin_bands": { type: "i", value: 3 },
        "wood_diffuse_perlin_weights": { type: "v4", value: new THREE$1.Vector4(0.15, 0.2, 0.05, 1) },
        "wood_diffuse_perlin_frequencies": { type: "v4", value: new THREE$1.Vector4(0.05, 0.1, 3, 1) },
        "wood_diffuse_perlin_scale_z": { type: "f", value: 0.2 },
        "wood_use_pores": { type: "i", value: 1 },
        "wood_pore_type": { type: "i", value: 0 },
        "wood_pore_radius": { type: "f", value: 0.04 },
        "wood_pore_cell_dim": { type: "f", value: 0.15 },
        "wood_pore_color_power": { type: "f", value: 1.45 },
        "wood_pore_depth": { type: "f", value: 0.02 },
        "wood_use_rays": { type: "i", value: 1 },
        "wood_ray_color_power": { type: "f", value: 1.1 },
        "wood_ray_seg_length_z": { type: "f", value: 5.0 },
        "wood_ray_num_slices": { type: "f", value: 160 },
        "wood_ray_ellipse_z2x": { type: "f", value: 10 },
        "wood_ray_ellipse_radius_x": { type: "f", value: 0.2 },
        "wood_use_latewood_bump": { type: "i", value: 1 },
        "wood_latewood_bump_depth": { type: "f", value: 0.01 },
        "wood_use_groove_roughness": { type: "i", value: 1 },
        "wood_groove_roughness": { type: "f", value: 0.85 },
        "wood_diffuse_lobe_weight": { type: "f", value: 0.9 },
        "wood_curly_distortion_enable": { type: "i", value: 0 },
        "wood_curly_distortion_scale": { type: "f", value: 0.25 },
        "wood_ring_fraction": { type: "v4", value: new THREE$1.Vector4(0.0, 0.0, 0.0, 0.0) },
        "wood_fall_rise": { type: "v2", value: new THREE$1.Vector2(0.0, 0.0) },
        "permutationMap": { type: "t", value: null },
        "gradientMap": { type: "t", value: null },
        "perm2DMap": { type: "t", value: null },
        "permGradMap": { type: "t", value: null },
        "importantSamplingRandomMap": { type: "t", value: null },
        "importantSamplingSolidAngleMap": { type: "t", value: null },
        "irradianceMap": { type: "t", value: null },
        "envMap": { type: "t", value: null },
        "exposureBias": { type: "f", value: 1.0 },
        "envMapExposure": { type: "f", value: 1.0 },
        "envRotationSin": { type: "f", value: 0.0 },
        "envRotationCos": { type: "f", value: 1.0 },
        "envExponentMin": { type: "f", value: 1.0 },
        "envExponentMax": { type: "f", value: 512.0 },
        "envExponentCount": { type: "f", value: 10.0 },
        // tiling
        "tilingOverallTransform": { type: "m4", value: new THREE$1.Matrix4() },
        // done above:
        //"TilingMap" : { type : "t", value: null },
        //"TilingMap_texMatrix" : { type: "m3", value: new THREE.Matrix3() },    // NOTE this is 3x3, OGS has it 4x4
        //"TilingNormalMap" : { type : "t", value: null },
        //"TilingNormalMap_texMatrix" : { type: "m3", value: new THREE.Matrix3() },    // NOTE this is 3x3, OGS has it 4x4
        //"TilingRandomMap" : { type : "t", value: null },
        //"TilingRandomMap_texMatrix" : { type: "m3", value: new THREE.Matrix3() },    // NOTE this is 3x3, OGS has it 4x4
        "uv2tile": { type: "v4", value: new THREE$1.Vector4(1.0, 0.0, 0.0, 1.0) },
        "tile2uv": { type: "v4", value: new THREE$1.Vector4(1.0, 0.0, 0.0, 1.0) },
        "tileAlignOffset": { type: "v2", value: new THREE$1.Vector2(0.0, 0.0) },
        "tilingUVTransform": { type: "m4", value: new THREE$1.Matrix4() },
        "tilingRandomAxisS": { type: "v2", value: new THREE$1.Vector2(0.0, 0.0) },
        "tilingRandomAxisT": { type: "v2", value: new THREE$1.Vector2(0.0, 0.0) },
        "tilingRandomAlignmentOffset": { type: "v2", value: new THREE$1.Vector2(0.0, 0.0) }
    }]),
    vertexShader: prism_vert,
    fragmentShader: prism_frag
};
THREE$1.ShaderLib['prism'] = PrismShader;
var createPrismMaterial = function createPrismMaterial() {
    var prismMat = ShaderUtils.createShaderMaterial(PrismShader);
    prismMat.defaultAttributeValues['uvw'] = [0, 0, 0];
    prismMat.enable3DWoodBump = false;
    prismMat.enableImportantSampling = false;
    prismMat.mapList = {};
    prismMat.isPrismMaterial = true;
    return prismMat;
};
var clonePrismMaterial$1 = function clonePrismMaterial(mat) {
    var prismMat = createPrismMaterial();
    // this is a dumb way to do what THREE.Material.prototype.clone.call( this, prismMat );
    // would do to create a clone and copy the basic properties. What's the non-stupid way?
    // And why does this material not have its own prototype.clone method?
    prismMat.name = mat.name;
    prismMat.side = mat.side;
    prismMat.opacity = mat.opacity;
    prismMat.transparent = mat.transparent;
    prismMat.blending = mat.blending;
    prismMat.blendSrc = mat.blendSrc;
    prismMat.blendDst = mat.blendDst;
    prismMat.blendEquation = mat.blendEquation;
    prismMat.blendSrcAlpha = mat.blendSrcAlpha;
    prismMat.blendDstAlpha = mat.blendDstAlpha;
    prismMat.blendEquationAlpha = mat.blendEquationAlpha;
    prismMat.depthTest = mat.depthTest;
    prismMat.depthWrite = mat.depthWrite;
    prismMat.polygonOffset = mat.polygonOffset;
    prismMat.polygonOffsetFactor = mat.polygonOffsetFactor;
    prismMat.polygonOffsetUnits = mat.polygonOffsetUnits;
    prismMat.alphaTest = mat.alphaTest;
    prismMat.overdraw = mat.overdraw;
    prismMat.visible = mat.visible;
    // end of the basics shared by all shaders
    prismMat.mapList = mat.mapList;
    prismMat.prismType = mat.prismType;
    //Prism common properties.
    prismMat.surface_albedo = mat.surface_albedo;
    if (mat.surface_albedo_map !== undefined) prismMat.surface_albedo_map = mat.surface_albedo_map;
    prismMat.surface_roughness = mat.surface_roughness;
    if (mat.surface_roughness_map !== undefined) prismMat.surface_roughness_map = mat.surface_roughness_map;
    prismMat.surface_anisotropy = mat.surface_anisotropy;
    if (mat.surface_anisotropy_map !== undefined) prismMat.surface_anisotropy_map = mat.surface_anisotropy_map;
    prismMat.surface_rotation = mat.surface_rotation;
    if (mat.surface_rotation_map !== undefined) prismMat.surface_rotation_map = mat.surface_rotation_map;
    if (mat.surface_cutout_map !== undefined) prismMat.surface_cutout_map = mat.surface_cutout_map;
    if (mat.surface_normal_map !== undefined) prismMat.surface_normal_map = mat.surface_normal_map;
    prismMat.uniforms.importantSamplingRandomMap.value = mat.uniforms.importantSamplingRandomMap.value;
    prismMat.uniforms.importantSamplingSolidAngleMap.value = mat.uniforms.importantSamplingSolidAngleMap.value;
    //Set Prism properties according to the material type.
    switch (prismMat.prismType) {
        case 'PrismOpaque':
            prismMat.opaque_albedo = new THREE$1.Color().copy(mat.opaque_albedo);
            prismMat.opaque_luminance_modifier = new THREE$1.Color().copy(mat.opaque_luminance_modifier);
            prismMat.opaque_f0 = mat.opaque_f0;
            prismMat.opaque_luminance = mat.opaque_luminance;
            if (mat.opaque_albedo_map !== undefined) prismMat.opaque_albedo_map = mat.opaque_albedo_map;
            if (mat.opaque_luminance_modifier_map !== undefined) prismMat.opaque_luminance_modifier_map = mat.opaque_luminance_modifier_map;
            if (mat.opaque_f0_map !== undefined) prismMat.opaque_f0_map = mat.opaque_f0_map;
            break;
        case 'PrismMetal':
            prismMat.metal_f0 = new THREE$1.Color().copy(mat.metal_f0);
            if (mat.metal_f0_map !== undefined) prismMat.metal_f0_map = mat.metal_f0_map;
            break;
        case 'PrismLayered':
            prismMat.layered_f0 = mat.layered_f0;
            prismMat.layered_diffuse = new THREE$1.Color().copy(mat.layered_diffuse);
            prismMat.layered_fraction = mat.layered_fraction;
            prismMat.layered_bottom_f0 = new THREE$1.Color().copy(mat.layered_bottom_f0);
            prismMat.layered_roughness = mat.layered_roughness;
            prismMat.layered_anisotropy = mat.layered_anisotropy;
            prismMat.layered_rotation = mat.layered_rotation;
            if (mat.layered_bottom_f0_map !== undefined) prismMat.layered_bottom_f0_map = mat.layered_bottom_f0_map;
            if (mat.layered_f0_map !== undefined) prismMat.layered_f0_map = mat.layered_f0_map;
            if (mat.layered_diffuse_map !== undefined) prismMat.layered_diffuse_map = mat.layered_diffuse_map;
            if (mat.layered_fraction_map !== undefined) prismMat.layered_fraction_map = mat.layered_fraction_map;
            if (mat.layered_rotationlayered_roughness_map !== undefined) prismMat.layered_rotationlayered_roughness_map = mat.layered_rotationlayered_roughness_map;
            if (mat.layered_anisotropy_map !== undefined) prismMat.layered_anisotropy_map = mat.layered_anisotropy_map;
            if (mat.layered_rotation_map !== undefined) prismMat.layered_rotation_map = mat.layered_rotation_map;
            if (mat.layered_normal_map !== undefined) prismMat.layered_normal_map = mat.layered_normal_map;
            break;
        case 'PrismTransparent':
            prismMat.transparent_color = new THREE$1.Color().copy(mat.transparent_color);
            prismMat.transparent_distance = mat.transparent_distance;
            prismMat.transparent_ior = mat.transparent_ior;
            prismMat.transparent = mat.transparent;
            prismMat.twoPassTransparency = mat.twoPassTransparency;
            break;
        case 'PrismGlazing':
            prismMat.glazing_f0 = new THREE$1.Color().copy(mat.glazing_f0);
            prismMat.glazing_transmission_color = new THREE$1.Color().copy(mat.glazing_transmission_color);
            prismMat.glazing_transmission_roughness = mat.glazing_transmission_roughness;
            if (mat.glazing_f0_map !== undefined) prismMat.glazing_f0_map = mat.glazing_f0_map;
            if (mat.glazing_transmission_color_map !== undefined) prismMat.glazing_transmission_color_map = mat.glazing_transmission_color_map;
            if (mat.glazing_transmission_roughness_map !== undefined) prismMat.glazing_transmission_roughness_map = mat.glazing_transmission_roughness_map;
            break;
        case 'PrismWood':
            prismMat.wood_fiber_cosine_enable = mat.wood_fiber_cosine_enable;
            prismMat.wood_fiber_cosine_bands = mat.wood_fiber_cosine_bands;
            prismMat.wood_fiber_cosine_weights = new THREE$1.Vector4().copy(mat.wood_fiber_cosine_weights);
            prismMat.wood_fiber_cosine_frequencies = new THREE$1.Vector4().copy(mat.wood_fiber_cosine_frequencies);
            prismMat.wood_fiber_perlin_enable = mat.wood_fiber_perlin_enable;
            prismMat.wood_fiber_perlin_bands = mat.wood_fiber_perlin_bands;
            prismMat.wood_fiber_perlin_weights = new THREE$1.Vector4().copy(mat.wood_fiber_perlin_weights);
            prismMat.wood_fiber_perlin_frequencies = new THREE$1.Vector4().copy(mat.wood_fiber_perlin_frequencies);
            prismMat.wood_fiber_perlin_scale_z = mat.wood_fiber_perlin_scale_z;
            prismMat.wood_growth_perlin_enable = mat.wood_growth_perlin_enable;
            prismMat.wood_growth_perlin_bands = mat.wood_growth_perlin_bands;
            prismMat.wood_growth_perlin_weights = new THREE$1.Vector4().copy(mat.wood_growth_perlin_weights);
            prismMat.wood_growth_perlin_frequencies = new THREE$1.Vector4().copy(mat.wood_growth_perlin_frequencies);
            prismMat.wood_latewood_ratio = mat.wood_latewood_ratio;
            prismMat.wood_earlywood_sharpness = mat.wood_earlywood_sharpness;
            prismMat.wood_latewood_sharpness = mat.wood_latewood_sharpness;
            prismMat.wood_ring_thickness = mat.wood_ring_thickness;
            prismMat.wood_earlycolor_perlin_enable = mat.wood_earlycolor_perlin_enable;
            prismMat.wood_earlycolor_perlin_bands = mat.wood_earlycolor_perlin_bands;
            prismMat.wood_earlycolor_perlin_weights = new THREE$1.Vector4().copy(mat.wood_earlycolor_perlin_weights);
            prismMat.wood_earlycolor_perlin_frequencies = new THREE$1.Vector4().copy(mat.wood_earlycolor_perlin_frequencies);
            prismMat.wood_early_color = new THREE$1.Color().copy(mat.wood_early_color);
            prismMat.wood_use_manual_late_color = mat.wood_use_manual_late_color;
            prismMat.wood_manual_late_color = new THREE$1.Color().copy(mat.wood_manual_late_color);
            prismMat.wood_latecolor_perlin_enable = mat.wood_latecolor_perlin_enable;
            prismMat.wood_latecolor_perlin_bands = mat.wood_latecolor_perlin_bands;
            prismMat.wood_latecolor_perlin_weights = new THREE$1.Vector4().copy(mat.wood_latecolor_perlin_weights);
            prismMat.wood_latecolor_perlin_frequencies = new THREE$1.Vector4().copy(mat.wood_latecolor_perlin_frequencies);
            prismMat.wood_late_color_power = mat.wood_late_color_power;
            prismMat.wood_diffuse_perlin_enable = mat.wood_diffuse_perlin_enable;
            prismMat.wood_diffuse_perlin_bands = mat.wood_diffuse_perlin_bands;
            prismMat.wood_diffuse_perlin_weights = new THREE$1.Vector4().copy(mat.wood_diffuse_perlin_weights);
            prismMat.wood_diffuse_perlin_frequencies = new THREE$1.Vector4().copy(mat.wood_diffuse_perlin_frequencies);
            prismMat.wood_diffuse_perlin_scale_z = mat.wood_diffuse_perlin_scale_z;
            prismMat.wood_use_pores = mat.wood_use_pores;
            prismMat.wood_pore_type = mat.wood_pore_type;
            prismMat.wood_pore_radius = mat.wood_pore_radius;
            prismMat.wood_pore_cell_dim = mat.wood_pore_cell_dim;
            prismMat.wood_pore_color_power = mat.wood_pore_color_power;
            prismMat.wood_pore_depth = mat.wood_pore_depth;
            prismMat.wood_use_rays = mat.wood_use_rays;
            prismMat.wood_ray_color_power = mat.wood_ray_color_power;
            prismMat.wood_ray_seg_length_z = mat.wood_ray_seg_length_z;
            prismMat.wood_ray_num_slices = mat.wood_ray_num_slices;
            prismMat.wood_ray_ellipse_z2x = mat.wood_ray_ellipse_z2x;
            prismMat.wood_ray_ellipse_radius_x = mat.wood_ray_ellipse_radius_x;
            prismMat.wood_use_latewood_bump = mat.wood_use_latewood_bump;
            prismMat.wood_latewood_bump_depth = mat.wood_latewood_bump_depth;
            prismMat.wood_use_groove_roughness = mat.wood_use_groove_roughness;
            prismMat.wood_groove_roughness = mat.wood_groove_roughness;
            prismMat.wood_diffuse_lobe_weight = mat.wood_diffuse_lobe_weight;
            // share common prism DataTextures
            // Note that these are directly stored in the uniforms (see MaterialConverter.convertMaterial)
            prismMat.uniforms.permutationMap.value = mat.uniforms.permutationMap.value;
            prismMat.uniforms.gradientMap.value = mat.uniforms.gradientMap.value;
            prismMat.uniforms.perm2DMap.value = mat.uniforms.perm2DMap.value;
            prismMat.uniforms.permGradMap.value = mat.uniforms.permGradMap.value;
            if (mat.wood_curly_distortion_map !== undefined) {
                prismMat.wood_curly_distortion_map = mat.wood_curly_distortion_map;
                prismMat.wood_curly_distortion_enable = mat.wood_curly_distortion_enable;
                prismMat.wood_curly_distortion_scale = mat.wood_curly_distortion_scale;
            }
            prismMat.wood_ring_fraction = mat.wood_ring_fraction;
            prismMat.wood_fall_rise = mat.wood_fall_rise;
            break;
        default:
            THREE$1.warn('Unknown prism type: ' + mat.prismType);
    }
    prismMat.envExponentMin = mat.envExponentMin;
    prismMat.envExponentMax = mat.envExponentMax;
    prismMat.envExponentCount = mat.envExponentCount;
    prismMat.envMap = mat.envMap;
    if (mat.useTiling) {
        prismMat.useTiling = mat.useTiling;
        prismMat.tilingOverallTransform = new THREE$1.Matrix4().copy(mat.tilingOverallTransform);
        prismMat.TilingMap = mat.TilingMap;
        prismMat.TilingMap_texMatrix = new THREE$1.Matrix3().copy(mat.TilingMap_texMatrix);
        prismMat.hasRoundCorner = mat.hasRoundCorner;
        if (prismMat.hasRoundCorner) {
            prismMat.TilingNormalMap = mat.TilingNormalMap;
            prismMat.TilingNormalMap_texMatrix = new THREE$1.Matrix3().copy(mat.TilingNormalMap_texMatrix);
        }
        prismMat.useRandomOffset = mat.useRandomOffset;
        if (prismMat.useRandomOffset) {
            prismMat.TilingRandomMap = mat.TilingRandomMap;
            prismMat.TilingRandomMap_texMatrix = new THREE$1.Matrix3().copy(mat.TilingRandomMap_texMatrix);
            prismMat.tilingRandomAxisS = new THREE$1.Vector2().copy(mat.tilingRandomAxisS);
            prismMat.tilingRandomAxisT = new THREE$1.Vector2().copy(mat.tilingRandomAxisT);
            prismMat.tilingRandomAlignmentOffset = new THREE$1.Vector2().copy(mat.tilingRandomAlignmentOffset);
        }
        prismMat.uv2tile = mat.uv2tile;
        prismMat.tile2uv = mat.tile2uv;
        prismMat.tilingRepeatRange = [mat.tilingRepeatRange[0], mat.tilingRepeatRange[1], mat.tilingRepeatRange[2], mat.tilingRepeatRange[3]];
        prismMat.tileAlignOffset = new THREE$1.Vector2().copy(mat.tileAlignOffset);
        prismMat.tilingUVTransform = new THREE$1.Matrix4().copy(mat.tilingUVTransform);
    }
    prismMat.defines = mat.defines;
    return prismMat;
};
var PrismShaderUtils = {
    PrismShader: PrismShader,
    GetPrismMapUniforms: GetPrismMapUniforms,
    createPrismMaterial: createPrismMaterial,
    clonePrismMaterial: clonePrismMaterial$1
};

/**
 * Logging levels. Higher number means more verbose logs,
 * for example, with level 3, `info`, `warn`, or `error`
 * logs will show up in the console but `debug` and `log` won't.
 *
 * Semantics of specific levels:
 *  - debug: low-level debugging logs
 *  - log: common, higher-level debugging logs
 *  - info: helpful runtime information (even for stag/prod environments)
 *  - warn: potentially problematic situations; handled exceptions
 *  - error: definitely problematic situations; unhandled exceptions
 * @readonly
 * @enum {number}
 */
/**
 * Logging levels. Higher number means more verbose logs,
 * for example, with level 3, `info`, `warn`, or `error`
 * logs will show up in the console but `debug` and `log` won't.
 *
 * Semantics of specific levels:
 *  - debug: low-level debugging logs
 *  - log: common, higher-level debugging logs
 *  - info: helpful runtime information (even for stag/prod environments)
 *  - warn: potentially problematic situations; handled exceptions
 *  - error: definitely problematic situations; unhandled exceptions
 * @readonly
 * @enum {number}
 */
(function (LogLevels) {
    LogLevels[LogLevels["DEBUG"] = 5] = "DEBUG";
    LogLevels[LogLevels["LOG"] = 4] = "LOG";
    LogLevels[LogLevels["INFO"] = 3] = "INFO";
    LogLevels[LogLevels["WARNING"] = 2] = "WARNING";
    LogLevels[LogLevels["ERROR"] = 1] = "ERROR";
    LogLevels[LogLevels["NONE"] = 0] = "NONE";
})(exports.LogLevels || (exports.LogLevels = {}));

// Default logger is the console.
exports.logger = {
    initialize: function initialize(options) {},
    shutdown: function shutdown() {},
    track: function track(entry) {},
    logToADP: function logToADP(entry) {
        return false;
    },
    updateRuntimeStats: function updateRuntimeStats(entry) {},
    reportRuntimeStats: function reportRuntimeStats() {},
    setLevel: function setLevel(level) {},
    error: function error$$1() {},
    warn: function warn$$1() {},
    info: function info() {},
    log: function log$$1() {},
    debug: function debug() {}
};
function setLogger(l) {
    exports.logger = l;
}

// Helper class to generate MSDF, copied from https://github.com/Chlumsky/msdfgen
// AUTHOR: Virgil Dong, Eric Haines
//**************************************************************************/
var SIGNED_DISTANCE_INF = -1e240;
function SignedDistance() {
    this.distance = SIGNED_DISTANCE_INF;
    this.dot = 1;
}
Object.assign(SignedDistance.prototype, {
    set: function set(distance, dot) {
        this.distance = distance;
        this.dot = dot;
        return this;
    },
    copy: function copy(sd) {
        this.distance = sd.distance;
        this.dot = sd.dot;
    },
    lessThan: function lessThan(sd) {
        return Math.abs(this.distance) < Math.abs(sd.distance) || Math.abs(this.distance) === Math.abs(sd.distance) && this.dot < sd.dot;
    },
    greaterThan: function greaterThan(sd) {
        return Math.abs(this.distance) > Math.abs(sd.distance) || Math.abs(this.distance) === Math.abs(sd.distance) && this.dot > sd.dot;
    },
    lessThanOrEquals: function lessThanOrEquals(sd) {
        return Math.abs(this.distance) < Math.abs(sd.distance) || Math.abs(this.distance) == Math.abs(sd.distance) && this.dot <= sd.dot;
    },
    greaterThanOrEquals: function greaterThanOrEquals(sd) {
        return Math.abs(this.distance) > Math.abs(sd.distance) || Math.abs(this.distance) == Math.abs(sd.distance) && this.dot >= sd.dot;
    }
});
function cross2d(a, b) {
    return a.x * b.y - a.y * b.x;
}
function getOrthonormal(p, polarity, allowZero) {
    polarity = polarity; // true if not specified
    allowZero = allowZero; // false if not specified
    var len = p.length();
    if (len === 0) return polarity ? new THREE$1.Vector2(0.0, allowZero ? 0.0 : 1.0) : new THREE$1.Vector2(0.0, -(allowZero ? 0.0 : 1.0));
    return polarity ? new THREE$1.Vector2(-p.y / len, p.x / len) : new THREE$1.Vector2(p.y / len, -p.x / len);
}
var MSDF_EDGE_COLOR_BLACK = 0;
var MSDF_EDGE_COLOR_RED = 1;
var MSDF_EDGE_COLOR_GREEN = 2;
var MSDF_EDGE_COLOR_YELLOW = 3;
var MSDF_EDGE_COLOR_BLUE = 4;
var MSDF_EDGE_COLOR_MAGENTA = 5;
var MSDF_EDGE_COLOR_CYAN = 6;
var MSDF_EDGE_COLOR_WHITE = 7;
function MSDFLinearSegment(pt1, pt2, color) {
    this.p = [];
    this.p[0] = pt1.clone();
    this.p[1] = pt2.clone();
    this.color = color;
}
Object.assign(MSDFLinearSegment.prototype, {
    set: function set(color) {
        this.color = color;
        return this;
    },
    clone: function clone() {
        return new this.constructor(this.p[0], this.p[1], this.color);
    },
    /// Returns the point on the edge specified by the parameter (between 0 and 1).
    point: function point(param) {
        return this.p[0].clone().lerp(this.p[1], param);
    },
    /// Returns the direction the edge.
    direction: function direction() {
        return this.p[1].clone().sub(this.p[0]);
    },
    /// Returns the minimum signed distance between origin and the edge.
    signedDistance: function signedDistance(origin) {
        var aq = origin.clone().sub(this.p[0]);
        var ab = this.direction();
        var param = aq.dot(ab) / ab.dot(ab);
        var eq = this.p[param > .5 ? 1 : 0].clone().sub(origin);
        var endpointDistance = eq.length();
        if (param > 0 && param < 1) {
            var orthoDistance = getOrthonormal(ab, false, false).dot(aq);
            if (Math.abs(orthoDistance) < endpointDistance) {
                var _sd = new SignedDistance();
                _sd.set(orthoDistance, 0);
                return [_sd, param];
            }
        }
        /// Returns 1 for non-negative values and -1 for negative values.
        var nzs = 2 * (cross2d(aq, ab) > 0 ? 1 : 0) - 1;
        var sd = new SignedDistance();
        sd.set(nzs * endpointDistance, Math.abs(ab.normalize().dot(eq.normalize(eq))));
        return [sd, param];
    },
    /// Converts a previously retrieved signed distance from origin to pseudo-distance.
    distanceToPseudoDistance: function distanceToPseudoDistance(sd, origin, param) {
        var pseudoDistance = void 0,
            dir = void 0,
            ts = void 0;
        if (param < 0) {
            dir = this.direction().normalize();
            var aq = origin.clone().sub(this.p[0]);
            ts = aq.dot(dir);
            if (ts < 0) {
                pseudoDistance = cross2d(aq, dir);
                if (Math.abs(pseudoDistance) <= Math.abs(sd.distance)) {
                    sd.distance = pseudoDistance;
                    sd.dot = 0;
                }
            }
        } else if (param > 1) {
            // note that this line is the same as above. In the original it is direction(0) vs. direction(1),
            // but for LinearSegment::direction the parameter 0 or 1 is ignored
            dir = this.direction().normalize();
            var bq = origin.clone().sub(this.p[1]);
            ts = bq.dot(dir);
            if (ts > 0) {
                pseudoDistance = cross2d(bq, dir);
                if (Math.abs(pseudoDistance) <= Math.abs(sd.distance)) {
                    sd.distance = pseudoDistance;
                    sd.dot = 0;
                }
            }
        }
    },
    /// Moves the start point of the edge segment.
    moveStartPoint: function moveStartPoint(to) {
        this.p[0].copy(to);
    },
    /// Moves the end point of the edge segment.
    moveEndPoint: function moveEndPoint(to) {
        this.p[1].copy(to);
    },
    /// Splits the edge segments into thirds which together represent the original edge.
    splitInThirds: function splitInThirds(part1, part2, part3) {
        // this could be made more efficient by saving the interpoa
        var oneThird = this.point(1 / 3.);
        var twoThirds = this.point(2 / 3.);
        part1 = new MSDFLinearSegment(this.p[0], oneThird, this.color);
        part2 = new MSDFLinearSegment(oneThird, twoThirds, this.color);
        part3 = new MSDFLinearSegment(twoThirds, this.p[1], this.color);
    }
});
function shoelace(a, b) {
    return (b.x - a.x) * (a.y + b.y);
}
function sign(n) {
    return n > 0 ? 1 : n < 0 ? -1 : 0;
}
function MSDFContour() {
    this.edges = [];
}
Object.assign(MSDFContour.prototype, {
    addEdge: function addEdge(lineSeg) {
        this.edges.push(lineSeg);
    },
    /// Computes the bounding box of the contour.
    // never called, so not translated: void bounds(double &l, double &b, double &r, double &t) const;
    /// Computes the winding of the contour. Returns 1 if positive, -1 if negative, 0 if no edges
    winding: function winding() {
        if (this.edges.length === 0) return 0;
        var total = 0;
        var a = void 0,
            b = void 0,
            c = void 0,
            d = void 0;
        if (this.edges.length == 1) {
            a = new THREE$1.Vector2();
            b = new THREE$1.Vector2();
            c = new THREE$1.Vector2();
            a.copy(this.edges[0].point(0));
            b.copy(this.edges[0].point(1 / 3.));
            c.copy(this.edges[0].point(2 / 3.));
            total += shoelace(a, b);
            total += shoelace(b, c);
            total += shoelace(c, a);
        } else if (this.edges.length == 2) {
            a = new THREE$1.Vector2();
            b = new THREE$1.Vector2();
            c = new THREE$1.Vector2();
            d = new THREE$1.Vector2();
            a.copy(this.edges[0].point(0));
            b.copy(this.edges[0].point(.5));
            c.copy(this.edges[1].point(0));
            d.copy(this.edges[1].point(.5));
            total += shoelace(a, b);
            total += shoelace(b, c);
            total += shoelace(c, d);
            total += shoelace(d, a);
        } else {
            var prev = new THREE$1.Vector2();
            var cur = new THREE$1.Vector2();
            prev = this.edges[this.edges.length - 1].point(0);
            for (var ie = 0; ie < this.edges.length; ie++) {
                cur = this.edges[ie].point(0);
                total += shoelace(prev, cur);
                prev = cur;
            }
        }
        return sign(total);
    }
});
// Is the shared vertex a corner? Inputs must be normalized.
function isCorner(aDir, bDir, crossThreshold) {
    // more than 90 degrees, or more than the cross threshold, in terms of the sign of the angle
    return aDir.dot(bDir) <= 0 || Math.abs(cross2d(aDir, bDir)) > crossThreshold;
}
function switchColor(color, seed) {
    return switchColorBanned(color, seed, MSDF_EDGE_COLOR_BLACK);
}
function switchColorBanned(color, seed, banned) {
    var combined = color & banned;
    if (combined == MSDF_EDGE_COLOR_RED || combined == MSDF_EDGE_COLOR_GREEN || combined == MSDF_EDGE_COLOR_BLUE) {
        color = combined ^ MSDF_EDGE_COLOR_WHITE;
        return [color, seed];
    }
    if (color == MSDF_EDGE_COLOR_BLACK || color == MSDF_EDGE_COLOR_WHITE) {
        var start = [MSDF_EDGE_COLOR_CYAN, MSDF_EDGE_COLOR_MAGENTA, MSDF_EDGE_COLOR_YELLOW];
        color = start[seed % 3];
        seed = Math.floor(seed / 3);
        return [color, seed];
    }
    var shifted = color << 1 + (seed & 1);
    color = (shifted | shifted >> 3) & MSDF_EDGE_COLOR_WHITE;
    seed >>= 1;
    return [color, seed];
}
function EdgePoint() {
    this.minDistance = new SignedDistance();
    this.nearEdge = null;
    this.nearParam = 0;
}
Object.assign(EdgePoint.prototype, {
    clear: function clear() {
        // note that the SignedDistance is not cleared
        this.nearEdge = null;
        this.nearParam = 0;
    },
    copy: function copy(ep) {
        this.minDistance.copy(ep.minDistance);
        this.nearEdge = ep.nearEdge;
        this.nearParam = ep.nearParam;
    }
});
function median(a, b, c) {
    return Math.max(Math.min(a, b), Math.min(Math.max(a, b), c));
}
function pointToEdgeDistance(origin, edge) {
    var a = edge.point(0);
    var b = edge.point(1);
    var q = origin;
    var aq = origin.clone().sub(a);
    var ab = b.clone().sub(a);
    var param = aq.dot(ab) / ab.dot(ab);
    if (param < 0) {
        return aq.length();
    } else if (param > 1) {
        return q.clone().sub(b).length();
    } else {
        return Math.abs(getOrthonormal(ab, false, false).dot(aq));
    }
}
function MSDFShape() {
    this.contours = [];
    this.windings = [];
    this.inverseYAxis = false; // TODOTODO might need to set to true for WebGL; right now MSDF itself ignores this value entirely, so an implementation of reversal code may be needed
}
//Object.defineProperties( MSDF.prototype, {} );
Object.assign(MSDFShape.prototype, {
    /// Adds a contour.
    addContour: function addContour(contour) {
        this.contours.push(contour);
    },
    /// Adds a blank contour and returns its reference.
    addBlankContour: function addBlankContour() {
        // push and return
        var contour = new MSDFContour();
        this.contours.push(contour);
        return contour;
    },
    // once contours are defined, copy over windings from all contours
    initialize: function initialize() {
        for (var ic = 0; ic < this.contours.length; ++ic) {
            var contour = this.contours[ic];
            this.windings.push(contour.winding());
        }
    },
    /// Performs basic checks to determine if the object represents a valid shape.
    // not translated, as never called: bool validate() const;
    /// Computes the shape's bounding box.
    // not translated, as never called: void bounds(double &l, double &b, double &r, double &t) const;
    /// coloring edges
    edgeColoringSimple: function edgeColoringSimple(angleThreshold, seed) {
        var crossThreshold = Math.sin(angleThreshold);
        for (var ic = 0; ic < this.contours.length; ++ic) {
            // Identify corners
            var contour = this.contours[ic];
            var corners = [];
            if (contour.edges.length > 0) {
                var prevDirection = contour.edges[contour.edges.length - 1].direction(1);
                for (var ie = 0; ie < contour.edges.length; ++ie) {
                    var edge = contour.edges[ie];
                    if (isCorner(prevDirection.normalize(), edge.direction(0).normalize(), crossThreshold)) corners.push(ie);
                    prevDirection = edge.direction(1);
                }
            }
            // Smooth contour
            if (corners.length === 0) {
                for (var _ie = 0; _ie < contour.edges.length; ++_ie) {
                    contour.edges[_ie].color = MSDF_EDGE_COLOR_WHITE;
                }
                // "Teardrop" case
            } else if (corners.length == 1) {
                var colors = [MSDF_EDGE_COLOR_WHITE, MSDF_EDGE_COLOR_WHITE];
                var results = switchColor(colors[0], seed);
                colors[0] = results[0];
                seed = results[1];
                colors[2] = colors[0];
                results = switchColor(colors[0], seed);
                colors[0] = results[0];
                seed = results[1];
                var corner = corners[0];
                if (contour.edges.length >= 3) {
                    var m = contour.edges.length;
                    // this equation basically gives 0,1,2 for indices, spread fairly equally across the range.
                    for (var i = 0; i < m; ++i) {
                        // original was:
                        // (colors + 1)[int(3 + 2.875*i / (m - 1) - 1.4375 + .5) - 3];
                        // This uses a trick that when i > -1.0 it will round to 0. The intent is to give
                        // for, say, m=6 a range 1,1,1,1,2,2
                        // Simplification:
                        // colors[int(4 + 2.875*i / (m - 1) - 1.4375 + .5) - 3];
                        // colors[int(1 + 2.875*i / (m - 1) - 0.9375)];
                        // colors[int(2.875*i / (m - 1) + 0.0625)];
                        // Verified my fix was OK with the author: https://github.com/Chlumsky/msdfgen/issues/62
                        contour.edges[(corner + i) % m].color = colors[Math.floor(2.875 * i / (m - 1) + 0.0625)];
                    }
                } else if (contour.edges.length >= 1) {
                    // Less than three edge segments for three colors => edges must be split
                    var parts = [];
                    contour.edges[0].splitInThirds(parts[0 + 3 * corner], parts[1 + 3 * corner], parts[2 + 3 * corner]);
                    if (contour.edges.length >= 2) {
                        contour.edges[1].splitInThirds(parts[3 - 3 * corner], parts[4 - 3 * corner], parts[5 - 3 * corner]);
                        parts[0].color = parts[1].color = colors[0];
                        parts[2].color = parts[3].color = colors[1];
                        parts[4].color = parts[5].color = colors[2];
                    } else {
                        parts[0].color = colors[0];
                        parts[1].color = colors[1];
                        parts[2].color = colors[2];
                    }
                    contour.edges.clear();
                    for (var _i = 0; _i < parts.length; ++_i) {
                        contour.edges.push(parts[_i]);
                    }
                }
            } else {
                var cornerCount = corners.length;
                var spline = 0;
                var start = corners[0];
                var _m = contour.edges.length;
                var color = MSDF_EDGE_COLOR_WHITE;
                var _results = switchColor(color, seed);
                color = _results[0];
                seed = _results[1];
                var initialColor = color;
                for (var _i2 = 0; _i2 < _m; ++_i2) {
                    var index = (start + _i2) % _m;
                    if (spline + 1 < cornerCount && corners[spline + 1] == index) {
                        ++spline;
                        _results = switchColorBanned(color, seed, (spline === cornerCount - 1 ? 1 : 0) * initialColor);
                        color = _results[0];
                        seed = _results[1];
                    }
                    contour.edges[index].color = color;
                }
            }
        }
    },
    /// calculate msdf value for point p
    calculateMSDFValue: function calculateMSDFValue(p) {
        var contourCount = this.contours.length;
        var contourSD = [];
        var sr = new EdgePoint();
        var sg = new EdgePoint();
        var sb = new EdgePoint();
        var d = Math.abs(SIGNED_DISTANCE_INF);
        var negDist = -SIGNED_DISTANCE_INF;
        var posDist = SIGNED_DISTANCE_INF;
        var winding = 0;
        var r = new EdgePoint();
        var g = new EdgePoint();
        var b = new EdgePoint();
        for (var i = 0; i < this.contours.length; ++i) {
            contourSD[i] = {
                r: SIGNED_DISTANCE_INF,
                g: SIGNED_DISTANCE_INF,
                b: SIGNED_DISTANCE_INF,
                med: SIGNED_DISTANCE_INF
            };
            var contour = this.contours[i];
            r.clear();
            g.clear();
            b.clear();
            for (var ie = 0; ie < contour.edges.length; ++ie) {
                var edge = contour.edges[ie];
                var resultArray = edge.signedDistance(p);
                var distance = resultArray[0];
                var param = resultArray[1];
                if ((edge.color & MSDF_EDGE_COLOR_RED) > 0 && distance.lessThan(r.minDistance)) {
                    r.minDistance.copy(distance);
                    r.nearEdge = edge;
                    r.nearParam = param;
                }
                if ((edge.color & MSDF_EDGE_COLOR_GREEN) > 0 && distance.lessThan(g.minDistance)) {
                    g.minDistance.copy(distance);
                    g.nearEdge = edge;
                    g.nearParam = param;
                }
                if ((edge.color & MSDF_EDGE_COLOR_BLUE) > 0 && distance.lessThan(b.minDistance)) {
                    b.minDistance.copy(distance);
                    b.nearEdge = edge;
                    b.nearParam = param;
                }
            }
            if (r.minDistance.lessThan(sr.minDistance)) sr.copy(r);
            if (g.minDistance.lessThan(sg.minDistance)) sg.copy(g);
            if (b.minDistance.lessThan(sb.minDistance)) sb.copy(b);
            var medMinDistance = Math.abs(median(r.minDistance.distance, g.minDistance.distance, b.minDistance.distance));
            if (medMinDistance < d) {
                d = medMinDistance;
                winding = -this.windings[i];
            }
            if (r.nearEdge) r.nearEdge.distanceToPseudoDistance(r.minDistance, p, r.nearParam);
            if (g.nearEdge) g.nearEdge.distanceToPseudoDistance(g.minDistance, p, g.nearParam);
            if (b.nearEdge) b.nearEdge.distanceToPseudoDistance(b.minDistance, p, b.nearParam);
            medMinDistance = median(r.minDistance.distance, g.minDistance.distance, b.minDistance.distance);
            contourSD[i].r = r.minDistance.distance;
            contourSD[i].g = g.minDistance.distance;
            contourSD[i].b = b.minDistance.distance;
            contourSD[i].med = medMinDistance;
            if (this.windings[i] > 0 && medMinDistance >= 0 && Math.abs(medMinDistance) < Math.abs(posDist)) posDist = medMinDistance;
            if (this.windings[i] < 0 && medMinDistance <= 0 && Math.abs(medMinDistance) < Math.abs(negDist)) negDist = medMinDistance;
        }
        if (sr.nearEdge) sr.nearEdge.distanceToPseudoDistance(sr.minDistance, p, sr.nearParam);
        if (sg.nearEdge) sg.nearEdge.distanceToPseudoDistance(sg.minDistance, p, sg.nearParam);
        if (sb.nearEdge) sb.nearEdge.distanceToPseudoDistance(sb.minDistance, p, sb.nearParam);
        // MultiDistance class
        var msd = {
            r: SIGNED_DISTANCE_INF,
            g: SIGNED_DISTANCE_INF,
            b: SIGNED_DISTANCE_INF,
            med: SIGNED_DISTANCE_INF
        };
        if (posDist >= 0 && Math.abs(posDist) <= Math.abs(negDist)) {
            msd.med = SIGNED_DISTANCE_INF;
            winding = 1;
            for (var _i3 = 0; _i3 < contourCount; ++_i3) {
                if (this.windings[_i3] > 0 && contourSD[_i3].med > msd.med && Math.abs(contourSD[_i3].med) < Math.abs(negDist)) msd = contourSD[_i3];
            }
        } else if (negDist <= 0 && Math.abs(negDist) <= Math.abs(posDist)) {
            msd.med = -SIGNED_DISTANCE_INF;
            winding = -1;
            for (var _i4 = 0; _i4 < contourCount; ++_i4) {
                if (this.windings[_i4] < 0 && contourSD[_i4].med < msd.med && Math.abs(contourSD[_i4].med) < Math.abs(posDist)) msd = contourSD[_i4];
            }
        }
        for (var _i5 = 0; _i5 < contourCount; ++_i5) {
            if (this.windings[_i5] != winding && Math.abs(contourSD[_i5].med) < Math.abs(msd.med)) {
                // note that we "cheat" here, vs. the original code, which copies the values. This is not
                // needed as msd gets used at the end, and it and the contourSD is discarded.
                msd = contourSD[_i5];
            }
        }
        if (median(sr.minDistance.distance, sg.minDistance.distance, sb.minDistance.distance) == msd.med) {
            msd.r = sr.minDistance.distance;
            msd.g = sg.minDistance.distance;
            msd.b = sb.minDistance.distance;
        }
        return new THREE$1.Vector3(msd.r, msd.g, msd.b);
    },
    /// calculate minium distance between edges that colored same color
    minSameColoredEdgeDistance: function minSameColoredEdgeDistance() {
        // all edges are colored by 3 colors in all.
        var minDistance = [1e10, 1e10, 1e10];
        for (var ic = 0; ic < this.contours.length; ++ic) {
            var contour = this.contours[ic];
            for (var i = 0; i < contour.edges.length; ++i) {
                var edge = contour.edges[i];
                // neighbor edges would not colored by same color, so inner loop ends at i-1
                for (var j = 0; j + 1 < i; ++j) {
                    var otherEdge = contour.edges[j];
                    if (edge.color == otherEdge.color) {
                        // as the MSDF algorithm would fail on self-intersected polygon, we only can
                        // simply assume all same colored edges are not intersected here. In this 
                        // case, the minimun distance between two edges are the min distance of end
                        // points to the other edge.
                        var dist = Math.min(Math.min(pointToEdgeDistance(edge.point(0), otherEdge), pointToEdgeDistance(edge.point(1), otherEdge)), Math.min(pointToEdgeDistance(otherEdge.point(0), edge), pointToEdgeDistance(otherEdge.point(1), edge)));
                        var idx = edge.color - MSDF_EDGE_COLOR_MAGENTA;
                        minDistance[idx] = Math.min(minDistance[idx], dist);
                    }
                }
            }
        }
        return Math.min(Math.min(minDistance[0], minDistance[1]), minDistance[2]);
    }
});

// Helper functions to parse ugly Protein JSON
function parseMaterialColor(props, name, unused) {
    if (!props || !props["colors"]) return new THREE$1.Color(1, 0, 0); //error -- return red
    var cobj = props["colors"][name];
    if (!cobj) return new THREE$1.Color(0, 0, 0); //ok -- color is not defined
    //which in the C++ LMVTK is equal to DEFAULT_COLOR, which is black
    var vals = cobj["values"];
    if (!vals || !vals.length) return new THREE$1.Color(1, 0, 0); //error
    var rgb = vals[0];
    return new THREE$1.Color(rgb["r"], rgb["g"], rgb["b"]);
}
function parseMaterialScalar(props, name, undefVal) {
    if (!props || !props["scalars"]) return undefVal;
    var vobj = props["scalars"][name];
    if (!vobj) return undefVal;
    return vobj["values"][0];
}
function parseMaterialBoolean(props, name, undefVal) {
    if (!props || !props["booleans"]) return undefVal;
    var b = props["booleans"][name];
    return b === undefined ? undefVal : b;
}
function parseMaterialGeneric(props, category, name, undefVal) {
    if (!props || !props[category]) return undefVal;
    var vobj = props[category][name];
    if (!vobj) return undefVal;
    return vobj["values"][0];
}
function parseWoodProfile(props, category, name) {
    //Init a default object.
    var ret = {
        bands: 0,
        weights: new THREE$1.Vector4(1, 1, 1, 1),
        frequencies: new THREE$1.Vector4(1, 1, 1, 1)
    };
    if (!props || !props[category]) return ret;
    var vobj = props[category][name];
    if (!vobj || !vobj.values || !(vobj.values instanceof Array)) return ret;
    var values = vobj.values;
    ret.bands = values.length / 2;
    for (var i = 0; i < ret.bands; ++i) {
        // Note that the frequencies stored in the material are actually used in the shader as 1/frequency.
        // We perform this computation once here and store these reciprocals, for efficiency.
        ret.frequencies.setComponent(i, 1 / values[2 * i]);
        ret.weights.setComponent(i, values[2 * i + 1]);
    }
    return ret;
}
function parseMaterialScalarWithSceneUnit(props, name, sceneUnit, undefVal) {
    if (!props || !props["scalars"]) return undefVal;
    var vobj = props["scalars"][name];
    if (!vobj) return undefVal;
    return ConvertDistance(vobj["values"][0], vobj["units"], sceneUnit);
}
function parseMaterialGenericConnection(props, category, name, undefVal) {
    if (!props || !props[category]) return undefVal;
    var vobj = props[category][name];
    if (!vobj) return undefVal;
    var connections = vobj["connections"];
    if (!connections) return undefVal;
    return vobj["connections"][0];
}
function SRGBToLinearFloat(component) {
    var result = component;
    if (result <= 0.04045) result /= 12.92;else result = Math.pow((result + 0.055) / 1.055, 2.4);
    return result;
}
function SRGBToLinear(color) {
    var r, g, b;
    r = SRGBToLinearFloat(color.r);
    g = SRGBToLinearFloat(color.g);
    b = SRGBToLinearFloat(color.b);
    return new THREE$1.Color(r, g, b);
}
// TODO, since web doesn't use AdCoreUnits dependencies, only 9 units are supported in web now.
var UnitPerMeter = {
    MilliMeter: 1000, mm: 1000, 8206: 1000,
    DeciMeter: 10, dm: 10, 8204: 10,
    CentiMeter: 100, cm: 100, 8205: 100,
    Meter: 1, m: 1, 8193: 1,
    KiloMeter: 0.001, km: 0.001, 8201: 0.001,
    Inch: 39.37008, in: 39.37008, 8214: 39.37008,
    Foot: 3.28084, ft: 3.28084, 8215: 3.28084,
    Mile: 0.00062137, mi: 0.00062137, 8225: 0.00062137,
    Yard: 1.09361, yard: 1.09361, 8221: 1.09361
};
// Convert meter to the new unit.
function ConvertDistance(distance, currentUnit, newUnit) {
    var factor = UnitPerMeter[newUnit];
    if (!factor) {
        factor = 1;
        THREE$1.warn('Unsupported unit: ' + newUnit);
    }
    var divisor = UnitPerMeter[currentUnit];
    if (!divisor) {
        divisor = 1;
        THREE$1.warn('Unsupported unit: ' + currentUnit);
    }
    return distance * factor / divisor;
}
function GetBumpScale(props, type, sceneUnit) {
    if (type === 0) {
        var depth = parseMaterialScalarWithSceneUnit(props, "bumpmap_Depth", sceneUnit, 0);
        var scale_x = 1;
        var scale_y = 1;
        if (parseMaterialGeneric(props, "scalars", "texture_RealWorldScale") != null) {
            scale_x = scale_y = parseMaterialScalarWithSceneUnit(props, "texture_RealWorldScale", sceneUnit, 1);
        } else {
            scale_x = parseMaterialScalarWithSceneUnit(props, "texture_RealWorldScaleX", sceneUnit, 1);
            scale_y = parseMaterialScalarWithSceneUnit(props, "texture_RealWorldScaleY", sceneUnit, 1);
        }
        scale_x = scale_x === 0 ? 1 : 1 / scale_x;
        scale_y = scale_y === 0 ? 1 : 1 / scale_y;
        return new THREE$1.Vector2(scale_x * depth, scale_y * depth);
    } else {
        var normalScale = parseMaterialGeneric(props, "scalars", "bumpmap_NormalScale", 1);
        return new THREE$1.Vector2(normalScale, normalScale);
    }
}
function Get2DPrismMapTransform(props, sceneUnit) {
    var worldOffsetX = parseMaterialScalarWithSceneUnit(props, "texture_RealWorldOffsetX", sceneUnit, 0);
    var worldOffsetY = parseMaterialScalarWithSceneUnit(props, "texture_RealWorldOffsetY", sceneUnit, 0);
    var texOffsetU = parseMaterialGeneric(props, "scalars", "texture_UOffset", 0);
    var texOffsetV = parseMaterialGeneric(props, "scalars", "texture_VOffset", 0);
    // Get the real-world size, i.e. the size of the map in a real unit, and use the reciprocal as
    // the scale.  If the scale is zero, use one instead.
    var worldScaleX = 1;
    var worldScaleY = 1;
    if (parseMaterialGeneric(props, "scalars", "texture_RealWorldScale") != null) {
        worldScaleX = worldScaleY = parseMaterialScalarWithSceneUnit(props, "texture_RealWorldScale", sceneUnit, 1);
    } else {
        worldScaleX = parseMaterialScalarWithSceneUnit(props, "texture_RealWorldScaleX", sceneUnit, 1);
        worldScaleY = parseMaterialScalarWithSceneUnit(props, "texture_RealWorldScaleY", sceneUnit, 1);
    }
    worldScaleX = worldScaleX === 0 ? 1 : worldScaleX;
    worldScaleY = worldScaleY === 0 ? 1 : worldScaleY;
    // include the additional U and V scales
    var texScaleU = parseMaterialGeneric(props, "scalars", "texture_UScale", 1);
    var texScaleV = parseMaterialGeneric(props, "scalars", "texture_VScale", 1);
    // Get the rotation angle and convert it from degrees to radians.
    var angle = parseMaterialGeneric(props, "scalars", "texture_WAngle", 1);
    angle *= Math.PI / 180.0;
    // Compute the final 3x3 matrix by combining the following transformations:
    // 1. inverse of the real world offset
    // 2. inverse of the real world scale
    // 3. uv scale
    // 4. uv rotation
    // 5. uv offset
    var c = Math.cos(angle),
        s = Math.sin(angle);
    var cx = texScaleU / worldScaleX,
        cy = texScaleV / worldScaleY;
    var matrix = {
        elements: [c * cx, s * cx, 0, -s * cy, c * cy, 0, -c * cx * worldOffsetX + s * cy * worldOffsetY + texOffsetU, -s * cx * worldOffsetX - c * cy * worldOffsetY + texOffsetV, 1]
    };
    return matrix;
}
var PrismImportantSamplingTexture;
function InitPrismImportantSamplingTextures() {
    //random number texture for prism important sampling.
    //We can reuse 3d wood noise texture, but to align with Fusion,
    //use the same random number texture.
    var randomNum = [0, 128, 64, 191, 32, 160, 96, 223, 16, 143, 80, 207, 48, 175, 112, 239, 8, 135, 72, 199, 40, 167, 103, 231, 25, 151, 88, 215, 56, 183, 120, 250];
    var randomNumBuffer = new Uint8Array(randomNum);
    var randomNumTex = new THREE$1.DataTexture(randomNumBuffer, 32, 1, THREE$1.LuminanceFormat, THREE$1.UnsignedByteType, THREE$1.UVMapping, THREE$1.RepeatWrapping, THREE$1.RepeatWrapping, THREE$1.NearestFilter, THREE$1.NearestFilter, 0);
    randomNumTex.generateMipmaps = false;
    randomNumTex.flipY = false;
    randomNumTex.needsUpdate = true;
    var areaElement = function areaElement(x, y) {
        return Math.atan2(x * y, Math.sqrt(x * x + y * y + 1.0));
    };
    //Calculate the solid angle, so we don't need to do this in the shader.
    /// http://www.mpia-hd.mpg.de/~mathar/public/mathar20051002.pdf
    /// http://www.rorydriscoll.com/2012/01/15/cubemap-texel-solid-angle/
    var solidAngleBuffer = new Uint8Array(128 * 128);
    var u, v;
    var invFaceSize = 1.0 / 128.0;
    for (var i = 0; i < 128; ++i) {
        for (var j = 0; j < 128; ++j) {
            u = i / 128.0 * 2.0 - 1.0;
            v = j / 128.0 * 2.0 - 1.0;
            u = Math.min(Math.max(-1.0 + invFaceSize, u), 1.0 - invFaceSize);
            v = Math.min(Math.max(-1.0 + invFaceSize, v), 1.0 - invFaceSize);
            var x0 = u - invFaceSize;
            var x1 = u + invFaceSize;
            var y0 = v - invFaceSize;
            var y1 = v + invFaceSize;
            // Compute solid angle of texel area.
            var solidAngle = areaElement(x1, y1) - areaElement(x0, y1) - areaElement(x1, y0) + areaElement(x0, y0);
            //The max result is 0.000244125724. Map to [0, 255]
            solidAngleBuffer[i * 128 + j] = solidAngle * 1000000;
        }
    }
    var solidAngleTex = new THREE$1.DataTexture(solidAngleBuffer, 128, 128, THREE$1.LuminanceFormat, THREE$1.UnsignedByteType, THREE$1.UVMapping, THREE$1.RepeatWrapping, THREE$1.RepeatWrapping, THREE$1.NearestFilter, THREE$1.NearestFilter, 0);
    solidAngleTex.generateMipmaps = false;
    solidAngleTex.flipY = false;
    solidAngleTex.needsUpdate = true;
    PrismImportantSamplingTexture = {
        randomNum: randomNumTex,
        solidAngle: solidAngleTex
    };
}
var PrismWoodTexture;
//Init the prism wood textures. They are used in all prism 3d wood materials, so keep them
//in the material manager.
function InitPrism3DWoodTextures() {
    var permutation = [151, 160, 137, 91, 90, 15, 131, 13, 201, 95, 96, 53, 194, 233, 7, 225, 140, 36, 103, 30, 69, 142, 8, 99, 37, 240, 21, 10, 23, 190, 6, 148, 247, 120, 234, 75, 0, 26, 197, 62, 94, 252, 219, 203, 117, 35, 11, 32, 57, 177, 33, 88, 237, 149, 56, 87, 174, 20, 125, 136, 171, 168, 68, 175, 74, 165, 71, 134, 139, 48, 27, 166, 77, 146, 158, 231, 83, 111, 229, 122, 60, 211, 133, 230, 220, 105, 92, 41, 55, 46, 245, 40, 244, 102, 143, 54, 65, 25, 63, 161, 1, 216, 80, 73, 209, 76, 132, 187, 208, 89, 18, 169, 200, 196, 135, 130, 116, 188, 159, 86, 164, 100, 109, 198, 173, 186, 3, 64, 52, 217, 226, 250, 124, 123, 5, 202, 38, 147, 118, 126, 255, 82, 85, 212, 207, 206, 59, 227, 47, 16, 58, 17, 182, 189, 28, 42, 223, 183, 170, 213, 119, 248, 152, 2, 44, 154, 163, 70, 221, 153, 101, 155, 167, 43, 172, 9, 129, 22, 39, 253, 19, 98, 108, 110, 79, 113, 224, 232, 178, 185, 112, 104, 218, 246, 97, 228, 251, 34, 242, 193, 238, 210, 144, 12, 191, 179, 162, 241, 81, 51, 145, 235, 249, 14, 239, 107, 49, 192, 214, 31, 181, 199, 106, 157, 184, 84, 204, 176, 115, 121, 50, 45, 127, 4, 150, 254, 138, 236, 205, 93, 222, 114, 67, 29, 24, 72, 243, 141, 128, 195, 78, 66, 215, 61, 156, 180];
    var permutationBuffer = new Uint8Array(permutation);
    var permutationTex = new THREE$1.DataTexture(permutationBuffer, 256, 1, THREE$1.LuminanceFormat, THREE$1.UnsignedByteType, THREE$1.UVMapping, THREE$1.RepeatWrapping, THREE$1.RepeatWrapping, THREE$1.NearestFilter, THREE$1.NearestFilter, 0);
    permutationTex.generateMipmaps = false;
    permutationTex.flipY = false;
    permutationTex.needsUpdate = true;
    //This is different with OGS desktop. OGS uses a float texture. I map these number to
    //unsight byte, since some platform may not support float texture. Test result shows that
    //the pixel diffrence is very small.
    var gradientData = [225, 39, 122, 231, 29, 173, 15, 159, 75, 88, 233, 19, 179, 79, 72, 94, 54, 73, 151, 161, 171, 113, 221, 144, 127, 83, 168, 19, 88, 122, 62, 225, 109, 128, 246, 247, 172, 101, 61, 139, 211, 168, 64, 210, 224, 82, 87, 97, 119, 250, 201, 44, 242, 239, 154, 99, 126, 13, 44, 70, 246, 170, 100, 52, 135, 28, 187, 22, 207, 119, 199, 1, 235, 187, 55, 131, 190, 124, 222, 249, 236, 53, 225, 231, 71, 30, 173, 185, 153, 47, 79, 133, 225, 10, 140, 62, 17, 99, 100, 29, 137, 95, 142, 244, 76, 5, 83, 124, 38, 216, 253, 195, 44, 210, 148, 185, 188, 39, 78, 195, 132, 30, 60, 73, 92, 223, 133, 80, 230, 56, 118, 207, 79, 15, 251, 211, 111, 21, 79, 23, 240, 146, 150, 207, 3, 61, 103, 27, 148, 6, 31, 127, 235, 58, 173, 244, 116, 81, 34, 120, 192, 213, 188, 226, 97, 23, 16, 161, 106, 80, 242, 148, 35, 37, 91, 117, 51, 216, 97, 193, 126, 222, 39, 38, 133, 217, 215, 23, 237, 57, 205, 42, 222, 165, 126, 133, 33, 8, 227, 154, 27, 18, 56, 11, 192, 120, 80, 92, 236, 38, 210, 207, 128, 31, 135, 39, 123, 5, 49, 127, 107, 200, 34, 14, 153, 239, 134, 19, 248, 162, 58, 201, 159, 198, 243, 158, 72, 5, 138, 184, 222, 200, 34, 141, 233, 40, 195, 238, 191, 122, 171, 32, 66, 254, 229, 197];
    var gradientBuffer = new Uint8Array(gradientData);
    var gradientTex = new THREE$1.DataTexture(gradientBuffer, 256, 1, THREE$1.LuminanceFormat, THREE$1.UnsignedByteType, THREE$1.UVMapping, THREE$1.RepeatWrapping, THREE$1.RepeatWrapping, THREE$1.NearestFilter, THREE$1.NearestFilter, 0);
    gradientTex.generateMipmaps = false;
    gradientTex.flipY = false;
    gradientTex.needsUpdate = true;
    var perm = function perm(x) {
        return permutation[x % 256];
    };
    var perm2D = new Array(256 * 256 * 4);
    var A, AA, AB, B, BA, BB, index, x;
    for (var y = 0; y < 256; ++y) {
        for (x = 0; x < 256; ++x) {
            A = perm(x) + y;
            AA = perm(A);
            AB = perm(A + 1);
            B = perm(x + 1) + y;
            BA = perm(B);
            BB = perm(B + 1);
            // Store (AA, AB, BA, BB) in pixel (x,y)
            index = 4 * (y * 256 + x);
            perm2D[index] = AA;
            perm2D[index + 1] = AB;
            perm2D[index + 2] = BA;
            perm2D[index + 3] = BB;
        }
    }var perm2DBuffer = new Uint8Array(perm2D);
    var perm2DTex = new THREE$1.DataTexture(perm2DBuffer, 256, 256, THREE$1.RGBAFormat, THREE$1.UnsignedByteType, THREE$1.UVMapping, THREE$1.RepeatWrapping, THREE$1.RepeatWrapping, THREE$1.NearestFilter, THREE$1.NearestFilter, 0);
    perm2DTex.generateMipmaps = false;
    perm2DTex.flipY = false;
    perm2DTex.needsUpdate = true;
    var gradients3D = [1, 1, 0, -1, 1, 0, 1, -1, 0, -1, -1, 0, 1, 0, 1, -1, 0, 1, 1, 0, -1, -1, 0, -1, 0, 1, 1, 0, -1, 1, 0, 1, -1, 0, -1, -1, 1, 1, 0, 0, -1, 1, -1, 1, 0, 0, -1, -1];
    var permGrad = new Array(1024);
    for (x = 0; x < 256; ++x) {
        var i = permutation[x] % 16;
        // Convert the gradient to signed-normalized int.
        permGrad[x * 4] = gradients3D[i * 3] * 127 + 128;
        permGrad[x * 4 + 1] = gradients3D[i * 3 + 1] * 127 + 128;
        permGrad[x * 4 + 2] = gradients3D[i * 3 + 2] * 127 + 128;
        permGrad[x * 4 + 3] = 0;
    }
    var permGradBuffer = new Uint8Array(permGrad);
    var permGradTex = new THREE$1.DataTexture(permGradBuffer, 256, 1, THREE$1.RGBAFormat, THREE$1.UnsignedByteType, THREE$1.UVMapping, THREE$1.RepeatWrapping, THREE$1.RepeatWrapping, THREE$1.NearestFilter, THREE$1.NearestFilter, 0);
    permGradTex.generateMipmaps = false;
    permGradTex.flipY = false;
    permGradTex.needsUpdate = true;
    PrismWoodTexture = {
        permutation: permutationTex,
        gradient: gradientTex,
        perm2D: perm2DTex,
        permGrad: permGradTex
    };
}
function parseWoodMap(tm, props, name) {
    tm[name + "_enable"] = parseMaterialGeneric(props, "booleans", name + "_enable", 0);
    var prof = parseWoodProfile(props, "scalars", name + "_prof");
    tm[name + "_bands"] = prof.bands;
    tm[name + "_weights"] = prof.weights;
    tm[name + "_frequencies"] = prof.frequencies;
}
function convertMaterial(matObj, sceneUnit, tm, index) {
    index = index || matObj["userassets"];
    var innerMats = matObj["materials"];
    var innerMat = innerMats[index];
    if (innerMat) {
        var definition = innerMat['definition'];
        // if this is a tiling, need to get the real grout material
        if (definition === 'TilingPattern') {
            // if first "material" is a tiling pattern, look at the grout material, which must always exist.
            var idx = innerMat.properties.references.grout_material.connections[0];
            innerMat = innerMats[idx];
        }
    }
    var props = innerMat["properties"];
    var isPrism = isPrismMaterial(matObj);
    if (!tm) {
        tm = isPrism ? PrismShaderUtils.createPrismMaterial() : new THREE$1.MeshPhongMaterial();
    } else if (isPrism ? !tm.isPrismMaterial : !(tm instanceof THREE$1.MeshPhongMaterial)) {
        return null;
    } else {
        tm.needsUpdate = true;
    }
    var map, texProps;
    tm.proteinMat = matObj;
    tm.proteinCategories = innerMat.categories;
    tm.packedNormals = true;
    if (innerMat && isPrism) {
        tm.tag = innerMat["tag"];
        tm.prismType = innerMat["definition"];
        if (tm.prismType === undefined) tm.prismType = "";
        // check for the new IsSingleSided tag from ATF. Note that we assume all objects are
        // single-sided (tm.side == THREE.FrontSide) unless tagged otherwise.
        if (matObj.IsSingleSided !== undefined && matObj.IsSingleSided === false) tm.side = THREE$1.DoubleSide;
        // else, by default, tm.side is FrontSide
        var mapList = tm.mapList;
        tm.transparent = false;
        tm.envExponentMin = 1.0;
        tm.envExponentMax = 512.0;
        tm.envExponentCount = 10.0;
        // among other things, set up mapList and note what map, if any, is attached to each property such as "surface_albedo".
        tm.surface_albedo = SRGBToLinear(parseMaterialColor(props, "surface_albedo", new THREE$1.Color(1, 0, 0)));
        mapList.surface_albedo_map = parseMaterialGenericConnection(props, "colors", "surface_albedo", null);
        tm.surface_anisotropy = parseMaterialGeneric(props, "scalars", "surface_anisotropy", 0);
        mapList.surface_anisotropy_map = parseMaterialGenericConnection(props, "scalars", "surface_anisotropy", null);
        tm.surface_rotation = parseMaterialGeneric(props, "scalars", "surface_rotation", 0);
        mapList.surface_rotation_map = parseMaterialGenericConnection(props, "scalars", "surface_rotation", null);
        tm.surface_roughness = parseMaterialGeneric(props, "scalars", "surface_roughness", 0);
        mapList.surface_roughness_map = parseMaterialGenericConnection(props, "scalars", "surface_roughness", null);
        mapList.surface_cutout_map = parseMaterialGenericConnection(props, "textures", "surface_cutout", null);
        mapList.surface_normal_map = parseMaterialGenericConnection(props, "textures", "surface_normal", null);
        // if there is a cutout map, we must make the surface double-sided since we can see through to the inside
        if (mapList.surface_cutout_map != null) {
            tm.side = THREE$1.DoubleSide;
            tm.transparent = true;
        }
        switch (tm.prismType) {
            case 'PrismOpaque':
                tm.opaque_albedo = SRGBToLinear(parseMaterialColor(props, "opaque_albedo", new THREE$1.Color(1, 0, 0)));
                mapList.opaque_albedo_map = parseMaterialGenericConnection(props, "colors", "opaque_albedo", null);
                tm.opaque_luminance_modifier = SRGBToLinear(parseMaterialColor(props, "opaque_luminance_modifier", new THREE$1.Color(0, 0, 0)));
                mapList.opaque_luminance_modifier_map = parseMaterialGenericConnection(props, "colors", "opaque_luminance_modifier", null);
                tm.opaque_f0 = parseMaterialGeneric(props, "scalars", "opaque_f0", 0);
                mapList.opaque_f0_map = parseMaterialGenericConnection(props, "scalars", "opaque_f0", null);
                tm.opaque_luminance = parseMaterialGeneric(props, "scalars", "opaque_luminance", 0);
                break;
            case 'PrismMetal':
                tm.metal_f0 = SRGBToLinear(parseMaterialColor(props, "metal_f0", new THREE$1.Color(1, 0, 0)));
                mapList.metal_f0_map = parseMaterialGenericConnection(props, "colors", "metal_f0", null);
                break;
            case 'PrismLayered':
                tm.layered_bottom_f0 = SRGBToLinear(parseMaterialColor(props, "layered_bottom_f0", new THREE$1.Color(1, 1, 1)));
                mapList.layered_bottom_f0_map = parseMaterialGenericConnection(props, "colors", "layered_bottom_f0", null);
                tm.layered_diffuse = SRGBToLinear(parseMaterialColor(props, "layered_diffuse", new THREE$1.Color(1, 0, 0)));
                mapList.layered_diffuse_map = parseMaterialGenericConnection(props, "colors", "layered_diffuse", null);
                tm.layered_anisotropy = parseMaterialGeneric(props, "scalars", "layered_anisotropy", 0);
                mapList.layered_anisotropy_map = parseMaterialGenericConnection(props, "scalars", "layered_anisotropy", null);
                tm.layered_f0 = parseMaterialGeneric(props, "scalars", "layered_f0", 0);
                mapList.layered_f0_map = parseMaterialGenericConnection(props, "scalars", "layered_f0", null);
                tm.layered_fraction = parseMaterialGeneric(props, "scalars", "layered_fraction", 0);
                mapList.layered_fraction_map = parseMaterialGenericConnection(props, "scalars", "layered_fraction", null);
                tm.layered_rotation = parseMaterialGeneric(props, "scalars", "layered_rotation", 0);
                mapList.layered_rotation_map = parseMaterialGenericConnection(props, "scalars", "layered_rotation", null);
                tm.layered_roughness = parseMaterialGeneric(props, "scalars", "layered_roughness", 0);
                mapList.layered_roughness_map = parseMaterialGenericConnection(props, "scalars", "layered_roughness", null);
                mapList.layered_normal_map = parseMaterialGenericConnection(props, "textures", "layered_normal", null);
                break;
            case 'PrismTransparent':
                tm.transparent_color = SRGBToLinear(parseMaterialColor(props, "transparent_color", new THREE$1.Color(1, 0, 0)));
                tm.transparent_distance = parseMaterialGeneric(props, "scalars", "transparent_distance", 0);
                tm.transparent_ior = parseMaterialGeneric(props, "scalars", "transparent_ior", 0);
                tm.transparent = true;
                break;
            case 'PrismGlazing':
                tm.glazing_f0 = SRGBToLinear(parseMaterialColor(props, "glazing_f0", new THREE$1.Color(1, 1, 1)));
                mapList.glazing_f0_map = parseMaterialGenericConnection(props, "colors", "glazing_f0", null);
                tm.glazing_transmission_color = SRGBToLinear(parseMaterialColor(props, "glazing_transmission_color", new THREE$1.Color(1, 1, 1)));
                mapList.glazing_transmission_color_map = parseMaterialGenericConnection(props, "colors", "glazing_transmission_color", null);
                tm.glazing_transmission_roughness = parseMaterialScalar(props, "glazing_transmission_roughness", 0);
                mapList.glazing_transmission_roughness_map = parseMaterialGenericConnection(props, "scalars", "glazing_transmission_roughness", null);
                tm.side = parseMaterialGeneric(props, "booleans", "glazing_backface_culling", false) ? THREE$1.FrontSide : THREE$1.DoubleSide;
                tm.transparent = true;
                break;
            case 'PrismWood':
                parseWoodMap(tm, props, "wood_fiber_cosine");
                parseWoodMap(tm, props, "wood_fiber_perlin");
                tm.wood_fiber_perlin_scale_z = parseMaterialGeneric(props, "scalars", "wood_fiber_perlin_scale_z", 0);
                parseWoodMap(tm, props, "wood_growth_perlin");
                tm.wood_latewood_ratio = parseMaterialGeneric(props, "scalars", "wood_latewood_ratio", 0);
                tm.wood_earlywood_sharpness = parseMaterialGeneric(props, "scalars", "wood_earlywood_sharpness", 0);
                tm.wood_latewood_sharpness = parseMaterialGeneric(props, "scalars", "wood_latewood_sharpness", 0);
                tm.wood_ring_thickness = parseMaterialGeneric(props, "scalars", "wood_ring_thickness", 0);
                parseWoodMap(tm, props, "wood_earlycolor_perlin");
                tm.wood_early_color = SRGBToLinear(parseMaterialColor(props, "wood_early_color", new THREE$1.Color(1, 0, 0)));
                tm.wood_use_manual_late_color = parseMaterialGeneric(props, "booleans", "wood_use_manual_late_color", 0);
                tm.wood_manual_late_color = SRGBToLinear(parseMaterialColor(props, "wood_manual_late_color", new THREE$1.Color(1, 0, 0)));
                parseWoodMap(tm, props, "wood_latecolor_perlin");
                tm.wood_late_color_power = parseMaterialGeneric(props, "scalars", "wood_late_color_power", 0);
                parseWoodMap(tm, props, "wood_diffuse_perlin");
                tm.wood_diffuse_perlin_scale_z = parseMaterialGeneric(props, "scalars", "wood_diffuse_perlin_scale_z", 0);
                tm.wood_use_pores = parseMaterialGeneric(props, "booleans", "wood_use_pores", 0);
                tm.wood_pore_type = parseMaterialGeneric(props, "choicelists", "wood_pore_type", 0);
                tm.wood_pore_radius = parseMaterialGeneric(props, "scalars", "wood_pore_radius", 0);
                tm.wood_pore_cell_dim = parseMaterialGeneric(props, "scalars", "wood_pore_cell_dim", 0);
                tm.wood_pore_color_power = parseMaterialGeneric(props, "scalars", "wood_pore_color_power", 0);
                tm.wood_pore_depth = parseMaterialGeneric(props, "scalars", "wood_pore_depth", 0);
                tm.wood_use_rays = parseMaterialGeneric(props, "booleans", "wood_use_rays", 0);
                tm.wood_ray_color_power = parseMaterialGeneric(props, "scalars", "wood_ray_color_power", 0);
                tm.wood_ray_seg_length_z = parseMaterialGeneric(props, "scalars", "wood_ray_seg_length_z", 0);
                tm.wood_ray_num_slices = parseMaterialGeneric(props, "integers", "wood_ray_num_slices", 0);
                tm.wood_ray_ellipse_z2x = parseMaterialGeneric(props, "scalars", "wood_ray_ellipse_z2x", 0);
                tm.wood_ray_ellipse_radius_x = parseMaterialGeneric(props, "scalars", "wood_ray_ellipse_radius_x", 0);
                tm.wood_use_latewood_bump = parseMaterialGeneric(props, "booleans", "wood_use_latewood_bump", 0);
                tm.wood_latewood_bump_depth = parseMaterialGeneric(props, "scalars", "wood_latewood_bump_depth", 0);
                tm.wood_use_groove_roughness = parseMaterialGeneric(props, "booleans", "wood_use_groove_roughness", 0);
                tm.wood_groove_roughness = parseMaterialGeneric(props, "scalars", "wood_groove_roughness", 0);
                tm.wood_diffuse_lobe_weight = parseMaterialGeneric(props, "scalars", "wood_diffuse_lobe_weight", 0);
                tm.wood_curly_distortion_enable = parseMaterialGeneric(props, "booleans", "wood_curly_distortion_enable", 0);
                tm.wood_curly_distortion_scale = parseMaterialGeneric(props, "scalars", "wood_curly_distortion_scale", 0);
                mapList.wood_curly_distortion_map = parseMaterialGenericConnection(props, "scalars", "wood_curly_distortion_map", null);
                //Create the wood noise textures. They are used for all wood materials.
                if (!PrismWoodTexture) InitPrism3DWoodTextures();
                tm.uniforms.permutationMap.value = PrismWoodTexture['permutation'];
                tm.uniforms.gradientMap.value = PrismWoodTexture['gradient'];
                tm.uniforms.perm2DMap.value = PrismWoodTexture['perm2D'];
                tm.uniforms.permGradMap.value = PrismWoodTexture['permGrad'];
                break;
            default:
                THREE$1.warn('Unknown prism type: ' + tm.prismType);
        }
        if (tm.enableImportantSampling && (tm.surface_anisotropy || tm.surface_rotation || tm.layered_anisotropy || tm.layered_rotation)) {
            if (!PrismImportantSamplingTexture) InitPrismImportantSamplingTextures();
            tm.uniforms.importantSamplingRandomMap.value = PrismImportantSamplingTexture.randomNum;
            tm.uniforms.importantSamplingSolidAngleMap.value = PrismImportantSamplingTexture.solidAngle;
        }
        // now that the mapList is set up, populate it
        tm.defines = {};
        tm.textureMaps = {};
        for (var p in mapList) {
            // does the map exist? If not, continue on.
            if (!mapList[p]) continue;
            // the map exists for this property, so set the various values.
            var textureObj = innerMats[mapList[p]];
            texProps = textureObj["properties"];
            textureObj.matrix = get2DMapTransform(textureObj, true, sceneUnit);
            var uriType = textureObj["definition"] == "BumpMap" ? "bumpmap_Bitmap" : "unifiedbitmap_Bitmap";
            var uri = texProps["uris"][uriType]["values"][0];
            if (!uri) continue;
            map = {
                mapName: p,
                uri: uri,
                textureObj: textureObj,
                isPrism: true
            };
            tm.textureMaps[map.mapName] = map;
            // This array gives the various #defines that are associated with this instance of
            // the PRISM material.
            tm.defines["USE_" + p.toUpperCase()] = "";
        }
        tm.defines[tm.prismType.toUpperCase()] = "";
        if (tm.prismType == 'PrismWood' && tm.enable3DWoodBump) tm.defines['PRISMWOODBUMP'] = "";
        if (tm.enableImportantSampling) tm.defines['ENABLEIMPORTANTSAMPLING'] = "";
    } else if (innerMat && !isPrism && innerMat["definition"] == "SimplePhong") {
        tm.tag = innerMat["tag"];
        tm.proteinType = innerMat["proteinType"];
        if (tm.proteinType === undefined) tm.proteinType = null;
        var baked_lighting = parseMaterialBoolean(props, "generic_baked_lighting", false);
        tm.disableEnvMap = baked_lighting;
        var a = tm.ambient = parseMaterialColor(props, "generic_ambient");
        var d = tm.color = parseMaterialColor(props, "generic_diffuse");
        var s = tm.specular = parseMaterialColor(props, "generic_specular");
        var e = tm.emissive = parseMaterialColor(props, "generic_emissive");
        tm.shininess = parseMaterialScalar(props, "generic_glossiness", 30);
        tm.opacity = 1.0 - parseMaterialScalar(props, "generic_transparency", 0);
        tm.reflectivity = parseMaterialScalar(props, "generic_reflectivity_at_0deg", 0);
        var isNormal = parseMaterialBoolean(props, "generic_bump_is_normal");
        var scale = parseMaterialScalar(props, "generic_bump_amount", 0);
        // If cannot read the scale, set the scale to 1 which is the default value for prism and protein.
        if (scale == null) scale = 1;
        if (isNormal) {
            if (scale > 1) scale = 1;
            tm.normalScale = new THREE$1.Vector2(scale, scale);
        } else {
            if (scale >= 1.0) scale = 0.03;
            tm.bumpScale = scale;
        }
        var isMetal = parseMaterialBoolean(props, "generic_is_metal");
        if (isMetal !== undefined) tm.metal = isMetal;
        var backfaceCulling = parseMaterialBoolean(props, "generic_backface_cull");
        if (backfaceCulling !== undefined && !backfaceCulling) tm.side = THREE$1.DoubleSide;
        tm.transparent = innerMat["transparent"];
        tm.textureMaps = {};
        var textures = innerMat["textures"];
        for (var texType in textures) {
            map = {};
            map.textureObj = innerMats[textures[texType]["connections"][0]];
            texProps = map.textureObj["properties"];
            map.textureObj.matrix = get2DMapTransform(map.textureObj, false, sceneUnit);
            // Grab URI
            map.uri = texProps["uris"]["unifiedbitmap_Bitmap"]["values"][0];
            if (!map.uri) continue;
            // Figure out map name
            if (texType == "generic_diffuse") {
                map.mapName = "map";
                if (!tm.color || tm.color.r === 0 && tm.color.g === 0 && tm.color.b === 0) tm.color.setRGB(1, 1, 1);
            } else if (texType == "generic_bump") {
                if (isNormal) map.mapName = "normalMap";else map.mapName = "bumpMap";
            } else if (texType == "generic_specular") {
                map.mapName = "specularMap";
            } else if (texType == "generic_alpha") {
                map.mapName = "alphaMap";
                tm.side = THREE$1.DoubleSide;
                tm.transparent = true;
            } else {
                // no map name recognized, skip
                continue;
            }
            tm.textureMaps[map.mapName] = map;
        }
        //If the material is completely black, use a default material.
        if (d.r === 0 && d.g === 0 && d.b === 0 && s.r === 0 && s.g === 0 && s.b === 0 && a.r === 0 && a.g === 0 && a.b === 0 && e.r === 0 && e.g === 0 && e.b === 0) d.r = d.g = d.b = 0.4;
        // Apply extra polygon offset to material if applicable
        // larger value means further away
        tm.extraDepthOffset = parseMaterialScalar(props, "generic_depth_offset");
        if (tm.extraDepthOffset) {
            // these values are overridden after the initial render by MaterialManager.prototype.togglePolygonOffset()
            tm.polygonOffset = true;
            tm.polygonOffsetFactor = tm.extraDepthOffset;
            tm.polygonOffsetUnits = 0;
        }
    } else {
        // unknown material, use default colors
        tm.ambient = new THREE$1.Color(0x030303);
        tm.color = new THREE$1.Color(0x777777);
        tm.specular = new THREE$1.Color(0x333333);
        tm.shininess = 30;
        tm.shading = THREE$1.SmoothShading;
    }
    //Add the transparent flag as a top level property of the
    //Protein JSON. This is currently how the BVH builder decides
    //whether an object is transparent. See also Package.addTransparencyFlagsToMaterials
    //which is an equivalent hack done on the web worker side.
    //Normally the BVH will be built on the worker side, so this property set here is
    //probably not needed.
    matObj.transparent = tm.transparent;
    return tm;
}
// takes a 4x4 matrix
function buildTextureTransform(mtx, trans, rotate, scale) {
    // Build a 3D "TRS" matrix: translate, then rotate (ZYX) with the translated coordinate
    // system, then scale with the rotated coordinate system.  This mimics what is done in the
    // 3ds Max material editor.
    mtx.scale(scale);
    var s = new THREE$1.Vector3(Math.sin(rotate.x), Math.sin(rotate.y), Math.sin(rotate.z));
    var c = new THREE$1.Vector3(Math.cos(rotate.x), Math.cos(rotate.y), Math.cos(rotate.z));
    var sysx = s.y * s.x;
    var sycx = s.y * c.x;
    var rmtx = new THREE$1.Matrix4();
    rmtx.set(c.z * c.y, s.z * c.y, -s.y, 0, c.z * sysx - s.z * c.x, s.z * sysx + c.z * c.x, c.y * s.x, 0, c.z * sycx + s.z * s.x, s.z * sycx - c.z * s.x, c.y * c.x, 0, 0, 0, 0, 1);
    rmtx.multiply(mtx);
    mtx.makeTranslation(trans.x, trans.y, trans.z);
    mtx.multiply(rmtx);
}
// we implement just the z axis rotation, since that's all that is used
function rotate_euler(z) {
    var sz = Math.sin(z);
    var cz = Math.cos(z);
    // rotates the transform itself clockwise, meaning the texture itself will rotate counterclockwise.
    var mtx = new THREE$1.Matrix4();
    mtx.set(cz, -sz, 0, 0, sz, cz, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1);
    return mtx;
}
/// Extract the texture transform matrix from prism effect instance
function extractTextureTransformByPriority(prismMaterial) {
    // a Prism material instance could have several textures. We extract one by predefined priority
    var priorityTexture = ["opaque_albedo_map", "opaque_f0_map", "layered_diffuse_map", "layered_bottom_f0_map", "surface_roughness_map", "surface_normal_map", "surface_albedo_map", "surface_anisotropy_map", "surface_cutout_map"];
    if (prismMaterial.textureMaps !== undefined) {
        for (var p = 0; p < priorityTexture.length; ++p) {
            // check texture input exists
            if (prismMaterial.textureMaps[priorityTexture[p]] !== undefined) {
                // check texture transform exists
                if (prismMaterial.textureMaps[priorityTexture[p]].textureObj !== undefined) {
                    if (prismMaterial.textureMaps[priorityTexture[p]].textureObj.matrix !== undefined) {
                        var e = prismMaterial.textureMaps[priorityTexture[p]].textureObj.matrix.elements;
                        var mtx = new THREE$1.Matrix4();
                        // Convert the 3x3 to a 4x4. We need a 4x4 because we combine it with other transforms.
                        // Old three.js does not have a good 3x3 matrix library.
                        mtx.set(e[0], e[1], 0, e[2], e[3], e[4], 0, e[5], 0, 0, 1, 0, e[6], e[7], 0, e[8]);
                        return mtx;
                    }
                }
            }
        }
    }
    // nothing found, return identity.
    return new THREE$1.Matrix4();
}
// float4x4 BuildTextureTransform(float2 offset, float3 rotation, float2 tiling, float3 center)
function buildTextureTransformOS(offset, scale) {
    // Build a 2D texture transformation matrix that mimics what is done in the 3ds Max material
    // editor.
    // NOTE: The translation indicates an apparent shift in the image (e.g. positive x is to the
    // right), which is the opposite of translating the texture coordinates, so the translation
    // is negated here.
    //float4x4 mtx = translate(float4(-center.x, -center.y, -center.z, 0.0f));// center offset
    //mtx = mul(translate(float4(-offset.x, -offset.y, 0.0f, 0.0f)), mtx);    // translate
    //mtx = mul(scale(float4(scale.x, scale.y, 1.0f, 1.0f)), mtx);          // scale
    //mtx = mul(rotate_euler(float4(rotation, 0.0f)), mtx);                   // rotate
    //mtx = mul(translate(float4(center.x, center.y, center.z, 0.0f)), mtx);  // center restore
    var mtx = new THREE$1.Matrix4();
    mtx.makeScale(scale.x, scale.y, 1);
    var tmtx = new THREE$1.Matrix4();
    tmtx.makeTranslation(-offset.x, -offset.y, 0);
    mtx.multiply(tmtx);
    return mtx;
}
/// Compute the random axis and alignment offset for random
function computeRandomnessParameters(material, tile) {
    // port from OGS, from https://git.autodesk.com/rapidrt/vxrender/blob/master/src/renderer/rapid_renderer/prism/nodes/TileNode.cpp. 
    // function void init(const PropertyCollectionOwner& material, Node::IDelegate& delegate)
    if (tile.randomOffsetMode === 0) return;
    material.tilingRandomAxisS = new THREE$1.Vector2();
    material.tilingRandomAxisT = new THREE$1.Vector2();
    material.tilingRandomAlignmentOffset = new THREE$1.Vector2();
    var outRandomAxisS = material.tilingRandomAxisS;
    outRandomAxisS.set(1.0, 0.0);
    var outRandomAxisT = material.tilingRandomAxisT;
    outRandomAxisT.set(0.0, 1.0);
    var outRandomTileAlignOffset = material.tilingRandomAlignmentOffset;
    outRandomTileAlignOffset.set(0.0, 0.0);
    // transform for tile vertices to texture space
    var xform = new THREE$1.Matrix4();
    // inverse matrix from texture space to random offset
    var invXform = new THREE$1.Matrix4();
    // get texture transform matrix from sub material effect instance
    var textureXform = extractTextureTransformByPriority(material);
    // always true: if (mFlipRandomV)
    {
        // if the texture flips Y, revert the flip matrix from texture transform
        var flip = buildTextureTransformOS(new THREE$1.Vector2(0.0, 1.0), new THREE$1.Vector2(1.0, -1.0));
        flip.multiply(textureXform); // sadly, there's no premultiply matrix method in r71
        textureXform.copy(flip);
    }
    // apply per-tile rotation to texture transform
    xform.multiplyMatrices(textureXform, material.tilingUVTransform);
    invXform.getInverse(xform);
    // calculate random axis in tile space by applying the inverse transform matrix to texture space axis
    var tvec3 = new THREE$1.Vector4(1, 0, 0, 0).applyMatrix4(invXform);
    outRandomAxisS.set(tvec3.x, tvec3.y);
    tvec3 = new THREE$1.Vector4(0, 1, 0, 0).applyMatrix4(invXform);
    outRandomAxisT.set(tvec3.x, tvec3.y);
    var tvec2 = new THREE$1.Vector2();
    // compute tile bounding box in texture space
    var bounding = new THREE$1.Box2();
    var verts = tile.alignedVertices;
    for (var vi = 0; vi < verts.length; vi++) {
        tvec3.set(verts[vi].x, verts[vi].y, 0, 1);
        tvec3.applyMatrix4(xform);
        tvec2.set(tvec3.x, tvec3.y);
        bounding.expandByPoint(tvec2);
    }
    // compute offset to move align tile bounding box to origin of texture in texture space, 
    // then convert back to tile space
    tvec3.set(-bounding.min.x, -bounding.min.y, 0, 0);
    tvec3.applyMatrix4(invXform);
    outRandomTileAlignOffset.set(tvec3.x, tvec3.y);
    // scale random axis for bounded random mode
    var size = bounding.size();
    var transformedTileDims = tile.randomOffsetMode === 1 ? new THREE$1.Vector2(size.x, size.y) : new THREE$1.Vector2(0, 0);
    // How much the texture can be wiggled. This axis can in fact become 0,0 due to the current algorithm.
    outRandomAxisS.multiplyScalar(1 - transformedTileDims.x);
    outRandomAxisT.multiplyScalar(1 - transformedTileDims.y);
}
// OGS equivalent: MaterialTilingPattern in MaterialTilingPattern.inl
// input JSON data is in matObj, globalTile, and the inputTiles array.
// modify the set of allocated output tile materials, adding parameters as needed.
function materialTilingPattern(matObj, globalTile, inputTiles, decals, sceneUnit) {
    // Determine global tiling values,
    // then rasterize tiles to MSDF and (optional) normal maps,
    // then fill in uniforms for each material.
    // tiling properties
    var tilingProps = globalTile["properties"];
    // We'll discard this global tiling object when done - it is just convenient to make an object created from
    // matObj's TilingPatternSchema and pass it around.
    var tiling = {
        overallTransform: new THREE$1.Matrix4(),
        insetSize: 0,
        hasRoundCorner: false,
        cornerRoundingAngle: 0,
        cornerRoundingSize: 0,
        offsetVectorA: new THREE$1.Vector2(),
        offsetVectorB: new THREE$1.Vector2()
    };
    // always set flip random offset v flag to true, because Get2DMapTransform() always flips Y. 
    var scaleFactor = new THREE$1.Vector2(parseMaterialScalarWithSceneUnit(tilingProps, "scale_factor_x", sceneUnit, 1), parseMaterialScalarWithSceneUnit(tilingProps, "scale_factor_y", sceneUnit, 1));
    // get overall transforms
    var overallOffsetX = parseMaterialScalarWithSceneUnit(tilingProps, "overall_offset_vector_x", sceneUnit, 1);
    var overallOffsetY = parseMaterialScalarWithSceneUnit(tilingProps, "overall_offset_vector_y", sceneUnit, 1);
    // TODOTODO - it is not documented as to what the units are for angles. Once known, add & implement
    // some form of parseMaterialScalarWithSceneUnit, but instead of it calling ConvertDistance it needs to ConvertAngle,
    // "rad" or "deg" or whatever they specify. See https://wiki.autodesk.com/display/saascore/Tiling+ProteinMaterials.json
    var overallRotateAngle = parseMaterialScalar(tilingProps, "overall_rotation_angle", 0) * Math.PI / 180.0; // degrees to radians
    buildTextureTransform(tiling.overallTransform, new THREE$1.Vector3(-overallOffsetX, -overallOffsetY, 0.0), new THREE$1.Vector3(0.0, 0.0, -overallRotateAngle), new THREE$1.Vector3(1.0, 1.0, 1.0));
    // inset size, convert to tile vertices coordinate
    tiling.insetSize = parseMaterialScalarWithSceneUnit(tilingProps, "inset_size", sceneUnit, 1);
    // corner rounding angle
    // TODOTODO - it is not documented as to what the units are for angles. Once known, add & implement this conversion function, as above
    tiling.cornerRoundingAngle = parseMaterialScalar(tilingProps, "overall_corner_rounding_angle", 0) * Math.PI / 180.0; // degrees to radians
    // corner rounding size/radius, convert to tile vertices coordinate
    tiling.cornerRoundingSize = parseMaterialScalarWithSceneUnit(tilingProps, "overall_corner_rounding_size", sceneUnit, 1);
    // repeat offset vectors
    // TODOTODO note that the current file has units, which is an error; the spec shows no units.
    // See https://wiki.autodesk.com/display/saascore/Tiling+ProteinMaterials.json
    // We (properly) ignore units here, using only the scale factors
    tiling.offsetVectorA.x = parseMaterialScalar(tilingProps, "offset_vector_a_x", 0) * scaleFactor.x;
    tiling.offsetVectorA.y = parseMaterialScalar(tilingProps, "offset_vector_a_y", 0) * scaleFactor.y;
    tiling.offsetVectorB.x = parseMaterialScalar(tilingProps, "offset_vector_b_x", 0) * scaleFactor.x;
    tiling.offsetVectorB.y = parseMaterialScalar(tilingProps, "offset_vector_b_y", 0) * scaleFactor.y;
    tiling.hasRoundCorner = tiling.cornerRoundingAngle > 0 && tiling.cornerRoundingSize > 0;
    var ti = void 0,
        tlen = void 0;
    // where we put the materials for the individual tilings, before "real" decals are applied
    // scale vertices directly into world units, in place
    var tiles = [];
    for (ti = 0, tlen = inputTiles.length; ti < tlen; ti++) {
        var inputTileProps = inputTiles[ti]["properties"];
        var tile = {
            material: decals[ti].material,
            randomOffsetMode: 0,
            rotation: 0,
            vertices: []
        };
        tiles[ti] = tile;
        // move tile information over from TilingAppearanceSchema
        tile.randomOffsetMode = parseMaterialGeneric(inputTileProps, "choicelists", "random_offset_mode", 0);
        // TODOTODO - it is not documented as to what the units are for angles. Once known, add & implement
        tile.rotation = parseMaterialScalar(inputTileProps, "rotation_angle", 0) * Math.PI / 180.0;
        // copy vertex array into Vector2's
        var vertList = inputTileProps["scalars"]["vertices"]["values"];
        for (var i = 0; i < vertList.length; i += 2) {
            tile.vertices[i / 2] = new THREE$1.Vector2(vertList[i], vertList[i + 1]);
        }
        // Use world scale factors to scale up vertices. Note there is no per-vertex-set unit scale factor.
        for (var vi = 0; vi < tile.vertices.length; vi++) {
            tile.vertices[vi].multiply(scaleFactor);
        }
        // per tile derived information; material just needs to know that random mode is on,
        // mode info is baked into the material's textures and vectors
        tile.material.useRandomOffset = tile.randomOffsetMode != 0;
    }
    // translate tile material asset and add the tile
    rasterizeTiles(tiling, tiles);
    // fill in uniforms
    var m2x2 = [tiling.offsetVectorA.clone(), tiling.offsetVectorB.clone()];
    var invM2x2 = invert(m2x2);
    for (ti = 0, tlen = tiles.length; ti < tlen; ti++) {
        var _tile = tiles[ti];
        var material = _tile.material;
        // TODOTODOTODO these should perhaps just be put in material, end of story?
        material.tilingOverallTransform = tiling.overallTransform;
        material.hasRoundCorner = tiling.hasRoundCorner;
        // per-tile texture rotation - TODO could be a 3x3, really
        material.tilingUVTransform = rotate_euler(_tile.rotation);
        if (material.useRandomOffset) {
            // compute random offset axis, and texture offset to support Bounded random mode
            computeRandomnessParameters(material, _tile);
        }
        // OGS: SetTilingParameters
        // calculate tile to uv and uv to tile transform matrixes
        material.tile2uv = new THREE$1.Vector4(tiling.offsetVectorA.x, tiling.offsetVectorA.y, tiling.offsetVectorB.x, tiling.offsetVectorB.y);
        material.uv2tile = new THREE$1.Vector4(invM2x2[0].x, invM2x2[0].y, invM2x2[1].x, invM2x2[1].y);
    }
}
function rasterizeTiles(tiling, tiles) {
    // calculate the tile repeat box, which is the parallelogram formed by repeat axis A & B
    var tileRepeatABBox = new THREE$1.Box2();
    tileRepeatABBox.expandByPoint(new THREE$1.Vector2(0.0, 0.0));
    tileRepeatABBox.expandByPoint(tiling.offsetVectorA);
    tileRepeatABBox.expandByPoint(tiling.offsetVectorB);
    var vec = new THREE$1.Vector2(tiling.offsetVectorA.x, tiling.offsetVectorA.y);
    vec.add(tiling.offsetVectorB);
    tileRepeatABBox.expandByPoint(vec);
    var ti = void 0,
        tlen = void 0;
    // for each tile
    for (ti = 0, tlen = tiles.length; ti < tlen; ti++) {
        var tile = tiles[ti];
        // compute repeat range that tile may cover the repeat ABBox
        tile.material.tilingRepeatRange = [];
        computeRange(tiling, tile, tile.material.tilingRepeatRange);
        // compute bbox - we compute this once, early on, since it is used by buildMSDFTexture
        tile.bbox = new THREE$1.Box2();
        for (var v = 0; v < tile.vertices.length; ++v) {
            tile.bbox.expandByPoint(tile.vertices[v]);
        }
        // build MSDF texture for the tile
        buildMSDFTexture(tiling, tile);
        // build normal map if it has a rounding corner
        if (tiling.hasRoundCorner) {
            buildNormalMap(tiling, tile);
        }
        // build randomness map if random is enabled
        if (tile.material.useRandomOffset) {
            buildRandomnessMap(tile, ti);
        }
        // reset tile vertices to align with tile bounding box
        tile.alignedVertices = [];
        for (var _v = 0; _v < tile.vertices.length; ++_v) {
            var newPoint = new THREE$1.Vector2(tile.vertices[_v].x, tile.vertices[_v].y);
            newPoint.sub(tile.bbox.min);
            tile.alignedVertices.push(newPoint);
        }
        // set tile alignment offset. It moves origin of tile texture UV to left-bottom corner of
        // tile bounding box. OGS calls this tileOffset
        tile.material.tileAlignOffset = new THREE$1.Vector2(-tile.bbox.min.x, -tile.bbox.min.y);
    }
}
function computeNormalToEdges(tile, cornerRoundingAngle) {
    tile.normalToEdges = [];
    var edges = tile.vertices.length;
    var zComponent = Math.cos(cornerRoundingAngle);
    var factor = Math.sin(cornerRoundingAngle); // 1.0 - zComponent * zComponent;
    for (var edgeIndex = 0; edgeIndex < edges; ++edgeIndex) {
        var startIndex = edgeIndex;
        var endIndex = edgeIndex == edges - 1 ? 0 : edgeIndex + 1;
        var tempEdge = new THREE$1.Vector2(tile.vertices[endIndex].x, tile.vertices[endIndex].y);
        tempEdge.sub(tile.vertices[startIndex]);
        tempEdge.normalize();
        var normalToEdge = new THREE$1.Vector3(tempEdge.y * factor, -tempEdge.x * factor, zComponent);
        tile.normalToEdges.push(normalToEdge);
    }
    tile.cornerRoundingAngle = cornerRoundingAngle;
}
function distanceToSegment(q, p0, p1) {
    var d = new THREE$1.Vector2(p1.x, p1.y).sub(p0);
    var qp0 = new THREE$1.Vector2(q.x, q.y).sub(p0);
    var t = d.dot(qp0);
    if (t <= 0.0) {
        // p0 is closest to q
        return qp0.length();
    }
    var d2 = d.dot(d);
    if (t >= d2) {
        // p1 is closest to q
        var qp1 = new THREE$1.Vector2(q).sub(p1);
        return qp1.length();
    }
    // otherwise closest point is interior to segment
    return Math.sqrt(Math.max(qp0.dot(qp0) - t * t / d2, 0.0));
}
// TileTexturalizer::Tile::DistanceToTile
function distanceToTileAndIndex(tile, pixelLoc) {
    var bestDistance = 10e10;
    var currentDistance = bestDistance;
    var edgeIndex = -1;
    for (var i = 0; i < tile.vertices.length; i++) {
        var j = i == tile.vertices.length - 1 ? 0 : i + 1;
        currentDistance = distanceToSegment(pixelLoc, tile.vertices[i], tile.vertices[j]);
        if (currentDistance < bestDistance) {
            bestDistance = currentDistance;
            edgeIndex = i;
        }
    }
    return [bestDistance, edgeIndex];
}
function pointInTilePolygon(vertices, x, y) {
    var polyCorners = vertices.length;
    var j = polyCorners - 1;
    var oddNodes = false;
    for (var i = 0; i < polyCorners; ++i) {
        if (vertices[i].y < y && vertices[j].y >= y || vertices[j].y < y && vertices[i].y >= y) {
            if (vertices[i].x + (y - vertices[i].y) / (vertices[j].y - vertices[i].y) * (vertices[j].x - vertices[i].x) < x) {
                oddNodes = !oddNodes;
            }
        }
        j = i;
    }
    return oddNodes;
}
function buildNormalMap(tiling, tile) {
    var tileBBSize = tile.bbox.size();
    // Evaluate the size for normal map texture.
    // to make normal map provide enough precision in the case of large tile but small corner size,
    // the normal map must use enough texels to cover the rounding edge. To sample correct normal 
    // on the edge, we extend normal map out by another mCornerRoundingRadius distance. Also notice,
    // normal value is continually at the inner side of the rounding edge, but discontinuity on the 
    // outside. So we need 3 texels to cover the rounding edge. Also consider the worst case of 45
    // degree case, our final pixel size is mCornerRoundingRadius * 2.0 / sqrt(2) / 3.0;
    var pixelSize = tiling.cornerRoundingSize * 2.0 * 0.7071 / 3.0;
    // To prevent meaningless sampling on normal texture bounding, add one pixel gap on each bound.
    // also, to prevent too small or too large texture size, limit texture size between 128 and 1024
    var width = clamp(Math.ceil(tileBBSize.x / pixelSize) + 2, 128, 1024);
    var height = clamp(Math.ceil(tileBBSize.y / pixelSize) + 2, 128, 1024);
    // Adjust the width or height so the ratio is the same as tileBBSize.
    {
        // leave out one pixel on boundary
        width -= 2;
        height -= 2;
        if (tileBBSize.x < tileBBSize.y) {
            // scale to keep width/height factor
            height = Math.floor(width * tileBBSize.y / tileBBSize.x);
        } else {
            // scale to keep width/height factor
            width = Math.floor(height * tileBBSize.x / tileBBSize.y);
        }
        // add back bounding pixel
        width += 2;
        height += 2;
    }
    computeNormalToEdges(tile, tiling.cornerRoundingAngle);
    var pixels = new Uint8Array(width * height * 4);
    // scale factor from tile vertices to image
    // scaled in one pixel each side for correct bilinear sampling on bound
    var scale = new THREE$1.Vector2(tileBBSize.x / (width - 2), tileBBSize.y / (height - 2));
    var pixelLoc = new THREE$1.Vector2();
    var pointNormal = new THREE$1.Vector3();
    var defaultNormal = new THREE$1.Vector3(0.0, 0.0, 1.0);
    //console.log("P3\n" + width + " " + height + "\n255");
    var idx = 0;
    for (var i = 0; i < height; i++) {
        // Begin from -1 for the one pixel left out along the edge. Move 0.5f to center the texel.
        // NOTE: we do a y reverse here for the texture, OpenGL-style. DX is simply "(i - 0.5)".
        pixelLoc.y = (height - i - 1.5) * scale.y + tile.bbox.min.y;
        for (var j = 0; j < width; j++) {
            // Begin from -1 for the one pixel left out. Move 0.5f to center the texel. 
            pixelLoc.x = (j - 0.5) * scale.x + tile.bbox.min.x;
            // we always calculate distance to tile for all pixels, but only write down normal into
            // normal map for distance less than corner rounding radius, so that we can have smooth
            // normal from tile center to edge. We add negative flag to pixels that out of polygon, 
            // so that we would have correct interpreted value on edge
            var dttei = distanceToTileAndIndex(tile, pixelLoc);
            var distanceToTile = dttei[0];
            var edgeIndex = dttei[1];
            if (distanceToTile < tiling.cornerRoundingSize + tiling.insetSize) {
                if (!pointInTilePolygon(tile.vertices, pixelLoc.x, pixelLoc.y)) {
                    distanceToTile = -distanceToTile;
                }
                pointNormal.copy(tile.normalToEdges[edgeIndex]);
                pointNormal.lerp(defaultNormal, (distanceToTile - tiling.insetSize) / tiling.cornerRoundingSize);
                pointNormal.normalize();
                // to avoid value flow out of 8-bit storage, we save normalized pointNormal in 
                // normal map. In pixel shader, we need minus (0,0,1) to get normal diff, then 
                // apply the normal diff to geometry normal
                // Note that Math.int is implied, as these get stored in unsigned ints
                pixels[idx++] = clamp((pointNormal.x + 1.0) * 0.5, 0.0, 1.0) * 255;
                pixels[idx++] = clamp((pointNormal.y + 1.0) * 0.5, 0.0, 1.0) * 255;
                pixels[idx++] = clamp((pointNormal.z + 1.0) * 0.5, 0.0, 1.0) * 255;
                pixels[idx++] = 255;
            } else {
                pixels[idx++] = 127;
                pixels[idx++] = 127;
                pixels[idx++] = 255;
                pixels[idx++] = 255;
            }
            //console.log(pixels[idx-4] + " " + pixels[idx-3] + " " + pixels[idx-2] + " ");
        }
    }
    //console.log("============ NORMAL BREAK ==============");
    // https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/texParameter
    // there is no "border color" supported for textures in WebGL, no BorderColor(OGS::float4(0.5f, 0.5f, 0.5f, 1.0f)
    // which would call mCtx->GLAPI()->glTexParameterfv(mObjTarget,_kGL_TEXTURE_BORDER_COLOR, border);
    // Create tile pattern texture
    tile.material.TilingNormalMap = new THREE$1.DataTexture(pixels, width, height, THREE$1.RGBAFormat, THREE$1.UnsignedByteType, THREE$1.UVMapping, THREE$1.ClampToEdgeWrapping, THREE$1.ClampToEdgeWrapping, THREE$1.LinearFilter, THREE$1.LinearFilter);
    // You'd think this would be the default setting for a new DataTexture. You'd be wrong. Without it the texture will not get loaded.
    tile.material.TilingNormalMap.needsUpdate = true;
    var tileBBOffset = new THREE$1.Vector2(-tile.bbox.min.x, -tile.bbox.min.y);
    tile.material.TilingNormalMap_texMatrix = new THREE$1.Matrix3();
    // note that the original C++ code assumes row-major form (translations in the bottom row), while three.js
    // assumes column-major, though of course internally putting the translations in the last 4 spots in the array.
    // Rather than mess with the code, we keep the row-major form here, and then transpose.
    // NOTE: we use a 3x3 transform here, unlike OGS.
    tile.material.TilingNormalMap_texMatrix.set(1.0 / tileBBSize.x * (width - 2.0) / width, 0.0, 0.0, 0.0, 1.0 / tileBBSize.y * (height - 2.0) / height, 0.0,
    //0.0, 0.0, 1.0, 0.0,
    tileBBOffset.x / tileBBSize.x * (width - 2.0) / width + 1.0 / width, tileBBOffset.y / tileBBSize.y * (height - 2.0) / height + 1.0 / height, 1.0);
    tile.material.TilingNormalMap_texMatrix.transpose();
}
function burtlerot(x, k) {
    return x << k | x >>> 32 - k; // note >>> if you ever touch this code: need this zero-fill shift for unsigned ints
}
function burtlefinal(a, b, c) {
    var fullbits = 4294967296; // 2**32
    c ^= b;
    c = (c - burtlerot(b, 14) + fullbits) % fullbits;
    a ^= c;
    a = (a - burtlerot(c, 11) + fullbits) % fullbits;
    b ^= a;
    b = (b - burtlerot(a, 25) + fullbits) % fullbits;
    c ^= b;
    c = (c - burtlerot(b, 16) + fullbits) % fullbits;
    a ^= c;
    a = (a - burtlerot(c, 4) + fullbits) % fullbits;
    b ^= a;
    b = (b - burtlerot(a, 14) + fullbits) % fullbits;
    c ^= b;
    c = (c - burtlerot(b, 24) + fullbits) % fullbits;
    return c;
}
function burtlehashword(key, /* the key */
//we assume key length of 2, as this is how OGS always uses it
//size_t          length,               /* the length of the key, in uint32_ts */
initval) {
    var a = void 0,
        b = void 0,
        c = void 0;
    /* Set up the internal state */
    a = b = c = 0xdeadbeef + (2 << 2) + initval;
    b += key.y;
    a += key.x;
    return burtlefinal(a, b, c);
}
// stripped way down from the OGS version, which always uses a seed array of size 2.
// From //depot/Raas/current/rsut/include/rsut/detail/burtle_hash_impl.hpp
function burtleNoise2Byte(seed2, result2) {
    var hash = burtlehashword(seed2, 33);
    // low 16bit for x, and high 16bit for y, converted to 0-255 pixel values
    result2.x = (hash & 0xFFFF) >>> 8;
    result2.y = hash >>> 16 >>> 8;
}
function buildRandomnessMap(tile, seed) {
    var width = 512;
    var height = 512;
    var PRIME = 107021;
    var pixels = new Uint8Array(width * height * 4);
    var pixelLoc = new THREE$1.Vector2();
    var seedVector = new THREE$1.Vector2(PRIME * seed, seed);
    var hashTranslationID = new THREE$1.Vector2();
    var randomOffset = new THREE$1.Vector2();
    //console.log("P3\n" + width + " " + (height/16) + "\n255");
    var idx = 0;
    for (var i = 0; i < height; i++) {
        // Begin from -1 for the one pixel left out along the edge. Move 0.5f to center the texel.
        // Move (0,0) to the center of texture
        // NOTE: we do a y reverse here for the texture, OpenGL-style. DX is simply "i - height / 2".
        //pixelLoc.y = Math.floor(i - height / 2); // Original code. For testing against OGS
        pixelLoc.y = Math.floor(-(i + 1 - height / 2));
        for (var j = 0; j < width; j++) {
            // Move (0,0) to the center of texture 
            pixelLoc.x = Math.floor(j - width / 2);
            hashTranslationID.copy(pixelLoc);
            hashTranslationID.add(seedVector);
            burtleNoise2Byte(hashTranslationID, randomOffset);
            pixels[idx++] = 0; // unused byte
            pixels[idx++] = 0; // unused byte
            pixels[idx++] = randomOffset.x;
            pixels[idx++] = randomOffset.y;
            //if ( i % 16 === 0 )
            //    console.log(pixels[idx-3] + " " + pixels[idx-2] + " " + pixels[idx-1] + " ");
        }
    }
    //console.log("============ NORMAL BREAK ==============");
    // Create tile pattern texture
    tile.material.TilingRandomMap = new THREE$1.DataTexture(pixels, width, height, THREE$1.RGBAFormat, THREE$1.UnsignedByteType, THREE$1.UVMapping, THREE$1.RepeatWrapping, THREE$1.RepeatWrapping, THREE$1.NearestFilter, THREE$1.NearestFilter);
    // You'd think this would be the default setting for a new DataTexture. You'd be wrong. Without it the texture will not get loaded.
    tile.material.TilingRandomMap.needsUpdate = true;
    var tileBBOffset = new THREE$1.Vector2(-tile.bbox.min.x, -tile.bbox.min.y);
    tile.material.TilingRandomMap_texMatrix = new THREE$1.Matrix3();
    // note that the original C++ code assumes row-major form (translations in the bottom row), while three.js
    // assumes column-major, though of course internally putting the translations in the last 4 spots in the array.
    // Rather than mess with the code, we keep the row-major form here, and then transpose.
    // NOTE: we use a 3x3 transform here, unlike OGS.
    tile.material.TilingRandomMap_texMatrix.set(1.0 / width, 0.0, 0.0, 0.0, 1.0 / height, 0.0,
    //0.0, 0.0, 1.0, 0.0,
    0.5, 0.5, 1.0);
    tile.material.TilingRandomMap_texMatrix.transpose();
}
function computeRange(tiling, tile, range) {
    // convert all tile vertices to repeat space, then compute bounding box in repeat space.
    // The repeat space is a 2D space by repeat vector mAxisA and mAxisB as its axis.
    var repeat2tile = [];
    repeat2tile[0] = new THREE$1.Vector2(tiling.offsetVectorA.x, tiling.offsetVectorB.x);
    repeat2tile[1] = new THREE$1.Vector2(tiling.offsetVectorA.y, tiling.offsetVectorB.y);
    var tile2repeat = invert(repeat2tile);
    var bounding = new THREE$1.Box2();
    var vertInRepeatSpace = new THREE$1.Vector2();
    for (var v = 0; v < tile.vertices.length; ++v) {
        vertInRepeatSpace.x = tile.vertices[v].dot(tile2repeat[0]);
        vertInRepeatSpace.y = tile.vertices[v].dot(tile2repeat[1]);
        bounding.expandByPoint(vertInRepeatSpace);
    }
    // compute the offset range, that,
    //     uv + offset = st, where uv belongs to [0, 1]x[0, 1]
    //                             st belongs to bounding of tile
    // This code is more efficient, but fails in a tiny way for
    // OGS test Protein_Material_PrismTiling_TwoObj_Random1
    //let epsilon = 1e-6;
    //range[0] = Math.floor(bounding.min.x + epsilon);
    //range[2] = Math.ceil(bounding.max.x - epsilon);
    //range[1] = Math.floor(bounding.min.y + epsilon);
    //range[3] = Math.ceil(bounding.max.y - epsilon);
    // OGS method. I suspect adding & subtracting epsilon, as above, can be more efficient
    // if there are precision problems.
    range[0] = Math.floor(bounding.min.x - 1);
    range[2] = Math.ceil(bounding.max.x);
    range[1] = Math.floor(bounding.min.y - 1);
    range[3] = Math.ceil(bounding.max.y);
}
function invert(m) {
    var det = m[0].x * m[1].y - m[0].y * m[1].x;
    var inverse = [];
    inverse[0] = new THREE$1.Vector2(m[1].y / det, -m[0].y / det);
    inverse[1] = new THREE$1.Vector2(-m[1].x / det, m[0].x / det);
    return inverse;
}
function clamp(v, min, max) {
    if (v > max) return max;
    if (v < min) return min;
    return v;
}
function constructMSDF(shape, tile) {
    // construct MSDF sharp by adding tile polygon as a contor of MSDF
    var contour = shape.addBlankContour();
    var edgeStartPoint = new THREE$1.Vector2();
    var edgeEndPoint = new THREE$1.Vector2();
    for (var e = 0; e < tile.vertices.length; ++e) {
        var edgeStart = e;
        var edgeEnd = (e + 1) % tile.vertices.length;
        edgeStartPoint = tile.vertices[edgeStart];
        edgeEndPoint = tile.vertices[edgeEnd];
        contour.addEdge(new MSDFLinearSegment(edgeStartPoint, edgeEndPoint, MSDF_EDGE_COLOR_WHITE));
    }
    shape.initialize();
    shape.edgeColoringSimple(3.0, 0);
}
function buildMSDFTexture(tiling, tile) {
    // construct the shape of MSDF
    var msdfShape = new MSDFShape();
    constructMSDF(msdfShape, tile);
    // rasterize tile into MSDF texture
    var tileBBSize = tile.bbox.size();
    // Evaluate the size for MSDF texture.
    // to prevent MSDF value overlap, the MSDF texture must use more than two texels to cover the
    // shortest distance between any two same colored edges. The shortest distance would face to 
    // arbitrary direction, we need consider the worst case, the 45 degree direction. So here use
    // msdfShape.MinSameColoredEdgeDistance() / sqrt(2) as the minimum same colored edge distance
    // on image x and y direction. The direction must cover at least two texels, so our final pixel
    // size is msdfShape.MinSameColoredEdgeDistance() / sqrt(2) / 2.0
    var pixelSize = msdfShape.minSameColoredEdgeDistance() * 0.7071 * 0.5;
    // The final texture size is the tile region to be texturalized divide pixel size. 
    // notice warp repeat on tile texture does not make sense. To prevent meaningless sampling on
    // tile texture bounding, add one pixel gap on each bound.
    // also, to prevent too small or too large texture size, limit texture size between 16 and 512.
    var width = clamp(Math.ceil(tileBBSize.x / pixelSize) + 2, 16, 512);
    var height = clamp(Math.ceil(tileBBSize.y / pixelSize) + 2, 16, 512);
    // use RGBA8 formated texture
    //    EFormat format = vd.Caps()->GetCompatibleFormat(EFORMAT_B8G8R8A8, TextureUsage);
    //    int bytesPerPixel = AFormatConvertor::BytesPerPixel(format);
    //    int bytesPerRow = width * bytesPerPixel;
    //    size_t totalImageSize = bytesPerRow*height;
    //    unsigned char* pImageData = new unsigned char[totalImageSize];
    //    int pixelOffset = bytesPerPixel;
    var pixels = new Uint8Array(width * height * 4);
    // leave out one pixel each side for correct bilinear sampling on bound
    var scale = new THREE$1.Vector2(tileBBSize.x / (width - 2), tileBBSize.y / (height - 2));
    var imageToTileScale = new THREE$1.Vector2(scale.x * width, scale.y * height);
    //    unsigned char *pixel = pImageData;
    // factor for cut out pixel values in MSDF texture
    var oneOverDistanceUnit = 0.5 / (scale.x + scale.y);
    var pixelLoc = new THREE$1.Vector2();
    var msdf = new THREE$1.Vector3();
    var idx = 0;
    //console.log("P3\n" + width + " " + height + "\n255");
    for (var i = 0; i < height; i++) {
        // Begin from -1 for the one pixel left out along the edge. Move 0.5f to center the texel.
        // NOTE: we do a y reverse here for the texture, OpenGL-style. DX is simply "(i - 0.5)".
        pixelLoc.y = (height - i - 1.5) * scale.y + tile.bbox.min.y;
        for (var j = 0; j < width; j++) {
            // Begin from -1 for the one pixel left out. Move 0.5f to center the texel. 
            pixelLoc.x = (j - 0.5) * scale.x + tile.bbox.min.x;
            // get the MSDF value for (x,y)
            msdf = msdfShape.calculateMSDFValue(pixelLoc);
            // considering inset, the real tile edge is the distance to tile edge minus inset size.
            // our msdf is always negative value for inside pixels, so final msdf is msdf+insetSize.
            msdf = msdf.add(new THREE$1.Vector3(tiling.insetSize, tiling.insetSize, tiling.insetSize));
            // compact float value into 8-bit int
            pixels[idx++] = clamp(msdf.x * oneOverDistanceUnit + 0.5, 0.0, 1.0) * 255.0;
            pixels[idx++] = clamp(msdf.y * oneOverDistanceUnit + 0.5, 0.0, 1.0) * 255.0;
            pixels[idx++] = clamp(msdf.z * oneOverDistanceUnit + 0.5, 0.0, 1.0) * 255.0;
            pixels[idx++] = 0;
            //console.log(pixels[idx-4] + " " + pixels[idx-3] + " " + pixels[idx-2] + " ");
        }
    }
    // Create tile pattern texture
    tile.material.TilingMap = new THREE$1.DataTexture(pixels, width, height, THREE$1.RGBAFormat, THREE$1.UnsignedByteType, THREE$1.UVMapping, THREE$1.ClampToEdgeWrapping, THREE$1.ClampToEdgeWrapping, THREE$1.LinearFilter, THREE$1.LinearFilter);
    // You'd think this would be the default setting for a new DataTexture. You'd be wrong. Without it the texture will not get loaded.
    tile.material.TilingMap.needsUpdate = true;
    // https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/texParameter
    // there is no "border color" supported for textures in WebGL, no BorderColor(OGS::float4(1.0f, 1.0f, 1.0f, 1.0f)
    // which would call mCtx->GLAPI()->glTexParameterfv(mObjTarget,_kGL_TEXTURE_BORDER_COLOR, border);
    var tileBBOffset = new THREE$1.Vector2(-tile.bbox.min.x, -tile.bbox.min.y);
    tile.material.TilingMap_texMatrix = new THREE$1.Matrix3();
    // note that the original C++ code assumes row-major form (translations in the bottom row), while three.js
    // assumes column-major, though of course internally putting the translations in the last 4 spots in the array.
    // Rather than mess with the code, we keep the row-major form here, and then transpose.
    // NOTE: we use a 3x3 transform here, unlike OGS.
    tile.material.TilingMap_texMatrix.set(1.0 / tileBBSize.x * (width - 2.0) / width, 0.0, 0.0, 0.0, 1.0 / tileBBSize.y * (height - 2.0) / height, 0.0,
    //0.0, 0.0, 1.0, 0.0,
    tileBBOffset.x / tileBBSize.x * (width - 2.0) / width + 1.0 / width, tileBBOffset.y / tileBBSize.y * (height - 2.0) / height + 1.0 / height, 1.0);
    // normally we would set the matrix above with the translations in the column, but we match the code in OGS for
    // maintainability, so we need to transpose here.
    tile.material.TilingMap_texMatrix.transpose();
}
function convertPrismTexture(textureObj, texture, sceneUnit) {
    var texProps = textureObj["properties"];
    // Note that the format of these booleans is different for Protein than for regular materials:
    // Prism: "texture_URepeat": { "values": [ false ] },
    // simple texture: "texture_URepeat":    false,
    texture.clampS = !parseMaterialGeneric(texProps, "booleans", "texture_URepeat", false);
    texture.clampT = !parseMaterialGeneric(texProps, "booleans", "texture_VRepeat", false);
    texture.wrapS = !texture.clampS ? THREE$1.RepeatWrapping : THREE$1.ClampToEdgeWrapping;
    texture.wrapT = !texture.clampT ? THREE$1.RepeatWrapping : THREE$1.ClampToEdgeWrapping;
    texture.matrix = textureObj.matrix || (textureObj.matrix = Get2DPrismMapTransform(texProps, sceneUnit));
    if (textureObj["definition"] == "UnifiedBitmap") {
        texture.invert = parseMaterialGeneric(texProps, "booleans", "unifiedbitmap_Invert", false);
    }
    if (textureObj["definition"] == "BumpMap") {
        texture.bumpmapType = parseMaterialGeneric(texProps, "choicelists", "bumpmap_Type", 0);
        texture.bumpScale = GetBumpScale(texProps, texture.bumpmapType, sceneUnit);
    }
}
function Get2DSimpleMapTransform(texProps) {
    var uscale = parseMaterialScalar(texProps, "texture_UScale", 1);
    var vscale = parseMaterialScalar(texProps, "texture_VScale", 1);
    var uoffset = parseMaterialScalar(texProps, "texture_UOffset", 0);
    var voffset = parseMaterialScalar(texProps, "texture_VOffset", 0);
    var wangle = parseMaterialScalar(texProps, "texture_WAngle", 0);
    return { elements: [Math.cos(wangle) * uscale, Math.sin(wangle) * vscale, 0, -Math.sin(wangle) * uscale, Math.cos(wangle) * vscale, 0, uoffset, voffset, 1] };
}
function convertSimpleTexture(textureObj, texture) {
    if (!textureObj) return;
    var texProps = textureObj["properties"];
    // Note that the format of these booleans is different for Protein than for regular materials:
    // Prism: "texture_URepeat": { "values": [ false ] },
    // simple texture: "texture_URepeat":    false,
    texture.invert = parseMaterialBoolean(texProps, "unifiedbitmap_Invert");
    texture.clampS = !parseMaterialBoolean(texProps, "texture_URepeat", true); // defaults to wrap
    texture.clampT = !parseMaterialBoolean(texProps, "texture_VRepeat", true);
    texture.wrapS = !texture.clampS ? THREE$1.RepeatWrapping : THREE$1.ClampToEdgeWrapping;
    texture.wrapT = !texture.clampT ? THREE$1.RepeatWrapping : THREE$1.ClampToEdgeWrapping;
    texture.matrix = textureObj.matrix || (textureObj.matrix = Get2DSimpleMapTransform(texProps));
}
function get2DMapTransform(textureObj, isPrism, sceneUnit) {
    if (!textureObj.matrix) {
        if (isPrism) {
            textureObj.matrix = Get2DPrismMapTransform(textureObj.properties, sceneUnit);
        } else {
            textureObj.matrix = Get2DSimpleMapTransform(textureObj.properties);
        }
    }
    return textureObj.matrix;
}
function convertTexture(textureDef, texture, sceneUnit, maxAnisotropy) {
    if (textureDef.mapName == "bumpMap" || textureDef.mapName == "normalMap") {
        texture.anisotropy = 0;
    } else {
        texture.anisotropy = maxAnisotropy || 0;
    }
    // Default params
    texture.flipY = textureDef.flipY !== undefined ? textureDef.flipY : true;
    texture.invert = false;
    texture.wrapS = THREE$1.RepeatWrapping;
    texture.wrapT = THREE$1.RepeatWrapping;
    //Per material type settings
    if (textureDef.isPrism) convertPrismTexture(textureDef.textureObj, texture, sceneUnit);else convertSimpleTexture(textureDef.textureObj, texture);
    // semi-fix for LMV-1832 - doesn't work for procedural wood, though.
    // if ( av.isIE11 && textureDef.isPrism ) {
    //      for (var i = 0; i < 4; i++)
    //          texture.matrix.elements[(i<2)?i:(i+1)] *= 0.5;  // elements 0,1,3,4
    // }
}
function isPrismMaterial(material) {
    var innerMats = material['materials'];
    var innerMat = innerMats[material['userassets'][0]];
    if (innerMat) {
        var definition = innerMat['definition'];
        if (definition === 'TilingPattern') {
            // if first "material" is a tiling pattern, look at the grout material, which must always exist.
            var idx = innerMat.properties.references.grout_material.connections[0];
            innerMat = innerMats[idx];
            if (innerMat) {
                definition = innerMat['definition'];
            } // else it stays TilingPattern and will fail below
        }
        return definition == 'PrismLayered' || definition == 'PrismMetal' || definition == 'PrismOpaque' || definition == 'PrismTransparent' || definition == 'PrismGlazing' || definition == 'PrismWood';
    }
    return false;
}
function hasTiling(material) {
    var innerMats = material['materials'];
    var innerMat = innerMats[material['userassets'][0]];
    if (innerMat) {
        var definition = innerMat['definition'];
        if (definition === 'TilingPattern') {
            return true;
        }
    }
    return false;
}
function convertMaterialGltf(matObj, svf) {
    var tm = new THREE$1.MeshPhongMaterial();
    tm.packedNormals = true;
    tm.textureMaps = {};
    var values = matObj.values;
    var diffuse = values.diffuse;
    if (diffuse) {
        if (Array.isArray(diffuse)) {
            tm.color = new THREE$1.Color(diffuse[0], diffuse[1], diffuse[2]);
        } else if (typeof diffuse === "string") {
            //texture
            tm.color = new THREE$1.Color(1, 1, 1);
            var map = {};
            map.mapName = "map";
            var texture = svf.gltf.textures[diffuse];
            //Use the ID of the texture, because in MaterialManager.loadTexture, the ID
            //is mapped to the path from the asset list. The logic matches what is done
            //with SVF materials.
            map.uri = texture.source; //svf.manifest.assetMap[texture.source].URI;
            map.flipY = false; //For GLTF, texture flip is OpenGL style by default, unlike Protein/Prism which is DX
            tm.textureMaps[map.mapName] = map;
        }
    }
    var specular = values.specular;
    if (specular) {
        tm.specular = new THREE$1.Color(specular[0], specular[1], specular[2]);
    }
    if (values.shininess) tm.shininess = values.shininess;
    tm.reflectivity = 0;
    //TODO: Where to get this for glTF materials?
    tm.transparent = false;
    return tm;
}
//Using post-gamma luminance, since input colors are assumed to
//have gamma (non-linearized).
function luminance(c) {
    return 0.299 * c.r + 0.587 * c.g + 0.114 * c.b;
}
function applyAppearanceHeuristics(mat, skipSimplePhongSpecific, depthWriteTransparent) {
    var proteinMaterial = mat.proteinMat ? mat.proteinMat : null;
    var isPrism = mat.prismType && mat.prismType.indexOf("Prism") !== -1;
    if (isPrism && mat.transparent) {
        // currently Fusion objects come in as double-sided. Once ATF and Fusion fix this, they
        // can come in as single-sided. For PRISM materials that are transparent, make these
        // always be double sided, so they render properly in two passes, back and front displayed.
        // The side for PrismGlazing materials is set from glazing_backface_culling property
        // so don't override it here.
        if (mat.side === THREE$1.FrontSide && mat.prismType != "PrismGlazing") mat.side = THREE$1.DoubleSide;
        // Add a flag that notes that two-pass transparency is to be used. This is meant for Fusion in
        // particular, where transparent objects are rendered in two passes, back faces then front faces.
        // This can cause problems with other, arbitrary geometry, such as found in
        // https://jira.autodesk.com/browse/LMV-1121.
        // If we want to extend this two-pass rendering method to all materials, we have to come up
        // with some rules for how to differentiate data here.
        if (mat.side === THREE$1.DoubleSide && mat.depthTest) mat.twoPassTransparency = true;
        //else
        //    mat.twoPassTransparency = false;
    }
    //apply various modifications to fit our rendering pipeline
    if (!skipSimplePhongSpecific) {
        //Is it a SimplePhong which was converted from a Prism source?
        var isSimpleFromPrism = mat.proteinType && mat.proteinType.indexOf("Prism") !== -1;
        //This pile of crazy hacks maps the various flavors of materials
        //to the shader parameters that we can handle.
        if (mat.metal) {
            if (!mat.reflectivity) {
                mat.reflectivity = luminance(mat.specular);
            }
            //Special handling for Protein and Prism metals
            if (proteinMaterial) {
                //For Prism metals, reflectivity is set to 1 and
                //the magnitude of the specular component acts
                //as reflectivity.
                if (mat.reflectivity === 1) mat.reflectivity = luminance(mat.specular);
                if (mat.color.r === 0 && mat.color.g === 0 && mat.color.b === 0) {
                    //Prism metals have no diffuse at all, but we need a very small
                    //amount of it to look reasonable
                    //mat.color.r = mat.specular.r * 0.1;
                    //mat.color.g = mat.specular.g * 0.1;
                    //mat.color.b = mat.specular.b * 0.1;
                } else {
                    //For Protein metals, we get a diffuse that is full powered, so we
                    //scale it down
                    mat.color.r *= 0.1;
                    mat.color.g *= 0.1;
                    mat.color.b *= 0.1;
                }
            }
        } else {
            //Non-metal materials
            if (isSimpleFromPrism) {
                var isMetallic = false;
                if (mat.proteinType === "PrismLayered") {
                    //For layered materials, the Prism->Simple translator
                    //stores something other than reflectivity in the
                    //reflectivity term. We also do special handling
                    //for paint clearcoat, and metallic paint. Longer term,
                    //the good solution is to add things we do support to the Simple
                    //representation, or failing that, support native Prism definitions.
                    mat.clearcoat = true;
                    mat.reflectivity = 0.06;
                    var cats = mat.proteinCategories;
                    if (cats && cats.length && cats[0].indexOf("Metal") != -1) {
                        isMetallic = true;
                    }
                }
                //De-linearize this value in case of Prism, since there it
                //seems to be physical (unlike the color values)
                mat.reflectivity = Math.sqrt(mat.reflectivity);
                if (isMetallic) {
                    //metallic paint has specular = diffuse in Prism.
                    mat.specular.copy(mat.color);
                } else {
                    //Prism non-metals just leave the specular term as 1,
                    //relying on reflectivity alone, but our shader needs
                    //both in different code paths.
                    mat.specular.r = mat.reflectivity;
                    mat.specular.g = mat.reflectivity;
                    mat.specular.b = mat.reflectivity;
                }
            } else {
                //Get a reasonable reflectivity value if there isn't any
                if (!mat.reflectivity) {
                    if (mat.color.r === 1 && mat.color.g === 1 && mat.color.b === 1 && mat.specular.r === 1 && mat.specular.g === 1 && mat.specular.b === 1 && (!mat.textureMaps || !mat.textureMaps.map && !mat.textureMaps.specularMap)) {
                        //This covers specific cases in DWF where metals get diffuse=specular=1.
                        mat.metal = true;
                        mat.reflectivity = 0.7;
                        mat.color.r *= 0.1;
                        mat.color.g *= 0.1;
                        mat.color.b *= 0.1;
                    } else {
                        //General case
                        //For non-metallic materials, reflectivity
                        //varies very little in the range 0.03-0.06 or so
                        //and is never below 0.02.
                        mat.reflectivity = 0.01 + 0.06 * luminance(mat.specular);
                        //For non-metals, reflectivity is either set
                        //correctly or we estimate it above, and the specular color
                        //just carries the hue
                        //Note: Protein (but not Prism) seems to have consistently high reflectivity
                        //values for its non-metals.
                        mat.specular.r *= mat.reflectivity;
                        mat.specular.g *= mat.reflectivity;
                        mat.specular.b *= mat.reflectivity;
                    }
                } else if (mat.reflectivity > 0.3) {
                    //If reflectivity is set explicitly to a high value, but metal is not, assume
                    //the material is metallic anyway and set specular=diffuse
                    //This covers specific cases in DWF.
                    mat.metal = true;
                    mat.specular.r = mat.color.r;
                    mat.specular.g = mat.color.g;
                    mat.specular.b = mat.color.b;
                    mat.color.r *= 0.1;
                    mat.color.g *= 0.1;
                    mat.color.b *= 0.1;
                } else {
                    //For non-metals, reflectivity is either set
                    //correctly or we estimate it above, and the specular color
                    //just carries the hue
                    //Note: Protein (but not Prism) seems to have consistently high reflectivity
                    //values for its non-metals.
                    mat.specular.r *= mat.reflectivity;
                    mat.specular.g *= mat.reflectivity;
                    mat.specular.b *= mat.reflectivity;
                }
                //For transparent non-layered materials, the reflectivity uniform is
                //used for scaling the Fresnel reflection at oblique angles
                //This is a non-physical hack to make stuff like ghosting
                //look reasonable, while having glass still reflect at oblique angles
                if (mat.opacity < 1) mat.reflectivity = 1.0;
            }
        }
        //Alpha test for materials with textures that are potentially opacity maps
        if (mat.transparent || mat.textureMaps && (mat.textureMaps.map && mat.textureMaps.map.uri.toLowerCase().indexOf(".png") !== -1 || mat.textureMaps.alphaMap)) {
            mat.alphaTest = 0.01;
        }
    }
    if (mat.textureMaps && mat.textureMaps.normalMap) {
        var scale = mat.bumpScale;
        if (scale === undefined || scale >= 1) scale = 1;
        mat.normalScale = new THREE$1.Vector2(scale, scale);
    } else {
        if (mat.bumpScale === undefined && mat.textureMaps && (mat.textureMaps.map || mat.textureMaps.bumpMap)) mat.bumpScale = 0.03; //seems like a good subtle default if not given
        else if (mat.bumpScale >= 1) mat.bumpScale = 0.03;
    }
    //Determine if we want depth write on for transparent materials
    //This check is done this way because for the ghosting and selection materials
    //we do not want to enable depth write regardless of what we do for the others
    //in order to get the see-through effect.
    if ((!skipSimplePhongSpecific || isPrism) && mat.transparent) {
        if (isPrism) {
            // normally set depth writing off for transparent surfaces
            mat.lmv_depthWriteTransparent = true;
            mat.depthWrite = !!depthWriteTransparent;
        } else {
            // Some models, such as Assembly_Chopper.svf, improperly are set to be transparent, even though the
            // surface opacity is 1.0.
            // Cutout textures (where opacity is also 1.0) should also not be considered transparent,
            // as far as depthWrite goes.
            if (mat.opacity >= 1.0) {
                var hasAlphaTexture = mat.textureMaps && mat.textureMaps.alphaMap;
                // this is either a surface with a cutout texture, or a defective material definition
                if (!hasAlphaTexture) {
                    // defective - turn transparency off
                    mat.transparency = false;
                }
                // else cutout detected: leave transparency on, leave depthWrite on
            } else {
                // opacity is less than 1, so this surface is meant to be transparent - turn off depth depthWrite
                mat.lmv_depthWriteTransparent = true;
                mat.depthWrite = !!depthWriteTransparent;
            }
        }
    }
    if (mat.shininess !== undefined) {
        //Blinn to Phong (for blurred environment map sampling)
        mat.shininess *= 0.25;
    }
    //if (mat.opacity < 1.0 || (mat.textureMaps && mat.textureMaps.alphaMap))
    //    mat.side = THREE.DoubleSide;
}
//Certain material properties only become available
//once we see a geometry that uses the material. Here,
//we modify the material based on a given geometry that's using it.
function applyGeometryFlagsToMaterial(material, threegeom) {
    if (threegeom.attributes.color) {
        //TODO: Are we likely to get the same
        //material used both with and without vertex colors?
        //If yes, then we need two versions of the material.
        material.vertexColors = THREE$1.VertexColors;
        material.needsUpdate = true;
    }
    //If we detect a repeating texture in the geometry, we assume
    //it is some kind of material roughness pattern and reuse
    //the texture as a low-perturbation bump map as well.
    if (!material.proteinType && threegeom.attributes.uv && threegeom.attributes.uv.isPattern) {
        if (material.map && !material.bumpMap) {
            material.bumpMap = material.map;
            material.needsUpdate = true;
        }
        if (material.textureMaps && material.textureMaps.map && !material.textureMaps.bumpMap) {
            material.textureMaps.bumpMap = material.textureMaps.map;
            material.needsUpdate = true;
        }
        material.bumpScale = 0.03; //seems like a good subtle default if not given
    }
}
var MaterialConverter = {
    convertMaterial: convertMaterial,
    materialTilingPattern: materialTilingPattern,
    convertTexture: convertTexture,
    get2DMapTransform: get2DMapTransform,
    isPrismMaterial: isPrismMaterial,
    hasTiling: hasTiling,
    convertMaterialGltf: convertMaterialGltf,
    applyAppearanceHeuristics: applyAppearanceHeuristics,
    applyGeometryFlagsToMaterial: applyGeometryFlagsToMaterial
};

var createLinePatternTexture = LineStyleDef.CreateLinePatternTexture;
var clonePrismMaterial = PrismShaderUtils.clonePrismMaterial;
/**
 * Helper class that can optionally be used to manage surface/line materials.
 *
 * It has several responsibilities:
 * 1. Keeps track of materials
 * 2. Extends materials with wgs.js specific properties and keeps
 *    materials in sync whenever the properties change
 *
 * @constructor
 */
var MaterialManager = function MaterialManager(renderer) {
    this._renderer = renderer;
    this._textures = {};
    this._texturesToUpdate = [];
    // TODO: use better naming for HDR, non-HDR, override, and line materials
    this._materials = {};
    this._materialsNonHDR = {};
    // Surface material properties
    this._exposureBias = 0.0;
    this._tonemapMethod = 0;
    this._envMapExposure = 1;
    this._envRotationSin = 0.0;
    this._envRotationCos = 1.0;
    this._reflectionMap = null;
    this._irradianceMap = null;
    this._cutplanes = [];
    this._mrtNormals = false;
    this._mrtIdBuffer = undefined;
    this._polygonOffsetOn = false;
    // Line material properties
    this._pixelsPerUnit = 1.0;
    this._layerMaskTex = null;
    this._layersMap = null;
    this._lineStyleTex = null;
    this._selectionTex = null;
    this._swapBlackAndWhite = 0.0;
    this._depthWriteTransparent = true;
    this._needsTwoSided = false;
    this._hasTransparentMaterial = false;
    this.hasPrism = false;
    this.defaultMaterial = new THREE$1.MeshPhongMaterial({
        ambient: 0x030303,
        color: 0x777777,
        specular: 0x333333,
        shininess: 30,
        shading: THREE$1.SmoothShading,
        reflectivity: 0
    });
    //Register the default material
    this.addMaterial("__defaultMaterial__", this.defaultMaterial);
};
/**
 * @enum {number}
 * @readonly
 */
MaterialManager.MATERIAL_VARIANT = {
    INSTANCED: 0,
    VERTEX_IDS: 1
};
// Material and texture management
MaterialManager.prototype.dtor = function () {
    this.cleanup();
    THREE$1.Cache.clear();
};
MaterialManager.prototype._getModelHash = function (model) {
    return 'model:' + (model ? model.id : '') + '|';
};
MaterialManager.prototype._getMaterialHash = function (model, name) {
    // OTG-models have sharable materials with globally unique names. For these, we
    // do not use per-model prefixes.
    if (model && model.isOTG()) {
        // Just return identity, because name is already unique.
        return name;
    }
    return this._getModelHash(model) + 'mat:' + name;
};
MaterialManager.prototype._getTextureHash = function (model, imageUri, mapName) {
    //TODO : It's possible that a texture is used as bitmap and bumpmap. In this situation,
    //if the bitmap is loaded first, the bumpscale won't be updated. To fix this, I added the
    //definition as part of the key. This is a easy fix but will make the texture loaded twice.
    //Ideally, we need to improve the current cache to save the texture properties like matrix,
    //invert flag, separately, because a texture can be used in many places and each of them can
    //have different properties.
    return this._getModelHash(model) + 'tex:' + imageUri + '|map:' + mapName;
};
/**
 * Adds surface material without HDR properties.
 * @param {string} name Unique material name.
 * @param {THREE.ShaderMaterial} mat Surface material.
 */
MaterialManager.prototype.addNonHDRMaterial = function (name, mat) {
    if (!mat.doNotCut) mat.cutplanes = this._cutplanes;
    this._materialsNonHDR[name] = mat;
};
/**
 * Same as addNonHDRMaterial, used for backwards API compatiblity
 * @param name
 * @param mat
 */
MaterialManager.prototype.addMaterialNonHDR = function (name, mat) {
    this.addNonHDRMaterial.call(this, name, mat);
};
/**
 * Adds surface material with HDR properties.
 * @param {string} name Unique material name.
 * @param {THREE.ShaderMaterial} mat Surface material.
 */
MaterialManager.prototype.addHDRMaterial = function (name, mat) {
    if (this._reflectionMap && !mat.disableEnvMap) mat.envMap = this._reflectionMap;
    if (this._irradianceMap) mat.irradianceMap = this._irradianceMap;
    mat.exposureBias = Math.pow(2.0, this._exposureBias);
    mat.tonemapOutput = this._tonemapMethod;
    mat.envMapExposure = this._envMapExposure;
    mat.envRotationSin = this._envRotationSin;
    mat.envRotationCos = this._envRotationCos;
    if (!mat.doNotCut) mat.cutplanes = this._cutplanes;
    this._applyMRTFlags(mat);
    this._applyPolygonOffset(mat, this._polygonOffsetOn);
    this._materials[name] = mat;
};
MaterialManager.prototype.addMaterial = function (name, mat, skipSimplePhongHeuristics) {
    var isPrism = mat.prismType && mat.prismType.indexOf("Prism") !== -1;
    this.hasPrism = isPrism || this.hasPrism;
    // Note if any material added this way is transparent. This property can be used to shortcut various
    // refreshes, etc. This must be done in this method, not addMaterial itself, as the default _fadeMaterial
    // is transparent. We care only about objects' materials here.
    this._hasTransparentMaterial = this._hasTransparentMaterial || mat.transparent;
    MaterialConverter.applyAppearanceHeuristics(mat, isPrism || skipSimplePhongHeuristics, this.isDepthWriteTransparentEnabled());
    if (mat.side === THREE$1.DoubleSide) {
        this._needsTwoSided = true;
    }
    this.addHDRMaterial(name, mat);
};
MaterialManager.prototype.addObjectMaterial = function (model, surfaceMat, matName) {
    var svf = model.getData();
    // We obey the double-sided global flag, but have asked ATF to minimize its use in the future.
    // Unnecessarily setting this to true wastes GPU cycles by processing hidden geometry.
    //TODO: it sucks to have this hack here, but it's the last place where we have the model
    //available to check the global double sided flag.
    if (svf.doubleSided) surfaceMat.side = THREE$1.DoubleSide;
    // last thing: add material to the materials array, performing any special processing needed.
    var matName = this._getMaterialHash(model, matName);
    this.addMaterial(matName, surfaceMat);
    // Note if any material added this way is transparent. This property can be used to shortcut various
    // refreshes, etc. This must be done in this method, not addMaterial itself, as the default _fadeMaterial
    // is transparent. We care only about objects' materials here.
    this._hasTransparentMaterial = this._hasTransparentMaterial || surfaceMat.transparent;
    return matName;
};
/**
 * Adds line material for use in 2D drawings.
 * @param {string} name Unique material name.
 * @param {THREE.ShaderMaterial} lineMaterial Line material.
 */
MaterialManager.prototype.addLineMaterial = function (name, lineMaterial) {
    if (this._layerMaskTex) {
        lineMaterial.defines["HAS_LAYERS"] = 1;
        lineMaterial.uniforms["tLayerMask"].value = this._layerMaskTex;
    }
    if (this._lineStyleTex) {
        lineMaterial.defines["HAS_LINESTYLES"] = 1;
        lineMaterial.defines["MAX_LINESTYLE_LENGTH"] = this._lineStyleTex.image.width;
        lineMaterial.uniforms["tLineStyle"].value = this._lineStyleTex;
        lineMaterial.uniforms["vLineStyleTexSize"].value.set(this._lineStyleTex.image.width, this._lineStyleTex.image.height);
    }
    lineMaterial.uniforms["aaRange"].value = 0.5 / (this._pixelsPerUnit * lineMaterial.modelScale);
    lineMaterial.uniforms["pixelsPerUnit"].value = this._pixelsPerUnit * lineMaterial.modelScale;
    lineMaterial.uniforms["swap"].value = this._swapBlackAndWhite;
    this._materials[name] = lineMaterial;
};
/**
 * Override materials may contain multiple variants (e.g. with/without instancing).
 *
 * This method is like addMaterialNonHDR, but allows custom variants of
 * this material - which are added as well.
 *
 * Requirement:
 *  Custom variants of an override material m must be available in array property
 *  called m.variants. If there is no such array, the behavior is identical with addMaterialNonHDR.
 *
 * @param {string}         name
 * @param {THREE.Material} material
 */
MaterialManager.prototype.addOverrideMaterial = function (name, mat) {
    // Add the main (default) override material
    this.addNonHDRMaterial(name, mat);
    // If there is just one variant of the override material, we are done.
    if (!mat.variants) {
        return;
    }
    // For each alternative variant of this material...
    for (var i = 0; i < mat.variants.length; i++) {
        var variant = mat.variants[i];
        if (!variant) {
            continue;
        }
        // Add custom variant with varied name
        var variantName = name + "_variant_" + i;
        this.addNonHDRMaterial(variantName, variant);
    }
};
/**
 * Returns a cloned version of the given material that has support for instancing or per-vertex ids.
 *
 *  The returned material is owned and cached by MaterialManager. It must be associated with a RenderModel
 *  (specified via svfPath) to make sure that it is disposed later with the other materials of this RenderModel.
 *
 *    @param {THREE.Material}   srcMaterial
 *    @param {MATERIAL_VARIANT} variant     - see MATERIAL_VARIANT enum
 *    @param {RenderModel}      model       - determines to which RenderModel the material belongs.
 *                                            this is important to control when the material is disposed.
 */
MaterialManager.prototype.getMaterialVariant = function (srcMaterial, variant, model) {
    // Check if srcMaterial is sharable or owned by a single render model. If shared, the variant will be shared as well.
    var isShared = !!srcMaterial.hash;
    // Create unique name for the new material variant.
    //  - If srcMaterial is not shared, prefix it with model-id string, so that the material will be disposed when RenderModel is removed.
    //  - If srcMaterial is shared, use global srcMaterial hash instead, so that the material variant can be shared by multiple RenderModels.
    var prefix = isShared ? srcMaterial.hash : this._getModelHash(model) + srcMaterial.id;
    var matName = prefix + '|' + variant;
    var result = this._materials[matName];
    if (!result) {
        // Create cloned material
        result = this.cloneMaterial(srcMaterial, model);
        // Apply variation
        if (variant === MaterialManager.MATERIAL_VARIANT.INSTANCED) {
            result.useInstancing = true;
            // IDs are actually provided per instance, but for the shader, it makes no difference.
            result.vertexIds = true;
        } else if (variant === MaterialManager.MATERIAL_VARIANT.VERTEX_IDS) {
            result.vertexIds = true;
        }
        this.addHDRMaterial(matName, result);
    }
    // For shared materials, we must track which RenderModels are using them. This is needed to dispose them
    // in when they are not used anymore. (see this.cleanup)
    if (isShared) {
        this._addMaterialRef(result, model.id);
    }
    return result;
};
/**
 * Adds intancing support for override materials: It attaches an alternative variant
 * with instancing support, which is used by WebGLRenderer to render instanced shapes correctly.
 *
 *  NOTE: This function can only be used for simple override materials that have no
 *        other alternative variants yet.
 *
 *   @param {THREE.Material} material
 */
MaterialManager.prototype.addInstancingSupport = function (material) {
    // create material clone with instancing
    var instMat = material.clone();
    instMat.useInstancing = true;
    var wideLinesMat = material.clone();
    wideLinesMat.wideLines = true;
    // Make this available as variant. Note that we generally store
    // material variants as an array member mat.variants, so that we have a uniform way to find them
    // (e.g. see MaterialManager.addOverrideMaterial), no matter if there are more variants or just one.
    material.variants = [instMat, wideLinesMat];
    // Make WebGLRenderer use the instancing material where needed
    material.getCustomOverrideMaterial = function (shapeMaterial) {
        if (shapeMaterial.useInstancing) {
            // use override material with instancing
            return this.variants[0];
        }
        if (shapeMaterial.wideLines) {
            return this.variants[1];
        }
        // use default
        return null;
    };
};
/**
 * Removes material from the manager.
 * @param {string} name Unique material name.
 */
MaterialManager.prototype.removeMaterial = function (name) {
    delete this._materials[name];
};
/**
 * Finds material by name.
 * @param {RenderModel} [model] Optional model in which to look for the material.
 * @param {string} name Material name.
 * @returns Desired material, or a default material as a fallback.
 */
MaterialManager.prototype.findMaterial = function (model, name) {
    var hname = this._getMaterialHash(model, name);
    var mat = this._materials[hname];
    //It's not expected that the material is null here, but in case
    //it is, warn and pick the first one available.
    return mat;
};
/**
 * Lookup material by name.
 * @param {RenderModel} [model] Optional model in which to look for the material.
 * @param {string} name Material name.
 * @returns Desired material, or falsy value.
 */
MaterialManager.prototype.lookupMaterial = function (model, name) {
    var hname = this._getMaterialHash(model, name);
    return this._materials[hname];
};
MaterialManager.prototype.convertSharedMaterial = function (model, matObj, matHash) {
    // check if material is already known from another RenderModel
    var surfaceMat = this.findMaterial(model, matHash);
    if (!surfaceMat) {
        surfaceMat = this.convertOneMaterial(model, matObj, matHash);
        surfaceMat.hash = matHash;
    }
    // for shared materials, track which RenderModels are using it.
    this._addMaterialRef(surfaceMat, model.id);
    return surfaceMat;
}, MaterialManager.prototype.convertOneMaterial = function (model, matObj, p) {
    var svf = model.getData();
    var sceneUnit = svf && svf.materials ? svf.materials.scene.SceneUnit : "inch";
    // gets material, or grout material if tiling is found
    var surfaceMat = MaterialConverter.convertMaterial(matObj, sceneUnit);
    var matName = this.addObjectMaterial(model, surfaceMat, p);
    // Process tiling, if any
    if (MaterialConverter.hasTiling(matObj)) {
        // The decals system is used for both tilings and decals:
        //   draw the grout (underlying) surface material fully
        //   draw all the tiles, composited atop
        //   draw all the decals, composited atop
        // Tilings are applied, one by one, then decals.
        surfaceMat.decals = [];
        // extract the tile descriptions from the matObj into an array
        var innerMats = matObj['materials'];
        var globalTile = innerMats[matObj['userassets'][0]];
        var materialIndices = globalTile.properties.references.base_materials.connections;
        var tileIndices = globalTile.properties.references.tiles.connections;
        var inputTiles = [];
        // put tiles in list into inputTiles, and generate output materials for each into the decals list
        for (var i = 0; i < tileIndices.length; i++) {
            var innerTile = innerMats[tileIndices[i]];
            inputTiles.push(innerTile);
            // add a decal material for each tile, which gets parameters added to by materialTilingPattern.
            var material = MaterialConverter.convertMaterial(matObj, sceneUnit, null, materialIndices[i]);
            material.useTiling = true;
            // Make it transparent for AA to work properly - TODOTODO could make this optional, but I think it's better always on.
            // Still, doing so does cost a bit of performance: blending is always more involved than simple replace.
            // If AA is off, this value can be false, for (slightly?) faster performance
            material.transparent = true;
            surfaceMat.decals.push({
                uv: 0,
                material: material
            });
            this.addMaterial(matName + '|tile|' + i, material); // giving it a unique name - TODOTODO: do we need something else here?
        }
        // We have already processed the grout with convertMaterial, above.
        // Now walk through the tilings, find their related materials, put in two arrays, while also gathering the
        // global tiling information and using that to fully form the "decals" materials.
        // At this point each inputTiles element in the array will directly correspond to a material in the decals array.
        // To clarify:
        // * matObj contains the read-in ProteinMaterials.json file (it should also work on non-PRISM materials; future-proof)
        // * globalTile is a temporary object of the "tile" global information, that affects all tiles
        // * inputTiles is an array of the TilingAppearanceSchema (the individual tiles) in the matObj, for convenience;
        //   this array could be made inside materialTilingPattern, but it felt a bit more structured to just do so here.
        // * surfaceMat.decals is the list of decal material, already created above, that will then get tiling information
        //   added to them. Note no rendering changes are needed: tiles and decals are put into this same array, and are
        //   rendered and composited on top of each other, one after the other.
        // * sceneUnit - the global scene unit, used when extracting information from matObj
        MaterialConverter.materialTilingPattern(matObj, globalTile, inputTiles, surfaceMat.decals, sceneUnit);
    }
    // Process decals
    if (matObj.decals) {
        // may have been defined by a tiling
        if (!surfaceMat.decals) {
            surfaceMat.decals = [];
        }
        for (var di = 0, dlen = matObj.decals.length; di < dlen; di++) {
            var decal = matObj.decals[di];
            var material = MaterialConverter.convertMaterial(decal.material, sceneUnit);
            surfaceMat.decals.push({
                uv: decal.uv || 0,
                material: material
            });
            this.addMaterial(matName + '|decal|' + di, material);
        }
    }
    /* standalone, convert decals to tiles, test code. Left here to show some sample tiling patterns and how they're set.
    // fake out: turn decals into tiles
    if (matObj.decals) {
        // 0 - diamonds (no longer supported?)
        // 1 - Hexagons 2x2 - TilingPattern-012
        // 2 - Basketweave - TilingPattern-014
        // 3 - Herringbone 3x1 - TilingPattern-006
        // 4 - Hopscotch 1/4 - TilingPattern-017
        let pattern = 3;
        let vector_a = [
            new THREE.Vector2( 1.02286470, 1.77165353 ),
            new THREE.Vector2( 2, 0 ),
            new THREE.Vector2( 2, 2 ),
            new THREE.Vector2( 1, 1 ),
            new THREE.Vector2( 1.0,-0.25 )
        ];
        let vector_b = [
            new THREE.Vector2( 2.04572940, 0.0 ),
            new THREE.Vector2( 0, 1.732051 ),
            new THREE.Vector2( 2, -2 ),
            new THREE.Vector2( 3, -3 ),
            new THREE.Vector2( 1.25,0.75 )
        ];
        let num_tiles = [3,4,4,2,2];
        // see https://wiki.autodesk.com/x/3wAjFQ for more information
        let incomingTileDescription = {tiling: null};
        incomingTileDescription.tiling = {
            // one tiling direction
            offset_vector_a: vector_a[pattern],
            offset_vector_a_x_units: "mm",   // OGS uses two units: scale_factor_x and scale_factor_y. See MaterialTilingPattern
            offset_vector_a_y_units: "mm",
            // the other tiling direction
            offset_vector_b: vector_b[pattern],
            offset_vector_b_x_units: "mm",
            offset_vector_b_y_units: "mm",
            // implied: grout_material
            // A 2D vector that specifies what 1 horizontal and 1 vertical length unit in the tiling description
            // maps to in real world units (e.g. 1 inch, 2 cm, etc.). This applies to the tile vertex coordinates and the
            // tile axis vectors a and b. In other words, this scaling only affects tile shapes. It does not scale texture
            // space, and does not affect the parameters below (inset, rounding, overall offset).
            scale_factor: new THREE.Vector2( 1,1 ),
            //scale_factor: new THREE.Vector2( 0.254, 0.254 ),    // for OGS tiling 17 testing
            scale_factor_x_units: "mm",
            scale_factor_y_units: "mm",
            // Width of each tile along its edge that should instead be grout. Note that the grout width is then 2x this size.
            inset_size: 0.0, // 0.005, // 0 * 0.4,
            inset_size_units: "mm",
            // The distance from the nearest tile edge where rounding will start. It is a scalar
            // with a specified unit.
            corner_rounding_size: 0.2, // 0.05,  // aka mInsetRadius in OGS
            corner_rounding_size_units: "mm",
            // The angle between the original tile normal and the modified (rounded) normal
            // at the edge of the tile (default unit: degrees).
            corner_rounding_angle: 45.0,
            corner_rounding_angle_units: "",
            // Offset the whole tiling in a given 2D direction, with a specified unit.
            overall_offset_vector: new THREE.Vector2( 0.0, 0.0 ),
            // Rotate the whole tiling by this angle (default unit: degrees).
            overall_rotation_angle: 0,
            overall_rotation_angle_units: "",
        };
             (surfaceMat as any).decals = [];
        let materials = [];
        if ( matObj.decals.length > num_tiles[pattern] ) {
            matObj.decals = matObj.decals.slice(0,num_tiles[pattern]);
        }
        for (var di = 0, dlen = matObj.decals.length; di < dlen; di++) {
            var decal = matObj.decals[di];
            //var material = MaterialConverter.convertMaterial(decal.material, sceneUnit);
            // CHEAT - use surface (prism) material, by making a copy of it
            var material = MaterialConverter.convertMaterial(matObj, sceneUnit);
            // needs to be at the material level so it's in "parameters"
            material.useTiling = true;
            // Controls the randomization of base material position within the tile. The possible
            // values are offset_none (points on the tile use standard UV queries as if the material was not tiled),
            // offset_within (map tile to a random position within the material, not crossing texture boundaries),
            // and offset_any (map tile to a random position within the material).
            // no randomness
            // None = 0,
            // random offset within texture
            // Bounded = 1,
            // random offset in any value
            // Uniform = 2
                 // this needs to be set per tile by incoming data
            decal.randomOffsetMode = 2; //1; // 0, 1, 2
            // Per tile rotation of the underlying material UV space (not rotating the tile itself). Default unit: degrees.
            decal.rotationAngle = 0; //( di === 0 ? 10.0 : ( di === 1 ? 20.0 : 30.0 ));
            // per tile scale
            decal.vertices_units = "mm";
            
            // make it transparent for AA to work properly
            material.transparent = true;
            if ( di == 0 ) {
                //material.color.setRGB( 1.0, 0.0, 0.0 );
                material.opaque_albedo.setRGB( 1.0, 1.0, 1.0 );
                //material.surface_albedo.setRGB( 1.0, 0.0, 0.0 );
                // lower right
                if ( pattern === 0 ) {
                    // diamonds (no longer supported?)
                    decal.vertices = [
                        new THREE.Vector2(2.91029167, 6.67924833),
                        new THREE.Vector2(2.91029167, 5.49814606),
                        new THREE.Vector2(3.93315625, 4.90759516),
                        new THREE.Vector2(3.93315625, 6.08869743) ];
                } else if ( pattern === 1 ) {
                    // Hexagons 2x2 - TilingPattern-012
                    decal.vertices = [
                        new THREE.Vector2(1,0.86603),
                        new THREE.Vector2(0.5,1.1547),
                        new THREE.Vector2(0,0.86603),
                        new THREE.Vector2(0,0.28868),
                        new THREE.Vector2(0.5,0),
                        new THREE.Vector2(1,0.28868) ];
                } else if ( pattern === 2 ) {
                    // Basketweave - TilingPattern-014
                    decal.rotationAngle += 90;
                    decal.vertices = [
                        new THREE.Vector2(1,3),
                        new THREE.Vector2(0,3),
                        new THREE.Vector2(0,0),
                        new THREE.Vector2(1,0) ];
                } else if ( pattern === 3 ) {
                    // Herringbone 3x1 - TilingPattern-006
                    decal.vertices = [
                        new THREE.Vector2(3,1),
                        new THREE.Vector2(0,1),
                        new THREE.Vector2(0,0),
                        new THREE.Vector2(3,0) ];
                } else {
                    // Hopscotch 1/4 - TilingPattern-017
                    decal.vertices = [
                        new THREE.Vector2(1,1),
                        new THREE.Vector2(0,1),
                        new THREE.Vector2(0,0),
                        new THREE.Vector2(1,0) ];
                }
            }
            else if ( di == 1 ) {
                //material.color.setRGB( 0.0, 1.0, 0.0 );
                material.opaque_albedo.setRGB( 0.3, 0.3, 0.3 );
                //material.surface_albedo.setRGB( 0.0, 1.0, 0.0 );
                // top
                if ( pattern === 0 ) {
                    decal.vertices = [
                        new THREE.Vector2(4.95602083, 6.67924833),
                        new THREE.Vector2(3.93315625, 7.26979971),
                        new THREE.Vector2(2.91029167, 6.67924833),
                        new THREE.Vector2(3.93315625, 6.08869743) ];
                } else if ( pattern === 1 ) {
                    decal.vertices = [
                        new THREE.Vector2(2,0.86603),
                        new THREE.Vector2(1.5,1.1547),
                        new THREE.Vector2(1,0.86603),
                        new THREE.Vector2(1,0.28868),
                        new THREE.Vector2(1.5,0),
                        new THREE.Vector2(2,0.28868) ];
                } else if ( pattern === 2 ) {
                    decal.vertices = [
                        new THREE.Vector2(2,1),
                        new THREE.Vector2(1,1),
                        new THREE.Vector2(1,0),
                        new THREE.Vector2(2,0) ];
                } else if ( pattern === 3 ) {
                    // Herringbone 3x1
                    decal.rotationAngle += 90;
                    decal.vertices = [
                        new THREE.Vector2(1,4),
                        new THREE.Vector2(0,4),
                        new THREE.Vector2(0,1),
                        new THREE.Vector2(1,1) ];
                } else {
                    decal.vertices = [
                        new THREE.Vector2(1.25,1),
                        new THREE.Vector2(1,1),
                        new THREE.Vector2(1,0.75),
                        new THREE.Vector2(1.25,0.75) ];
                }
            }
            else if ( di == 2 ) {
                //material.color.setRGB( 0.0, 0.0, 1.0 );
                material.opaque_albedo.setRGB( 1.0, 0.2, 0.2 );
                //material.surface_albedo.setRGB( 0.0, 0.0, 1.0 );
                // lower left
                if ( pattern === 0 ) {
                    decal.vertices = [
                        new THREE.Vector2(4.95602083, 6.67924833),
                        new THREE.Vector2(3.93315625, 6.08869743),
                        new THREE.Vector2(3.93315625, 4.90759516),
                        new THREE.Vector2(4.95602083, 5.49814606) ];
                } else if ( pattern === 1 ) {
                    decal.vertices = [
                        new THREE.Vector2(1.5,1.7321,1,2.0207,0.5,1.7321,0.5,1.1547,1,0.86603,1.5,1.1547),
                        new THREE.Vector2(1,2.0207),
                        new THREE.Vector2(0.5,1.7321),
                        new THREE.Vector2(0.5,1.1547),
                        new THREE.Vector2(1,0.86603),
                        new THREE.Vector2(1.5,1.1547) ];
                } else if ( pattern === 2 ) {
                    decal.vertices = [
                        new THREE.Vector2(4,1),
                        new THREE.Vector2(4,2),
                        new THREE.Vector2(1,2),
                        new THREE.Vector2(1,1) ];
                }
            }
            else if ( di == 3 ) {
                //material.color.setRGB( 0.0, 0.0, 1.0 );
                material.opaque_albedo.setRGB( 1.0, 1.0, 0.2 );
                //material.surface_albedo.setRGB( 0.0, 0.0, 1.0 );
                // lower left
                if ( pattern === 1 ) {
                    decal.vertices = [
                        new THREE.Vector2(2.5,1.7321),
                        new THREE.Vector2(2,2.0207),
                        new THREE.Vector2(1.5,1.7321),
                        new THREE.Vector2(1.5,1.1547),
                        new THREE.Vector2(2,0.86603),
                        new THREE.Vector2(2.5,1.1547) ];
                } else if ( pattern === 2 ) {
                    decal.vertices = [
                        new THREE.Vector2(2,3),
                        new THREE.Vector2(1,3),
                        new THREE.Vector2(1,2),
                        new THREE.Vector2(2,2) ];
                }
            }
            (surfaceMat as any).decals.push({
                uv: 0,
                //uv: decal.uv || 0,
                material: material
            });
            this.addMaterial(matName + '|decal|' + di, material);
            materials[di] = material;
        }
        // surfaceMat.tiling is kept around, with the processed values that go into uniforms.
        MaterialConverter.materialTilingPattern(matObj.decals, incomingTileDescription.tiling, materials, sceneUnit);
    }
    */
    return surfaceMat;
};
/**
 * Executes callback function for each material.
 * @param {function} callback Callback function with material as the single parameter.
 * @param {bool} [exclude2d] - skip 2d materials
 */
MaterialManager.prototype.forEach = function (callback, exclude2d) {
    var materials = this._materials;
    for (var name in materials) {
        var material = materials[name];
        if (exclude2d && material.is2d) {
            continue;
        }
        callback(material);
    }
};
//Called at the beginning of every frame, to perform pending
//operations like texture updates. This function also
//has a chance to request full repaint at that time.
MaterialManager.prototype.updateMaterials = function () {
    var result = { needsClear: false, needsRender: false, overlayDirty: false };
    while (this._texturesToUpdate.length) {
        var def = this._texturesToUpdate.pop();
        for (var slot in def.slots) {
            var mats = def.slots[slot];
            for (var i = 0; i < mats.length; i++) {
                mats[i][slot] = def.tex;
                mats[i].needsUpdate = true;
                //If we knew that there are no transparent materials in the scene,
                //we could just do a needsRender here instead of needsClear, to avoid flashing the model
                //while loading textures.
                result.needsClear = true;
            }
        }
    }
    return result;
};
function addMaterial(def, mat, slot) {
    var mats = def.slots[slot];
    if (mats) {
        if (mats.indexOf(mat) == -1) {
            mats.push(mat);
        }
    } else {
        def.slots[slot] = [mat];
    }
}
function removeMaterial(def, mat, slot) {
    var mats = def.slots[slot];
    mats = mats.filter(function (material) {
        return material != mat;
    });
    if (mats.length == 0) {
        delete def.slots[slot];
    } else {
        def.slots[slot] = mats;
    }
}
MaterialManager.prototype.clearTextureFromMaterial = function (model, mat, map, slotName) {
    // Texture loaded successfully
    var texName = this._getTextureHash(model, map.uri, map.mapName);
    var def = this._textures[texName];
    // If the model was unloaded before the texture loaded, the texture def will no longer exist
    if (!def) return;
    removeMaterial(def, mat, slotName);
};
MaterialManager.prototype.setTextureInCache = function (model, map, tex, image_url) {
    // Texture loaded successfully
    var texName = this._getTextureHash(model, map.uri, map.mapName);
    var def = this._textures[texName];
    // If the model was unloaded before the texture loaded, the texture def will no longer exist
    // If we have loaded a texture and the image url is different from the one we want,
    // then we don't want this texture.
    if (!def) {
        return;
    }
    var urlIndex = def.urls.findIndex(function (url) {
        return url.url == image_url;
    });
    if (urlIndex == -1) {
        def.urls.unshift({ url: image_url });
        urlIndex = 0;
    }
    if (urlIndex <= def.loaded) {
        // This was loaded out of order, skip it.
        return;
    }
    // Set the texture
    def.tex = tex;
    def.loaded = urlIndex;
    // Set it on all materials that use it
    // TODO: Is this needed? It is also done in updateMaterials
    for (var slot in def.slots) {
        var mats = def.slots[slot];
        for (var i = 0; i < mats.length; i++) {
            mats[i][slot] = tex;
        }
    }
    for (var _i = 0; _i <= urlIndex; ++_i) {
        var callback = def.urls[_i].callback;
        delete def.urls[_i].callback;
        if (callback) {
            callback.forEach(function (callback) {
                callback(tex);
            });
        }
    }
    // Keep track of materials that need updating on the
    // next frame. We can use this to throttle texture GPU upload
    this._texturesToUpdate.push(def);
};
MaterialManager.prototype.loadTextureFromCache = function (model, material, map, slotName, image_url, onDone) {
    var texName = this._getTextureHash(model, map.uri, map.mapName);
    var def = this._textures[texName];
    if (def) {
        //Cache entry exists
        // If we also want to check the URL, then do that, too
        var urlIndex = 0;
        if (image_url) {
            urlIndex = def.urls.findIndex(function (url) {
                return url.url == image_url;
            });
            if (urlIndex == -1) {
                // Cache entry exists, but this url hasn't been loaded
                var url = { url: image_url };
                if (onDone) {
                    url.callback = [onDone];
                }
                def.urls.push(url);
                return false;
            }
        }
        //Track all texture uses so we can change it if we want to.
        addMaterial(def, material, slotName);
        //Texture loaded set it on the material directly
        if (def.tex) {
            //Texture is already loaded, update the material directly
            material[slotName] = def.tex;
            material.needsUpdate = true;
        }
        if (def.loaded >= urlIndex) {
            onDone && onDone(def.tex);
        } else if (onDone && def.urls.length > 0) {
            var _url = def.urls[urlIndex];
            var callback = _url.callback = _url.callback || [];
            callback.push(onDone);
        }
    } else {
        var slots = {};
        slots[slotName] = [material];
        //Create a blank cache entry
        var tex = this._textures[texName] = { slots: slots, tex: null, loaded: -1, url: image_url, urls: [] };
        if (image_url) {
            var _url2 = { url: image_url };
            tex.urls.push(_url2);
            if (onDone) {
                _url2.callback = [onDone];
            }
        }
    }
    return !!def;
};
MaterialManager.prototype.enumTextures = function (model, callback) {
    var hash = model ? this._getModelHash(model) : "";
    for (var t in this._textures) {
        if (t.indexOf(hash) === 0) {
            callback(this._textures[t].tex);
        }
    }
};
/** Removes all materials of the given RenderModel from this manager and collects them in
 *  a container object. This object can be used to import these materials into another MaterialManager.
 *   @param {RenderModel} model
 */
MaterialManager.prototype.exportModelMaterials = function (model, targetManager) {
    var hash = this._getModelHash(model);
    // Remember all materials and materials keys for this model
    var modelMaterials = {};
    for (var m in this._materials) {
        if (m.indexOf(hash) !== -1) {
            var mat = this._materials[m];
            // The selection material is not referenced by any shape and uses MaterialManager's own
            // selectionTexture. We don't transfer it, because the receiving MaterialManager will
            // create its own one in init2DSelectionMaterial(). Note that skipping it is essential:
            // Without it, the receiving MaterialManager would skip the initialization of its own
            // selection material, assuming that it already happened.
            var isSelectionMaterial = mat.defines && mat.defines.hasOwnProperty("SELECTION_RENDERER");
            if (!isSelectionMaterial) {
                modelMaterials[m] = mat;
            }
        }
    }
    // Remember non-hdr materials
    var modelMaterialsNonHDR = {};
    for (var m in this._materialsNonHDR) {
        if (m.indexOf(hash) !== -1) {
            modelMaterialsNonHDR[m] = this._materialsNonHDR[m];
        }
    }
    // Remember cached textures for this model
    var modelTextures = {};
    for (var t in this._textures) {
        if (t.indexOf(hash) !== -1) {
            modelTextures[t] = this._textures[t];
        }
    }
    // dispose all GPU resources for this model
    this.cleanup(model);
    return {
        mats: modelMaterials,
        matsNonHDR: modelMaterialsNonHDR,
        textures: modelTextures
    };
};
/** Adds all materials of a RenderModel to this MaterialManager. Note that Materials cannot
 *  be owned by multiple MaterialManagers at once.
 *   @param {Object} modelMaterials - must be obtained by a prior exportModelMaterials() call
 *                                    to this or another MaterialManager.
 */
MaterialManager.prototype.importModelMaterials = function (modelMaterials) {
    // Add materials to the new MaterialManager.
    // Note that we exploit here that material names are unique across different MaterialManagers.
    for (var m in modelMaterials.mats) {
        var mat = modelMaterials.mats[m];
        if (mat.is2d) {
            this.addLineMaterial(m, mat);
        } else {
            this.addHDRMaterial(m, mat);
        }
    }
    // Add all non-hdr materials
    for (var m in modelMaterials.matsNonHDR) {
        this.addMaterialNonHDR(m, modelMaterials.matsNonHDR[m]);
    }
    // Add all textures
    for (var t in modelMaterials.textures) {
        this._textures[t] = modelMaterials.textures[t];
    }
};
/**
 * Returns a copy of the given material. Note that textures are shared, not copied.
 * If not all textures of mat are loaded yet, the owning RenderModel is required
 * to enure that the cloned material receives the textures as well.
 *
 * @param {THREE.Material}    mat
 * @param {RenderModel}       Required if some textures might not be loaded yet.
 * @returns {THREE.Material}
 */
MaterialManager.prototype.cloneMaterial = function (mat, model) {
    var material = mat.isPrismMaterial ? clonePrismMaterial(mat) : mat.clone();
    //Have to clone this manually, otherwise it's shared between the clones
    if (mat.defines) {
        material.defines = Object.assign({}, mat.defines);
    }
    // clone additional properties
    if (material instanceof THREE$1.MeshPhongMaterial || material.isPrismMaterial) {
        material.packedNormals = mat.packedNormals;
        material.exposureBias = mat.exposureBias;
        material.irradianceMap = mat.irradianceMap;
        material.envMapExposure = mat.envMapExposure;
        material.envRotationSin = mat.envRotationSin;
        material.envRotationCos = mat.envRotationCos;
        material.proteinType = mat.proteinType;
        material.proteinMat = mat.proteinMat;
        material.proteinCategories = mat.proteinCategories;
        material.tonemapOutput = mat.tonemapOutput;
        material.cutplanes = mat.cutplanes;
        material.textureMaps = mat.textureMaps;
        material.texturesLoaded = mat.texturesLoaded;
    }
    if (mat.is2d) {
        material.is2d = true;
    }
    if (mat.disableEnvMap) {
        material.disableEnvMap = true;
    }
    if (mat.textureMaps) {
        for (var mapName in mat.textureMaps) {
            if (mat[mapName]) {
                // texture is already loaded - we can share it right now
                material[mapName] = mat[mapName];
            } else if (model) {
                // texture loading is in progress. Make sure that the cloned
                // material receives it as well.
                // get texture name
                var mapDef = material.textureMaps[mapName];
                var texUri = mapDef.uri;
                var sharedMapName = mapDef.mapName; //NOTE: mapName and mapDef.mapName could differ in case a physical texture is shared between e.g. the diffuse and bump maps
                var texName = this._getTextureHash(model, texUri, sharedMapName);
                // add new material to receiver list
                var texReceiverObj = this._textures[texName];
                if (!texReceiverObj) {
                    exports.logger.error("Missing texture receiver", texName);
                } else {
                    addMaterial(texReceiverObj, material, mapName);
                }
            } else {
                exports.logger.error("Cannot connect pending texture maps because cloneMaterial was called without a model");
            }
        }
    }
    this._applyMRTFlags(material);
    return material;
};
/**
 * Sets up the THREE.Material for a fragment.
 */
MaterialManager.prototype.setupMaterial = function (model, threegeom, materialId) {
    var svf = model.getData();
    // Check if this geometry is to be rendered with a line mesh
    var material;
    if (threegeom.isLines || threegeom.isPoints) {
        // Check to see if there are vertex colors
        var vertexColors = !!threegeom.attributes.color;
        // Create a new LineBasicMaterial with vertexColors true/false depending on above
        //TODO: this material also needs to be added to the materials set, but first
        //make sure this will not cause line display side effects.
        var svfmat = this.findMaterial(model, materialId);
        if (threegeom.isPoints) {
            material = new THREE$1.PointCloudMaterial({
                vertexColors: vertexColors,
                size: threegeom.pointSize
            });
        } else if (threegeom.isWideLines) {
            material = new THREE$1.MeshBasicMaterial({ vertexColors: vertexColors });
            material.wideLines = true;
            threegeom.isLines = false;
            material.polygonOffset = svfmat.polygonOffset;
            material.polygonOffsetFactor = svfmat.polygonOffsetFactor;
            material.polygonOffsetUnits = svfmat.polygonOffsetUnits;
        } else {
            if (vertexColors) {
                if (!svfmat.cachedLineMaterialVC) svfmat.cachedLineMaterialVC = new THREE$1.LineBasicMaterial({ vertexColors: vertexColors });
                material = svfmat.cachedLineMaterialVC;
            } else {
                if (!svfmat.cachedLineMaterial) svfmat.cachedLineMaterial = new THREE$1.LineBasicMaterial({ vertexColors: vertexColors });
                material = svfmat.cachedLineMaterial;
            }
        }
        // If there are no vertex colors, default to the material color
        if (!vertexColors) {
            material.color = svfmat.color;
        }
        // Save in material so we can map back from material to SVF id.
        material.svfMatId = materialId;
        //Register it with material manager so that cutplanes get updated
        this.addMaterialNonHDR(svf.basePath + materialId + "_line_" + material.id, material);
        svf.hasLines = true;
    } else {
        material = this.findMaterial(model, materialId);
        if (material) material.svfMatId = materialId;
        MaterialConverter.applyGeometryFlagsToMaterial(material, threegeom);
    }
    return material;
};
// Track which RenderModels are using a shared material.
// Note that we don't count references per model, but just track whether a RenderModel is using the material or not.
MaterialManager.prototype._addMaterialRef = function (sharedMat, modelId) {
    // create model-id array on first ref
    if (!sharedMat._sharedBy) {
        sharedMat._sharedBy = [];
    }
    var refs = sharedMat._sharedBy;
    // don't add any model id twice
    var index = refs.indexOf(modelId);
    if (index !== -1) {
        return;
    }
    refs.push(modelId);
};
// Called if a material is not used by the given RenderModel anymore.
MaterialManager.prototype._removeMaterialRef = function (sharedMat, modelId) {
    var refs = sharedMat._sharedBy;
    // find modelId in reference list
    var index = refs ? refs.indexOf(modelId) : -1;
    if (index !== -1) {
        // remove modeId from reference list
        refs.splice(index, 1);
    }
};
/**
 * Deallocates any material related GL objects associated with the given model.
 * !model means Deallocate all materials.
 */
MaterialManager.prototype.cleanup = function (model) {
    var hash = this._getModelHash(model);
    //Dispose all textures that were loaded as part of the given SVF
    var newTex = {};
    for (var t in this._textures) {
        var tdef = this._textures[t];
        if (t.indexOf(hash) === -1) newTex[t] = tdef;else if (tdef.tex) {
            tdef.tex.dispose();
            tdef.tex.needsUpdate = true;
        }
    }
    this._textures = newTex;
    //Remove all materials that were used by the given SVF
    var newMats = {};
    var DISPOSE_EVENT = { type: 'dispose' };
    for (var m in this._materials) {
        var mat = this._materials[m];
        // If the material was solely owned by this model, or we are disposing everything, we can dispose it.
        var disposeMat = !model || m.indexOf(hash) !== -1;
        // If the material is shared, check if this was the last RenderModel using it
        if (mat._sharedBy) {
            if (disposeMat) {
                mat._sharedBy.length = 0;
            } else {
                // remove model from list of models that are using this material
                this._removeMaterialRef(mat, model.id);
                // if model was the last one, dispose material
                if (mat._sharedBy.length === 0) {
                    disposeMat = true;
                }
            }
        }
        if (!disposeMat) {
            newMats[m] = this._materials[m];
        } else {
            var mat = this._materials[m];
            mat.dispatchEvent(DISPOSE_EVENT);
            mat.needsUpdate = true; //in case it gets used again
            mat.envMap = null;
            if (mat.is2d) {
                // decouple from textures owned by MaterialManager
                mat.uniforms["tLayerMask"].value = null;
                mat.uniforms["tLineStyle"].value = null;
                // dispose raster texture
                var rasterTex = mat.uniforms["tRaster"];
                if (rasterTex && rasterTex.value instanceof THREE$1.Texture) {
                    rasterTex.value.dispose();
                    rasterTex.value.needsUpdate = true;
                }
            }
        }
    }
    this._materials = newMats;
    // cleanup non-HDR materials
    var newMatsNonHDR = {};
    for (var m in this._materialsNonHDR) {
        if (model && m.indexOf(hash) === -1) {
            newMatsNonHDR[m] = this._materialsNonHDR[m];
        } else {
            var mat = this._materialsNonHDR[m];
            mat.dispatchEvent(DISPOSE_EVENT);
            mat.needsUpdate = true; //in case it gets used again
        }
    }
    this._materialsNonHDR = newMatsNonHDR;
};
MaterialManager.prototype.toggleDepthWriteTransparent = function (enable) {
    if (this._depthWriteTransparent != enable) {
        this._depthWriteTransparent = enable;
        // Change depth write for the transparent objects.
        this.forEach(function (mtl) {
            if (mtl.lmv_depthWriteTransparent) mtl.depthWrite = enable;
        });
    }
};
MaterialManager.prototype.isDepthWriteTransparentEnabled = function () {
    return this._depthWriteTransparent;
};
// Reports whether the manager has encountered a material that needs two-sided rendering.
MaterialManager.prototype.hasTwoSidedMaterials = function () {
    return this._needsTwoSided;
};
MaterialManager.prototype.hasTransparentMaterial = function () {
    return this._hasTransparentMaterial;
};
MaterialManager.prototype.texturesLoaded = function () {
    return this._texturesToUpdate.length === 0;
};
// Surface material properties
/**
 * Sets exposure bias for all surface materials.
 *
 * Exposure correction of 2^exposureBias applied to rendered output color
 * before passing into the tone mapper.
 *
 * @param {number} exposureBias Exposure bias input.
 */
MaterialManager.prototype.setTonemapExposureBias = function (exposureBias) {
    this._exposureBias = exposureBias;
    var bias = Math.pow(2.0, exposureBias);
    this.forEach(function (m) {
        m.exposureBias = bias;
        m.needsUpdate = true;
    }, true);
};
/**
 * Sets tone mapping method for all surface materials.
 * @param {number} method Tone mapping method (0: none, 1: Canon lum., 2: Canon RGB)
 */
MaterialManager.prototype.setTonemapMethod = function (method) {
    this._tonemapMethod = method;
    this.forEach(function (m) {
        m.tonemapOutput = method;
        m.needsUpdate = true;
    }, true);
};
/**
 * Sets env. exposure for all surface materials.
 *
 * An additional multiplier of 2^envExposure will be applied
 * to the env. map intensities, in case RGBM environment map is used.
 *
 * @param {number} envExposure Environment exposure input.
 */
MaterialManager.prototype.setEnvExposure = function (envExposure) {
    var scale = Math.pow(2.0, envExposure);
    this._envMapExposure = scale;
    this.forEach(function (m) {
        m.envMapExposure = scale;
        m.needsUpdate = true;
    }, true);
};
/**
 * Sets env. rotation for all surface materials.
 * @param {number} rotation Relative angle in radians (-Pi..Pi).
 */
MaterialManager.prototype.setEnvRotation = function (rotation) {
    var s = this._envRotationSin = Math.sin(rotation);
    var c = this._envRotationCos = Math.cos(rotation);
    this.forEach(function (m) {
        m.envRotationSin = s;
        m.envRotationCos = c;
        m.needsUpdate = true;
    }, true);
};
/**
 * Sets reflection map (env. map) for all surface materials.
 * @param {THREE.Texture} map Reflection map.
 */
MaterialManager.prototype.setReflectionMap = function (map) {
    this._reflectionMap = map;
    this.forEach(function (m) {
        if (!m.disableEnvMap) {
            m.envMap = map;
            m.needsUpdate = true;
        }
    }, true);
};
/**
 * Sets irradiance map for all surface materials.
 * @param {THREE.Texture} map Irradiance map.
 */
MaterialManager.prototype.setIrradianceMap = function (map) {
    this._irradianceMap = map;
    this.forEach(function (m) {
        m.irradianceMap = map;
        m.needsUpdate = true;
    }, true);
};
/**
 * Sets cut planes for all materials
 * Clears any existing cutplanes and populates with the new ones
 * If empty array or undefined, cut planes will be turned off (cleared)
 */
MaterialManager.prototype.setCutPlanes = function (cutplanes) {
    // Update shaders if num of planes changed
    if (this._cutplanes.length !== (cutplanes ? cutplanes.length || 0 : 0)) {
        this.forEach(function (mat) {
            if (!mat.doNotCut) {
                mat.needsUpdate = true;
                if (cutplanes && cutplanes.length > 0) mat.side = THREE$1.DoubleSide;
            }
        });
        for (var p in this._materialsNonHDR) {
            if (!this._materialsNonHDR[p].doNotCut) this._materialsNonHDR[p].needsUpdate = true;
        }
    }
    // Empty array (http://jsperf.com/empty-javascript-array)
    while (this._cutplanes.length > 0) {
        this._cutplanes.pop();
    } // Copy cutplanes
    if (cutplanes) {
        for (var i = 0; i < cutplanes.length; i++) {
            this._cutplanes.push(cutplanes[i].clone());
        }
    }
};
/**
 * Returns a copy of cut planes
 */
MaterialManager.prototype.getCutPlanes = function () {
    return this._cutplanes.slice();
};
/**
 * @returns {Array} The internal cutplanes array (not a copy, the actual thing)
 */
MaterialManager.prototype.getCutPlanesRaw = function () {
    return this._cutplanes;
};
MaterialManager.prototype._applyPolygonOffset = function (mat) {
    if (mat instanceof THREE$1.MeshPhongMaterial || mat.isPrismMaterial) {
        mat.polygonOffset = this._polygonOffsetOn;
        mat.polygonOffsetFactor = this._polygonOffsetFactor;
        mat.polygonOffsetUnits = this._polygonOffsetUnits;
        if (mat.extraDepthOffset) {
            mat.polygonOffsetFactor += mat.extraDepthOffset;
        }
        mat.needsUpdate = true;
    }
};
MaterialManager.prototype.getPolygonOffsetOn = function () {
    return this._polygonOffsetOn;
};
MaterialManager.prototype.getPolygonOffsetFactor = function () {
    return this._polygonOffsetFactor;
};
MaterialManager.prototype.getPolygonOffsetUnits = function () {
    return this._polygonOffsetUnits;
};
MaterialManager.prototype.togglePolygonOffset = function (state, factor, units) {
    this._polygonOffsetOn = state;
    this._polygonOffsetFactor = state ? factor || 1 : 0;
    this._polygonOffsetUnits = state ? units || 0.1 : 0; // 1.0 is much too high, see LMV-1072; may need more adjustment
    var scope = this;
    this.forEach(function (mat) {
        scope._applyPolygonOffset(mat);
    });
};
MaterialManager.prototype._applyMRTFlags = function (mat) {
    // Activating MRTNormals requires the existence of a variable geomNormals in the shader. (see final_frag.glsl)
    // E.g., for MeshBasicMaterials, setting MRTNormals would cause a compile error. Therefore,
    // we whitelist materials here that support MRT normals.
    var matSupportsMrtNormals = mat.supportsMrtNormals || mat instanceof THREE$1.MeshPhongMaterial || mat.isPrismMaterial;
    var oldN = mat.mrtNormals;
    var oldI = mat.mrtIdBuffer;
    var hasMRT = this._renderer && this._renderer.supportsMRT();
    mat.mrtNormals = matSupportsMrtNormals && hasMRT && this._mrtNormals;
    mat.mrtIdBuffer = hasMRT ? this._mrtIdBuffer : undefined;
    if (mat.mrtNormals !== oldN || mat.mrtIdBuffer !== oldI) mat.needsUpdate = true;
};
MaterialManager.prototype.toggleMRTSetting = function (flags) {
    this._mrtNormals = flags.mrtNormals;
    this._mrtIdBuffer = flags.mrtIdBuffer;
    var self = this;
    this.forEach(function (m) {
        if (!m.is2d) {
            self._applyMRTFlags(m);
        }
    });
};
// Line material properties
MaterialManager.prototype.initLineStyleTexture = function () {
    this._lineStyleTex = createLinePatternTexture();
};
/**
 * Creates a texture where each pixel corresponds to the visibility of a 2D layer.
 * The LineShader samples the texture to determine if a geometry is visible
 * based on its layer visibility.
 */
MaterialManager.prototype.initLayersTexture = function (count, layersMap) {
    //TODO: Layer and selection textures need to contain information about all models.
    //This means that each loaded 2d model needs to have a base offset into the layer and selection
    //textures, so that we are able to highlight and determine which specific model a pixel belongs to.
    //If you fix this, you will need to worry about the id material, which isn't model specific,
    //because the RenderContext just keeps one. There are other issues with multi-model scenarios.
    //The each model has a layersMap but we only keep one, here. Also each model will call
    //this method and changed the layer mask texture, without updating materials that use
    //the texture being replaced. Use the layersMap and texture for the first model.
    //This will cause problems if the first model is transfered to a new RenderContext.
    if (this._layerMaskTex) {
        return;
    }
    // TODO: Once arbitrary layer texture size works
    // we can base the allocation size on the layerCount
    var tw = 256;
    // TODO: Currently the shader math is limited to
    // a square 256x256 layers mask, since it just does a
    // scale of the two layer bytes by 1/255. We would need to
    // send the height of the layer texture to do something smarter,
    // or wait for texture size query in WebGL 2.
    // var th = 0 | Math.ceil((layersList.length) / 256.0);
    var th = 256;
    var layerMask = new Uint8Array(tw * th);
    for (var l = 0, lEnd = count; l < lEnd; l++) {
        layerMask[l] = 0xff;
    }
    var layerMaskTex = new THREE$1.DataTexture(layerMask, tw, th, THREE$1.LuminanceFormat, THREE$1.UnsignedByteType, THREE$1.UVMapping, THREE$1.ClampToEdgeWrapping, THREE$1.ClampToEdgeWrapping, THREE$1.NearestFilter, THREE$1.NearestFilter, 0);
    layerMaskTex.generateMipmaps = false;
    layerMaskTex.flipY = false;
    layerMaskTex.needsUpdate = true;
    // TODO: These are per-model, so we will need
    // to remember multiple sets in case we support
    // multi-drawing views.
    this._layerMaskTex = layerMaskTex;
    this._layersMap = layersMap;
};
/**
 * Toggles 2D layer visibility by setting the corresponding pixel in the layers texture.
 */
MaterialManager.prototype.setLayerVisible = function (layerIndexes, visible) {
    var layerMaskTex = this._layerMaskTex,
        layerMaskData = layerMaskTex.image.data,
        layersMap = this._layersMap,
        mask = visible ? 0xff : 0;
    for (var i = 0; i < layerIndexes.length; ++i) {
        var layerIndex = layerIndexes[i];
        layerMaskData[layersMap[layerIndex]] = mask;
    }
    layerMaskTex.needsUpdate = true;
    this.forEach(function (m) {
        if (m.is2d) {
            m.needsUpdate = true;
        }
    });
};
MaterialManager.prototype.isLayerVisible = function (layerIndex) {
    return !!this._layerMaskTex.image.data[this._layersMap[layerIndex]];
};
/**
 * @param {number} maxObjectCount Upper boundary of all ids we can expect. Used to determine required size.
 */
MaterialManager.prototype.initSelectionTexture = function (maxObjectCount) {
    //TODO: Layer and selection textures need to contain information about all models.
    //This means that each loaded 2d model needs to have a base offset into the layer and selection
    //textures, so that we are able to highlight and determine which specific model a pixel belongs to.
    var numObj = maxObjectCount || 1;
    // determine texture extents
    var tw = 4096; //NOTE: This size is assumed in the shader, so update the shader if this changes!
    var th = 0 | Math.ceil(numObj / tw);
    var p2 = 1;
    while (p2 < th) {
        p2 *= 2;
    }th = p2;
    // init all pixels with 0
    var selectionMask = new Uint8Array(tw * th);
    for (var i = 0; i < numObj; i++) {
        selectionMask[i] = 0;
    }
    // create texture
    var selectionTex = new THREE$1.DataTexture(selectionMask, tw, th, THREE$1.LuminanceFormat, THREE$1.UnsignedByteType, THREE$1.UVMapping, THREE$1.ClampToEdgeWrapping, THREE$1.ClampToEdgeWrapping, THREE$1.NearestFilter, THREE$1.NearestFilter, 0);
    selectionTex.generateMipmaps = false;
    selectionTex.flipY = false;
    selectionTex.needsUpdate = true;
    this._selectionTex = selectionTex;
    return selectionTex;
};
//Meshes for 2d drawings contain many objects in a single mesh.
//So we use a mask texture to pick out which object specifically
//to highlight or render in ghosted style. The shader samples this texture to deside whether
//to draw or not.
MaterialManager.prototype.highlightObject2D = function (dbId, state) {
    var tex = this._selectionTex;
    if (tex) {
        var data = tex.image.data;
        data[dbId] = state ? 0xff : 0;
        //TODO: partial texture update using TexSubImage possible?
        tex.needsUpdate = true;
    }
};
MaterialManager.prototype.updatePixelScale = function (pixelsPerUnit) {
    var val = this._pixelsPerUnit = pixelsPerUnit;
    this.forEach(function (m) {
        if (m.is2d) {
            m.uniforms["aaRange"].value = 0.5 / (val * m.modelScale);
            m.uniforms["pixelsPerUnit"].value = val * m.modelScale;
        }
    });
};
MaterialManager.prototype.updateSwapBlackAndWhite = function (reverse) {
    var val = this._swapBlackAndWhite = reverse ? 1.0 : 0.0;
    this.forEach(function (m) {
        if (m.is2d) {
            m.uniforms["swap"].value = val;
        }
    });
};
MaterialManager.prototype.updateViewportId = function (vpId) {
    this.forEach(function (m) {
        if (m.is2d) {
            m.uniforms["viewportId"].value = vpId;
            m.needsUpdate = true;
        }
    });
};

var getVertexCount$2 = VertexEnumerator.getVertexCount;
var runMergeSingleThreaded = ParallelGeomMergeUtils.runMergeSingleThreaded;
var ParallelGeomMerge = ParallelGeomMergeUtils.ParallelGeomMerge;
// Maximum vertex count that we allow for a consolidated mesh. For simplicity, we keep it within 16 bit scope, so that
// we can always use Uint16 indices. Allowing too large containers may backfire in several ways, e.g.,
// it would reduce granularity for progressive rendering and frustum culling too much.
var MaxVertexCountPerMesh = 0xFFFF;
var MATERIAL_VARIANT = MaterialManager.MATERIAL_VARIANT;
var PRIMITIVE_TYPE = {
    UNKNOWN: 0,
    TRIANGLES: 1,
    LINES: 2,
    WIDE_LINES: 3,
    POINTS: 4
};
function getPrimitiveType(geom) {
    if (geom.isLines) return PRIMITIVE_TYPE.LINES;
    if (geom.isPoints) return PRIMITIVE_TYPE.POINTS;
    if (geom.isWideLines) return PRIMITIVE_TYPE.WIDE_LINES;
    return PRIMITIVE_TYPE.TRIANGLES;
}
function setPrimitiveType(geom, type) {
    // clear any previous flags
    if (geom.isLines === true) geom.isLines = undefined;
    if (geom.isWideLines === true) geom.isWideLines = undefined;
    if (geom.isPoints === true) geom.isPoints = undefined;
    switch (type) {
        case PRIMITIVE_TYPE.LINES:
            geom.isLines = true;
            break;
        case PRIMITIVE_TYPE.WIDE_LINES:
            geom.isWideLines = true;
            break;
        case PRIMITIVE_TYPE.POINTS:
            geom.isPoints = true;
            break;
    }
}
/**
  *  Helper class to collect shapes with identical materials and merge them into a single large shape.
  *
  *  @constructor
  *    @param {THREE.Material} material - Material must be the same for all added geometries.
  */
function MergeBucket(material) {
    this.geoms = [];
    this.matrices = [];
    this.vertexCount = 0;
    this.material = material;
    this.fragIds = [];
    this.worldBox = new THREE$1.Box3();
}
MergeBucket.prototype = {
    constructor: MergeBucket,
    /**
     * @param {THREE.BufferGeometry} geom
     * @param {THREE.Box3}           worldBox
     * @param {Number}               fragId
     * @returns {Number}             costs - memory cost increase caused by the new geometry
     */
    addGeom: function addGeom(geom, worldBox, fragId) {
        this.geoms.push(geom);
        this.fragIds.push(fragId);
        this.worldBox.union(worldBox);
        this.vertexCount += getVertexCount$2(geom);
        // Track memory costs. As long as the bucket has only a single shape,
        // we have no costs at all.
        var numGeoms = this.geoms.length;
        if (numGeoms == 1) {
            return 0;
        }
        // Fragment geometries are usually BufferGeometry, which provide a byteSize for the
        // interleaved buffer. Anything else is currently unexpected and needs code change.
        if (geom.byteSize === undefined) {
            THREE$1.warn("Error in consolidation: Geometry must contain byteSize.");
        }
        // For any bucket with >=2 geoms, all geometries must be considered for the costs.
        return geom.byteSize + (numGeoms == 2 ? this.geoms[0].byteSize : 0);
    }
};
/**
 *  Set vertex attributes and vbstride of dstGeom to the same vertex format as srcGeom.
 *  Note that this can only be used for interleaved vertex buffers.
 *   @param {LmvBufferGeometry} srcGeom
 *   @param {LmvBufferGeometry} dstGeom
 */
function copyVertexFormat(srcGeom, dstGeom) {
    if (!srcGeom.vb || !srcGeom.vbstride) {
        THREE$1.warn("copyVertexFormat() supports only interleaved buffers");
    }
    // VertexAttribute objects of WGS BufferGeometry do not contain actual vertex data.
    // Therfore, identical BufferAttribute objects are shared among different
    // BufferGeometries. (see findBufferAttribute in BufferGeometry.js)
    for (var attrib in srcGeom.attributes) {
        dstGeom.attributes[attrib] = srcGeom.attributes[attrib];
    }
    // copy attribute keys
    dstGeom.attributesKeys = srcGeom.attributesKeys.slice(0);
    dstGeom.vbstride = srcGeom.vbstride;
}
/**
 *  Set primitive type and related params (lineWidth/pointSize) of dstGeom to the same values as srcGeom.
 *   @param {BufferGeometry} srcGeom
 *   @param {BufferGeometry} dstGeom
 */
function copyPrimitiveProps(srcGeom, dstGeom) {
    var primType = getPrimitiveType(srcGeom);
    setPrimitiveType(dstGeom, primType);
    // pointSize/lineWidth
    dstGeom.lineWidth = srcGeom.lineWidth;
    dstGeom.pointSize = srcGeom.pointSize;
}
/**
 * Creates target BufferGeometry used to merge several src BufferGeometries into one. (see mergeGeometries)
 *
 * Returns a new BufferGeometry for which...
 *  - vb/ib are large enough to fit in all src geometry vertices/indices (allocated, but not filled yet)
 *  - the vertex-format of the interleaved vb is the same as for the input geometries
 *  - primitive type is the same as for (including pointSize/lineWidth)
 *  - it has an additional attribute for per-vertex ids
 *
 *  @param   {BufferGeometry[]} geoms - source geometry buffers.
 *  @returns {BufferGeometry}
 */
function createMergeGeom(geoms) {
    // floats per vertex
    var stride = geoms[0].vbstride; // same for src and dst, because we add per-vertex ids as separate attribute
    // compute summed vertex and index count (and summed box if needed)
    var indexCount = 0;
    var vertexCount = 0;
    var indexLinesCount = 0;
    for (var i = 0; i < geoms.length; i++) {
        var geom = geoms[i];
        indexCount += geoms[i].ib.length;
        vertexCount += getVertexCount$2(geom);
        if (geoms[i].iblines) indexLinesCount += geoms[i].iblines.length;
    }
    var mergedGeom = createBufferGeometry();
    // allocate new geometry with vertex and index buffer
    mergedGeom.vb = new Float32Array(vertexCount * stride);
    mergedGeom.ib = new Uint16Array(indexCount);
    if (indexLinesCount) mergedGeom.iblines = new Uint16Array(indexLinesCount);
    // make sure that byteSize is set just like for input geometry. This is required for later memory tracking.
    mergedGeom.byteSize = mergedGeom.vb.byteLength + mergedGeom.ib.byteLength;
    if (mergedGeom.iblines) mergedGeom.byteSize += mergedGeom.iblines.byteLength;
    // copy primitive type + params (pointSize/lineWidth)
    copyPrimitiveProps(geoms[0], mergedGeom);
    // copy common properties from geom[0]
    copyVertexFormat(geoms[0], mergedGeom);
    // In the shader, an id is a vec3 with components in [0,1].
    // In memory, each component has 8 Bits of the dbId.
    var IDItemSize = 3; // IDs are vec3 in the shader
    // create/add additional per-vertex id attribute
    //
    // Note: The actual array buffer is not created yet, but assigned later.
    //       (see mergeGeometries)
    var idAttrib = new THREE$1.BufferAttribute(null, IDItemSize);
    idAttrib.normalize = true; // shader needs normalized components
    idAttrib.bytesPerItem = 1;
    mergedGeom.addAttribute('id', idAttrib);
    // set primitive type
    var firstGeom = geoms[0];
    var primType = getPrimitiveType(firstGeom);
    setPrimitiveType(mergedGeom, primType);
    // copy size/width for points/wide-lines
    if (firstGeom.isPoints) mergedGeom = firstGeom.pointSize;
    if (firstGeom.isWideLines) mergedGeom = firstGeom.lineWidth;
    return mergedGeom;
}
/**
 * Copies the vertex/index buffers of geoms into mergedGeom. Indices are modified by an offset
 * so that they point to the correct position in mergedGeom's vertex buffer.
 *  @param {BufferGeometry[]} geoms
 *  @param {BufferGeometry}   mergedGeom
 */
function copyVertexAndIndexBuffers(geoms, mergedGeom) {
    // write-offset in mergedGeom.vb (in floats)
    var dstOffset = 0;
    // create combined vertex and index buffer - including transforms
    var vertexOffset = 0;
    var indexOffset = 0;
    var indexOffsetLines = 0;
    for (var i = 0; i < geoms.length; i++) {
        var geom = geoms[i];
        var vertexCount = getVertexCount$2(geom);
        // copy indices (+ offset)
        for (var j = 0; j < geom.ib.length; j++) {
            mergedGeom.ib[indexOffset + j] = geom.ib[j] + vertexOffset;
        }
        // copy line indices
        if (geom.iblines) {
            for (var j = 0; j < geom.iblines.length; j++) {
                mergedGeom.iblines[indexOffsetLines + j] = geom.iblines[j] + vertexOffset;
            }
            indexOffsetLines += geom.iblines.length;
        }
        // copy vertex buffer
        mergedGeom.vb.set(geom.vb, dstOffset);
        dstOffset += geom.vb.length;
        // set offsets for next geom
        vertexOffset += vertexCount;
        indexOffset += geom.ib.length;
    }
}
/**
 * Create a single BufferGeometry that contains all geometries.
 * Requirements:
 *  - All geoms must have identical vertex format.
 *  - Geometries must have interleaved vertex buffers
 *  - Geometries must not have instance buffers. But the same geometry may be added with different matrices.
 *
 *  @param {THREE.BufferGeometry[]} geoms
 *  @param {Float32Array}           matrices - array of matrices per geometry. Each matrix is a range of 16 floats.
 *  @param {Int32Array}             dbIds    - db per input geometry. Used to create per-vertex ids.
 *  @param {THREE.Box3}             worldBox - summed worldBox of all transformed geometries
 *  @param {ParallelGeomMerge}      [parallelMerge] - Coordinates worker threads for parallel merge.
 *                                                    Not needed for single-threaded use.
 *  @returns {LmvBufferGeometry}
 */
function mergeGeometries(geoms, matrices, dbIds, worldBox, parallelMerge) {
    var mergedGeom = createMergeGeom(geoms);
    mergedGeom.boundingBox = worldBox.clone();
    // copy src vertex/index buffers into mergedGeom
    copyVertexAndIndexBuffers(geoms, mergedGeom);
    // The last steps are either done directly or delegated to a worker thread
    if (parallelMerge) {
        parallelMerge.addMergeTask(geoms, mergedGeom, matrices, dbIds);
    } else {
        runMergeSingleThreaded(geoms, mergedGeom, matrices, dbIds);
    }
    return mergedGeom;
}
/**
 *  Returns true if geom1 and geom2 have compatible vertex format to allow merging.
 *  For this, vbstride and all vertex attributes must be equal.
 *
 * Requirement: This function is only called for geoms that...
 *  1. use interleaved vertex buffers
 *  2. do not use instancing
 *
 * @param {THREE.BufferGeometry} geom1
 * @param {THREE.BufferGeometry} geom2
 * @returns {boolean}
 */
function canBeMerged(geom1, geom2) {
    if (geom1.vbstride != geom2.vbstride) {
        return false;
    }
    var primType1 = getPrimitiveType(geom1);
    var primType2 = getPrimitiveType(geom2);
    if (primType1 !== primType2) {
        return false;
    }
    // compare pointSize/lineWidth for points/wideLines
    if (geom1.isPoints && geom1.pointSize !== geom2.pointSize) return false;
    if (geom1.isWideLines && geom1.lineWidth !== geom2.lineWidth) return false;
    if (geom1.attributesKeys.length != geom2.attributesKeys.length) {
        return false;
    }
    // compare each attribute
    for (var i = 0, iEnd = geom1.attributesKeys.length; i < iEnd; i++) {
        var key = geom1.attributesKeys[i];
        // get BufferAttributes of both geoms
        var attrib1 = geom1.attributes[key];
        var attrib2 = geom2.attributes[key];
        // if geom2 does not have this, we are done
        if (!attrib2) {
            return false;
        }
        // Since attributes are cached in WGS BufferGeometry, we will mostly detect equality here already.
        if (attrib1 === attrib2) {
            return true;
        }
        // Compare values. Note that it's not enough to compare the THREE.BufferAttribute properties itemSize and normalize, but
        // also some WGS-specific values (see BufferGeometry.js).
        if (attrib1.itemOffset !== attrib2.itemOffset || attrib1.normalize !== attrib2.normalize || attrib1.itemSize !== attrib2.itemSize || attrib1.bytesPerItem !== attrib2.bytesPerItem || attrib1.isPattern !== attrib2.isPattern) {
            return false;
        }
    }
    return true;
}
/** @class Helper class to collect results of ConsolidationBuilder. */
function Consolidation(fragCount) {
    // all consolidated meshes (+ some original geometries if they could not be merged)
    this.meshes = []; // {THREE.Mesh[]}
    // for each initially added source geometry, this array provides the position
    // in this.meshes where we can find the corresponding output mesh. The output mesh
    // is either
    //  a) a consolidated mesh that includes the input geometry or
    //  b) a mesh that shares the original material and geometry (if it couldn't be merged)
    this.fragId2MeshIndex = new Int32Array(fragCount);
    // init with -1
    for (var i = 0; i < this.fragId2MeshIndex.length; i++) {
        this.fragId2MeshIndex[i] = -1;
    }
    // track summed size
    this.byteSize = 0;
    // keep intermediate result to make reruns faster
    this.consolidationMap = null;
}
Consolidation.prototype = {
    constructor: Consolidation,
    /** Add a consolidation mesh that combines several source geometries.
     *   @param {THREE.BufferGeometry} geom
     *   @param {THREE.Material}       material
     *   @param {number[]}             fragIds      - array of fragment ids associated with this container
     *   @param {number}               [firstFrag]  - Optional: Use (firstFrag, fragCount) to specify
     *   @param {number}               [fragCount]    a range within the fragIds array.
     */
    addContainerMesh: function addContainerMesh(geom, material, fragIds, firstFrag, fragCount) {
        // add new mesh
        var newMesh = new THREE$1.Mesh(geom, material);
        this.meshes.push(newMesh);
        // track byte size
        this.byteSize += geom.byteSize;
        // default range: full array
        var rangeStart = firstFrag || 0;
        var rangeLength = fragCount || fragIds.length;
        var rangeEnd = rangeStart + rangeLength;
        // Disable THREE frustum culling for all shapes.
        //
        // Reason:
        // Default frustum culling of THREE.js does not work and would let the mesh disappear.
        // This happens because newMesh.computeBoundingSphere() fails for interleaved vertex buffers.
        // (see Frustum.intersectsObject used in FireFlyWebGLRenderer.projectObject)
        //
        // Instead, we apply culling before passing a mesh to the Renderer. (see ConsolidationIterator.js)
        newMesh.frustumCulled = false;
        // For each source fragment, remember in which container we find it
        var meshIndex = this.meshes.length - 1;
        for (var i = rangeStart; i < rangeEnd; i++) {
            var fragId = fragIds[i];
            this.fragId2MeshIndex[fragId] = meshIndex;
        }
    },
    /**
     *  Add a single mesh that has unique matrix, fragId, and dbId. This is used to add meshes
     *  that share original geometry that could not be merged with anything else.
     *
     *   @param {THREE.BufferGeometry} geom
     *   @param {THREE.Material}      material
     *   @param {number}               fragId
     *   @param {THREE.Matrix4}        matrix
     *   @param {number}               dbId
     */
    addSingleMesh: function addSingleMesh(geom, material, fragId, matrix, dbId) {
        // create new mesh
        var newMesh = new THREE$1.Mesh(geom, material);
        newMesh.matrix.copy(matrix);
        newMesh.matrixAutoUpdate = false;
        newMesh.dbId = dbId;
        newMesh.fragId = fragId;
        // add it to mesh array
        this.meshes.push(newMesh);
        // Note: We don't track byteSize for these, because these geometries are shared, i.e., do
        //       not consume any extra memory compared to original geometry.
        // Disable frustum culling (see comment in addContainerMesh)
        newMesh.frustumCulled = false;
        // make it possible to find it later
        this.fragId2MeshIndex[fragId] = this.meshes.length - 1;
    },
    /**
     *  Shortcut to add geometry, material etc. of a single fragment to the consolidation.
     *  This is used for all fragments that could not be combined with others.
     *   @param {FragmentList}  fragList
     *   @param {number}        fragId
     */
    addSingleFragment: function addSingleFragment(fragList, fragId) {
        var mesh = fragList.getVizmesh(fragId);
        this.addSingleMesh(mesh.geometry, mesh.material, fragId, mesh.matrixWorld, mesh.dbId);
    }
};
/**
 *  @class ConsolidationBuilder is a utility to merge several (usually small) objects into larger ones to
 *  improve rendering performance.
 */
function ConsolidationBuilder() {
    this.buckets = {}; // {MergeBuchet[]}
    this.bucketCount = 0;
    this.costs = 0; // Consolidation costs in bytes (=costs of merged Geometries for each bucket with >=2 geoms)
}
ConsolidationBuilder.prototype = {
    /**
     *  Add a new Geometry for consolidation. Note that some geometries cannot be merged (e.g., if their material
     *  is different from all others.). In this case, the output mesh just shares input geometry and material.
     *
     *   @param {THREE.BufferGeometry} geom
     *   @param {THREE.Material}       material
     *   @param {THREE.Box3}           worldBox - worldBox (including matrix transform!)
     *   @param {Number}               fragId   - used to find out later in which output mesh you find this fragment
     */
    addGeom: function addGeom(geom, material, worldBox, fragId) {
        // find bucket of meshes that can be merged with the new one
        var bucket = null;
        var buckets = this.buckets[material.id];
        if (buckets) {
            for (var i = 0; i < buckets.length; i++) {
                // get next bucket
                var nextBucket = buckets[i];
                // compatible primitive type and vertex format?
                var bucketGeom = nextBucket.geoms[0];
                if (!canBeMerged(bucketGeom, geom)) {
                    continue;
                }
                // this bucket would allow merging, but only if the vertex count doesn't grow too much
                var vertexCount = getVertexCount$2(geom);
                if (vertexCount + nextBucket.vertexCount > MaxVertexCountPerMesh) {
                    continue;
                }
                // we found a bucket to merge with
                bucket = nextBucket;
                break;
            }
        }
        // create a new bucket to collect this mesh
        if (!bucket) {
            bucket = new MergeBucket(material);
            this.bucketCount++;
            if (!this.buckets[material.id]) this.buckets[material.id] = [bucket];else this.buckets[material.id].push(bucket);
        }
        // add geometry to bucket
        this.costs += bucket.addGeom(geom, worldBox, fragId);
    },
    /**
     * When all geometries have been added to buckets using addGeom() calls, this function converts the buckets into a
     * more compact representation called ConsolidationMap. This map summarizes all information that we need to build
     * the FragmentList consolidation.
     *
     * @param {Uint32Array}    allFragIds      - all fragIds, sorted by consolidation costs.
     * @param {numConsolidate} numConsolidated - number of ids in allFragIds that have been added to consolidation buckets
     *                                           all remaining ones are processed separately by instancing.
     * @returns {ConsolidationMap}
     */
    createConsolidationMap: function createConsolidationMap(allFragIds, numConsolidated) {
        // init result object
        var fragCount = allFragIds.length;
        var result = new ConsolidationMap(fragCount, this.bucketCount);
        // fill fragOrder and ranges. Each range contains all fragIds of a single bucket
        var nextIndex = 0;
        var bucketIdx = 0;
        for (var matId in this.buckets) {
            var buckets = this.buckets[matId];
            for (var b = 0; b < buckets.length; b++) {
                var bucket = buckets[b];
                // store start index of the range in fragOrder that corresponds to this bucket
                result.ranges[bucketIdx] = nextIndex;
                // store bucket box (no need to copy)
                result.boxes[bucketIdx] = bucket.worldBox;
                // append all fragIds in this bucket
                result.fragOrder.set(bucket.fragIds, nextIndex);
                // move nextIndex to the next range start
                nextIndex += bucket.fragIds.length;
                bucketIdx++;
            }
        }
        // remember which fragIds remain and must be processed by instancing
        result.numConsolidated = numConsolidated;
        for (var i = numConsolidated; i < allFragIds.length; i++) {
            result.fragOrder[i] = allFragIds[i];
        }
        return result;
    }
};
/**
 * A ConsolidationMap is an intermediate result of a FragmentList consolidation. It describes which
 * fragments are to be merged into consolidated meshes and which ones have to be processed by instancing.
 */
function ConsolidationMap(fragCount, bucketCount) {
    // Ordered array of fragIds. Each range of the array defines a merge bucket.
    this.fragOrder = new Uint32Array(fragCount);
    // Offsets into fragOrder. ranges[i] is the startIndex of the range corresponding to merge bucket i.
    this.ranges = new Uint32Array(bucketCount);
    // Cached bboxes of consolidated meshes
    this.boxes = new Array(bucketCount);
    // Store how many fragIds in fragOrder have been added to merge buckets.
    // (fragIds[0], ..., fragIds[numConsolidated-1].
    this.numConsolidated = -1; // will be set in createConsolidationMap
}
ConsolidationMap.prototype = {
    /**
     * Create consolidated meshes.
     *  @param {FragmentList}   fragList
     *  @param {MaterialManage} matman
     *  @param {RenderModel}    model
     *  @param {boolean}        [multithreaded] - If true, a part of the geometry merge work is delegated to a
     *                                            worker thread, so that the blocking time is shorter.
     *  @returns {Consolidation}
     */
    buildConsolidation: function buildConsolidation(fragList, matman, model) {
        // some shortcuts
        var fragIds = this.fragOrder;
        var fragCount = fragList.getCount();
        var rangeCount = this.ranges.length;
        var result = new Consolidation(fragCount);
        // Init worker thread if enabled
        var parallelMerge = null;
        // Check if a worker-implementation is available.
        if (multithreadingSupported()) {
            // Activate multithreaded consolidation
            parallelMerge = new ParallelGeomMerge(result);
        } else {}
        // ParallelGeomMerge.registerWorkerSupport(..) must be called before parallel consolidation can be used.
        //console.warn("Multithreaded consolidation requires to registers worker support. Falling back to single-threaded consolidation.");

        // tmp objects
        var geoms = [];
        var matrix = new THREE$1.Matrix4();
        // each range of fragIds is merged into a consolidated mesh
        for (var c = 0; c < rangeCount; c++) {
            // get range of fragIds in this.fragOrder from which we build the next consolidated mesh.
            // Note that this.ranges only contains the range begins and the last range ends at this.numConsolidated.
            var rangeBegin = this.ranges[c];
            var rangeEnd = c === rangeCount - 1 ? this.numConsolidated : this.ranges[c + 1];
            var rangeLength = rangeEnd - rangeBegin;
            // just 1 shape? => just share original geometry and material
            if (rangeLength === 1) {
                var fragId = fragIds[rangeBegin];
                result.addSingleFragment(fragList, fragId, result);
            }
            // create array of BufferGeometry pointers
            geoms.length = rangeLength;
            // create Float32Array containing the matrix per src fragment
            var matrices = new Float32Array(16 * rangeLength);
            // create Int32Array of dbIds
            var dbIds = new Uint32Array(rangeLength);
            for (var i = 0; i < rangeLength; i++) {
                fragId = fragIds[rangeBegin + i];
                // fill geoms
                geoms[i] = fragList.getGeometry(fragId);
                // store matrix as 16 floats
                fragList.getOriginalWorldMatrix(fragId, matrix);
                matrices.set(matrix.elements, 16 * i);
                // store dbId in Int32Array
                dbIds[i] = fragList.getDbIds(fragId);
            }
            // get box of consolidated mesh
            var box = this.boxes[c];
            // use material of first frag in the bucket
            var firstFrag = fragIds[rangeBegin];
            var material = fragList.getMaterial(firstFrag);
            // get geom and material for consolidated mesh
            var mergedGeom = mergeGeometries(geoms, matrices, dbIds, box, parallelMerge);
            var newMaterial = matman.getMaterialVariant(material, MATERIAL_VARIANT.VERTEX_IDS, model);
            // add result
            result.addContainerMesh(mergedGeom, newMaterial, fragIds, rangeBegin, rangeLength);
        }
        if (parallelMerge) {
            // start workers for geometry merging. This will invoke the worker operations and
            // set result.inProgress to true until all worker results are returned.
            parallelMerge.runTasks();
        }
        // store this consolidation map with the consolidation, so that we can rebuild it faster.
        result.consolidationMap = this;
        return result;
    }
};
/**
 * Workaround: Since there is currently no support to spawn workers from WGS
 * code, a createWorker function must be registered from outside to use parallel geometry merging. CreateWorker
 * must return a new worker object that meets the following requirements:
 *
 *   - It is started by:
 *
 *     // msg.operation == "MERGE_GEOMETRY" and msg.tasks an array containing GeomMergeTasks
 *     // The worker runs each GeomMergeTask in msg.tasks in the worker thread.
 *     worker.doOperation(msg, transferList);
 *
 *   - It allows to register an event listener to receive results by:
 *
 *     // see ParallelGeomMerge.handleGeomMergeResults
 *     worker.addEventListenerWithIntercept(handleGeomMergeResult);
 *
 * To activate it in LMV, just call
 *   WGS.Consolidation.registerWorkerSupport(avp.createWorkerWithIntercept);
 *
 * TODO: This can be removed if we get proper worker support in WGS.
 */
function registerWorkerSupport(createWorker) {
    ParallelGeomMerge.createWorker = createWorker;
}
function multithreadingSupported() {
    return !!ParallelGeomMerge.createWorker;
}
var ConsolidationUtils = {
    copyVertexFormat: copyVertexFormat,
    copyPrimitiveProps: copyPrimitiveProps,
    mergeGeometries: mergeGeometries,
    Consolidation: Consolidation,
    ConsolidationBuilder: ConsolidationBuilder,
    registerWorkerSupport: registerWorkerSupport,
    multithreadingSupported: multithreadingSupported
};

/**
 * @class Combines multiple instances of a GeometryBuffer into a single GeometryBuffer that uses hardware instancing.
 *        Input is a single geometry and a sequence of matrix/dbId pairs. Result is a single THREE.Mesh that contains
 *        transforms and dbIds as instance buffer.
 * @constructor
 *  @param {BufferGeometr} srcGeom - Geometry shared by all instances. vb and ib of this buffer will be shared.
 *                                   (unfortunately not on GPU though, because WebGLRenderer doesn't detect support
 *                                   sharing among different GeometryBuffers.)
 *  @param {number} capacity       - Number of instances to be added. It should match the number of instances
 *                                   to avoid wasting memory.
 */
function InstanceBufferBuilder(srcGeom, capacity) {
    // create new geometry that shares vb, ib, and per-vertex attributes
    var _result = createBufferGeometry();
    _result.ib = srcGeom.ib;
    _result.vb = srcGeom.vb;
    _result.iblines = srcGeom.iblines;
    copyVertexFormat(srcGeom, _result);
    copyPrimitiveProps(srcGeom, _result);
    // Currently, we actually write 3 bytes per id. It might be better to use an additional byte for aligment,
    // but non-interleaved BufferAttributes do currently not support that.
    var IDItemSize = 3; // IDs are vec3 in the shader
    var IDBytesPerInstance = 3;
    // buffers that are incrementally filled with addInstance calls
    this.offsets = new Float32Array(3 * capacity); // Vector3
    this.rotations = new Float32Array(4 * capacity); // Quaternion
    this.scalings = new Float32Array(3 * capacity); // Vector3
    this.ids = new Uint8Array(IDBytesPerInstance * capacity); // Vec3<Uint8>
    // temp objects for reuse
    var _offset = new THREE$1.Vector3();
    var _quat = new THREE$1.Quaternion();
    var _scale = new THREE$1.Vector3();
    var _tempMatrix = new THREE$1.Matrix4();
    // number of added instance transforms so far
    var _counter = 0;
    var _capacity = capacity;
    /**
     *  Decomposition of a matrix into translation, rotation, and scale is mostly possible
     *  but not always. If a matrix decomposition is wrong, THREE.Matrix4.decompose() will just
     *  return a wrong result. Therefore, we have to compose it back and compare to see if it
     *  was valid.
     */
    function decompositionValid(srcMatrix, offset, quat, scale) {
        // compose matrix
        _tempMatrix.compose(offset, quat, scale);
        // compare with source matrix
        var Tolerance = 0.00001;
        var ma = srcMatrix.elements;
        var mb = _tempMatrix.elements;
        for (var i = 0; i < 16; i++) {
            var a = ma[i];
            var b = mb[i];
            if (Math.abs(b - a) > Tolerance) {
                return false;
            }
        }
        return true;
    }
    /**
     *  Add next instance. Make sure that you don't exceed the initially given capacity.
     *
     * @param {THREE.Matrix4} transform
     * @param {number}        dbId
     * @returns {boolean}     True:  Instance was successfully added.
     *                        False: Instance could not be added, because the matrix could not be decomposed.
     */
    // Must be called 'numInstances' times to fill the instance buffer.
    this.addInstance = function (transform, dbId) {
        if (_counter >= _capacity) {
            THREE$1.warn("Instance buffer is already full.");
            return false;
        }
        // decompose transform
        transform.decompose(_offset, _quat, _scale);
        // We can only add instances for which the instance matrix can be decomposed.
        // Otherwise, the transform of the instancing version would be wrong.
        if (!decompositionValid(transform, _offset, _quat, _scale)) {
            return false;
        }
        // write offset
        this.offsets[3 * _counter] = _offset.x;
        this.offsets[3 * _counter + 1] = _offset.y;
        this.offsets[3 * _counter + 2] = _offset.z;
        // write rotation
        this.rotations[4 * _counter] = _quat.x;
        this.rotations[4 * _counter + 1] = _quat.y;
        this.rotations[4 * _counter + 2] = _quat.z;
        this.rotations[4 * _counter + 3] = _quat.w;
        // write scale
        this.scalings[IDBytesPerInstance * _counter] = _scale.x;
        this.scalings[IDBytesPerInstance * _counter + 1] = _scale.y;
        this.scalings[IDBytesPerInstance * _counter + 2] = _scale.z;
        // write dbId
        writeIdToBuffer(dbId, this.ids, IDBytesPerInstance * _counter);
        _counter++;
        return true;
    };
    /**
     * Call this after adding all transforms to get instanced geometry.
     *  @returns {null|THREE.Mesh} Returns instanced GeometryBuffer if >=1 instances have been added successfully.
     */
    // note that addInstance() must be called for each instance transform first.
    this.finish = function () {
        // no instances
        if (_counter == 0) {
            return null;
        }
        // In special cases, we had to reject some addInstance() calls, so that the
        // instance buffer is not fully used. In this case, we create smaller views
        // to the same buffers that ignore the unused elements at the end.
        if (_counter < _capacity) {
            this.offsets = new Float32Array(this.offsets.buffer, 0, 3 * _counter); // Vector3
            this.rotations = new Float32Array(this.rotations.buffer, 0, 4 * _counter); // Quaternion
            this.scalings = new Float32Array(this.scalings.buffer, 0, 3 * _counter); // Vector3
            this.ids = new Uint8Array(this.ids.buffer, 0, IDBytesPerInstance * _counter); // Vec3<Uint8>
        }
        // add attributes for transforms
        var offsetAttrib = new THREE$1.BufferAttribute(this.offsets, 3);
        var rotationAttrib = new THREE$1.BufferAttribute(this.rotations, 4);
        var scalingAttrib = new THREE$1.BufferAttribute(this.scalings, 3);
        var idAttrib = new THREE$1.BufferAttribute(this.ids, IDItemSize);
        idAttrib.normalize = true;
        idAttrib.bytesPerItem = 1;
        // mark attributes as "per-instance" (instead of per-vertex as default)
        offsetAttrib.divisor = 1;
        rotationAttrib.divisor = 1;
        scalingAttrib.divisor = 1;
        idAttrib.divisor = 1;
        _result.addAttribute('instOffset', offsetAttrib);
        _result.addAttribute('instRotation', rotationAttrib);
        _result.addAttribute('instScaling', scalingAttrib);
        _result.addAttribute('id', idAttrib);
        _result.numInstances = _counter;
        // add byte size for memory tracking (vertices + indices + instances)
        _result.byteSize = _result.vb.byteLength + _result.ib.byteLength + this.offsets.byteLength + this.rotations.byteLength + this.scalings.byteLength;
        return _result;
    };
}

var resolve$1 = ShaderChunks.resolve;
var isIE11 = typeof navigator !== "undefined" && !!navigator.userAgent.match(/Trident\/7\./);
var PrismMaps = ["opaque_luminance_modifier", "surface_albedo", "surface_roughness", "surface_anisotropy", "surface_rotation", "opaque_f0", "opaque_albedo", "metal_f0", "layered_f0", "layered_diffuse", "layered_roughness", "layered_anisotropy", "layered_rotation", "layered_bottom_f0", "layered_fraction", "surface_cutout", "glazing_transmission_color", "glazing_f0", "glazing_transmission_roughness", "wood_curly_distortion"];
// We test if the UVs are in the bounds when clamping; if not, discard!
// This is done here because we have access to the clamp parameters. The macro #defined
// by this method can then be used elsewhere, e.g. GetPrismMapSampleChunk, without knowledge of these parameters.
// Here is a typical result returned when clamping is on and "opaque_albedo" is passed in for the name:
// #define OPAQUE_ALBEDO_CLAMP_TEST if (uv_opaque_albedo_map.x < 0.0 || uv_opaque_albedo_map.x > 1.0 || uv_opaque_albedo_map.y < 0.0 || uv_opaque_albedo_map.y > 1.0) { discard; }
var GetPrismMapChunk = function GetPrismMapChunk(name, clampS, clampT) {
    var uv = "uv_" + name + "_map";
    var conditionChunk = "";
    if (clampS && clampT) conditionChunk = "if (" + uv + ".x < 0.0 || " + uv + ".x > 1.0 || " + uv + ".y < 0.0 || " + uv + ".y > 1.0) { discard; }";else if (clampS) conditionChunk = "if (" + uv + ".x < 0.0 || " + uv + ".x > 1.0) { discard; }";else if (clampT) conditionChunk = "if (" + uv + ".y < 0.0 || " + uv + ".y > 1.0) { discard; }";
    return "#define " + name.toUpperCase() + "_CLAMP_TEST " + conditionChunk;
};
//Based on THREE.WebGLProgram, with some defines added / removed.
var WebGLProgram = function () {
    'use strict';

    var programIdCount = 0;
    var generateDefines = function generateDefines(defines) {
        var value,
            chunk,
            chunks = [];
        for (var d in defines) {
            value = defines[d];
            if (value === false) continue;
            chunk = "#define " + d + " " + value;
            chunks.push(chunk);
        }
        return chunks.join("\n");
    };
    var cacheUniformLocations = function cacheUniformLocations(gl, program, identifiers) {
        var uniforms = {};
        for (var i = 0, l = identifiers.length; i < l; i++) {
            var id = identifiers[i];
            uniforms[id] = gl.getUniformLocation(program, id);
        }
        return uniforms;
    };
    var cacheAttributeLocations = function cacheAttributeLocations(gl, program, identifiers) {
        var attributes = {};
        for (var i = 0, l = identifiers.length; i < l; i++) {
            var id = identifiers[i];
            attributes[id] = gl.getAttribLocation(program, id);
        }
        return attributes;
    };
    // Add clamping and inversion code for the simple Phong material perform any operations needed.
    // This is done here because we have access to the clamp and inversion parameters. The macro #defined
    // by this method can then be used elsewhere without knowledge of these parameters.
    var getMapChunk = function getMapChunk(name, clampS, clampT, invert, emptyChunk) {
        var invertChunk = invert ? "1.0-" : "";
        var readChunk = "texture2D(" + name + ", (UV))";
        var conditionChunk = "";
        emptyChunk = emptyChunk || "vec4(0.0)";
        if (clampS && clampT) conditionChunk = "((UV).x < 0.0 || (UV).x > 1.0 || (UV).y < 0.0 || (UV).y > 1.0) ? " + emptyChunk + " : ";else if (clampS) conditionChunk = "((UV).x < 0.0 || (UV).x > 1.0) ? " + emptyChunk + " : ";else if (clampT) conditionChunk = "((UV).y < 0.0 || (UV).y > 1.0) ? " + emptyChunk + " : ";
        return "#define GET_" + name.toUpperCase() + "(UV) (" + conditionChunk + invertChunk + readChunk + ")";
    };
    var getPrismMapsChunk = function getPrismMapsChunk(parameters) {
        var result = "\n";
        for (var i = 0; i < PrismMaps.length; i++) {
            var val = parameters[PrismMaps[i]];
            if (val) result += GetPrismMapChunk(PrismMaps[i], val.S, val.T) + "\n";
        }
        return result;
    };
    return function (renderer, code, material, parameters) {
        var _this = renderer;
        var _gl = _this.context;
        var defines = material.defines;
        var uniforms = material.__webglShader.uniforms;
        var attributes = material.attributes;
        var vertexShader = resolve$1(material.__webglShader.vertexShader);
        var fragmentShader = resolve$1(material.__webglShader.fragmentShader);
        var index0AttributeName = material.index0AttributeName;
        if (index0AttributeName === undefined && parameters.morphTargets === true) {
            // programs with morphTargets displace position out of attribute 0
            index0AttributeName = 'position';
        }
        var envMapTypeDefine = 'ENVMAP_TYPE_CUBE';
        var envMapModeDefine = 'ENVMAP_MODE_REFLECTION';
        var envMapBlendingDefine = 'ENVMAP_BLENDING_MULTIPLY';
        var gammaFactorDefine = renderer.gammaFactor > 0 ? renderer.gammaFactor : 1.0;
        // THREE.log( "building new program " );
        //
        var customDefines = generateDefines(defines);
        //
        var program = _gl.createProgram();
        var prefix_vertex, prefix_fragment;
        if (material instanceof THREE$1.RawShaderMaterial) {
            prefix_vertex = '';
            prefix_fragment = '';
        } else {
            prefix_vertex = ["precision " + parameters.precision + " float;", "precision " + parameters.precision + " int;", customDefines, parameters.vertexPrefix, parameters.supportsVertexTextures ? "#define VERTEX_TEXTURES" : "", _this.gammaInput ? "#define GAMMA_INPUT" : "", _this.gammaOutput ? "#define GAMMA_OUTPUT" : "", '#define GAMMA_FACTOR ' + gammaFactorDefine, parameters.mrtNormals ? "#define MRT_NORMALS" : "", parameters.mrtIdBuffer ? "#define MRT_ID_BUFFER" : "", "#define MAX_DIR_LIGHTS " + parameters.maxDirLights, "#define MAX_POINT_LIGHTS " + parameters.maxPointLights, "#define MAX_SPOT_LIGHTS " + parameters.maxSpotLights, "#define MAX_HEMI_LIGHTS " + parameters.maxHemiLights, "#define MAX_BONES " + parameters.maxBones, "#define NUM_CUTPLANES " + parameters.numCutplanes, parameters.map ? "#define USE_MAP" : "", parameters.envMap ? "#define USE_ENVMAP" : "", parameters.envMap ? '#define ' + envMapModeDefine : '', parameters.irradianceMap ? "#define USE_IRRADIANCEMAP" : "", parameters.lightMap ? "#define USE_LIGHTMAP" : "", parameters.bumpMap ? "#define USE_BUMPMAP" : "", parameters.normalMap ? "#define USE_NORMALMAP" : "", parameters.specularMap ? "#define USE_SPECULARMAP" : "", parameters.alphaMap ? "#define USE_ALPHAMAP" : "", parameters.vertexColors ? "#define USE_COLOR" : "", parameters.vertexIds ? "#define USE_VERTEX_ID" : "", parameters.useTiling ? "#define USE_TILING" : "", parameters.useInstancing ? "#define USE_INSTANCING" : "", parameters.wideLines ? "#define WIDE_LINES" : "", parameters.skinning ? "#define USE_SKINNING" : "", parameters.useVertexTexture ? "#define BONE_TEXTURE" : "", parameters.morphTargets ? "#define USE_MORPHTARGETS" : "", parameters.morphNormals ? "#define USE_MORPHNORMALS" : "", parameters.wrapAround ? "#define WRAP_AROUND" : "", parameters.doubleSided ? "#define DOUBLE_SIDED" : "", parameters.flipSided ? "#define FLIP_SIDED" : "", parameters.sizeAttenuation ? "#define USE_SIZEATTENUATION" : "", parameters.logarithmicDepthBuffer ? "#define USE_LOGDEPTHBUF" : "", parameters.useFragDepthExt ? "#define USE_LOGDEPTHBUF_EXT" : "", parameters.packedNormals ? "#define UNPACK_NORMALS" : "",
            // "#define FLAT_SHADED",  // TODO_NOP: hook up to param
            "uniform mat4 modelMatrix;", "uniform mat4 modelViewMatrix;", "uniform mat4 projectionMatrix;", "uniform mat4 viewMatrix;", "uniform mat3 normalMatrix;", "uniform vec3 cameraPosition;", "attribute vec3 position;", "#ifdef UNPACK_NORMALS", "attribute vec2 normal;", "#else", "attribute vec3 normal;", "#endif", "attribute vec2 uv;", "attribute vec2 uv2;", "#ifdef PRISMWOOD", "attribute vec3 uvw;", "#endif", "#ifdef USE_COLOR", "   attribute vec3 color;", "#endif", ""].join('\n');
            prefix_fragment = [parameters.bumpMap || parameters.normalMap ? "#extension GL_OES_standard_derivatives : enable" : "", (parameters.mrtIdBuffer || parameters.mrtNormals) && !isIE11 ? "#extension GL_EXT_draw_buffers : enable" : "", parameters.mrtIdBuffer ? "#define gl_FragColor gl_FragData[0]" : "", parameters.haveTextureLod ? "#define HAVE_TEXTURE_LOD" : "", customDefines, parameters.fragmentPrefix, "#define MAX_DIR_LIGHTS " + parameters.maxDirLights, "#define MAX_POINT_LIGHTS " + parameters.maxPointLights, "#define MAX_SPOT_LIGHTS " + parameters.maxSpotLights, "#define MAX_HEMI_LIGHTS " + parameters.maxHemiLights, "#define NUM_CUTPLANES " + parameters.numCutplanes, parameters.alphaTest ? "#define ALPHATEST " + parameters.alphaTest : "", _this.gammaInput ? "#define GAMMA_INPUT" : "", _this.gammaOutput ? "#define GAMMA_OUTPUT" : "", '#define GAMMA_FACTOR ' + gammaFactorDefine, parameters.mrtNormals ? "#define MRT_NORMALS" : "", parameters.mrtIdBuffer ? "#define MRT_ID_BUFFER" : "", parameters.mrtIdBuffer > 1 ? "#define MODEL_COLOR" : "", '#define TONEMAP_OUTPUT ' + (parameters.tonemapOutput || 0), parameters.useFog && parameters.fog ? "#define USE_FOG" : "", parameters.useFog && parameters.fogExp ? "#define FOG_EXP2" : "", parameters.map ? "#define USE_MAP" : "", parameters.envMap ? "#define USE_ENVMAP" : "", parameters.envMap ? '#define ' + envMapTypeDefine : '', parameters.envMap ? '#define ' + envMapModeDefine : '', parameters.envMap ? '#define ' + envMapBlendingDefine : '', parameters.irradianceMap ? "#define USE_IRRADIANCEMAP" : "", parameters.envGammaEncoded ? "#define ENV_GAMMA" : "", parameters.irrGammaEncoded ? "#define IRR_GAMMA" : "", parameters.envRGBM ? "#define ENV_RGBM" : "", parameters.irrRGBM ? "#define IRR_RGBM" : "", parameters.lightMap ? "#define USE_LIGHTMAP" : "", parameters.bumpMap ? "#define USE_BUMPMAP" : "", parameters.normalMap ? "#define USE_NORMALMAP" : "", parameters.specularMap ? "#define USE_SPECULARMAP" : "", parameters.alphaMap ? "#define USE_ALPHAMAP" : "", parameters.vertexColors ? "#define USE_COLOR" : "", parameters.vertexIds ? "#define USE_VERTEX_ID" : "", parameters.metal ? "#define METAL" : "", parameters.clearcoat ? "#define CLEARCOAT" : "", parameters.wrapAround ? "#define WRAP_AROUND" : "", parameters.doubleSided ? "#define DOUBLE_SIDED" : "", parameters.flipSided ? "#define FLIP_SIDED" : "", parameters.logarithmicDepthBuffer ? "#define USE_LOGDEPTHBUF" : "",
            //parameters.useFragDepthExt ? "#define USE_LOGDEPTHBUF_EXT" : "",
            parameters.hatchPattern ? "#define HATCH_PATTERN" : "", parameters.mapInvert ? "#define MAP_INVERT" : "", parameters.useTiling ? "#define USE_TILING" : "", parameters.useTiling ? "#define TILE_RANGE_X_MIN " + parameters.tilingRepeatRange[0] : "", parameters.useTiling ? "#define TILE_RANGE_Y_MIN " + parameters.tilingRepeatRange[1] : "", parameters.useTiling ? "#define TILE_RANGE_X_MAX " + parameters.tilingRepeatRange[2] : "", parameters.useTiling ? "#define TILE_RANGE_Y_MAX " + parameters.tilingRepeatRange[3] : "", parameters.hasRoundCorner ? "#define USE_TILING_NORMAL" : "", parameters.useRandomOffset ? "#define USE_TILING_RANDOM" : "", getMapChunk("map", parameters.mapClampS, parameters.mapClampT), getMapChunk("bumpMap", parameters.bumpMapClampS, parameters.bumpMapClampT), getMapChunk("normalMap", parameters.normalMapClampS, parameters.normalMapClampT), getMapChunk("specularMap", parameters.specularMapClampS, parameters.specularMapClampT), getMapChunk("alphaMap", parameters.alphaMapClampS, parameters.alphaMapClampT, parameters.alphaMapInvert),
            // "#define FLAT_SHADED",  // TODO_NOP: hook up to param
            "#ifdef USE_ENVMAP", "#ifdef HAVE_TEXTURE_LOD", "#extension GL_EXT_shader_texture_lod : enable", "#endif", '#endif', "#extension GL_OES_standard_derivatives : enable", "precision " + parameters.precisionFragment + " float;", "precision " + parameters.precisionFragment + " int;", "uniform highp mat4 viewMatrix;", "uniform highp mat4 projectionMatrix;", "uniform highp vec3 cameraPosition;", "#if defined(USE_ENVMAP) || defined(USE_IRRADIANCEMAP)", "uniform mat4 viewMatrixInverse;", "#endif", ""].join('\n');
            // now get map chunks for PRISM material
            // mapPrismOpaqueLuminanceModifierClampS etc. are set in WebGLRenderer.js in the parameters
            if (parameters.isPrism) prefix_fragment += getPrismMapsChunk(parameters);
        }
        var glVertexShader = new WebGLShader(_gl, _gl.VERTEX_SHADER, prefix_vertex + vertexShader);
        var glFragmentShader = new WebGLShader(_gl, _gl.FRAGMENT_SHADER, prefix_fragment + fragmentShader);
        _gl.attachShader(program, glVertexShader);
        _gl.attachShader(program, glFragmentShader);
        if (index0AttributeName !== undefined) {
            // Force a particular attribute to index 0.
            // because potentially expensive emulation is done by browser if attribute 0 is disabled.
            // And, color, for example is often automatically bound to index 0 so disabling it
            _gl.bindAttribLocation(program, 0, index0AttributeName);
        }
        _gl.linkProgram(program);
        if (DEBUG_SHADERS) {
            if (_gl.getProgramParameter(program, _gl.LINK_STATUS) === false) {
                THREE$1.error('THREE.WebGLProgram: Could not initialise shader.');
                THREE$1.error('gl.VALIDATE_STATUS', _gl.getProgramParameter(program, _gl.VALIDATE_STATUS));
                THREE$1.error('gl.getError()', _gl.getError());
            }
            if (_gl.getProgramInfoLog(program) !== '') {
                THREE$1.warn('THREE.WebGLProgram: gl.getProgramInfoLog()', _gl.getProgramInfoLog(program));
            }
        }
        // clean up
        _gl.deleteShader(glVertexShader);
        _gl.deleteShader(glFragmentShader);
        // cache uniform locations
        var identifiers = ['viewMatrix', 'modelViewMatrix', 'projectionMatrix', 'normalMatrix', 'modelMatrix', 'cameraPosition', 'viewMatrixInverse', 'mvpMatrix', 'dbId' //FY
        ];
        if (parameters.logarithmicDepthBuffer) {
            identifiers.push('logDepthBufFC');
        }
        for (var u in uniforms) {
            identifiers.push(u);
        }
        this.uniforms = cacheUniformLocations(_gl, program, identifiers);
        // cache attributes locations
        identifiers = ["position", "normal", "uv", "uv2", "tangent", "color", "lineDistance", "uvw", "id", "instOffset", "instScaling", "instRotation", "prev", "next", "side" // attributes for wide lines
        ];
        for (var a in attributes) {
            identifiers.push(a);
        }
        this.attributes = cacheAttributeLocations(_gl, program, identifiers);
        this.attributesKeys = Object.keys(this.attributes);
        //
        this.id = programIdCount++;
        this.code = code;
        this.usedTimes = 1;
        this.program = program;
        this.vertexShader = glVertexShader;
        this.fragmentShader = glFragmentShader;
        return this;
    };
}();
var WebGLProgramUtils = {
    PrismMaps: PrismMaps,
    GetPrismMapChunk: GetPrismMapChunk,
    WebGLProgram: WebGLProgram
};

var groundshadow_depth_vert = "#ifdef USE_LOGDEPTHBUF\n#ifdef USE_LOGDEPTHBUF_EXT\nvarying float vFragDepth;\n#endif\nuniform float logDepthBufFC;\n#endif\n#if NUM_CUTPLANES > 0\nvarying vec3 vWorldPosition;\n#endif\nvoid main() {\n    gl_Position = projectionMatrix * modelViewMatrix * vec4( position, 1.0 );;\n#if NUM_CUTPLANES > 0\n    vec4 worldPosition = modelMatrix * vec4( position, 1.0 );\n    vWorldPosition = worldPosition.xyz;\n#endif\n#ifdef USE_LOGDEPTHBUF\n    gl_Position.z = log2(max(1e-6, gl_Position.w + 1.0)) * logDepthBufFC;\n#ifdef USE_LOGDEPTHBUF_EXT\n    vFragDepth = 1.0 + gl_Position.w;\n#else\n    gl_Position.z = (gl_Position.z - 1.0) * gl_Position.w;\n#endif\n#endif\n}\n";

var groundshadow_depth_frag = "#ifdef USE_LOGDEPTHBUF\nuniform float logDepthBufFC;\n#ifdef USE_LOGDEPTHBUF_EXT\n#extension GL_EXT_frag_depth : enable\nvarying float vFragDepth;\n#endif\n#endif\n#include<pack_depth>\n#if NUM_CUTPLANES > 0\nvarying vec3 vWorldPosition;\n#endif\n#include<cutplanes>\nvoid main() {\n#if NUM_CUTPLANES > 0\n    checkCutPlanes(vWorldPosition);\n#endif\n#if defined(USE_LOGDEPTHBUF) && defined(USE_LOGDEPTHBUF_EXT)\n    gl_FragDepthEXT = log2(vFragDepth) * logDepthBufFC * 0.5;\n#endif\n#ifdef USE_LOGDEPTHBUF_EXT\n    float depth = gl_FragDepthEXT / gl_FragCoord.w;\n#else\n    float depth = gl_FragCoord.z / gl_FragCoord.w;\n#endif\n    depth = 1.0 - depth;\n    gl_FragColor = packDepth(depth);\n}\n";

var groundshadow_ao_frag = "#define NUM_SAMPLES 29.0\n#define NUM_SPIRAL_TURNS 7.0\nuniform sampler2D tDepth;\nuniform vec3 worldSize;\nvarying vec2 vUv;\n#ifdef PRESET_2\n#define SAMPLE_RADIUS 0.3\n#define AO_GAMMA 1.0\n#define AO_INTENSITY 1.0\n#else\n#define SAMPLE_RADIUS 0.2\n#define AO_GAMMA 3.0\n#define AO_INTENSITY 0.8\n#endif\n#include<pack_depth>\n#define PI 3.14159265358979\nfloat rand(vec2 co) {\n    return fract(sin(dot(co.xy, vec2(12.9898, 78.233))) * 43758.5453);\n}\nfloat getRandomAngle(vec2 pos) {\n    return rand(pos) * (2.0 * PI);\n}\nvec2 tapLocation(float sampleNumber, float spinAngle, out float ssR){\n    float alpha = float(sampleNumber + 0.5) * (1.0 / NUM_SAMPLES);\n    float angle = alpha * (NUM_SPIRAL_TURNS * PI * 2.0) + spinAngle;\n    ssR = alpha;\n    return vec2(cos(angle), sin(angle));\n}\nvec2 sampleAO(vec2 unitDirection, float radius) {\n    vec2 sampleOffset = unitDirection * radius;\n    float idepth = unpackDepth(texture2D(tDepth, vUv + sampleOffset));\n    float depth = 1.0 - idepth;\n    if (depth < 1e-6) {\n        if (radius == 0.0)\n            return vec2(1.0, 1.0);\n        else\n            return vec2(0.0, 1.0);\n    }\n    vec3 dir = vec3(sampleOffset.x, depth, sampleOffset.y) * worldSize;\n    float distance2 = dot(dir,dir);\n    float idistance = 1.0 / sqrt(distance2);\n    vec3 ndir = dir * idistance;\n#ifdef PRESET_2\n    float importance = ndir.y * idistance;\n#else\n    float importance = ndir.y / distance2;\n#endif\n    vec2 ret;\n    ret.x = (idepth == 0.0) ? 0.0 : importance;\n    ret.y = importance;\n    return ret;\n}\nvoid main() {\n    vec2 sum = vec2(0.0);\n    float angle = getRandomAngle(vUv);\n    for (float i = 0.0; i<NUM_SAMPLES; i+= 1.0) {\n        float ssR;\n        vec2 uv = tapLocation(i, angle, ssR);\n        sum += sampleAO(uv, ssR * SAMPLE_RADIUS);\n    }\n    float ao = sum.x / sum.y;\n    gl_FragColor = packDepth(AO_INTENSITY * clamp(pow(ao, AO_GAMMA), 0.0, 0.9999));\n}\n";

var groundshadow_blur_frag = "uniform sampler2D tDepth;\nvarying vec2 vUv;\n#ifdef HORIZONTAL\n#define GET_UV(X) vec2(vUv.x + KERNEL_SCALE*(X), vUv.y)\n#else\n#define GET_UV(Y) vec2(vUv.x, vUv.y + KERNEL_SCALE*(Y))\n#endif\n#include<pack_depth>\n#define PI 3.14159265358979\n#define SIGMA ((2.0 * KERNEL_RADIUS+1.0) / 6.0)\n#define SIGMASQ2 (2.0 * SIGMA * SIGMA)\n#ifdef BOX\n#define KERNEL_VAL(X) 1.0\n#else\n#define KERNEL_VAL(X) ( (1.0 / sqrt(PI * SIGMASQ2)) * exp(-(X)*(X)/SIGMASQ2) )\n#endif\nvoid main() {\n    float depthVal = 0.0;\n    float sum = 0.0;\n    for (float x=-KERNEL_RADIUS; x<=KERNEL_RADIUS; x+=1.0) {\n        depthVal += unpackDepth(texture2D(tDepth, GET_UV(x))) * KERNEL_VAL(x);\n        sum += KERNEL_VAL(x);\n    }\n    gl_FragColor = packDepth(depthVal/sum);\n}\n";

var groundshadow_color_frag = "uniform sampler2D tDepth;\nuniform vec4 uShadowColor;\nvarying vec2 vUv;\n#include<pack_depth>\nvoid main() {\n    float depthVal = unpackDepth(texture2D(tDepth, vUv));\n    gl_FragColor = vec4(uShadowColor.rgb, uShadowColor.a * depthVal);\n}\n";

var GroundDepthShader = {
    uniforms: {
        "cutplanes": { type: "v4v", value: [] }
    },
    vertexShader: groundshadow_depth_vert,
    fragmentShader: groundshadow_depth_frag
};
var GroundShadowAOShader = {
    uniforms: {
        tDepth: { type: "t", value: null },
        worldSize: { type: "v3", value: new THREE$1.Vector3(1, 1, 1) }
    },
    defines: {},
    vertexShader: screen_quad_uv_vert,
    fragmentShader: groundshadow_ao_frag
};
var GroundShadowBlurShader = {
    uniforms: {
        tDepth: { type: "t", value: null }
    },
    defines: {},
    vertexShader: screen_quad_uv_vert,
    fragmentShader: groundshadow_blur_frag
};
var GroundShadowColorShader = {
    uniforms: {
        tDepth: { type: "t", value: null },
        uShadowColor: { type: "v4", value: new THREE$1.Vector4(0, 0, 0, 1) }
    },
    vertexShader: screen_quad_uv_vert,
    fragmentShader: groundshadow_color_frag
};
// create plane shape to render shadow on the ground. It is a quad located in the z=0.0 plane
// with an xy-extent of [-0.5, -0.5].
function createGroundShape(material) {
    var planeGeo = new THREE$1.PlaneBufferGeometry(1, 1);
    // invert orientation so that it finally faces upwards
    if (planeGeo.attributes.index.array.reverse) {
        planeGeo.attributes.index.array.reverse();
    } else {
        // IE11...
        // in-place swapping
        var tmp;
        var arr = planeGeo.attributes.index.array;
        var half = Math.floor(arr.length / 2);
        for (var i = 0, len = arr.length; i < half; ++i) {
            tmp = arr[i];
            arr[i] = arr[len - 1 - i];
            arr[len - 1 - i] = tmp;
        }
    }
    var planeMesh = new THREE$1.Mesh(planeGeo, material);
    return planeMesh;
}
var setGroundShapeTransform = function () {
    var m, from, bottomFaceCenter;
    return function (mesh, center, size, worldUp, rightAxis) {
        if (!m) m = new THREE$1.Matrix4();
        if (!from) from = new THREE$1.Vector3();
        if (!bottomFaceCenter) bottomFaceCenter = new THREE$1.Vector3();
        // compute rotation
        from.subVectors(center, worldUp);
        m.lookAt(from, center, rightAxis);
        // the ground shape quad center is the lower-face center of the bbox
        bottomFaceCenter.copy(worldUp).multiplyScalar(-0.5 * size.y).add(center);
        // plane transform
        mesh.position.copy(bottomFaceCenter);
        mesh.rotation.setFromRotationMatrix(m);
        mesh.scale.set(size.z, size.x, size.y);
    };
}();
var GroundShadow = function GroundShadow(renderer, params) {
    var _renderer = renderer;
    var _camera;
    var _scene;
    var _planeMesh;
    var _targetH, _targetV;
    var _matDepth, _matColor;
    var _blurPassH, _blurPassV, _aoPass;
    var _debugBox;
    var _bufferValid = false;
    var USE_AO_PASS = false;
    var _needClear = true;
    var _status = GROUND_FINISHED;
    // param defaults
    var _params = {
        texSize: USE_AO_PASS ? 128.0 : 64.0,
        pixScale: 1.0,
        blurRadius: USE_AO_PASS ? 5.0 : 7.0,
        debug: false
    };
    // FUNCTIONS
    /**
     * Set transform of the ground shadow system
     * @param {Vector3} center  center of bounding box
     * @param {Vector3} size    size in look&up coordinates, look = y
     * @param {Vector3} lookDir look direction, where ground camera is facing
     * @param {Vector3} upDir   up direction for ground camera
     */
    this.setTransform = function () {
        var prevCenter = new THREE$1.Vector3(0, 0, 0);
        var prevSize = new THREE$1.Vector3(0, 0, 0);
        var prevLookDir = new THREE$1.Vector3(0, 0, 0);
        var prevUpDir = new THREE$1.Vector3(0, 0, 0);
        return function (center, size, lookDir, upDir) {
            // check if changed - if not, it saves us an entire ground shadow redraw!
            if (center.equals(prevCenter) && size.equals(prevSize) && lookDir.equals(prevLookDir) && upDir.equals(prevUpDir)) {
                return;
            }
            prevCenter.copy(center);
            prevSize.copy(size);
            prevLookDir.copy(lookDir);
            prevUpDir.copy(upDir);
            // something's changing, so need to regenerate ground shadow
            this.setDirty();
            // ortho frustrum
            _camera.left = -size.z / 2.0;
            _camera.right = size.z / 2.0;
            _camera.top = size.x / 2.0;
            _camera.bottom = -size.x / 2.0;
            _camera.near = 1.0;
            _camera.far = size.y + _camera.near;
            // update projection
            _camera.updateProjectionMatrix();
            setGroundShapeTransform(_planeMesh, center, size, lookDir, upDir);
            // camera transform
            _camera.position.addVectors(center, lookDir.clone().multiplyScalar(-size.y / 2.0 - _camera.near));
            if (upDir) _camera.up.set(upDir.x, upDir.y, upDir.z);
            _camera.lookAt(center);
            // debug box
            if (_params.debug) {
                _debugBox.position.set(center.x, center.y, center.z);
                _debugBox.rotation.set(_camera.rotation.x, _camera.rotation.y, _camera.rotation.z);
                _debugBox.scale.set(size.z, size.x, size.y);
            }
            _aoPass.uniforms['worldSize'].value.copy(size);
        };
    }();
    this.renderIntoShadow = function (scene) {
        //Skip ghosted objects
        if (scene.overrideMaterial && scene.overrideMaterial.transparent) return;
        var oldMat = scene.overrideMaterial;
        scene.overrideMaterial = _matDepth;
        _renderer.render(scene, _camera, _targetH, false);
        scene.overrideMaterial = oldMat;
        // THREE.log("GS render in");
    };
    // Generate ground shadow texture. Return GROUND code.
    // The ground shadow generation has two modes:
    // No argument means render the whole shadow until done
    // else, argument means render the shadow until time is up.
    // This second mode is mean for progressive rendering of small scenes;
    // if during command creation we approximate that the whole shadow process
    // will be done quickly enough, we try to render it fully in the allotted time.
    // Arguments are:
    //   modelQueue - what to render
    //   maxTime - current budget left. Infinite, if not specified.
    //   ratio - how much of this budget we get. 1.0 if not specified.
    //   maxObjs - can also give a maximum number of objects.
    // returns time left, if maxTime is specified; else just returns maxTime value (undefined).
    this.prepareGroundShadow = function () {
        var qScenes;
        var qSceneCount = 0;
        var qSceneIdx = 0;
        var MAX_PROCESS_FRAMES = 100;
        var maxScenesPerFrame = 0;
        return function (modelQueue, minScenesPerFrame, maxTime, ratio) {
            // if the ground shadow is off, don't continue
            if (!this.enabled || modelQueue.isEmpty()) {
                _status = GROUND_FINISHED;
                return maxTime;
            }
            // This will happen once the linear render list is replaced
            // by the BVH.
            if (qScenes != modelQueue.getGeomScenes()) _needClear = true;
            // Get a separate set of scenes (render batches) for us to traverse. Everything gets traversed.
            if (_needClear) {
                this.clear();
                _needClear = false;
                qScenes = modelQueue.getGeomScenes();
                qSceneCount = qScenes.length;
                qSceneIdx = 0;
                if (minScenesPerFrame) {
                    maxScenesPerFrame = Math.max(Math.ceil(qSceneCount / MAX_PROCESS_FRAMES), minScenesPerFrame);
                } else {
                    maxScenesPerFrame = qSceneCount;
                }
            } else if (_status === GROUND_RENDERED || _status === GROUND_FINISHED) {
                // If drop shadow is valid, we're done, no rendering needed.
                // this call did not render it, so make sure the rendered status is set to finished.
                _status = GROUND_FINISHED;
                return maxTime;
            } else if (minScenesPerFrame === 0) {
                // render rest of scene, time permitting
                maxScenesPerFrame = qSceneCount;
            }
            // progressive draw into shadow
            var startTime, budget;
            if (maxTime) {
                startTime = performance.now();
                ratio = ratio === undefined ? 1.0 : ratio;
                budget = ratio * maxTime;
            }
            var retval;
            var i = 0;
            while (i < maxScenesPerFrame && qSceneIdx < qSceneCount) {
                // Note that we'll always render at least one batch here, regardless of time.
                // Not sure this is necessary, but it does avoid something going bad that causes
                // the timer to always fail and so get us caught in an infinite loop of calling
                // this method again and again.
                var qScene = qScenes[qSceneIdx++];
                if (qScene) {
                    i++;
                    // passing forceVisible to WebGLRenderer.projectObject()
                    qScene.forceVisible = true;
                    // Note we render everything in the scene (render batch) to the ground plane,
                    // so we don't have to worry about frustum culling, etc. - just blast through.
                    this.renderIntoShadow(qScene);
                    qScene.forceVisible = false;
                    // check time, if used
                    if (maxTime) {
                        var timeElapsed = performance.now() - startTime;
                        // is time up and we're not done?
                        if (budget < timeElapsed) {
                            // couldn't finish render in time
                            _status = GROUND_UNFINISHED;
                            retval = maxTime - timeElapsed;
                            break;
                        }
                    }
                }
            }
            // Did we finish? We only reach this path if the maxObj limit is reached.
            if (qSceneIdx < qSceneCount) {
                _status = GROUND_UNFINISHED;
                // return time left, or 1, meaning we're not done.
                retval = maxTime ? maxTime - performance.now() + startTime : 1;
            }
            if (retval !== undefined) {
                // out of time, or done with object quota
                return retval;
            }
            // We just finished, great, do the post-process
            this.postprocess();
            // We give back a sign that it was *this* call that actually finished up. By doing so,
            // the calling method may (or may not) want to signal for an invalidate to occur,
            // typically in a progressive rendering situation where a full redraw is then needed.
            _status = GROUND_RENDERED;
            return maxTime ? maxTime - performance.now() + startTime : 1;
        };
    }();
    this.renderShadow = function (camera, target) {
        if (!_bufferValid) return;
        if (target) _renderer.render(_scene, camera, target, false);else _renderer.render(_scene, camera);
        // THREE.log("GS render out");
    };
    this.postprocess = function () {
        if (USE_AO_PASS) {
            _aoPass.render(_renderer, _targetV, _targetH);
            _blurPassV.render(_renderer, _targetH, _targetV);
            _blurPassH.render(_renderer, _targetV, _targetH);
        } else {
            _blurPassV.render(_renderer, _targetV, _targetH);
            _blurPassH.render(_renderer, _targetH, _targetV);
        }
        _bufferValid = true;
        // THREE.log("GS postprocess");
    };
    this.clear = function () {
        var oldClearColor = _renderer.getClearColor().getHex();
        var oldClearAlpha = _renderer.getClearAlpha();
        _renderer.setClearColor(0, 0);
        _renderer.clearTarget(_targetH, true, true, false);
        _renderer.setClearColor(oldClearColor, oldClearAlpha);
        _renderer.clearBlend();
        _bufferValid = false;
        // THREE.log("GS clear");
    };
    this.setColor = function (color) {
        _matColor.uniforms.uShadowColor.value.x = color.r;
        _matColor.uniforms.uShadowColor.value.y = color.g;
        _matColor.uniforms.uShadowColor.value.z = color.b;
    };
    this.getColor = function () {
        return new THREE$1.Color(_matColor.uniforms.uShadowColor.value.x, _matColor.uniforms.uShadowColor.value.y, _matColor.uniforms.uShadowColor.value.z);
    };
    this.setAlpha = function (alpha) {
        _matColor.uniforms.uShadowColor.value.w = alpha;
    };
    this.getAlpha = function () {
        return _matColor.uniforms.uShadowColor.value.w;
    };
    // This means "was the blur post-process done?" not "are we done rendering?"
    // Progressive rendering can make a partial valid drop shadow, but it's not done
    this.isValid = function () {
        return _bufferValid;
    };
    this.getStatus = function () {
        return _status;
    };
    this.setDirty = function () {
        _needClear = true;
        _status = GROUND_UNFINISHED;
    };
    // TODO_NOP: hack exposing groundshadow material
    this.getDepthMaterial = function () {
        return _matDepth;
    };
    // INITIALIZATION
    if (params) {
        for (var i in _params) {
            _params[i] = params[i] || _params[i];
        }
    }
    // init scene
    _scene = new THREE$1.Scene();
    // init camera
    _camera = new THREE$1.OrthographicCamera();
    // init targets
    _targetH = new THREE$1.WebGLRenderTarget(_params.texSize, _params.texSize, {
        minFilter: THREE$1.LinearFilter,
        magFilter: THREE$1.LinearFilter,
        format: THREE$1.RGBAFormat,
        stencilBuffer: false
    });
    _targetH.generateMipmaps = false;
    _targetV = new THREE$1.WebGLRenderTarget(_params.texSize, _params.texSize, {
        minFilter: THREE$1.LinearFilter,
        magFilter: THREE$1.LinearFilter,
        format: THREE$1.RGBAFormat,
        stencilBuffer: false
    });
    _targetV.generateMipmaps = false;
    // init materials
    _matDepth = ShaderUtils.createShaderMaterial(GroundDepthShader);
    _matDepth.side = THREE$1.DoubleSide;
    _matDepth.blending = THREE$1.NoBlending;
    _blurPassH = new ShaderPass(GroundShadowBlurShader, "tDepth");
    _blurPassV = new ShaderPass(GroundShadowBlurShader, "tDepth");
    _aoPass = new ShaderPass(GroundShadowAOShader, "tDepth");
    // write defines
    _blurPassH.material.defines["KERNEL_SCALE"] = _blurPassV.material.defines["KERNEL_SCALE"] = (_params.pixScale / _params.texSize).toFixed(4);
    _blurPassH.material.defines["KERNEL_RADIUS"] = _blurPassV.material.defines["KERNEL_RADIUS"] = _params.blurRadius.toFixed(2);
    //Some standard GL setup for the blur passes.
    _aoPass.material.blending = _blurPassH.material.blending = _blurPassV.material.blending = THREE$1.NoBlending;
    _aoPass.material.depthWrite = _blurPassH.material.depthWrite = _blurPassV.material.depthWrite = false;
    _aoPass.material.depthTest = _blurPassH.material.depthTest = _blurPassV.material.depthTest = false;
    _blurPassH.material.defines["HORIZONTAL"] = 1;
    _matColor = ShaderUtils.createShaderMaterial(GroundShadowColorShader);
    _matColor.uniforms.tDepth.value = USE_AO_PASS ? _targetV : _targetH;
    _matColor.depthWrite = false;
    _matColor.transparent = true;
    // init plane
    _planeMesh = createGroundShape(_matColor);
    _scene.add(_planeMesh);
    // init debug box
    if (_params.debug) {
        _debugBox = new THREE$1.Mesh(new THREE$1.BoxGeometry(1, 1, 1), new THREE$1.MeshBasicMaterial({ color: 0x00ff00, wireframe: true }));
        _scene.add(_debugBox);
    }
    // init with default bounds and up
    this.setTransform(new THREE$1.Vector3(0, 0, 0), new THREE$1.Vector3(1, 1, 1), new THREE$1.Vector3(0, 1, 0), THREE$1.Object3D.DefaultUp);
};
GroundShadow.prototype.constructor = GroundShadow;
var GroundShadowUtils = {
    GroundShadow: GroundShadow,
    createGroundShape: createGroundShape,
    setGroundShapeTransform: setGroundShapeTransform
};

var shadowmap_vert$1 = "#include<shadowmap_decl_common>\nvarying float depth;\n#ifdef USE_SURFACE_CUTOUT_MAP\nvarying vec2 vUv;\n#else\n#ifdef USE_MAP\nvarying vec2 vUv;\nuniform mat3 texMatrix;\n#endif\n#ifdef USE_ALPHAMAP\nvarying vec2 vUvAlpha;\nuniform mat3 texMatrixAlpha;\n#endif\n#endif\nvoid passCutoutUVCoords() {\n#ifdef USE_SURFACE_CUTOUT_MAP\n    vUv = uv;\n#else\n#ifdef USE_MAP\n    vUv = (texMatrix * vec3(uv, 1.0)).xy;\n#endif\n#ifdef USE_ALPHAMAP\n    vUvAlpha = (texMatrixAlpha * vec3(uv, 1.0)).xy;\n#endif\n#endif\n}\nvoid main() {\n    vec4 mvPosition = modelViewMatrix * vec4( position, 1.0 );\n    vec4 p_Position = projectionMatrix * mvPosition;\n    gl_Position = p_Position;\n    depth = -mvPosition.z;\n    passCutoutUVCoords();\n}\n";

var shadowmap_frag = "#include<shadowmap_decl_common>\nvarying float depth;\n#ifdef USE_SURFACE_CUTOUT_MAP\n#include<float3_average>\n#prism_uniforms<surface_cutout_map>\nvarying vec2 vUv;\n#else\n#ifdef USE_MAP\nvarying vec2 vUv;\nuniform sampler2D map;\n#endif\n#ifdef USE_ALPHAMAP\nvarying vec2 vUvAlpha;\nuniform sampler2D alphaMap;\n#endif\n#endif\nuniform float shadowMinOpacity;\nvoid applyCutoutMaps() {\n    float opacity = 1.0;\n#ifdef USE_SURFACE_CUTOUT_MAP\n#prism_sample_texture<surface_cutout, opacity, true, false>\n#else\n#ifdef USE_MAP\n    opacity *= GET_MAP(vUv).a;\n#endif\n#ifdef USE_ALPHAMAP\n    opacity *= GET_ALPHAMAP(vUvAlpha).r;\n#endif\n#endif\n#if defined(USE_SURFACE_CUTOUT_MAP) || defined(USE_MAP) || defined(USE_ALPHAMAP)\n    if (opacity < shadowMinOpacity) discard;\n#endif\n}\nvoid main() {\n    float normalizedLinearDepth = (depth - shadowMapRangeMin) / shadowMapRangeSize;\n    float val = exp(shadowESMConstant * normalizedLinearDepth);\n#ifdef USE_HARD_SHADOWS\n    val = normalizedLinearDepth;\n#endif\n    applyCutoutMaps();\n    gl_FragColor = vec4(val, 0, 0, 1);\n}\n";

var shadowmap_ground_vert = "#include<shadowmap_decl_vert>\nvoid main() {\n    gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);\n#include<shadowmap_vert>\n}\n";

var shadowmap_ground_frag = "#include<shadowmap_decl_frag>\nvoid main() {\n    float shadowIntensity = 0.5 * (1.0 - getShadowValue());\n    gl_FragColor = vec4(0.0, 0.0, 0.0, shadowIntensity);\n}\n";

//
// All shaders related to shadow mapping.
//
// Material shader chunks are only active if the USE_SHADOWMAP macro is set and have no effect otherwise.
// Default values for constant uniforms are specified in ShadowMap.js.
//
// How to add shadow-mapping to a material shader:
//  1. Add ShadowMapDeclareUniforms to uniforms
//  2. Add ShadowMapVertexDeclaration to the vertex-shader declarations
//  3. Make sure that these variables are available in the vertex-shader:
//      - vec3 position;            // vertex-position in model-coords
//      - uniform mat4 modelMatrix;
//  4. Add ShadowMapVertexShaderChunk to the vertex-shader.
//  5. Add ShadowMapFragmentDeclarion to the fragment-shader declarations
//  6. Now, you can use getShadowValue() in your fragment shader to get the
//     shadow attenuation value. (see function comment for details)
//     If the USE_SHADOWMAP macro is not set, it is replaced by a dummy implementation.
// Shader to render into the shadow map
var ShadowMapShader = {
    uniforms: THREE$1.UniformsUtils.merge([ShaderChunks.ShadowMapCommonUniforms, {
        // all values are set in ShadowMaps.js
        "shadowMapRangeMin": { type: "f", value: 0.0 },
        "shadowMapRangeSize": { type: "f", value: 0.0 },
        "shadowMinOpacity": { type: "f", value: 0.0 },
        // uniforms needed to use texture sample chunks for Phong
        "map": { type: "t", value: null },
        "alphaMap": { type: "t", value: null },
        "texMatrix": { type: "m3", value: new THREE$1.Matrix3() },
        "texMatrixAlpha": { type: "m3", value: new THREE$1.Matrix3() }
    },
    // uniforms needed to use texture sample chunks for Prism
    PrismShaderUtils.GetPrismMapUniforms("surface_cutout_map")]),
    vertexShader: shadowmap_vert$1,
    fragmentShader: shadowmap_frag
};
// Shader to render ground-shadow based on shadow-map.
// Unlike other shadow receivers, the ground plane itself is not visible - just its shadow is rendered.
var GroundShadowShader = {
    uniforms: ShaderChunks.ShadowMapUniforms,
    vertexShader: shadowmap_ground_vert,
    fragmentShader: shadowmap_ground_frag
};
/**
 * ShadowMapOverrideMaterials is used by ShadowMaps to support cutout maps and transparency of individual shapes
 * when rendering into the shadow map.
 *
 * This class manages several customized variants of the shadow map shader material. The goal is:
 *  - Fully Invisible/Transparent objects will be excluded (based on threshold)
 *  - Prism cutout maps, alpha maps, and alpha channels of rgba maps are considered by override effects.
 * @constructor
 */
var ShadowMapOverrideMaterials = function ShadowMapOverrideMaterials() {
    // contains different macro variant of ShadowMapShader to avoid frequent shader recompile.
    // indexed by material key (see MaterialFlags.getMaterialIndex() below)
    // Each effect is reused with different uniforms.
    var _cachedMaterials = [];
    // used to derive new effect variants that already know the latest state of common shadow-map uniforms
    var _prototypeMaterial = ShaderUtils.createShaderMaterial(ShadowMapShader);
    // dummy material to exclude shapes completely
    var _invisibleMaterial = new THREE$1.Material();
    _invisibleMaterial.visible = false;
    // reused array of decal objects. (see getCustomOverrideMaterial)
    var _overrideDecals = [];
    // flags to determine which macro-configuration of the override material is needed
    function MaterialFlags() {
        this.init = function () {
            this.isPrism = false;
            this.alphaMap = false; // for Prism, this flag is used for the cutout map
            this.alphaClampS = false;
            this.alphaClampT = false;
            this.alphaInvert = false;
            this.rgbaMap = false;
            this.rgbaClampS = false;
            this.rgbaClampT = false;
            this.rgbaInvert = false;
            this.instanced = false; // for geometry with per-instance transform
            // Even if the flags above are equal, we cannot reuse the same
            // override material for different decals: They are
            // used at the same time but may need different uniforms for the cutout_maps.
            // Therefore, we use the decal index to make sure that decal effects are
            // always independent.
            this.decalIndex = -1;
        };
        this.init();
        // get a unique index for this flag combination
        this.getMaterialIndex = function () {
            // Note: When returning the term here directly, i.e., writing "return" instead of "var index =",
            //       the result would be undefined. The reason is a trap in JS: If a line only contains a single
            //       "return" statement, JS "helpfully" adds a ; automatically and ignores the rest.
            var index = (this.isPrism ? 0x01 : 0) | (this.alphaMap ? 0x02 : 0) | (this.alphaClampS ? 0x04 : 0) | (this.alphaClampT ? 0x08 : 0) | (this.alphaInvert ? 0x10 : 0) | (this.rgbaMap ? 0x20 : 0) | (this.rgbaClampS ? 0x40 : 0) | (this.rgbaClampT ? 0x80 : 0) | (this.rgbaInvert ? 0x100 : 0) | (this.instanced ? 0x200 : 0) | (this.decalIndex + 1) * 0x400; // enforce different keys for different decals
            return index;
        };
    }
    // reused temp object
    var _tmpFlags = new MaterialFlags();
    // Creates an appropriate override material or gets it from cache.
    //  @param   {MaterialFlags}        flags
    //  @param   {Number}               [decalIndex] - make sure that different decals always use different
    //                                                 override materials.
    //  @returns {THREE.ShaderMaterial}
    function acquireOverrideMaterial(flags, decalIndex) {
        var key = flags.getMaterialIndex();
        if (!_cachedMaterials[key]) {
            // Note:
            //  - Cloning the prototype makes sure that common shadowmap shader uniforms are also known by new effects.
            //  - Although we are sometimes creating the same ShaderMaterial here, separate caching still makes sense,
            //    because FireFlyWebGLProgram will compile different variants depending for each one.
            //    E.g., with/without USE_ALPHAMAP macro or with different GET_MAP chunks, depending on clamp settings.
            var newEffect = _prototypeMaterial.clone();
            // set macro to indicate that we must use prism shader chunks to sample the cutout map
            if (flags.isPrism && flags.alphaMap) {
                ShaderUtils.setMacro(newEffect, "USE_SURFACE_CUTOUT_MAP");
                // prepend SURFACE_CUTOUT_CLAMP macro function
                // For Prism materials, FireFlyWebGL does this automatically. But for the shadow map shader, we
                // have to do it ourselves here.
                newEffect.fragmentShader = WebGLProgramUtils.GetPrismMapChunk("surface_cutout", flags.alphaClampS, flags.alphaClampT) + "\n" + newEffect.fragmentShader;
            }
            // acitvate hardware instancing
            if (flags.instanced) {
                newEffect.useInstancing = true;
            }
            _cachedMaterials[key] = newEffect;
        }
        return _cachedMaterials[key];
    }
    // determines whether a material should be excluded from shadow-map rendering
    //  @param {THREE.Material} mat
    //  @returns {bool}
    function isInvisibleOrTransparent(mat) {
        if (mat instanceof THREE$1.MeshPhongMaterial) {
            // Phong shaders take opacity directly from the material property
            return mat.opacity < ShadowConfig.ShadowMinOpacity;
        } else if (mat.isPrismMaterial) {
            // For transparent prism materials, the surface opacity may actually vary per fragment depending on
            // surface orientation and roughness texture. Since we can only make binary decisions in the
            // shadow map shader, it's better to exclude those shapes completely. Otherwise, they would
            // rather cast random pixel artifacts than actual shadows.
            return mat.prismType === 'PrismTransparent' || mat.prismType === 'PrismGlazing';
        } else if (!mat.visible) {
            // the original material is set to invisble already
            return true;
        }
        // If we reach this, we don't know anything about transparency.
        // Therefore, we assume it to be relevant.
        return false;
    }
    // runs a function cb(material) for each override material variant.
    this.forEachMaterial = function (cb) {
        // run for all cached effects
        for (var i = 0; i < _cachedMaterials.length; i++) {
            var mat = _cachedMaterials[i];
            if (mat) {
                cb(mat);
            }
        }
        // apply on prototype, so that new materials inherit changes
        cb(_prototypeMaterial);
        // The _invisibleMaterial is excluded here, for two reasons:
        //  1. It is rather a cached constant without any configuration.
        //  2. By excluding it, we can safely assume that all materials are variants of
        //     the ShadowMapShader, so that all expected uniforms exist etc.
    };
    // Returns a custom override effect if needed for the given shape material.
    //  @param {THREE.Material}  origMat      - the original material of the shape to be rendered.
    //  @param {Number}          [decalIndex] - if orgigMat is from a decal, this must be its index in the decal array
    //  @returns {null|THREE.Material} returns null if the default override effect can be used.
    function getOverrideMaterial(origMat, decalIndex) {
        // handle overall transparency
        if (isInvisibleOrTransparent(origMat)) {
            return _invisibleMaterial;
        }
        // check for texture alpha
        var isPhong = origMat instanceof THREE$1.MeshPhongMaterial;
        var isPrism = origMat.isPrismMaterial;
        if (!isPhong && !isPrism) {
            // cutout/alpha maps are only supported for phong and prism materials
            return null;
        }
        // check for alpha/cutout map
        var alphaMap = isPhong ? origMat.alphaMap : origMat["surface_cutout_map"];
        // check for opacity in rgba map (phong only)
        // we ignore the map is alphaTest is not set.
        var rgbaMap = isPhong && !!origMat.alphaTest ? origMat.map : null;
        if (!alphaMap && !rgbaMap && !origMat.useInstancing) {
            // no custom effect needed
            return null;
        }
        var flags = _tmpFlags;
        flags.init();
        flags.isPrism = isPrism;
        flags.alphaMap = !!alphaMap;
        flags.rgbaMap = !!rgbaMap;
        flags.instanced = origMat.useInstancing;
        flags.decalIndex = decalIndex === undefined ? -1 : decalIndex;
        // configure clamp & invert flags for alpha map
        if (alphaMap) {
            // These properties are set for all textures - no matter if Prism or Phong.
            // (see convertSimpleTexture/convertPrismTexture in MaterialConverter.js)
            flags.alphaClampS = alphaMap.clampS;
            flags.alphaClampT = alphaMap.clampT;
            flags.alphaInvert = alphaMap.invert;
        }
        // same for rgba map
        if (rgbaMap) {
            flags.rgbaClampS = rgbaMap.clampS;
            flags.rgbaClampT = rgbaMap.clampT;
            flags.rgbaInvert = rgbaMap.invert;
        }
        // get material for current macro-combination
        var override = acquireOverrideMaterial(flags, decalIndex);
        // configure uniforms
        if (alphaMap) {
            if (isPhong) {
                override.uniforms["alphaMap"].value = alphaMap;
                override.uniforms["texMatrixAlpha"].value = alphaMap.matrix;
                // This lets WebGLRenderer set the USE_ALPHAMAP macro and allow the shader to use GET_ALPHAMAP
                // to handle clamping and invert. Note that we still need to set the uniforms above,
                // because the renderer does not call refreshUniformsCommon() for generic ShaderMaterials.
                override.alphaMap = alphaMap;
                // Get singe/double side setting from original material
                override.side = origMat.side;
            } else {
                // use prism uniforms for this case, so that we can reuse the prism sampling chunk
                override.uniforms["surface_cutout_map"].value = alphaMap;
                override.uniforms["surface_cutout_map_texMatrix"].value.copy(alphaMap.matrix);
                override.uniforms["surface_cutout_map_invert"].value = alphaMap.invert;
                // Workaround: Double-sided materials are currently only supported for Phong materials
                // (via "generic_backface_cull" property, see MaterialConverter.js), i.e., Prism materials
                // always seem to be single-sided. When using cutouts, you usually don't have closed surfaces.
                // Therefore, the camera and the shadow camera may see the cutout surface from different
                // directions - which looks confusing because either shadow or surface itself seems to be missing.
                // A cleaner solution would be to support double-sided for Prism as well. Then, we could
                // just set override.side = origMat.side like for Phong here.
                override.side = THREE$1.DoubleSide;
            }
        }
        // the same for alpha maps (Phong only)
        if (rgbaMap) {
            override.uniforms["map"].value = rgbaMap;
            override.uniforms["texMatrix"].value = rgbaMap.matrix;
            override.map = rgbaMap;
        }
        return override;
    }
    // Returns a custom override effect if needed for the given shape material - including decals if needed.
    //  @param {THREE.Material}  origMat - the original material of the shape to be rendered.
    //  @returns {null|THREE.Material} returns null if the default override effect can be used.
    this.getCustomOverrideMaterial = function (origMat) {
        // check if this shape material requires a custom override material
        var override = getOverrideMaterial(origMat);
        // If no custom override is needed, the shape can be assumed to be fully opaque.
        // Decals cannot change this, so we can ignore them and just use the default shadow-map shader.
        if (!override) {
            return null;
        }
        // If there are no decals, just use the override material
        if (!origMat.decals) {
            override.decals = null;
            return override;
        }
        // Since override is not null, the main material is (maybe partially) transparent. In this case,
        // any decal may contribute to the shape opacity by defining separate cutouts.
        // Therefore, we have to add corresponding decals to the override material as well.
        if (origMat.decals) {
            _overrideDecals.length = 0;
            // for each original decal, add a corresponding one to the override material
            for (var i = 0; i < origMat.decals.length; i++) {
                var decal = origMat.decals[i];
                // get override effect for this decal
                var decalOverride = getOverrideMaterial(decal.material, i);
                if (!decalOverride) {
                    // if this decal does not need a custom override, it is fully opaque.
                    // In this case, the whole shape is rendered to the shadow map anyway and
                    // we don't need the decals at all.
                    return null;
                }
                // this decal may contribute to the overall shape opacity.
                // Therefore, we add a corresponding decal to the override matierial as well.
                _overrideDecals.push({
                    uv: decal.uv,
                    material: decalOverride // but with shadowmap material
                });
            }
        }
        // attach temporary override decals to main override effect
        override.decals = _overrideDecals;
        return override;
    };
    // dispose all owned GPU resources
    this.dispose = function () {
        // dispose all ShaderMaterials
        this.forEachMaterial(function (mat) {
            mat.dispose();
        });
        // Note that _invisibleMaterial does not need dispose, because it is always skipped
        // by the renderer anyway.
    };
};
// Toggles and constants
var ShadowConfig = {
    // Tweakable constants
    ShadowMapSize: 1024,
    ShadowESMConstant: 80.0,
    ShadowBias: 0.001,
    ShadowDarkness: 0.7,
    ShadowMapBlurRadius: 4.0,
    ShadowMinOpacity: 0.9,
    // Debug toggles
    UseHardShadows: false,
    BlurShadowMap: true
};
// Enum for different states of the shadow map during progressive rendering
var SHADOWMAP_NEEDS_UPDATE = 0;
var SHADOWMAP_INCOMPLETE = 1;
var SHADOWMAP_VALID = 2;
// ShadowParams defines all parameters needed by material shaders to access the shadow map.
function ShadowParams() {
    this.shadowMap = undefined;
    this.shadowMapSize = undefined;
    this.shadowMatrix = undefined;
    this.shadowLightDir = undefined;
    /** @param {THREE.WebGLRenderTarget} */
    this.init = function (target) {
        this.shadowMap = target;
        this.shadowMapSize = new THREE$1.Vector2(target.width, target.height);
        this.shadowMatrix = new THREE$1.Matrix4();
        this.shadowLightDir = new THREE$1.Vector3();
    };
    /** Set (or remove) uniforms and defines for a material, so that it uses the current shadow map
     *   @param {THREE.Material} mat
     */
    this.apply = function (mat) {
        mat.shadowMap = this.shadowMap;
        mat.shadowMatrix = this.shadowMatrix;
        mat.shadowLightDir = this.shadowLightDir;
        // add/remove shadow-map macro
        if (this.shadowMap) {
            ShaderUtils.setMacro(mat, "USE_SHADOWMAP");
            if (ShadowConfig.UseHardShadows) {
                ShaderUtils.setMacro(mat, "USE_HARD_SHADOWS");
            }
        } else {
            ShaderUtils.removeMacro(mat, "USE_SHADOWMAP");
            ShaderUtils.removeMacro(mat, "USE_HARD_SHADOWS");
        }
        // Note that mat.needsUpdate is not needed here and would cause an expensive shader-recompile.
        // It is only called when the macro changes (see add/removeMacro).
    };
}
// NoShadows.apply() removes all shadow-map properties from a material.
var NoShadows = new ShadowParams();
/** @class Main class to manage ShadowMaps. Responsible for
 *   - creating and updating the shadow map
 *   - support progressive rendering of shadow maps
 *   - update materials to give them access to the shadow map.
 *   - rendering the ground shadow (a transparent plane where only shadow is visible)
 *
 *  How to use it: The main steps to update a shadow map are:
 *   - beginShadowMapUpdate:  prepares the shadow map rendering (clear target, setup camera etc.)
 *   - renderIntoShadowMap:   called for all scenes to be rendered into the shadow map, so that they cast shadows.
 *   - finishShadowMapUpdate: Makes the rendered shadow-map available to all materials.
 *
 *  To support progressive rendering, there are two higher-level functions that work with RenderScene and
 *  use the functions above:
 *   - startUpdate:    Reset render scene to start progressive rendering of the RenderScene into the shadow map
 *   - continueUpdate: Render more stuff into the shadow map. After calling, there are two possible results:
 *                      a) Finished: ShadowMap is ready and materials are configured to use it.
 *                      b) Timeout:  ShadowMaps are temporarily disabled for all materials. More continueUpdate()
 *                                   calls are needed next frame.
 *                     Use this.state to check whether the shadow map is finished.
 **/
function ShadowMaps(glRenderer) {
    var _shadowParams = null;
    var _gaussianPass = null;
    var _shadowCamera = new THREE$1.OrthographicCamera();
    // maximum possible value for exponential shadow map
    var _ESMMaxValue = Math.exp(ShadowConfig.ShadowESMConstant);
    // set clear color to maximum possible value in the shadow map
    var _clearColor = ShadowConfig.UseHardShadows ? new THREE$1.Color(1, 1, 1) : new THREE$1.Color(_ESMMaxValue, 1.0, 1.0);
    var _renderer = glRenderer;
    // ground-shadow
    var _groundMaterial = null; // {THREE.ShaderMaterial} ShaderMaterial to render plane with transparent shadow
    var _groundShape = null; // {THREE.Mesh}           ground plane geometry
    var _groundScene = null; // {THREE.Scene}          scene containing _groundShape
    // material used to render into shadow map
    var _shadowMapMaterial = ShaderUtils.createShaderMaterial(ShadowMapShader);
    // attach a callback for _shadowMapMaterial that provides custom variants used for cutout maps and to exclude invisible shapes
    var _customOverrideMaterials = new ShadowMapOverrideMaterials();
    _shadowMapMaterial.getCustomOverrideMaterial = _customOverrideMaterials.getCustomOverrideMaterial;
    // dummy 1x1 pixel shadow-map that we use to temporarily hide shadows during shadow-map update.
    // switching off shadows instead would require to recompile a lot of material shaders.
    var _dummyShadowMap = null; // {THREE.WebGLRenderTarget}
    //
    // --- Some local helper functions ----
    //
    /** Apply shadow params to all materials
     *   @param {ShadowParams}
     */
    function setShadowParams(matman, params) {
        matman.forEach(function (m) {
            params.apply(m);
        });
    }
    // @param {Number} size - widht/height of shadow target
    function createShadowTarget(size) {
        var target = new THREE$1.WebGLRenderTarget(size, size, { minFilter: THREE$1.LinearFilter,
            magFilter: THREE$1.LinearFilter,
            format: THREE$1.RGBAFormat,
            type: THREE$1.FloatType,
            stencilBuffer: false,
            generateMipmaps: false
        });
        // TODO: generateMipmaps is ignored in the option struct
        target.generateMipmaps = false;
        return target;
    }
    // param {THREE.WebGLRenderTarget}
    function clearShadowMap(target) {
        _renderer.setRenderTarget(target);
        _renderer.setClearColor(_clearColor, 1.0);
        _renderer.clear();
    }
    // make all materials use _dummyShadowMap.
    // @param {MaterialManager} matman
    function hideShadows(matman) {
        // replace actual shadow map by dummy shadow map
        var shadowMap = _shadowParams.shadowMap;
        _shadowParams.shadowMap = _dummyShadowMap;
        // update all materials
        setShadowParams(matman, _shadowParams);
        _shadowParams.apply(_groundMaterial);
        // set _shadowParams back to actual target
        _shadowParams.shadowMap = shadowMap;
    }
    /** Configures the given shadow ortho camera to fit the given worldBox.
     *   @param {THREE.OrthographicCamera} cam      - camera to be configured
     *   @param {THREE.Box3}                worldBox - worldBox of the scene that have to be captured by the camera
     *   @param {THREE.Vector3}             lightDir - direction from which the DirectionalLight comes
     */
    var fitShadowCam = function () {
        // lookAt for shadowCamera. Rotates (0,0,-1) to shadowCam direction
        var _lookAtMatrix = new THREE$1.Matrix4();
        // inverse lookAt. Rotates shadowCam direction to (0,0,-1)
        var _lookAtInverse = new THREE$1.Matrix4();
        // we always use origin as light target
        var _origin = new THREE$1.Vector3(0, 0, 0);
        // bbox to define shadow-camera frustum
        var _shadowBox = new THREE$1.Box3();
        // shadow-camera position in world-space
        var _shadowCamPos = new THREE$1.Vector3();
        // temp use
        var _tmp = new THREE$1.Vector3();
        return function (cam, worldBox, lightDir) {
            // let initial camera look from light position towards target (pos will be adjusted afterwards)
            cam.position.copy(lightDir);
            cam.lookAt(_origin);
            _lookAtMatrix.makeRotationFromQuaternion(cam.quaternion);
            _lookAtInverse.getInverse(_lookAtMatrix);
            // rotate worldBox to shadow-camera space
            // Note that we need the inverse to transform from worldSpace to shadowCam space
            _shadowBox.copy(worldBox).applyMatrix4(_lookAtInverse);
            // get final shadowCam pos in worldCoords: We choose the center of maxZ face.
            // Note that in camera space, view direction is -z, i.e., +z is pointing towards the camera.
            _tmp = _shadowBox.center(_tmp);
            _shadowCamPos.set(_tmp.x, _tmp.y, _shadowBox.max.z);
            _shadowCamPos.applyMatrix4(_lookAtMatrix);
            cam.position.copy(_shadowCamPos);
            // derive ortho-frustum extent from bbox.
            _tmp = _shadowBox.size(_tmp);
            cam.left = -0.5 * _tmp.x;
            cam.right = 0.5 * _tmp.x;
            cam.bottom = -0.5 * _tmp.y;
            cam.top = 0.5 * _tmp.y;
            cam.near = 0.0;
            cam.far = _tmp.z;
            // update all affected matrices
            cam.updateMatrixWorld();
            cam.matrixWorldInverse.getInverse(cam.matrixWorld);
            cam.updateProjectionMatrix();
        };
    }();
    /** Sets parameters needed for the Shader to render into the shadow map.
      *  @param {THREE.Material} mat
      */
    function setShadowMapShaderParams(mat) {
        mat.uniforms["shadowMapRangeMin"].value = _shadowCamera.near;
        mat.uniforms["shadowMapRangeSize"].value = _shadowCamera.far - _shadowCamera.near;
        mat.uniforms["shadowESMConstant"].value = ShadowConfig.ShadowESMConstant;
        mat.uniforms["shadowMinOpacity"].value = ShadowConfig.ShadowMinOpacity;
    }
    //
    // --- Initialization ---
    //
    this.init = function () {
        // init shadow params
        _shadowParams = new ShadowParams();
        _shadowParams.init(createShadowTarget(ShadowConfig.ShadowMapSize));
        // Note that the gauss pass creates its own target - which must use the same format and type as the shadow map.
        _gaussianPass = ShadowConfig.BlurShadowMap ? new GaussianPass(ShadowConfig.ShadowMapSize, ShadowConfig.ShadowMapSize, ShadowConfig.ShadowMapBlurRadius, 1.0, {
            type: _shadowParams.shadowMap.type,
            format: _shadowParams.shadowMap.format
        }) : undefined;
        // ground shadow material
        _groundMaterial = ShaderUtils.createShaderMaterial(GroundShadowShader);
        _groundMaterial.depthWrite = false;
        _groundMaterial.transparent = true;
        // ground shadow shape
        _groundShape = GroundShadowUtils.createGroundShape(_groundMaterial);
        _groundScene = new THREE$1.Scene();
        _groundScene.add(_groundShape);
        // needed from outside to adjust far-plane
        this.groundShapeBox = new THREE$1.Box3();
        // dummy 1x1 pixel shadow-map that we use to temporarily hide shadows during shadow-map update.
        // switching off shadows instead would require to recompile a lot of material shaders.
        _dummyShadowMap = createShadowTarget(1);
        clearShadowMap(_dummyShadowMap);
    };
    this.init();
    //
    // --- Main functions for progressive shadow map update ---
    //
    // used to manage state of the shadow-map for progressive update.
    this.state = SHADOWMAP_NEEDS_UPDATE;
    /** Clears the shadow map and prepares shadow camera and model for rendering. If possible within the given
     *  frame time, the shadow map will already be finished after calling this function. (use this.state to check).
     *  If not, more calls to continueUpdate() are needed in subsequent frames.
     *
     *  @param {RenderScene}     modelQueue     - Used for progressive rendering into shadow map.
     *  @param {Number}          frameRemaining - Frame budget in milliseconds
     *  @param {THREE.Camera}    camera         - Main camera for scene rendering
     *  @param {THREE.Vector3}   lightDir       - points to the direction where the light comes from (world-space)
     *  @param {MaterialManager} matman
     */
    this.startUpdate = function (modelQueue, frameRemaining, camera, lightDir, matman) {
        // clear shadow map and setup shadow map camera
        var worldBox = modelQueue.getVisibleBounds(true);
        this.beginShadowMapUpdate(camera, worldBox, lightDir);
        // reset queue to start progressive render into shadow map
        modelQueue.reset(_shadowCamera, 3 /*RENDER_SHADOWMAP*/, true);
        // state is in progress. This may change in the call below if the shadow
        // map can be fully rendered at once.
        this.state = SHADOWMAP_INCOMPLETE;
        // try to render the whole shadow map immediately in the given frame time.
        frameRemaining = this.continueUpdate(modelQueue, frameRemaining, matman);
        return frameRemaining;
    };
    /** Continues to render into the shadow map. startUpdate must have been called before.
     *   @param {RenderScene}     modelQueue
     *   @param {Number}          frameRemaining - available frame time budget in milliseconds
     *   @param {MaterialManager} matman
     *   @returns {Number} remaining frame time
     *
     *  Note: If other tasks call q.renderSome() or q.reset() on the modelQueue while the shadow-map update is in progress,
     *        the shadow map update has to be restarted. */
    this.continueUpdate = function (modelQueue, frameRemaining, matman) {
        // render some more scenes into shadow map
        frameRemaining = modelQueue.renderSome(this.renderSceneIntoShadowMap, frameRemaining);
        // if shadow map rendering is already finished, let's use it in this frame already
        if (modelQueue.isDone()) {
            this.state = SHADOWMAP_VALID;
            this.finishShadowMapUpdate(matman);
        } else {
            // model is too big to render shadow map in a single frame.
            // Hide shadows until shadow map update is finished.
            hideShadows(matman);
        }
        return frameRemaining;
    };
    ///
    /// --- Core functions for shadow-map update ---
    ///
    /** Clear shadow target and initialize shadow camera.
     *   @param {THREE.Camera}  camera
     *   @param {THREE.Box3}    worldBox
     *   @param {THREE.Vector3} lightDir - points to the direction where the light comes from (world-space)
     */
    this.beginShadowMapUpdate = function (camera, worldBox, lightDir) {
        fitShadowCam(_shadowCamera, worldBox, lightDir);
        // update shadowmap shader params
        setShadowMapShaderParams(_shadowMapMaterial);
        _customOverrideMaterials.forEachMaterial(setShadowMapShaderParams);
        // activate hard-shadows fallback if enabled
        if (ShadowConfig.UseHardShadows) {
            ShaderUtils.setMacro(_shadowMapMaterial, "USE_HARD_SHADOWS");
            _customOverrideMaterials.forEachMaterial(function (mat) {
                ShaderUtils.setMacro(mat, "USE_HARD_SHADOWS");
            });
        }
        clearShadowMap(_shadowParams.shadowMap);
        // render ground shape into shadow map. Although the ground will usually only receive shadow
        // and not cast it, this is necessary to avoid artifacts with exponential shadow mapping,
        // because the smoothing usually fails at the boundary to clear-color (=maxDepth) pixels in the shadow map.
        this.renderSceneIntoShadowMap(_groundScene);
    };
    /** @param {THREE.Scene} scene */
    this.renderSceneIntoShadowMap = function (scene) {
        scene.overrideMaterial = _shadowMapMaterial;
        _renderer.render(scene, _shadowCamera, _shadowParams.shadowMap);
        scene.overrideMaterial = null;
    };
    /** @param {MaterialManager} matman */
    this.finishShadowMapUpdate = function (matman) {
        // Note that the gaussianPass has its own intermediate target, so that it's okay
        // to use the same target for input and output.
        if (_gaussianPass && !ShadowConfig.UseHardShadows) {
            _gaussianPass.render(_renderer, _shadowParams.shadowMap, _shadowParams.shadowMap);
        }
        // compute shadowMatrix param: It maps world-coords to NDC for the shadow-camera
        _shadowParams.shadowMatrix.multiplyMatrices(_shadowCamera.projectionMatrix, _shadowCamera.matrixWorldInverse);
        _shadowParams.shadowMapRangeMin = _shadowCamera.near;
        _shadowParams.shadowMapRangeSize = _shadowCamera.far - _shadowCamera.near;
        _shadowParams.shadowLightDir.copy(_shadowCamera.position).normalize();
        // update param on all materials
        setShadowParams(matman, _shadowParams);
        // update our own ground shadow shader
        _shadowParams.apply(_groundMaterial);
        this.isValid = true;
    };
    /**
     *  Dispose GPU resources of ShadowMaps.
     *  @param {MaterialManager} matman
     **/
    this.cleanup = function (matman) {
        if (_gaussianPass) {
            _gaussianPass.cleanup();
        }
        if (_shadowParams.shadowMap) {
            _shadowParams.shadowMap.dispose();
        }
        // remove all shadow-map params from materials
        setShadowParams(matman, NoShadows);
        // dispose shader for shadow-map rendering
        _shadowMapMaterial.dispose();
        _customOverrideMaterials.dispose();
        // dispose ground shape
        _groundMaterial.dispose();
        _groundShape.geometry.dispose();
        // TODO: Probably LmvShaderPasses should get cleanup() functions as well to dispose targets and geometry?
    };
    ///
    /// --- Ground shadow rendering ---
    ///
    this.setGroundShadowTransform = function () {
        return function (center, size, worldUp, rightAxis) {
            // update shape transform
            GroundShadowUtils.setGroundShapeTransform(_groundShape, center, size, worldUp, rightAxis);
            // expose ground shape box (needed for far-plane adjustment)
            this.groundShapeBox.setFromObject(_groundShape);
        };
    }();
    this.renderGroundShadow = function (camera, target) {
        _renderer.render(_groundScene, camera, target, false);
    };
    /** Returns a corner of the bbox, enumerating from 0=minPoint to 7=maxPoint.
     * @param {THREE.Box3}    box
     * @param {Number}        index - in [0,7]
     * @param {THREE.Vector3} [optionalTarget]
     * @returns {THREE.Vector3}
     */
    function getBoxCorner(box, index, optionalTarget) {
        var result = optionalTarget || new THREE$1.Vector3();
        result.x = index & 1 ? box.max.x : box.min.x;
        result.y = index & 2 ? box.max.y : box.min.y;
        result.z = index & 4 ? box.max.z : box.min.z;
        return result;
    }
    /** Expands the given box in xz by its ground shadow, assuming a ground plane { y = inoutBox.min.y } .
     *   @param {THREE.Box3}    inoutBox  - box to be expanded.
     *   @param {THREE.Vector3} shadowDir - direction pointing towards the light
     */
    this.expandByGroundShadow = function () {
        var _plane = new THREE$1.Plane();
        var _ray = new THREE$1.Ray();
        var _tmpCenter = new THREE$1.Vector3();
        var _tmpVec = new THREE$1.Vector3();
        var _tmpBox = new THREE$1.Box3();
        return function (inoutBox, shadowDir) {
            // y is up vector.
            _plane.normal.set(0, 1, 0);
            _plane.constant = -inoutBox.min.y;
            // note that shadow is the direction pointing towards the light
            _ray.direction.copy(shadowDir).negate().normalize();
            // Don't add points if they would grow the box too much
            var MaxBoxGrow = 100.0;
            var center = inoutBox.center(_tmpCenter);
            var maxDist2 = center.distanceToSquared(inoutBox.min) * MaxBoxGrow * MaxBoxGrow;
            // For all box corners, add the corresponding ground shadow point.
            _tmpBox.makeEmpty();
            for (var i = 0; i < 8; i++) {
                // shoot ray from box corner along the light dir
                _ray.origin = getBoxCorner(inoutBox, i);
                var onPlane = _ray.intersectPlane(_plane, _tmpVec);
                if (!onPlane) {
                    continue;
                }
                // If the hit is too far away, we drop this point. This may happen if the light direction
                // is close to horizontal. Growing the bbox too much would make the whole rendering fail
                // (z-buffer artifacts or worse). So it's better to accept the clipped shadow in this case.
                if (onPlane.distanceToSquared(center) >= maxDist2) {
                    continue;
                }
                // add point to bbox
                _tmpBox.expandByPoint(onPlane);
            }
            // Finally, expand the original box with the shadow extent
            inoutBox.union(_tmpBox);
        };
    }();
    // used by debugging tools
    this.getShadowParams = function () {
        return _shadowParams;
    };
    this.getShadowCamera = function () {
        return _shadowCamera;
    };
}
// Provides functionality needed by FireFlyWebGLRenderer to work with shadow maps.
var ShadowRender = function ShadowRender() {};
ShadowRender.RefreshUniformsShadow = function (uniforms, material) {
    // may vary at runtime
    if (uniforms.shadowMap) uniforms.shadowMap.value = material.shadowMap;
    if (uniforms.shadowMatrix) uniforms.shadowMatrix.value = material.shadowMatrix;
    if (uniforms.shadowLightDir) uniforms.shadowLightDir.value = material.shadowLightDir;
    // Currently constant
    if (uniforms.shadowESMConstant) uniforms.shadowESMConstant.value = ShadowConfig.ShadowESMConstant;
    if (uniforms.shadowBias) uniforms.shadowBias.value = ShadowConfig.ShadowBias;
    if (uniforms.shadowMapSize) uniforms.shadowMapSize.value = ShadowConfig.ShadowMapSize;
    if (uniforms.shadowDarkness) uniforms.shadowDarkness.value = ShadowConfig.ShadowDarkness;
};
var ShadowMapUtils = {
    ShadowMapOverrideMaterials: ShadowMapOverrideMaterials,
    SHADOWMAP_NEEDS_UPDATE: 0,
    SHADOWMAP_INCOMPLETE: 1,
    SHADOWMAP_VALID: 2,
    ShadowConfig: ShadowConfig,
    ShadowRender: ShadowRender,
    ShadowMaps: ShadowMaps
};

var _typeof = typeof Symbol === "function" && typeof Symbol.iterator === "symbol" ? function (obj) {
  return typeof obj;
} : function (obj) {
  return obj && typeof Symbol === "function" && obj.constructor === Symbol && obj !== Symbol.prototype ? "symbol" : typeof obj;
};





var asyncGenerator = function () {
  function AwaitValue(value) {
    this.value = value;
  }

  function AsyncGenerator(gen) {
    var front, back;

    function send(key, arg) {
      return new Promise(function (resolve, reject) {
        var request = {
          key: key,
          arg: arg,
          resolve: resolve,
          reject: reject,
          next: null
        };

        if (back) {
          back = back.next = request;
        } else {
          front = back = request;
          resume(key, arg);
        }
      });
    }

    function resume(key, arg) {
      try {
        var result = gen[key](arg);
        var value = result.value;

        if (value instanceof AwaitValue) {
          Promise.resolve(value.value).then(function (arg) {
            resume("next", arg);
          }, function (arg) {
            resume("throw", arg);
          });
        } else {
          settle(result.done ? "return" : "normal", result.value);
        }
      } catch (err) {
        settle("throw", err);
      }
    }

    function settle(type, value) {
      switch (type) {
        case "return":
          front.resolve({
            value: value,
            done: true
          });
          break;

        case "throw":
          front.reject(value);
          break;

        default:
          front.resolve({
            value: value,
            done: false
          });
          break;
      }

      front = front.next;

      if (front) {
        resume(front.key, front.arg);
      } else {
        back = null;
      }
    }

    this._invoke = send;

    if (typeof gen.return !== "function") {
      this.return = undefined;
    }
  }

  if (typeof Symbol === "function" && Symbol.asyncIterator) {
    AsyncGenerator.prototype[Symbol.asyncIterator] = function () {
      return this;
    };
  }

  AsyncGenerator.prototype.next = function (arg) {
    return this._invoke("next", arg);
  };

  AsyncGenerator.prototype.throw = function (arg) {
    return this._invoke("throw", arg);
  };

  AsyncGenerator.prototype.return = function (arg) {
    return this._invoke("return", arg);
  };

  return {
    wrap: function (fn) {
      return function () {
        return new AsyncGenerator(fn.apply(this, arguments));
      };
    },
    await: function (value) {
      return new AwaitValue(value);
    }
  };
}();





var classCallCheck = function (instance, Constructor) {
  if (!(instance instanceof Constructor)) {
    throw new TypeError("Cannot call a class as a function");
  }
};

var createClass = function () {
  function defineProperties(target, props) {
    for (var i = 0; i < props.length; i++) {
      var descriptor = props[i];
      descriptor.enumerable = descriptor.enumerable || false;
      descriptor.configurable = true;
      if ("value" in descriptor) descriptor.writable = true;
      Object.defineProperty(target, descriptor.key, descriptor);
    }
  }

  return function (Constructor, protoProps, staticProps) {
    if (protoProps) defineProperties(Constructor.prototype, protoProps);
    if (staticProps) defineProperties(Constructor, staticProps);
    return Constructor;
  };
}();







var get = function get(object, property, receiver) {
  if (object === null) object = Function.prototype;
  var desc = Object.getOwnPropertyDescriptor(object, property);

  if (desc === undefined) {
    var parent = Object.getPrototypeOf(object);

    if (parent === null) {
      return undefined;
    } else {
      return get(parent, property, receiver);
    }
  } else if ("value" in desc) {
    return desc.value;
  } else {
    var getter = desc.get;

    if (getter === undefined) {
      return undefined;
    }

    return getter.call(receiver);
  }
};

var inherits = function (subClass, superClass) {
  if (typeof superClass !== "function" && superClass !== null) {
    throw new TypeError("Super expression must either be null or a function, not " + typeof superClass);
  }

  subClass.prototype = Object.create(superClass && superClass.prototype, {
    constructor: {
      value: subClass,
      enumerable: false,
      writable: true,
      configurable: true
    }
  });
  if (superClass) Object.setPrototypeOf ? Object.setPrototypeOf(subClass, superClass) : subClass.__proto__ = superClass;
};











var possibleConstructorReturn = function (self, call) {
  if (!self) {
    throw new ReferenceError("this hasn't been initialised - super() hasn't been called");
  }

  return call && (typeof call === "object" || typeof call === "function") ? call : self;
};





var slicedToArray = function () {
  function sliceIterator(arr, i) {
    var _arr = [];
    var _n = true;
    var _d = false;
    var _e = undefined;

    try {
      for (var _i = arr[Symbol.iterator](), _s; !(_n = (_s = _i.next()).done); _n = true) {
        _arr.push(_s.value);

        if (i && _arr.length === i) break;
      }
    } catch (err) {
      _d = true;
      _e = err;
    } finally {
      try {
        if (!_n && _i["return"]) _i["return"]();
      } finally {
        if (_d) throw _e;
      }
    }

    return _arr;
  }

  return function (arr, i) {
    if (Array.isArray(arr)) {
      return arr;
    } else if (Symbol.iterator in Object(arr)) {
      return sliceIterator(arr, i);
    } else {
      throw new TypeError("Invalid attempt to destructure non-iterable instance");
    }
  };
}();

// Add stencil buffer to THREE WebGLState. I followed the way this is done in r86 to
// to make upgrading easier.
var WebGLState$1 = function (_ThreeState) {
    inherits(WebGLState$$1, _ThreeState);

    function WebGLState$$1(gl, paramThreeToGL) {
        classCallCheck(this, WebGLState$$1);

        var capabilities = {};
        function enable(id) {
            if (capabilities[id] !== true) {
                gl.enable(id);
                capabilities[id] = true;
            }
        }
        function disable(id) {
            if (capabilities[id] !== false) {
                gl.disable(id);
                capabilities[id] = false;
            }
        }
        function StencilBuffer() {
            var locked = false;
            var currentStencilMask = null;
            var currentStencilFunc = null;
            var currentStencilRef = null;
            var currentStencilFuncMask = null;
            var currentStencilFail = null;
            var currentStencilZFail = null;
            var currentStencilZPass = null;
            var currentStencilClear = null;
            return {
                setTest: function setTest(stencilTest) {
                    if (stencilTest) {
                        enable(gl.STENCIL_TEST);
                    } else {
                        disable(gl.STENCIL_TEST);
                    }
                },
                setMask: function setMask(stencilMask) {
                    if (currentStencilMask !== stencilMask && !locked) {
                        gl.stencilMask(stencilMask);
                        currentStencilMask = stencilMask;
                    }
                },
                setFunc: function setFunc(stencilFunc, stencilRef, stencilMask) {
                    if (currentStencilFunc !== stencilFunc || currentStencilRef !== stencilRef || currentStencilFuncMask !== stencilMask) {
                        gl.stencilFunc(stencilFunc, stencilRef, stencilMask);
                        currentStencilFunc = stencilFunc;
                        currentStencilRef = stencilRef;
                        currentStencilFuncMask = stencilMask;
                    }
                },
                setOp: function setOp(stencilFail, stencilZFail, stencilZPass) {
                    if (currentStencilFail !== stencilFail || currentStencilZFail !== stencilZFail || currentStencilZPass !== stencilZPass) {
                        gl.stencilOp(stencilFail, stencilZFail, stencilZPass);
                        currentStencilFail = stencilFail;
                        currentStencilZFail = stencilZFail;
                        currentStencilZPass = stencilZPass;
                    }
                },
                setLocked: function setLocked(lock) {
                    locked = lock;
                },
                setClear: function setClear(stencil) {
                    if (currentStencilClear !== stencil) {
                        gl.clearStencil(stencil);
                        currentStencilClear = stencil;
                    }
                },
                reset: function reset() {
                    locked = false;
                    currentStencilMask = null;
                    currentStencilFunc = null;
                    currentStencilRef = null;
                    currentStencilFuncMask = null;
                    currentStencilFail = null;
                    currentStencilZFail = null;
                    currentStencilZPass = null;
                    currentStencilClear = null;
                }
            };
        }
        // Call the super class

        var _this = possibleConstructorReturn(this, (WebGLState$$1.__proto__ || Object.getPrototypeOf(WebGLState$$1)).call(this, gl, paramThreeToGL));

        _this.buffers = {
            stencil: StencilBuffer()
        };
        // THREE.WebGLState doesn't use prototypes, so it wasn't clear to me
        // that typescript method overriding would work for this case. So
        // I manually override reset here.
        var superReset = _this.reset.bind(_this);
        _this.reset = function () {
            this.buffers.stencil.reset();
            superReset();
        };
        return _this;
    }

    return WebGLState$$1;
}(THREE$1.WebGLState);

var DEBUG_TEXTURE_LOAD = false;
/**
 * @author supereggbert / http://www.paulbrunt.co.uk/
 * @author mrdoob / http://mrdoob.com/
 * @author alteredq / http://alteredqualia.com/
 * @author szimek / https://github.com/szimek/
 * @author stanevt -- Modified for Autodesk LMV web viewer
 * @constructor
 */
var WebGLRenderer = function WebGLRenderer(parameters) {
    THREE$1.log('THREE.WebGLRenderer', THREE$1.REVISION);
    parameters = parameters || {};
    var _canvas = parameters.canvas !== undefined ? parameters.canvas : document.createElement('canvas'),
        pixelRatio = window.devicePixelRatio || 1,
        _precisionVertex = parameters.precision !== undefined ? parameters.precision : 'highp',
        _precisionFragment = _precisionVertex,
        _alpha = parameters.alpha !== undefined ? parameters.alpha : false,
        _premultipliedAlpha = parameters.premultipliedAlpha !== undefined ? parameters.premultipliedAlpha : true,
        _antialias = parameters.antialias !== undefined ? parameters.antialias : false,
        _stencil = parameters.stencil !== undefined ? parameters.stencil : true,
        _preserveDrawingBuffer = parameters.preserveDrawingBuffer !== undefined ? parameters.preserveDrawingBuffer : true,
        //change it to true for the screen capture api
    _logarithmicDepthBuffer = parameters.logarithmicDepthBuffer !== undefined ? parameters.logarithmicDepthBuffer : false,
        _useFragBuffer = false,
        _clearColor = new THREE$1.Color(0x000000),
        _clearAlpha = 0;
    // Firefox on Mac OSX reports it can do MRT, but it actually does not work in our case,
    // so we have to detect this case manually.
    var _blockMRT = window.navigator.userAgent.indexOf("Firefox") != -1 && window.navigator.userAgent.indexOf("Mac OS") != -1;
    var lights = [];
    var _webglObjects = {};
    var _webglObjectsImmediate = [];
    var _objectModelViewMatrix = new THREE$1.Matrix4();
    var _objectNormalMatrix = new THREE$1.Matrix3();
    var opaqueObjects = [];
    var transparentObjects = [];
    // public properties
    this.domElement = _canvas;
    this.context = null;
    // clearing
    this.autoClear = true;
    this.autoClearColor = true;
    this.autoClearDepth = true;
    this.autoClearStencil = true;
    // scene graph
    this.sortObjects = true;
    // physically based shading
    this.gammaInput = false;
    this.gammaOutput = false;
    // morphs
    this.maxMorphTargets = 8;
    this.maxMorphNormals = 4;
    // flags
    this.autoScaleCubemaps = true;
    // info
    this.info = {
        memory: {
            programs: 0,
            geometries: 0,
            textures: 0
        },
        render: {
            calls: 0,
            vertices: 0,
            faces: 0,
            points: 0
        }
    };
    // internal properties
    var _this = this,
        _programs = [],

    // internal state cache
    _currentProgram = null,
        _currentFramebuffer = null,
        _currentMaterialId = -1,
        _currentCamera = null,
        _currentGeometryProgram = '',
        _programIndex = 0,
        _vertexPrefix = "",
        _fragmentPrefix = "",
        _usedTextureUnits = 0,

    // GL state cache
    _viewportX = 0,
        _viewportY = 0,
        _viewportWidth = _canvas.width,
        _viewportHeight = _canvas.height,

    //_currentWidth = 0,
    //_currentHeight = 0,
    _dynamicBuffers = {},
        //gl buffers used for streaming draw
    // frustum
    _frustum = new THREE$1.Frustum(),

    // camera matrices cache
    _projScreenMatrix = new THREE$1.Matrix4(),
        _viewInverseEnv = new THREE$1.Matrix4(),
        _vector3 = new THREE$1.Vector3(),

    // light arrays cache
    _direction = new THREE$1.Vector3(),
        _lightsNeedUpdate = true,
        _lights = {
        ambient: [0, 0, 0],
        directional: { length: 0, colors: [], positions: [] },
        point: { length: 0, colors: [], positions: [], distances: [] },
        spot: { length: 0, colors: [], positions: [], distances: [], directions: [], anglesCos: [], exponents: [] },
        hemi: { length: 0, skyColors: [], groundColors: [], positions: [] }
    };
    // initialize
    var _gl;
    var _glExtensionDrawBuffers;
    var _glExtensionInstancedArrays;
    var _glExtensionVAO;
    try {
        var attributes = {
            alpha: _alpha,
            premultipliedAlpha: _premultipliedAlpha,
            antialias: _antialias,
            stencil: _stencil,
            preserveDrawingBuffer: _preserveDrawingBuffer
        };
        _gl = _canvas.getContext('webgl', attributes) || _canvas.getContext('experimental-webgl', attributes);
        if (_gl === null) {
            if (_canvas.getContext('webgl') !== null) {
                throw 'Error creating WebGL context with your selected attributes.';
            } else {
                throw 'Error creating WebGL context.';
            }
        }
        /* You can substitute your own error catcher for WebGL, by adding a script.
         * This can be particularly handy for putting a break when a particular error is encountered,
         * so you can see exactly what line is causing the problem. You can also catch errors where
         * we pass in "undefined" as an argument, which is something that is rarely a good idea.
         *
         * As commented out in viewer3d.html, you need to include in viewer3d.html:
         *     <script src="thirdparty/khronos/webgl-debug.js"></script>"
         * in order to use this functionality. Then just uncomment the rest, and choose
         * which of the makeDebugContext lines at the end to uncomment.
         */
        /*
        // A standard one. Chrome already reports such errors without you adding this, and yourw
        // will take the place of theirs.
        function throwOnGLError(err, funcName, args) {
            throw WebGLDebugUtils.glEnumToString(err) + " was caused by call to: " + funcName;
        };
        
        // this one is terribly weird, but provided by Khronos as an example.
        function logGLCall(functionName, args) {
             console.log("gl." + functionName + "(" +
                WebGLDebugUtils.glFunctionArgsToString(functionName, args) + ")");
        }
        
        // this one is actually handy: flags an error when we try to pass in an argument that is undefined.
        function validateNoneOfTheArgsAreUndefined(functionName, args) {
            for (var ii = 0; ii < args.length; ++ii) {
              if (args[ii] === undefined) {
                console.error("undefined passed to gl." + functionName + "(" +
                              WebGLDebugUtils.glFunctionArgsToString(functionName, args) + ")");
              }
            }
        }
         // Choose one of these two:
        // the default, shows usual errors.
        _gl = WebGLDebugUtils.makeDebugContext(_gl, throwOnGLError);
        // to check for undefined args passed in to WebGL, which is a no-no:
        //_gl = WebGLDebugUtils.makeDebugContext(_gl, undefined, validateNoneOfTheArgsAreUndefined);
        */
        //LMV-1914: lower fragment precision for low-end mobile devices (Android)
        var highp = _gl.getShaderPrecisionFormat(_gl.FRAGMENT_SHADER, _gl.HIGH_FLOAT);
        if (highp.precision == 0) _precisionFragment = 'mediump';
        _gl = rescueFromPolymer(_gl);
        _canvas.addEventListener('webglcontextlost', function (event) {
            event.preventDefault();
            resetGLState();
            setDefaultGLState();
            _webglObjects = {};
        }, false);
    } catch (error$$1) {
        THREE$1.error(error$$1);
        return;
    }
    var state = new WebGLState$1(_gl, paramThreeToGL);
    if (_gl.getShaderPrecisionFormat === undefined) {
        _gl.getShaderPrecisionFormat = function () {
            return {
                "rangeMin": 1,
                "rangeMax": 1,
                "precision": 1
            };
        };
    }
    var extensions = new THREE$1.WebGLExtensions(_gl);
    //We know we are going to be using some extensions for sure
    extensions.get('OES_texture_float');
    extensions.get('OES_texture_float_linear');
    extensions.get('OES_texture_half_float');
    extensions.get('OES_texture_half_float_linear');
    extensions.get('OES_standard_derivatives');
    extensions.get('EXT_shader_texture_lod');
    extensions.get('EXT_texture_filter_anisotropic');
    extensions.get('WEBGL_compressed_texture_s3tc');
    _glExtensionDrawBuffers = extensions.get('WEBGL_draw_buffers');
    _glExtensionInstancedArrays = extensions.get('ANGLE_instanced_arrays');
    _glExtensionVAO = extensions.get('OES_vertex_array_object');
    if (_logarithmicDepthBuffer) {
        extensions.get('EXT_frag_depth');
    }
    var glClearColor = function glClearColor(r, g, b, a) {
        if (_premultipliedAlpha === true) {
            r *= a;
            g *= a;
            b *= a;
        }
        _gl.clearColor(r, g, b, a);
    };
    var setDefaultGLState = function setDefaultGLState() {
        _gl.clearColor(0, 0, 0, 1);
        _gl.clearDepth(1);
        _gl.clearStencil(0);
        _gl.enable(_gl.DEPTH_TEST);
        _gl.depthFunc(_gl.LEQUAL);
        _gl.frontFace(_gl.CCW);
        _gl.cullFace(_gl.BACK);
        _gl.enable(_gl.CULL_FACE);
        _gl.enable(_gl.BLEND);
        _gl.blendEquation(_gl.FUNC_ADD);
        _gl.blendFunc(_gl.SRC_ALPHA, _gl.ONE_MINUS_SRC_ALPHA);
        _gl.viewport(_viewportX, _viewportY, _viewportWidth, _viewportHeight);
        glClearColor(_clearColor.r, _clearColor.g, _clearColor.b, _clearAlpha);
    };
    var resetGLState = function resetGLState() {
        _currentProgram = null;
        _currentCamera = null;
        _currentGeometryProgram = '';
        _currentMaterialId = -1;
        _lightsNeedUpdate = true;
        state.reset();
        state.disableUnusedAttributes();
    };
    setDefaultGLState();
    this.context = _gl;
    this.state = state;
    // GPU capabilities
    var _maxTextures = _gl.getParameter(_gl.MAX_TEXTURE_IMAGE_UNITS);
    var _maxVertexTextures = _gl.getParameter(_gl.MAX_VERTEX_TEXTURE_IMAGE_UNITS);
    var _maxTextureSize = _gl.getParameter(_gl.MAX_TEXTURE_SIZE);
    var _maxCubemapSize = _gl.getParameter(_gl.MAX_CUBE_MAP_TEXTURE_SIZE);
    var _supportsVertexTextures = _maxVertexTextures > 0;
    // not used, though used in three.js's version:
    //var _supportsBoneTextures = _supportsVertexTextures && extensions.get( 'OES_texture_float' );
    var _vertexShaderPrecisionHighpFloat = _gl.getShaderPrecisionFormat(_gl.VERTEX_SHADER, _gl.HIGH_FLOAT);
    var _vertexShaderPrecisionMediumpFloat = _gl.getShaderPrecisionFormat(_gl.VERTEX_SHADER, _gl.MEDIUM_FLOAT);
    //var _vertexShaderPrecisionLowpFloat = _gl.getShaderPrecisionFormat( _gl.VERTEX_SHADER, _gl.LOW_FLOAT );
    var _fragmentShaderPrecisionHighpFloat = _gl.getShaderPrecisionFormat(_gl.FRAGMENT_SHADER, _gl.HIGH_FLOAT);
    var _fragmentShaderPrecisionMediumpFloat = _gl.getShaderPrecisionFormat(_gl.FRAGMENT_SHADER, _gl.MEDIUM_FLOAT);
    //var _fragmentShaderPrecisionLowpFloat = _gl.getShaderPrecisionFormat( _gl.FRAGMENT_SHADER, _gl.LOW_FLOAT );
    // Sometimes a texture is not actually available to bind. We use _nullTexture so that the uniform sampler2D
    // is bound to something, so that we don't get a warning from Chrome.
    var pixels = new Uint8Array(16);
    // checkerboard
    for (var i = 0; i < 4; i++) {
        // for debugging - gives a pink and green pattern, which will show textures that are not loaded properly.
        // Sometimes textures are not loaded yet and so will use this texture temporarily, so we don't normally load this pattern.
        if (DEBUG_TEXTURE_LOAD) {
            if (i === 1 || i === 2) {
                pixels[i * 4] = 246;
                pixels[i * 4 + 1] = 140;
                pixels[i * 4 + 2] = 220;
            } else {
                pixels[i * 4] = 48;
                pixels[i * 4 + 1] = 195;
                pixels[i * 4 + 2] = 3;
            }
        } else {
            // black - we actually use this color as a sign that the texture is not loaded for Graphite and take corrective action there.
            pixels[i * 4] = pixels[i * 4 + 1] = pixels[i * 4 + 2] = 0;
        }
        pixels[i * 4 + 3] = 255;
    }
    var _nullTexture = new THREE$1.DataTexture(pixels, 2, 2, THREE$1.RGBAFormat, THREE$1.UnsignedByteType, THREE$1.UVMapping, THREE$1.RepeatWrapping, THREE$1.RepeatWrapping, THREE$1.NearestFilter, THREE$1.NearestFilter);
    _nullTexture.needsUpdate = true;
    var getCompressedTextureFormats = function () {
        var array;
        return function () {
            if (array !== undefined) {
                return array;
            }
            array = [];
            if (extensions.get('WEBGL_compressed_texture_pvrtc') || extensions.get('WEBGL_compressed_texture_s3tc')) {
                var formats = _gl.getParameter(_gl.COMPRESSED_TEXTURE_FORMATS);
                for (var i = 0; i < formats.length; i++) {
                    array.push(formats[i]);
                }
            }
            return array;
        };
    }();
    // clamp precision to maximum available
    var highpAvailable = _vertexShaderPrecisionHighpFloat.precision > 0;
    var mediumpAvailable = _vertexShaderPrecisionMediumpFloat.precision > 0;
    if (_precisionVertex === "highp" && !highpAvailable) {
        if (mediumpAvailable) {
            _precisionVertex = "mediump";
            THREE$1.warn("WebGLRenderer: highp not supported, using mediump");
        } else {
            _precisionVertex = "lowp";
            THREE$1.warn("WebGLRenderer: highp and mediump not supported, using lowp");
        }
    }
    if (_precisionVertex === "mediump" && !mediumpAvailable) {
        _precisionVertex = "lowp";
        THREE$1.warn("WebGLRenderer: mediump not supported, using lowp");
    }
    highpAvailable = _fragmentShaderPrecisionHighpFloat.precision > 0;
    mediumpAvailable = _fragmentShaderPrecisionMediumpFloat.precision > 0;
    if (_precisionFragment === "highp" && !highpAvailable) {
        if (mediumpAvailable) {
            _precisionFragment = "mediump";
            THREE$1.warn("WebGLRenderer: highp not supported, using mediump");
        } else {
            _precisionFragment = "lowp";
            THREE$1.warn("WebGLRenderer: highp and mediump not supported, using lowp");
        }
    }
    if (_precisionFragment === "mediump" && !mediumpAvailable) {
        _precisionFragment = "lowp";
        THREE$1.warn("WebGLRenderer: mediump not supported, using lowp");
    }
    // API
    this.getContext = function () {
        return _gl;
    };
    this.forceContextLoss = function () {
        extensions.get('WEBGL_lose_context').loseContext();
    };
    this.supportsVertexTextures = function () {
        return _supportsVertexTextures;
    };
    this.supportsFloatTextures = function () {
        return extensions.get('OES_texture_float');
    };
    this.supportsHalfFloatTextures = function () {
        return extensions.get('OES_texture_half_float_linear');
    };
    this.supportsStandardDerivatives = function () {
        return extensions.get('OES_standard_derivatives');
    };
    this.supportsCompressedTextureS3TC = function () {
        return extensions.get('WEBGL_compressed_texture_s3tc');
    };
    this.supportsMRT = function () {
        return !_blockMRT && _glExtensionDrawBuffers;
    };
    this.supportsInstancedArrays = function () {
        return !!_glExtensionInstancedArrays;
    };
    this.supportsBlendMinMax = function () {
        return extensions.get('EXT_blend_minmax');
    };
    this.getMaxAnisotropy = function () {
        var value;
        return function () {
            if (value !== undefined) {
                return value;
            }
            var extension = extensions.get('EXT_texture_filter_anisotropic');
            value = extension !== null ? _gl.getParameter(extension.MAX_TEXTURE_MAX_ANISOTROPY_EXT) : 0;
            return value;
        };
    }();
    this.getPixelRatio = function () {
        return pixelRatio;
    };
    this.setPixelRatio = function (value) {
        pixelRatio = value;
    };
    /**
     * @returns {WebGLFramebuffer} Currently bound framebuffer
     */
    this.getCurrentFramebuffer = function () {
        return _currentFramebuffer;
    };
    this.setIdBufferSource = function (value) {
        switch (value) {
            case DB_ID:
                _useFragBuffer = false;
                break;
            case FRAGMENT_ID:
                _useFragBuffer = true;
                break;
            default:
                return false;
        }
        return true;
    };
    this.setSize = function (width, height, updateStyle) {
        _canvas.width = width * pixelRatio;
        _canvas.height = height * pixelRatio;
        if (updateStyle !== false) {
            _canvas.style.width = width + 'px';
            _canvas.style.height = height + 'px';
        }
        this.setViewport(0, 0, width, height);
    };
    this.setViewport = function (x, y, width, height) {
        _viewportX = x * pixelRatio;
        _viewportY = y * pixelRatio;
        _viewportWidth = width * pixelRatio;
        _viewportHeight = height * pixelRatio;
        _gl.viewport(_viewportX, _viewportY, _viewportWidth, _viewportHeight);
    };
    var _viewportStack = [];
    /** Push current viewport to viewport stack, so that it can be recovered by popViewport later. */
    this.pushViewport = function () {
        _viewportStack.push(_viewportX);
        _viewportStack.push(_viewportY);
        _viewportStack.push(_viewportWidth);
        _viewportStack.push(_viewportHeight);
    };
    /** Recover previously pushed viewport.*/
    this.popViewport = function () {
        var index = _viewportStack.length - 4;
        _viewportX = _viewportStack[index];
        _viewportY = _viewportStack[index + 1];
        _viewportWidth = _viewportStack[index + 2];
        _viewportHeight = _viewportStack[index + 3];
        _gl.viewport(_viewportX, _viewportY, _viewportWidth, _viewportHeight);
        _viewportStack.length = index;
    };
    this.setScissor = function (x, y, width, height) {
        _gl.scissor(x * pixelRatio, y * pixelRatio, width * pixelRatio, height * pixelRatio);
    };
    this.enableScissorTest = function (enable) {
        if (enable) {
            _gl.enable(_gl.SCISSOR_TEST);
        } else {
            _gl.disable(_gl.SCISSOR_TEST);
        }
    };
    // Clearing
    this.getClearColor = function () {
        return _clearColor;
    };
    this.setClearColor = function (color, alpha) {
        _clearColor.set(color);
        _clearAlpha = alpha !== undefined ? alpha : 1;
        glClearColor(_clearColor.r, _clearColor.g, _clearColor.b, _clearAlpha);
    };
    this.getClearAlpha = function () {
        return _clearAlpha;
    };
    this.setClearAlpha = function (alpha) {
        _clearAlpha = alpha;
        glClearColor(_clearColor.r, _clearColor.g, _clearColor.b, _clearAlpha);
    };
    this.clear = function (color, depth, stencil) {
        var bits = 0;
        if (color === undefined || color) bits |= _gl.COLOR_BUFFER_BIT;
        if (depth === undefined || depth) bits |= _gl.DEPTH_BUFFER_BIT;
        if (stencil === undefined || stencil) bits |= _gl.STENCIL_BUFFER_BIT;
        _gl.clear(bits);
    };
    this.clearColor = function () {
        _gl.clear(_gl.COLOR_BUFFER_BIT);
    };
    this.clearDepth = function () {
        _gl.clear(_gl.DEPTH_BUFFER_BIT);
    };
    this.clearStencil = function () {
        _gl.clear(_gl.STENCIL_BUFFER_BIT);
    };
    this.clearTarget = function (renderTarget, color, depth, stencil) {
        this.setRenderTarget(renderTarget);
        this.clear(color, depth, stencil);
    };
    // Reset
    this.resetGLState = resetGLState;
    // Internal functions
    // Buffer allocation
    function createLineBuffers(geometry) {
        geometry.__webglVertexBuffer = _gl.createBuffer();
        geometry.__webglColorBuffer = _gl.createBuffer();
        geometry.__webglLineDistanceBuffer = _gl.createBuffer();
        _this.info.memory.geometries++;
    }
    function createPointCloudBuffers(geometry) {
        geometry.__webglVertexBuffer = _gl.createBuffer();
        geometry.__webglColorBuffer = _gl.createBuffer();
        _this.info.memory.geometries++;
    }
    function createMeshBuffers(geometryGroup) {
        geometryGroup.__webglVertexBuffer = _gl.createBuffer();
        geometryGroup.__webglNormalBuffer = _gl.createBuffer();
        geometryGroup.__webglTangentBuffer = _gl.createBuffer();
        geometryGroup.__webglColorBuffer = _gl.createBuffer();
        geometryGroup.__webglUVBuffer = _gl.createBuffer();
        geometryGroup.__webglUV2Buffer = _gl.createBuffer();
        geometryGroup.__webglSkinIndicesBuffer = _gl.createBuffer();
        geometryGroup.__webglSkinWeightsBuffer = _gl.createBuffer();
        geometryGroup.__webglFaceBuffer = _gl.createBuffer();
        geometryGroup.__webglLineBuffer = _gl.createBuffer();
        _this.info.memory.geometries++;
    }
    // Events
    var onObjectRemoved = function onObjectRemoved(event) {
        var object = event.target;
        object.traverse(function (child) {
            child.removeEventListener('remove', onObjectRemoved);
            removeObject(child);
        });
    };
    var onGeometryDispose = function onGeometryDispose(event) {
        var geometry = event.target;
        geometry.removeEventListener('dispose', onGeometryDispose);
        deallocateGeometry(geometry);
    };
    var onTextureDispose = function onTextureDispose(event) {
        var texture = event.target;
        texture.removeEventListener('dispose', onTextureDispose);
        deallocateTexture(texture);
        _this.info.memory.textures--;
    };
    var onRenderTargetDispose = function onRenderTargetDispose(event) {
        var renderTarget = event.target;
        renderTarget.removeEventListener('dispose', onRenderTargetDispose);
        deallocateRenderTarget(renderTarget);
        _this.info.memory.textures--;
    };
    var onMaterialDispose = function onMaterialDispose(event) {
        var material = event.target;
        material.removeEventListener('dispose', onMaterialDispose);
        deallocateMaterial(material);
    };
    // Buffer deallocation
    var deleteBuffers = function deleteBuffers(geometry) {
        if (geometry.__webglVertexBuffer !== undefined) {
            _gl.deleteBuffer(geometry.__webglVertexBuffer);
            geometry.__webglVertexBuffer = undefined;
        }
        if (geometry.__webglNormalBuffer !== undefined) {
            _gl.deleteBuffer(geometry.__webglNormalBuffer);
            geometry.__webglNormalBuffer = undefined;
        }
        if (geometry.__webglTangentBuffer !== undefined) {
            _gl.deleteBuffer(geometry.__webglTangentBuffer);
            geometry.__webglTangentBuffer = undefined;
        }
        if (geometry.__webglColorBuffer !== undefined) {
            _gl.deleteBuffer(geometry.__webglColorBuffer);
            geometry.__webglColorBuffer = undefined;
        }
        if (geometry.__webglUVBuffer !== undefined) {
            _gl.deleteBuffer(geometry.__webglUVBuffer);
            geometry.__webglUVBuffer = undefined;
        }
        if (geometry.__webglUV2Buffer !== undefined) {
            _gl.deleteBuffer(geometry.__webglUV2Buffer);
            geometry.__webglUV2Buffer = undefined;
        }
        if (geometry.__webglSkinIndicesBuffer !== undefined) {
            _gl.deleteBuffer(geometry.__webglSkinIndicesBuffer);
            geometry.__webglSkinIndicesBuffer = undefined;
        }
        if (geometry.__webglSkinWeightsBuffer !== undefined) {
            _gl.deleteBuffer(geometry.__webglSkinWeightsBuffer);
            geometry.__webglSkinWeightsBuffer = undefined;
        }
        if (geometry.__webglFaceBuffer !== undefined) {
            _gl.deleteBuffer(geometry.__webglFaceBuffer);
            geometry.__webglFaceBuffer = undefined;
        }
        if (geometry.__webglLineBuffer !== undefined) {
            _gl.deleteBuffer(geometry.__webglLineBuffer);
            geometry.__webglLineBuffer = undefined;
        }
        if (geometry.__webglLineDistanceBuffer !== undefined) {
            _gl.deleteBuffer(geometry.__webglLineDistanceBuffer);
            geometry.__webglLineDistanceBuffer = undefined;
        }
        // custom attributes
        if (geometry.__webglCustomAttributesList !== undefined) {
            for (var name in geometry.__webglCustomAttributesList) {
                _gl.deleteBuffer(geometry.__webglCustomAttributesList[name].buffer);
            }
            geometry.__webglCustomAttributesList = undefined;
        }
        _this.info.memory.geometries--;
    };
    var deallocateGeometry = function deallocateGeometry(geometry) {
        geometry.__webglInit = undefined;
        var i, len, m, ml;
        if (geometry instanceof THREE$1.BufferGeometry) {
            //[Firefly] Delete interleaved buffer
            if (geometry.vbbuffer !== undefined) {
                _gl.deleteBuffer(geometry.vbbuffer);
                geometry.vbbuffer = undefined;
            }
            //[Firefly] Delete index buffer (if not stored in vertex attribute object)
            if (geometry.ibbuffer !== undefined) {
                _gl.deleteBuffer(geometry.ibbuffer);
                geometry.ibbuffer = undefined;
            }
            if (geometry.iblinesbuffer !== undefined) {
                _gl.deleteBuffer(geometry.iblinesbuffer);
                geometry.iblinesbuffer = undefined;
            }
            //[Firefly] Delete vertex array objects.
            if (geometry.vaos) {
                for (i = 0; i < geometry.vaos.length; i++) {
                    _glExtensionVAO.deleteVertexArrayOES(geometry.vaos[i].vao);
                }
                geometry.vaos = undefined;
            }
            var attributes = geometry.attributes;
            for (var key in attributes) {
                if (attributes[key].buffer !== undefined) {
                    _gl.deleteBuffer(attributes[key].buffer);
                    attributes[key].buffer = undefined;
                }
            }
            _this.info.memory.geometries--;
        } else {
            var geometryGroupsList = geometryGroups[geometry.id];
            if (geometryGroupsList !== undefined) {
                for (i = 0, len = geometryGroupsList.length; i < len; i++) {
                    var geometryGroup = geometryGroupsList[i];
                    if (geometryGroup.numMorphTargets !== undefined) {
                        for (m = 0, ml = geometryGroup.numMorphTargets; m < ml; m++) {
                            _gl.deleteBuffer(geometryGroup.__webglMorphTargetsBuffers[m]);
                        }
                        delete geometryGroup.__webglMorphTargetsBuffers;
                    }
                    if (geometryGroup.numMorphNormals !== undefined) {
                        for (m = 0, ml = geometryGroup.numMorphNormals; m < ml; m++) {
                            _gl.deleteBuffer(geometryGroup.__webglMorphNormalsBuffers[m]);
                        }
                        delete geometryGroup.__webglMorphNormalsBuffers;
                    }
                    deleteBuffers(geometryGroup);
                }
                delete geometryGroups[geometry.id];
            } else {
                deleteBuffers(geometry);
            }
        }
    };
    this.deallocateGeometry = deallocateGeometry;
    var deallocateTexture = function deallocateTexture(texture) {
        if (texture.__webglTextureCube) {
            // cube texture
            _gl.deleteTexture(texture.__webglTextureCube);
            texture.__webglTextureCube = undefined;
        } else {
            // 2D texture
            if (!texture.__webglInit) return;
            _gl.deleteTexture(texture.__webglTexture);
            texture.__webglInit = undefined;
            texture.__webglTexture = undefined;
        }
    };
    var deallocateRenderTarget = function deallocateRenderTarget(renderTarget) {
        if (!renderTarget || !renderTarget.__webglTexture) return;
        _gl.deleteTexture(renderTarget.__webglTexture);
        _gl.deleteFramebuffer(renderTarget.__webglFramebuffer);
        // if the z-buffer is shared among targets, the first deallocation will set this shared
        // value to be undefined. Avoid calling WebGL with undefined parameters.
        if (renderTarget.__webglRenderbuffer !== undefined) {
            _gl.deleteRenderbuffer(renderTarget.__webglRenderbuffer);
        }
    };
    var deallocateMaterial = function deallocateMaterial(material) {
        var deleteProgram = false;
        material.program = undefined;
        material.programs.forEach(function (wrapper) {
            var program;
            if (wrapper === undefined || (program = wrapper.program) == undefined) return;
            // only deallocate GL program if this was the last use of shared program
            // assumed there is only single copy of any program in the _programs list
            // (that's how it's constructed)
            var i, il, programInfo;
            for (i = 0, il = _programs.length; i < il; i++) {
                programInfo = _programs[i];
                if (programInfo && programInfo.program === program) {
                    programInfo.usedTimes--;
                    if (programInfo.usedTimes === 0) {
                        _programs[i] = undefined;
                        _gl.deleteProgram(program);
                        _this.info.memory.programs--;
                        deleteProgram = true;
                    }
                    break;
                }
            }
        }, false);
        material.programs.length = 0;
        if (deleteProgram) {
            // avoid using array.splice, this is costlier than creating new array from scratch
            _programs = _programs.filter(function (programInfo) {
                return programInfo !== undefined;
            });
        }
    };
    // Buffer initialization
    function initCustomAttributes(geometry, object) {
        var nvertices = geometry.vertices.length;
        var material = object.material;
        if (material.attributes) {
            if (geometry.__webglCustomAttributesList === undefined) {
                geometry.__webglCustomAttributesList = [];
            }
            for (var a in material.attributes) {
                var attribute = material.attributes[a];
                if (!attribute.__webglInitialized || attribute.createUniqueBuffers) {
                    attribute.__webglInitialized = true;
                    var size = 1; // "f" and "i"
                    if (attribute.type === "v2") size = 2;else if (attribute.type === "v3") size = 3;else if (attribute.type === "v4") size = 4;else if (attribute.type === "c") size = 3;
                    attribute.size = size;
                    attribute.array = new Float32Array(nvertices * size);
                    attribute.buffer = _gl.createBuffer();
                    attribute.buffer.belongsToAttribute = a;
                    attribute.needsUpdate = true;
                }
                geometry.__webglCustomAttributesList.push(attribute);
            }
        }
    }
    function initLineBuffers(geometry, object) {
        var nvertices = geometry.vertices.length;
        geometry.__vertexArray = new Float32Array(nvertices * 3);
        geometry.__colorArray = new Float32Array(nvertices * 3);
        geometry.__lineDistanceArray = new Float32Array(nvertices * 1);
        geometry.__webglLineCount = nvertices;
        initCustomAttributes(geometry, object);
    }
    function initPointCloudBuffers(geometry, object) {
        var nvertices = geometry.vertices.length;
        geometry.__vertexArray = new Float32Array(nvertices * 3);
        geometry.__colorArray = new Float32Array(nvertices * 3);
        geometry.__webglPointCount = nvertices;
        initCustomAttributes(geometry, object);
    }
    function initMeshBuffers(geometryGroup, object) {
        var geometry = object.geometry,
            faces3 = geometryGroup.faces3,
            nvertices = faces3.length * 3,
            ntris = faces3.length * 1,
            nlines = faces3.length * 3,
            material = getBufferMaterial(object, geometryGroup),
            uvType = bufferGuessUVType(material),
            normalType = bufferGuessNormalType(material),
            vertexColorType = bufferGuessVertexColorType(material);
        // THREE.log( "uvType", uvType, "normalType", normalType, "vertexColorType", vertexColorType, object, geometryGroup, material );
        geometryGroup.__vertexArray = new Float32Array(nvertices * 3);
        if (normalType) {
            geometryGroup.__normalArray = new Float32Array(nvertices * 3);
        }
        if (geometry.hasTangents) {
            geometryGroup.__tangentArray = new Float32Array(nvertices * 4);
        }
        if (vertexColorType) {
            geometryGroup.__colorArray = new Float32Array(nvertices * 3);
        }
        if (uvType) {
            if (geometry.faceVertexUvs.length > 0) {
                geometryGroup.__uvArray = new Float32Array(nvertices * 2);
            }
            if (geometry.faceVertexUvs.length > 1) {
                geometryGroup.__uv2Array = new Float32Array(nvertices * 2);
            }
        }
        if (object.geometry.skinWeights.length && object.geometry.skinIndices.length) {
            geometryGroup.__skinIndexArray = new Float32Array(nvertices * 4);
            geometryGroup.__skinWeightArray = new Float32Array(nvertices * 4);
        }
        var UintArray = extensions.get('OES_element_index_uint') !== null && ntris > 21845 ? Uint32Array : Uint16Array; // 65535 / 3
        geometryGroup.__typeArray = UintArray;
        geometryGroup.__faceArray = new UintArray(ntris * 3);
        geometryGroup.__lineArray = new UintArray(nlines * 2);
        geometryGroup.__webglFaceCount = ntris * 3;
        geometryGroup.__webglLineCount = nlines * 2;
        // custom attributes
        if (material.attributes) {
            if (geometryGroup.__webglCustomAttributesList === undefined) {
                geometryGroup.__webglCustomAttributesList = [];
            }
            for (var a in material.attributes) {
                // Do a shallow copy of the attribute object so different geometryGroup chunks use different
                // attribute buffers which are correctly indexed in the setMeshBuffers function
                var originalAttribute = material.attributes[a];
                var attribute = {};
                for (var property in originalAttribute) {
                    attribute[property] = originalAttribute[property];
                }
                if (!attribute.__webglInitialized || attribute.createUniqueBuffers) {
                    attribute.__webglInitialized = true;
                    var size = 1; // "f" and "i"
                    if (attribute.type === "v2") size = 2;else if (attribute.type === "v3") size = 3;else if (attribute.type === "v4") size = 4;else if (attribute.type === "c") size = 3;
                    attribute.size = size;
                    attribute.array = new Float32Array(nvertices * size);
                    attribute.buffer = _gl.createBuffer();
                    attribute.buffer.belongsToAttribute = a;
                    originalAttribute.needsUpdate = true;
                    attribute.__original = originalAttribute;
                }
                geometryGroup.__webglCustomAttributesList.push(attribute);
            }
        }
        geometryGroup.__inittedArrays = true;
    }
    function getBufferMaterial(object, geometryGroup) {
        return object.material instanceof THREE$1.MeshFaceMaterial ? object.material.materials[geometryGroup.materialIndex] : object.material;
    }
    function materialNeedsSmoothNormals(material) {
        return material && material.shading !== undefined && material.shading === THREE$1.SmoothShading;
    }
    function bufferGuessNormalType(material) {
        // only MeshBasicMaterial and MeshDepthMaterial don't need normals
        if (material instanceof THREE$1.MeshBasicMaterial && !material.envMap || material instanceof THREE$1.MeshDepthMaterial) {
            return false;
        }
        if (materialNeedsSmoothNormals(material)) {
            return THREE$1.SmoothShading;
        } else {
            return THREE$1.FlatShading;
        }
    }
    function bufferGuessVertexColorType(material) {
        if (material.vertexColors) {
            return material.vertexColors;
        }
        return false;
    }
    function bufferGuessUVType(material) {
        // material must use some texture to require uvs
        if (material.map || material.lightMap || material.bumpMap || material.normalMap || material.specularMap || material.alphaMap || material instanceof THREE$1.ShaderMaterial) {
            return true;
        }
        return false;
    }
    // Buffer setting
    function setLineBuffers(geometry, hint) {
        var v,
            c,
            d,
            vertex,
            offset,
            color,
            vertices = geometry.vertices,
            colors = geometry.colors,
            lineDistances = geometry.lineDistances,
            vl = vertices.length,
            cl = colors.length,
            dl = lineDistances.length,
            vertexArray = geometry.__vertexArray,
            colorArray = geometry.__colorArray,
            lineDistanceArray = geometry.__lineDistanceArray,
            dirtyVertices = geometry.verticesNeedUpdate,
            dirtyColors = geometry.colorsNeedUpdate,
            dirtyLineDistances = geometry.lineDistancesNeedUpdate,
            customAttributes = geometry.__webglCustomAttributesList,
            i,
            il,
            ca,
            cal,
            value,
            customAttribute;
        if (dirtyVertices) {
            for (v = 0; v < vl; v++) {
                vertex = vertices[v];
                offset = v * 3;
                vertexArray[offset] = vertex.x;
                vertexArray[offset + 1] = vertex.y;
                vertexArray[offset + 2] = vertex.z;
            }
            _gl.bindBuffer(_gl.ARRAY_BUFFER, geometry.__webglVertexBuffer);
            _gl.bufferData(_gl.ARRAY_BUFFER, vertexArray, hint);
        }
        if (dirtyColors) {
            for (c = 0; c < cl; c++) {
                color = colors[c];
                offset = c * 3;
                colorArray[offset] = color.r;
                colorArray[offset + 1] = color.g;
                colorArray[offset + 2] = color.b;
            }
            _gl.bindBuffer(_gl.ARRAY_BUFFER, geometry.__webglColorBuffer);
            _gl.bufferData(_gl.ARRAY_BUFFER, colorArray, hint);
        }
        if (dirtyLineDistances) {
            for (d = 0; d < dl; d++) {
                lineDistanceArray[d] = lineDistances[d];
            }
            _gl.bindBuffer(_gl.ARRAY_BUFFER, geometry.__webglLineDistanceBuffer);
            _gl.bufferData(_gl.ARRAY_BUFFER, lineDistanceArray, hint);
        }
        if (customAttributes) {
            for (i = 0, il = customAttributes.length; i < il; i++) {
                customAttribute = customAttributes[i];
                if (customAttribute.needsUpdate && (customAttribute.boundTo === undefined || customAttribute.boundTo === "vertices")) {
                    offset = 0;
                    cal = customAttribute.value.length;
                    if (customAttribute.size === 1) {
                        for (ca = 0; ca < cal; ca++) {
                            customAttribute.array[ca] = customAttribute.value[ca];
                        }
                    } else if (customAttribute.size === 2) {
                        for (ca = 0; ca < cal; ca++) {
                            value = customAttribute.value[ca];
                            customAttribute.array[offset] = value.x;
                            customAttribute.array[offset + 1] = value.y;
                            offset += 2;
                        }
                    } else if (customAttribute.size === 3) {
                        if (customAttribute.type === "c") {
                            for (ca = 0; ca < cal; ca++) {
                                value = customAttribute.value[ca];
                                customAttribute.array[offset] = value.r;
                                customAttribute.array[offset + 1] = value.g;
                                customAttribute.array[offset + 2] = value.b;
                                offset += 3;
                            }
                        } else {
                            for (ca = 0; ca < cal; ca++) {
                                value = customAttribute.value[ca];
                                customAttribute.array[offset] = value.x;
                                customAttribute.array[offset + 1] = value.y;
                                customAttribute.array[offset + 2] = value.z;
                                offset += 3;
                            }
                        }
                    } else if (customAttribute.size === 4) {
                        for (ca = 0; ca < cal; ca++) {
                            value = customAttribute.value[ca];
                            customAttribute.array[offset] = value.x;
                            customAttribute.array[offset + 1] = value.y;
                            customAttribute.array[offset + 2] = value.z;
                            customAttribute.array[offset + 3] = value.w;
                            offset += 4;
                        }
                    }
                    _gl.bindBuffer(_gl.ARRAY_BUFFER, customAttribute.buffer);
                    _gl.bufferData(_gl.ARRAY_BUFFER, customAttribute.array, hint);
                }
            }
        }
    }
    function setPointCloudBuffers(geometry, hint) {
        var v,
            c,
            vertex,
            offset,
            color,
            vertices = geometry.vertices,
            colors = geometry.colors,
            vl = vertices.length,
            cl = colors.length,
            vertexArray = geometry.__vertexArray,
            colorArray = geometry.__colorArray,
            dirtyVertices = geometry.verticesNeedUpdate,
            dirtyColors = geometry.colorsNeedUpdate,
            customAttributes = geometry.__webglCustomAttributesList,
            i,
            il,
            ca,
            cal,
            value,
            customAttribute;
        if (dirtyVertices) {
            for (v = 0; v < vl; v++) {
                vertex = vertices[v];
                offset = v * 3;
                vertexArray[offset] = vertex.x;
                vertexArray[offset + 1] = vertex.y;
                vertexArray[offset + 2] = vertex.z;
            }
            _gl.bindBuffer(_gl.ARRAY_BUFFER, geometry.__webglVertexBuffer);
            _gl.bufferData(_gl.ARRAY_BUFFER, vertexArray, hint);
        }
        if (dirtyColors) {
            for (c = 0; c < cl; c++) {
                color = colors[c];
                offset = c * 3;
                colorArray[offset] = color.r;
                colorArray[offset + 1] = color.g;
                colorArray[offset + 2] = color.b;
            }
            _gl.bindBuffer(_gl.ARRAY_BUFFER, geometry.__webglColorBuffer);
            _gl.bufferData(_gl.ARRAY_BUFFER, colorArray, hint);
        }
        if (customAttributes) {
            for (i = 0, il = customAttributes.length; i < il; i++) {
                customAttribute = customAttributes[i];
                if (customAttribute.needsUpdate && (customAttribute.boundTo === undefined || customAttribute.boundTo === "vertices")) {
                    offset = 0;
                    cal = customAttribute.value.length;
                    if (customAttribute.size === 1) {
                        for (ca = 0; ca < cal; ca++) {
                            customAttribute.array[ca] = customAttribute.value[ca];
                        }
                    } else if (customAttribute.size === 2) {
                        for (ca = 0; ca < cal; ca++) {
                            value = customAttribute.value[ca];
                            customAttribute.array[offset] = value.x;
                            customAttribute.array[offset + 1] = value.y;
                            offset += 2;
                        }
                    } else if (customAttribute.size === 3) {
                        if (customAttribute.type === "c") {
                            for (ca = 0; ca < cal; ca++) {
                                value = customAttribute.value[ca];
                                customAttribute.array[offset] = value.r;
                                customAttribute.array[offset + 1] = value.g;
                                customAttribute.array[offset + 2] = value.b;
                                offset += 3;
                            }
                        } else {
                            for (ca = 0; ca < cal; ca++) {
                                value = customAttribute.value[ca];
                                customAttribute.array[offset] = value.x;
                                customAttribute.array[offset + 1] = value.y;
                                customAttribute.array[offset + 2] = value.z;
                                offset += 3;
                            }
                        }
                    } else if (customAttribute.size === 4) {
                        for (ca = 0; ca < cal; ca++) {
                            value = customAttribute.value[ca];
                            customAttribute.array[offset] = value.x;
                            customAttribute.array[offset + 1] = value.y;
                            customAttribute.array[offset + 2] = value.z;
                            customAttribute.array[offset + 3] = value.w;
                            offset += 4;
                        }
                    }
                    _gl.bindBuffer(_gl.ARRAY_BUFFER, customAttribute.buffer);
                    _gl.bufferData(_gl.ARRAY_BUFFER, customAttribute.array, hint);
                }
            }
        }
    }
    function setMeshBuffers(geometryGroup, object, hint, dispose, material) {
        if (!geometryGroup.__inittedArrays) {
            return;
        }
        var normalType = bufferGuessNormalType(material),
            vertexColorType = bufferGuessVertexColorType(material),
            uvType = bufferGuessUVType(material),
            needsSmoothNormals = normalType === THREE$1.SmoothShading;
        var f,
            fl,
            fi,
            face,
            vertexNormals,
            faceNormal,
            vertexColors,
            faceColor,
            vertexTangents,
            uv,
            uv2,
            v1,
            v2,
            v3,
            t1,
            t2,
            t3,
            c1,
            c2,
            c3,
            i,
            il,
            vn,
            uvi,
            uv2i,
            vertexIndex = 0,
            offset = 0,
            offset_uv = 0,
            offset_uv2 = 0,
            offset_face = 0,
            offset_normal = 0,
            offset_tangent = 0,
            offset_line = 0,
            offset_color = 0,
            offset_custom = 0,
            value,
            vertexArray = geometryGroup.__vertexArray,
            uvArray = geometryGroup.__uvArray,
            uv2Array = geometryGroup.__uv2Array,
            normalArray = geometryGroup.__normalArray,
            tangentArray = geometryGroup.__tangentArray,
            colorArray = geometryGroup.__colorArray,
            customAttributes = geometryGroup.__webglCustomAttributesList,
            customAttribute,
            faceArray = geometryGroup.__faceArray,
            lineArray = geometryGroup.__lineArray,
            geometry = object.geometry,
            // this is shared for all chunks
        dirtyVertices = geometry.verticesNeedUpdate,
            dirtyElements = geometry.elementsNeedUpdate,
            dirtyUvs = geometry.uvsNeedUpdate,
            dirtyNormals = geometry.normalsNeedUpdate,
            dirtyTangents = geometry.tangentsNeedUpdate,
            dirtyColors = geometry.colorsNeedUpdate,
            vertices = geometry.vertices,
            chunk_faces3 = geometryGroup.faces3,
            obj_faces = geometry.faces,
            obj_uvs = geometry.faceVertexUvs[0],
            obj_uvs2 = geometry.faceVertexUvs[1];
        if (dirtyVertices) {
            for (f = 0, fl = chunk_faces3.length; f < fl; f++) {
                face = obj_faces[chunk_faces3[f]];
                v1 = vertices[face.a];
                v2 = vertices[face.b];
                v3 = vertices[face.c];
                vertexArray[offset] = v1.x;
                vertexArray[offset + 1] = v1.y;
                vertexArray[offset + 2] = v1.z;
                vertexArray[offset + 3] = v2.x;
                vertexArray[offset + 4] = v2.y;
                vertexArray[offset + 5] = v2.z;
                vertexArray[offset + 6] = v3.x;
                vertexArray[offset + 7] = v3.y;
                vertexArray[offset + 8] = v3.z;
                offset += 9;
            }
            _gl.bindBuffer(_gl.ARRAY_BUFFER, geometryGroup.__webglVertexBuffer);
            _gl.bufferData(_gl.ARRAY_BUFFER, vertexArray, hint);
        }
        if (dirtyColors && vertexColorType) {
            for (f = 0, fl = chunk_faces3.length; f < fl; f++) {
                face = obj_faces[chunk_faces3[f]];
                vertexColors = face.vertexColors;
                faceColor = face.color;
                if (vertexColors.length === 3 && vertexColorType === THREE$1.VertexColors) {
                    c1 = vertexColors[0];
                    c2 = vertexColors[1];
                    c3 = vertexColors[2];
                } else {
                    c1 = faceColor;
                    c2 = faceColor;
                    c3 = faceColor;
                }
                colorArray[offset_color] = c1.r;
                colorArray[offset_color + 1] = c1.g;
                colorArray[offset_color + 2] = c1.b;
                colorArray[offset_color + 3] = c2.r;
                colorArray[offset_color + 4] = c2.g;
                colorArray[offset_color + 5] = c2.b;
                colorArray[offset_color + 6] = c3.r;
                colorArray[offset_color + 7] = c3.g;
                colorArray[offset_color + 8] = c3.b;
                offset_color += 9;
            }
            if (offset_color > 0) {
                _gl.bindBuffer(_gl.ARRAY_BUFFER, geometryGroup.__webglColorBuffer);
                _gl.bufferData(_gl.ARRAY_BUFFER, colorArray, hint);
            }
        }
        if (dirtyTangents && geometry.hasTangents) {
            for (f = 0, fl = chunk_faces3.length; f < fl; f++) {
                face = obj_faces[chunk_faces3[f]];
                vertexTangents = face.vertexTangents;
                t1 = vertexTangents[0];
                t2 = vertexTangents[1];
                t3 = vertexTangents[2];
                tangentArray[offset_tangent] = t1.x;
                tangentArray[offset_tangent + 1] = t1.y;
                tangentArray[offset_tangent + 2] = t1.z;
                tangentArray[offset_tangent + 3] = t1.w;
                tangentArray[offset_tangent + 4] = t2.x;
                tangentArray[offset_tangent + 5] = t2.y;
                tangentArray[offset_tangent + 6] = t2.z;
                tangentArray[offset_tangent + 7] = t2.w;
                tangentArray[offset_tangent + 8] = t3.x;
                tangentArray[offset_tangent + 9] = t3.y;
                tangentArray[offset_tangent + 10] = t3.z;
                tangentArray[offset_tangent + 11] = t3.w;
                offset_tangent += 12;
            }
            _gl.bindBuffer(_gl.ARRAY_BUFFER, geometryGroup.__webglTangentBuffer);
            _gl.bufferData(_gl.ARRAY_BUFFER, tangentArray, hint);
        }
        if (dirtyNormals && normalType) {
            for (f = 0, fl = chunk_faces3.length; f < fl; f++) {
                face = obj_faces[chunk_faces3[f]];
                vertexNormals = face.vertexNormals;
                faceNormal = face.normal;
                if (vertexNormals.length === 3 && needsSmoothNormals) {
                    for (i = 0; i < 3; i++) {
                        vn = vertexNormals[i];
                        normalArray[offset_normal] = vn.x;
                        normalArray[offset_normal + 1] = vn.y;
                        normalArray[offset_normal + 2] = vn.z;
                        offset_normal += 3;
                    }
                } else {
                    for (i = 0; i < 3; i++) {
                        normalArray[offset_normal] = faceNormal.x;
                        normalArray[offset_normal + 1] = faceNormal.y;
                        normalArray[offset_normal + 2] = faceNormal.z;
                        offset_normal += 3;
                    }
                }
            }
            _gl.bindBuffer(_gl.ARRAY_BUFFER, geometryGroup.__webglNormalBuffer);
            _gl.bufferData(_gl.ARRAY_BUFFER, normalArray, hint);
        }
        if (dirtyUvs && obj_uvs && uvType) {
            for (f = 0, fl = chunk_faces3.length; f < fl; f++) {
                fi = chunk_faces3[f];
                uv = obj_uvs[fi];
                if (uv === undefined) continue;
                for (i = 0; i < 3; i++) {
                    uvi = uv[i];
                    uvArray[offset_uv] = uvi.x;
                    uvArray[offset_uv + 1] = uvi.y;
                    offset_uv += 2;
                }
            }
            if (offset_uv > 0) {
                _gl.bindBuffer(_gl.ARRAY_BUFFER, geometryGroup.__webglUVBuffer);
                _gl.bufferData(_gl.ARRAY_BUFFER, uvArray, hint);
            }
        }
        if (dirtyUvs && obj_uvs2 && uvType) {
            for (f = 0, fl = chunk_faces3.length; f < fl; f++) {
                fi = chunk_faces3[f];
                uv2 = obj_uvs2[fi];
                if (uv2 === undefined) continue;
                for (i = 0; i < 3; i++) {
                    uv2i = uv2[i];
                    uv2Array[offset_uv2] = uv2i.x;
                    uv2Array[offset_uv2 + 1] = uv2i.y;
                    offset_uv2 += 2;
                }
            }
            if (offset_uv2 > 0) {
                _gl.bindBuffer(_gl.ARRAY_BUFFER, geometryGroup.__webglUV2Buffer);
                _gl.bufferData(_gl.ARRAY_BUFFER, uv2Array, hint);
            }
        }
        if (dirtyElements) {
            for (f = 0, fl = chunk_faces3.length; f < fl; f++) {
                faceArray[offset_face] = vertexIndex;
                faceArray[offset_face + 1] = vertexIndex + 1;
                faceArray[offset_face + 2] = vertexIndex + 2;
                offset_face += 3;
                lineArray[offset_line] = vertexIndex;
                lineArray[offset_line + 1] = vertexIndex + 1;
                lineArray[offset_line + 2] = vertexIndex;
                lineArray[offset_line + 3] = vertexIndex + 2;
                lineArray[offset_line + 4] = vertexIndex + 1;
                lineArray[offset_line + 5] = vertexIndex + 2;
                offset_line += 6;
                vertexIndex += 3;
            }
            _gl.bindBuffer(_gl.ELEMENT_ARRAY_BUFFER, geometryGroup.__webglFaceBuffer);
            _gl.bufferData(_gl.ELEMENT_ARRAY_BUFFER, faceArray, hint);
            _gl.bindBuffer(_gl.ELEMENT_ARRAY_BUFFER, geometryGroup.__webglLineBuffer);
            _gl.bufferData(_gl.ELEMENT_ARRAY_BUFFER, lineArray, hint);
        }
        if (customAttributes) {
            for (i = 0, il = customAttributes.length; i < il; i++) {
                customAttribute = customAttributes[i];
                if (!customAttribute.__original.needsUpdate) continue;
                offset_custom = 0;
                if (customAttribute.size === 1) {
                    if (customAttribute.boundTo === undefined || customAttribute.boundTo === "vertices") {
                        for (f = 0, fl = chunk_faces3.length; f < fl; f++) {
                            face = obj_faces[chunk_faces3[f]];
                            customAttribute.array[offset_custom] = customAttribute.value[face.a];
                            customAttribute.array[offset_custom + 1] = customAttribute.value[face.b];
                            customAttribute.array[offset_custom + 2] = customAttribute.value[face.c];
                            offset_custom += 3;
                        }
                    } else if (customAttribute.boundTo === "faces") {
                        for (f = 0, fl = chunk_faces3.length; f < fl; f++) {
                            value = customAttribute.value[chunk_faces3[f]];
                            customAttribute.array[offset_custom] = value;
                            customAttribute.array[offset_custom + 1] = value;
                            customAttribute.array[offset_custom + 2] = value;
                            offset_custom += 3;
                        }
                    }
                } else if (customAttribute.size === 2) {
                    if (customAttribute.boundTo === undefined || customAttribute.boundTo === "vertices") {
                        for (f = 0, fl = chunk_faces3.length; f < fl; f++) {
                            face = obj_faces[chunk_faces3[f]];
                            v1 = customAttribute.value[face.a];
                            v2 = customAttribute.value[face.b];
                            v3 = customAttribute.value[face.c];
                            customAttribute.array[offset_custom] = v1.x;
                            customAttribute.array[offset_custom + 1] = v1.y;
                            customAttribute.array[offset_custom + 2] = v2.x;
                            customAttribute.array[offset_custom + 3] = v2.y;
                            customAttribute.array[offset_custom + 4] = v3.x;
                            customAttribute.array[offset_custom + 5] = v3.y;
                            offset_custom += 6;
                        }
                    } else if (customAttribute.boundTo === "faces") {
                        for (f = 0, fl = chunk_faces3.length; f < fl; f++) {
                            value = customAttribute.value[chunk_faces3[f]];
                            v1 = value;
                            v2 = value;
                            v3 = value;
                            customAttribute.array[offset_custom] = v1.x;
                            customAttribute.array[offset_custom + 1] = v1.y;
                            customAttribute.array[offset_custom + 2] = v2.x;
                            customAttribute.array[offset_custom + 3] = v2.y;
                            customAttribute.array[offset_custom + 4] = v3.x;
                            customAttribute.array[offset_custom + 5] = v3.y;
                            offset_custom += 6;
                        }
                    }
                } else if (customAttribute.size === 3) {
                    var pp;
                    if (customAttribute.type === "c") {
                        pp = ["r", "g", "b"];
                    } else {
                        pp = ["x", "y", "z"];
                    }
                    if (customAttribute.boundTo === undefined || customAttribute.boundTo === "vertices") {
                        for (f = 0, fl = chunk_faces3.length; f < fl; f++) {
                            face = obj_faces[chunk_faces3[f]];
                            v1 = customAttribute.value[face.a];
                            v2 = customAttribute.value[face.b];
                            v3 = customAttribute.value[face.c];
                            customAttribute.array[offset_custom] = v1[pp[0]];
                            customAttribute.array[offset_custom + 1] = v1[pp[1]];
                            customAttribute.array[offset_custom + 2] = v1[pp[2]];
                            customAttribute.array[offset_custom + 3] = v2[pp[0]];
                            customAttribute.array[offset_custom + 4] = v2[pp[1]];
                            customAttribute.array[offset_custom + 5] = v2[pp[2]];
                            customAttribute.array[offset_custom + 6] = v3[pp[0]];
                            customAttribute.array[offset_custom + 7] = v3[pp[1]];
                            customAttribute.array[offset_custom + 8] = v3[pp[2]];
                            offset_custom += 9;
                        }
                    } else if (customAttribute.boundTo === "faces") {
                        for (f = 0, fl = chunk_faces3.length; f < fl; f++) {
                            value = customAttribute.value[chunk_faces3[f]];
                            v1 = value;
                            v2 = value;
                            v3 = value;
                            customAttribute.array[offset_custom] = v1[pp[0]];
                            customAttribute.array[offset_custom + 1] = v1[pp[1]];
                            customAttribute.array[offset_custom + 2] = v1[pp[2]];
                            customAttribute.array[offset_custom + 3] = v2[pp[0]];
                            customAttribute.array[offset_custom + 4] = v2[pp[1]];
                            customAttribute.array[offset_custom + 5] = v2[pp[2]];
                            customAttribute.array[offset_custom + 6] = v3[pp[0]];
                            customAttribute.array[offset_custom + 7] = v3[pp[1]];
                            customAttribute.array[offset_custom + 8] = v3[pp[2]];
                            offset_custom += 9;
                        }
                    } else if (customAttribute.boundTo === "faceVertices") {
                        for (f = 0, fl = chunk_faces3.length; f < fl; f++) {
                            value = customAttribute.value[chunk_faces3[f]];
                            v1 = value[0];
                            v2 = value[1];
                            v3 = value[2];
                            customAttribute.array[offset_custom] = v1[pp[0]];
                            customAttribute.array[offset_custom + 1] = v1[pp[1]];
                            customAttribute.array[offset_custom + 2] = v1[pp[2]];
                            customAttribute.array[offset_custom + 3] = v2[pp[0]];
                            customAttribute.array[offset_custom + 4] = v2[pp[1]];
                            customAttribute.array[offset_custom + 5] = v2[pp[2]];
                            customAttribute.array[offset_custom + 6] = v3[pp[0]];
                            customAttribute.array[offset_custom + 7] = v3[pp[1]];
                            customAttribute.array[offset_custom + 8] = v3[pp[2]];
                            offset_custom += 9;
                        }
                    }
                } else if (customAttribute.size === 4) {
                    if (customAttribute.boundTo === undefined || customAttribute.boundTo === "vertices") {
                        for (f = 0, fl = chunk_faces3.length; f < fl; f++) {
                            face = obj_faces[chunk_faces3[f]];
                            v1 = customAttribute.value[face.a];
                            v2 = customAttribute.value[face.b];
                            v3 = customAttribute.value[face.c];
                            customAttribute.array[offset_custom] = v1.x;
                            customAttribute.array[offset_custom + 1] = v1.y;
                            customAttribute.array[offset_custom + 2] = v1.z;
                            customAttribute.array[offset_custom + 3] = v1.w;
                            customAttribute.array[offset_custom + 4] = v2.x;
                            customAttribute.array[offset_custom + 5] = v2.y;
                            customAttribute.array[offset_custom + 6] = v2.z;
                            customAttribute.array[offset_custom + 7] = v2.w;
                            customAttribute.array[offset_custom + 8] = v3.x;
                            customAttribute.array[offset_custom + 9] = v3.y;
                            customAttribute.array[offset_custom + 10] = v3.z;
                            customAttribute.array[offset_custom + 11] = v3.w;
                            offset_custom += 12;
                        }
                    } else if (customAttribute.boundTo === "faces") {
                        for (f = 0, fl = chunk_faces3.length; f < fl; f++) {
                            value = customAttribute.value[chunk_faces3[f]];
                            v1 = value;
                            v2 = value;
                            v3 = value;
                            customAttribute.array[offset_custom] = v1.x;
                            customAttribute.array[offset_custom + 1] = v1.y;
                            customAttribute.array[offset_custom + 2] = v1.z;
                            customAttribute.array[offset_custom + 3] = v1.w;
                            customAttribute.array[offset_custom + 4] = v2.x;
                            customAttribute.array[offset_custom + 5] = v2.y;
                            customAttribute.array[offset_custom + 6] = v2.z;
                            customAttribute.array[offset_custom + 7] = v2.w;
                            customAttribute.array[offset_custom + 8] = v3.x;
                            customAttribute.array[offset_custom + 9] = v3.y;
                            customAttribute.array[offset_custom + 10] = v3.z;
                            customAttribute.array[offset_custom + 11] = v3.w;
                            offset_custom += 12;
                        }
                    } else if (customAttribute.boundTo === "faceVertices") {
                        for (f = 0, fl = chunk_faces3.length; f < fl; f++) {
                            value = customAttribute.value[chunk_faces3[f]];
                            v1 = value[0];
                            v2 = value[1];
                            v3 = value[2];
                            customAttribute.array[offset_custom] = v1.x;
                            customAttribute.array[offset_custom + 1] = v1.y;
                            customAttribute.array[offset_custom + 2] = v1.z;
                            customAttribute.array[offset_custom + 3] = v1.w;
                            customAttribute.array[offset_custom + 4] = v2.x;
                            customAttribute.array[offset_custom + 5] = v2.y;
                            customAttribute.array[offset_custom + 6] = v2.z;
                            customAttribute.array[offset_custom + 7] = v2.w;
                            customAttribute.array[offset_custom + 8] = v3.x;
                            customAttribute.array[offset_custom + 9] = v3.y;
                            customAttribute.array[offset_custom + 10] = v3.z;
                            customAttribute.array[offset_custom + 11] = v3.w;
                            offset_custom += 12;
                        }
                    }
                }
                _gl.bindBuffer(_gl.ARRAY_BUFFER, customAttribute.buffer);
                _gl.bufferData(_gl.ARRAY_BUFFER, customAttribute.array, hint);
            }
        }
        if (dispose) {
            delete geometryGroup.__inittedArrays;
            delete geometryGroup.__colorArray;
            delete geometryGroup.__normalArray;
            delete geometryGroup.__tangentArray;
            delete geometryGroup.__uvArray;
            delete geometryGroup.__uv2Array;
            delete geometryGroup.__faceArray;
            delete geometryGroup.__vertexArray;
            delete geometryGroup.__lineArray;
            delete geometryGroup.__skinIndexArray;
            delete geometryGroup.__skinWeightArray;
        }
    }
    //[Firefly] This function is different from Three.js -- it adds
    //support for interleaved buffers and drawing from system memory
    //using a shared dynamic buffer.
    function setDirectBuffers(geometry) {
        //[Firefly]
        //Geometries that will draw directly
        //from system memory skip alocations of
        //GPU side GL buffers.
        if (geometry.streamingDraw) {
            //Do we want just the index buffer on the GPU?
            if (!geometry.streamingIndex) {
                var index = geometry.attributes.index;
                if (index) {
                    index.buffer = _gl.createBuffer();
                    _gl.bindBuffer(_gl.ELEMENT_ARRAY_BUFFER, index.buffer);
                    _gl.bufferData(_gl.ELEMENT_ARRAY_BUFFER, index.array || geometry.ib, _gl.STATIC_DRAW);
                }
            }
            return;
        }
        //[Firefly]
        //Does the geometry have an interleaved
        //vertex buffer?
        if (geometry.vb && geometry.vbbuffer === undefined) {
            geometry.vbbuffer = _gl.createBuffer();
            geometry.vbNeedsUpdate = true;
        }
        //[Firefly] Is there an .ib property outside the index attribute (since we use globally shared attributes)?
        if (geometry.ib && geometry.ibbuffer === undefined) {
            geometry.ibbuffer = _gl.createBuffer();
            _gl.bindBuffer(_gl.ELEMENT_ARRAY_BUFFER, geometry.ibbuffer);
            _gl.bufferData(_gl.ELEMENT_ARRAY_BUFFER, geometry.ib, _gl.STATIC_DRAW);
        }
        if (geometry.iblines && geometry.iblinesbuffer === undefined) {
            geometry.iblinesbuffer = _gl.createBuffer();
            _gl.bindBuffer(_gl.ELEMENT_ARRAY_BUFFER, geometry.iblinesbuffer);
            _gl.bufferData(_gl.ELEMENT_ARRAY_BUFFER, geometry.iblines, _gl.STATIC_DRAW);
        }
        var attributes = geometry.attributes;
        var attributesKeys = geometry.attributesKeys;
        for (var i = 0, len = attributesKeys.length; i < len; i++) {
            var attributeName = attributesKeys[i];
            var attributeItem = attributes[attributeName];
            var isIndex = attributeName === 'index';
            if (attributeItem.array && attributeItem.buffer === undefined) {
                attributeItem.buffer = _gl.createBuffer();
                attributeItem.needsUpdate = true;
            }
            if (attributeItem.needsUpdate === true) {
                var bufferType = isIndex ? _gl.ELEMENT_ARRAY_BUFFER : _gl.ARRAY_BUFFER;
                _gl.bindBuffer(bufferType, attributeItem.buffer);
                _gl.bufferData(bufferType, attributeItem.array, _gl.STATIC_DRAW);
                attributeItem.needsUpdate = false;
            }
        }
        //Update the common interleaved vb if needed
        if (geometry.vbNeedsUpdate) {
            _gl.bindBuffer(_gl.ARRAY_BUFFER, geometry.vbbuffer);
            _gl.bufferData(_gl.ARRAY_BUFFER, geometry.vb, _gl.STATIC_DRAW);
            geometry.vbNeedsUpdate = false;
            // free cpu-side copy (if wanted)
            if (geometry.discardAfterUpload) {
                geometry.vb = null;
            }
        }
    }
    // Buffer rendering
    //[Firefly] Setup rendering of static model data using Vertex Array Objects
    //Currently we only do this for buffer geometry that is on GPU memory and has no
    //default material attributes and has a single draw batch (offsets array has length 1).
    //Other geometry passes through setupVertexAttributes instead, to set up
    //the vertex layout on every draw.
    function setupVAO(material, program, geometry, uvChannel) {
        var vao;
        if (geometry.streamingDraw) {
            geometry.vaos = null;
            return false;
        }
        if (geometry.offsets && geometry.offsets.length > 1) {
            geometry.vaos = null;
            return false;
        }
        if (!_glExtensionVAO) {
            geometry.vaos = null;
            return false;
        }
        if (geometry.vaos === undefined) geometry.vaos = [];
        //Set up a VAO for this object
        vao = _glExtensionVAO.createVertexArrayOES();
        geometry.vaos.push({ geomhash: program.id, uv: uvChannel, vao: vao });
        _glExtensionVAO.bindVertexArrayOES(vao);
        //bind the index buffer
        if (material.isEdgeMaterial) {
            _gl.bindBuffer(_gl.ELEMENT_ARRAY_BUFFER, geometry.iblinesbuffer);
        } else {
            var index = geometry.attributes.index;
            if (index) _gl.bindBuffer(_gl.ELEMENT_ARRAY_BUFFER, geometry.ibbuffer || index.buffer);
        }
        //Bind the vertex attributes used by the current program
        var boundBuffer = null;
        var programAttributes = program.attributes;
        var programAttributesKeys = program.attributesKeys;
        var stride = geometry.vbstride;
        var startIndex = geometry.offsets && geometry.offsets.length ? geometry.offsets[0].index : 0;
        //Set up vertex attributes
        for (var i = 0, len = programAttributesKeys.length; i < len; i++) {
            var key = programAttributesKeys[i];
            var programAttribute = programAttributes[key];
            if (programAttribute >= 0) {
                var geometryAttribute = geometry.attributes[key];
                // Override 'uv' attribute mapping if uvChannel is specified
                // (account for the 1-based indexing used for the additional UV channel attributes)
                if (key === 'uv' && uvChannel) {
                    geometryAttribute = geometry.attributes['uv' + (uvChannel + 1)];
                }
                if (geometryAttribute) {
                    var type = _gl.FLOAT;
                    var itemWidth = geometryAttribute.bytesPerItem || 4;
                    if (itemWidth === 1) {
                        type = _gl.UNSIGNED_BYTE;
                    } else if (itemWidth === 2) {
                        type = _gl.UNSIGNED_SHORT;
                    }
                    _gl.enableVertexAttribArray(programAttribute);
                    if (geometryAttribute.itemOffset !== undefined) {
                        if (boundBuffer != geometry.vbbuffer) {
                            _gl.bindBuffer(_gl.ARRAY_BUFFER, geometry.vbbuffer);
                            boundBuffer = geometry.vbbuffer;
                        }
                        _gl.vertexAttribPointer(programAttribute, geometryAttribute.itemSize, type, !!geometryAttribute.normalize, stride * 4, (geometryAttribute.itemOffset + startIndex * stride) * 4);
                    } else {
                        _gl.bindBuffer(_gl.ARRAY_BUFFER, geometryAttribute.buffer);
                        boundBuffer = geometryAttribute.buffer;
                        _gl.vertexAttribPointer(programAttribute, geometryAttribute.itemSize, type, !!geometryAttribute.normalize, 0, startIndex * geometryAttribute.itemSize * itemWidth); // 4 bytes per Float32
                    }
                    if (_glExtensionInstancedArrays) {
                        _glExtensionInstancedArrays.vertexAttribDivisorANGLE(programAttribute, geometry.numInstances ? geometryAttribute.divisor || 0 : 0);
                    }
                } else {
                    //Default material attributes cannot be set in VAO, so we have to abort the VAO setup
                    //and fall back to the regular setupVertexAttributes in draw loop way.
                    //This is hopefully very rare.
                    _glExtensionVAO.bindVertexArrayOES(null);
                    for (var j = 0; j < geometry.vaos.length; j++) {
                        _glExtensionVAO.deleteVertexArrayOES(geometry.vaos[j].vao);
                    }geometry.vaos = null; //Flag it so we don't pass through here again.
                    return false;
                }
            }
        }
        return true;
    }
    function activateVAO(material, program, geometry, uvChannel) {
        var vaos = geometry.vaos;
        if (vaos) {
            //The assumption is that this array is rarely bigger than one or two items,
            //so it's faster to do a search than use object hashmap based on geomhash.
            for (var i = 0, len = vaos.length; i < len; i++) {
                var cache = vaos[i];
                if (cache.geomhash === program.id && cache.uv === uvChannel) {
                    _glExtensionVAO.bindVertexArrayOES(cache.vao);
                    return true;
                }
            }
        } else if (vaos === null) {
            return false;
        }
        return setupVAO(material, program, geometry, uvChannel);
    }
    function bindDynamic(dynBufName, srcData) {
        var boundBuffer = _dynamicBuffers[dynBufName];
        if (!boundBuffer) {
            boundBuffer = _gl.createBuffer();
            _dynamicBuffers[dynBufName] = boundBuffer;
        }
        _gl.bindBuffer(_gl.ARRAY_BUFFER, boundBuffer);
        _gl.bufferData(_gl.ARRAY_BUFFER, srcData, _gl.DYNAMIC_DRAW);
        return boundBuffer;
    }
    //[Firefly] This function is different from Three.js -- it adds
    //support for interleaved buffers and drawing from system memory
    //using a shared dynamic buffer.
    function setupVertexAttributes(material, program, geometry, startIndex, indices, uvChannel) {
        var programAttributes = program.attributes;
        var programAttributesKeys = program.attributesKeys;
        //Those two need to be unequal to begin with...
        var boundBuffer = 0;
        var interleavedBuffer;
        if (indices) {
            // indices (they can have a VBO even if the geometry part is streamed)
            if (!indices.buffer && geometry.streamingDraw) {
                var buffer = _dynamicBuffers.index;
                if (!buffer) {
                    buffer = _gl.createBuffer();
                    _dynamicBuffers.index = buffer;
                }
                //_gl.bindBuffer( _gl.ELEMENT_ARRAY_BUFFER, null);
                _gl.bindBuffer(_gl.ELEMENT_ARRAY_BUFFER, buffer);
                if (material.isEdgeMaterial) {
                    _gl.bufferData(_gl.ELEMENT_ARRAY_BUFFER, geometry.iblines, _gl.DYNAMIC_DRAW);
                } else {
                    _gl.bufferData(_gl.ELEMENT_ARRAY_BUFFER, indices.array || geometry.ib, _gl.DYNAMIC_DRAW);
                }
            } else {
                if (material.isEdgeMaterial) {
                    _gl.bindBuffer(_gl.ELEMENT_ARRAY_BUFFER, geometry.iblinesbuffer);
                } else {
                    _gl.bindBuffer(_gl.ELEMENT_ARRAY_BUFFER, geometry.ibbuffer || indices.buffer);
                }
            }
        }
        //Set attributes
        for (var i = 0, len = programAttributesKeys.length; i < len; i++) {
            var key = programAttributesKeys[i];
            var programAttribute = programAttributes[key];
            if (programAttribute >= 0) {
                var geometryAttribute = geometry.attributes[key];
                if (key === 'uv' && uvChannel) {
                    geometryAttribute = geometry.attributes['uv' + (uvChannel + 1)];
                }
                if (geometryAttribute) {
                    var isInterleaved = geometryAttribute.itemOffset !== undefined;
                    var stride, itemOffset;
                    if (isInterleaved) {
                        stride = geometry.vbstride;
                        itemOffset = geometryAttribute.itemOffset;
                        if (boundBuffer !== interleavedBuffer) {
                            if (geometry.streamingDraw) {
                                boundBuffer = bindDynamic('interleavedVB', geometry.vb);
                            } else {
                                boundBuffer = geometry.vbbuffer;
                                _gl.bindBuffer(_gl.ARRAY_BUFFER, boundBuffer);
                            }
                            interleavedBuffer = boundBuffer;
                        }
                    } else {
                        stride = geometryAttribute.itemSize;
                        itemOffset = 0;
                        if (geometry.streamingDraw) {
                            boundBuffer = bindDynamic(key, geometryAttribute.array);
                        } else {
                            boundBuffer = geometryAttribute.buffer;
                            _gl.bindBuffer(_gl.ARRAY_BUFFER, boundBuffer);
                        }
                    }
                    var type = _gl.FLOAT;
                    var itemWidth = geometryAttribute.bytesPerItem || 4;
                    if (itemWidth === 1) {
                        type = _gl.UNSIGNED_BYTE;
                    } else if (itemWidth === 2) {
                        type = _gl.UNSIGNED_SHORT;
                    }
                    if (isInterleaved) itemWidth = 4; //our interleaved buffers define stride in multiples of 4 bytes
                    state.enableAttribute(programAttribute);
                    _gl.vertexAttribPointer(programAttribute, geometryAttribute.itemSize, type, geometryAttribute.normalize, stride * itemWidth, (itemOffset + startIndex * stride) * itemWidth);
                    if (_glExtensionInstancedArrays) {
                        _glExtensionInstancedArrays.vertexAttribDivisorANGLE(programAttribute, geometry.numInstances ? geometryAttribute.divisor || 0 : 0);
                    }
                } else if (material.defaultAttributeValues) {
                    var attr = material.defaultAttributeValues[key];
                    if (attr && attr.length === 2) {
                        _gl.vertexAttrib2fv(programAttribute, material.defaultAttributeValues[key]);
                    } else if (attr && attr.length === 3) {
                        _gl.vertexAttrib3fv(programAttribute, material.defaultAttributeValues[key]);
                    } else if (attr && attr.length === 4) {
                        _gl.vertexAttrib4fv(programAttribute, material.defaultAttributeValues[key]);
                    }
                }
            }
        }
        state.disableUnusedAttributes();
    }
    // Buffer rendering
    this.renderBufferDirect = function (camera, lights, fog, material, geometry, object, uvChannel) {
        if (material.visible === false) return;
        if (material.isEdgeMaterial && !geometry.iblines) return;
        //updateObject(object);
        setDirectBuffers(object.geometry);
        var program = setProgram(camera, lights, fog, material, object);
        var geometryAttributes = geometry.attributes;
        var updateBuffers = false,
            wireframeBit = material.wireframe ? 1 : 0,
            geometryHash = 'direct_' + geometry.id + (uvChannel ? '/' + uvChannel : '') + '_' + program.id + '_' + wireframeBit;
        if (geometryHash !== _currentGeometryProgram) {
            _currentGeometryProgram = geometryHash;
            updateBuffers = true;
        }
        var vao = activateVAO(material, program, geometry, uvChannel || 0);
        updateBuffers = updateBuffers && !vao;
        if (updateBuffers) {
            state.initAttributes();
        }
        // render mesh
        if (object instanceof THREE$1.Mesh) {
            var index = geometryAttributes.index;
            // indexed triangles
            var geomType;
            if (index) {
                var type, size;
                var ib = index.array ? index.array : geometry.ib;
                if (material.isEdgeMaterial) {
                    index = geometryAttributes.indexlines;
                    ib = geometry.iblines;
                }
                if (index.bytesPerItem) {
                    size = index.bytesPerItem;
                    if (size === 4) {
                        // load the unsigned integer index buffer extension if needed.
                        extensions.get('OES_element_index_uint');
                    }
                } else {
                    if (ib instanceof Uint32Array && extensions.get('OES_element_index_uint')) {
                        size = 4;
                    } else {
                        size = 2;
                    }
                }
                if (size === 4) {
                    type = _gl.UNSIGNED_INT;
                } else {
                    type = _gl.UNSIGNED_SHORT;
                }
                var offsets = material.isEdgeMaterial ? null : geometry.offsets;
                // if there is more than 1 chunk
                // must set attribute pointers to use new offsets for each chunk
                // even if geometry and materials didn't change
                if (offsets && offsets.length > 1) updateBuffers = true;
                var i = 0;
                do {
                    var startIndex, startOffset, count;
                    if (offsets && offsets.length) {
                        startIndex = offsets[i].index;
                        startOffset = offsets[i].start;
                        count = offsets[i].count;
                    } else {
                        startIndex = 0;
                        startOffset = 0;
                        count = ib.length;
                    }
                    if (updateBuffers) {
                        setupVertexAttributes(material, program, geometry, startIndex, index, uvChannel);
                    }
                    // render indexed triangles
                    geomType = _gl.TRIANGLES;
                    if (geometry.isPoints) geomType = _gl.POINTS;else if (geometry.isLines || material.isEdgeMaterial) geomType = _gl.LINES;
                    if (geometry.numInstances) _glExtensionInstancedArrays.drawElementsInstancedANGLE(geomType, count, type, startOffset * size, geometry.numInstances); // 2 bytes per Uint16
                    else {
                            _gl.drawElements(geomType, count, type, startOffset * size); // 2 bytes per Uint16
                        }
                } while (offsets && ++i < offsets.length);
                // non-indexed triangles
            } else {
                if (updateBuffers) {
                    setupVertexAttributes(material, program, geometry, 0, undefined, uvChannel);
                }
                var position = geometry.attributes.position;
                // render non-indexed triangles
                geomType = _gl.TRIANGLES;
                if (geometry.isPoints) geomType = _gl.POINTS;else if (geometry.isLines || material.isEdgeMaterial) geomType = _gl.LINES;
                if (geometry.numInstances) _glExtensionInstancedArrays.drawArraysInstancedANGLE(geomType, 0, position.array.length / 3, geometry.numInstances);else {
                    _gl.drawArrays(geomType, 0, position.array.length / position.itemSize);
                }
            }
        } else {
            THREE$1.log("Only THREE.Mesh can be rendered by the Firefly renderer. Use THREE.Mesh to draw lines.");
        }
        if (vao) _glExtensionVAO.bindVertexArrayOES(null);
    };
    this.renderBuffer = function (camera, lights, fog, material, geometryGroup, object) {
        if (material.visible === false) return;
        updateObject(object);
        var program = setProgram(camera, lights, fog, material, object);
        var attributes = program.attributes;
        var updateBuffers = false,
            wireframeBit = material.wireframe ? 1 : 0,
            geometryGroupHash = geometryGroup.id + '_' + program.id + '_' + wireframeBit;
        if (geometryGroupHash !== _currentGeometryProgram) {
            _currentGeometryProgram = geometryGroupHash;
            updateBuffers = true;
        }
        if (updateBuffers) {
            state.initAttributes();
        }
        // vertices
        if (!material.morphTargets && attributes.position >= 0) {
            if (updateBuffers) {
                _gl.bindBuffer(_gl.ARRAY_BUFFER, geometryGroup.__webglVertexBuffer);
                state.enableAttribute(attributes.position);
                _gl.vertexAttribPointer(attributes.position, 3, _gl.FLOAT, false, 0, 0);
            }
        }
        if (updateBuffers) {
            // custom attributes
            // Use the per-geometryGroup custom attribute arrays which are setup in initMeshBuffers
            if (geometryGroup.__webglCustomAttributesList) {
                for (var i = 0, il = geometryGroup.__webglCustomAttributesList.length; i < il; i++) {
                    var attribute = geometryGroup.__webglCustomAttributesList[i];
                    if (attributes[attribute.buffer.belongsToAttribute] >= 0) {
                        _gl.bindBuffer(_gl.ARRAY_BUFFER, attribute.buffer);
                        state.enableAttribute(attributes[attribute.buffer.belongsToAttribute]);
                        _gl.vertexAttribPointer(attributes[attribute.buffer.belongsToAttribute], attribute.size, _gl.FLOAT, false, 0, 0);
                    }
                }
            }
            // colors
            if (attributes.color >= 0) {
                if (object.geometry.colors.length > 0 || object.geometry.faces.length > 0) {
                    _gl.bindBuffer(_gl.ARRAY_BUFFER, geometryGroup.__webglColorBuffer);
                    state.enableAttribute(attributes.color);
                    _gl.vertexAttribPointer(attributes.color, 3, _gl.FLOAT, false, 0, 0);
                } else if (material.defaultAttributeValues) {
                    _gl.vertexAttrib3fv(attributes.color, material.defaultAttributeValues.color);
                }
            }
            // normals
            if (attributes.normal >= 0) {
                _gl.bindBuffer(_gl.ARRAY_BUFFER, geometryGroup.__webglNormalBuffer);
                state.enableAttribute(attributes.normal);
                _gl.vertexAttribPointer(attributes.normal, 3, _gl.FLOAT, false, 0, 0);
            }
            // tangents
            if (attributes.tangent >= 0) {
                _gl.bindBuffer(_gl.ARRAY_BUFFER, geometryGroup.__webglTangentBuffer);
                state.enableAttribute(attributes.tangent);
                _gl.vertexAttribPointer(attributes.tangent, 4, _gl.FLOAT, false, 0, 0);
            }
            // uvs
            if (attributes.uv >= 0) {
                if (object.geometry.faceVertexUvs[0]) {
                    _gl.bindBuffer(_gl.ARRAY_BUFFER, geometryGroup.__webglUVBuffer);
                    state.enableAttribute(attributes.uv);
                    _gl.vertexAttribPointer(attributes.uv, 2, _gl.FLOAT, false, 0, 0);
                } else if (material.defaultAttributeValues) {
                    _gl.vertexAttrib2fv(attributes.uv, material.defaultAttributeValues.uv);
                }
            }
            if (attributes.uv2 >= 0) {
                if (object.geometry.faceVertexUvs[1]) {
                    _gl.bindBuffer(_gl.ARRAY_BUFFER, geometryGroup.__webglUV2Buffer);
                    state.enableAttribute(attributes.uv2);
                    _gl.vertexAttribPointer(attributes.uv2, 2, _gl.FLOAT, false, 0, 0);
                } else if (material.defaultAttributeValues) {
                    _gl.vertexAttrib2fv(attributes.uv2, material.defaultAttributeValues.uv2);
                }
            }
            // line distances
            if (attributes.lineDistance >= 0) {
                _gl.bindBuffer(_gl.ARRAY_BUFFER, geometryGroup.__webglLineDistanceBuffer);
                state.enableAttribute(attributes.lineDistance);
                _gl.vertexAttribPointer(attributes.lineDistance, 1, _gl.FLOAT, false, 0, 0);
            }
        }
        state.disableUnusedAttributes();
        // render mesh
        if (object instanceof THREE$1.Mesh) {
            var type = geometryGroup.__typeArray === Uint32Array ? _gl.UNSIGNED_INT : _gl.UNSIGNED_SHORT;
            // wireframe
            if (material.wireframe) {
                state.setLineWidth(material.wireframeLinewidth * pixelRatio);
                if (updateBuffers) _gl.bindBuffer(_gl.ELEMENT_ARRAY_BUFFER, geometryGroup.__webglLineBuffer);
                _gl.drawElements(_gl.LINES, geometryGroup.__webglLineCount, type, 0);
                // triangles
            } else {
                if (updateBuffers) _gl.bindBuffer(_gl.ELEMENT_ARRAY_BUFFER, geometryGroup.__webglFaceBuffer);
                _gl.drawElements(_gl.TRIANGLES, geometryGroup.__webglFaceCount, type, 0);
            }
            // render lines
        } else if (object instanceof THREE$1.Line) {
            var mode = object.mode === THREE$1.LineStrip ? _gl.LINE_STRIP : _gl.LINES;
            state.setLineWidth(material.linewidth * pixelRatio);
            _gl.drawArrays(mode, 0, geometryGroup.__webglLineCount);
            // render particles
        } else if (object instanceof THREE$1.PointCloud) {
            _gl.drawArrays(_gl.POINTS, 0, geometryGroup.__webglPointCount);
        }
    };
    // Sorting
    // This method is for transparency
    function painterSortStable(a, b) {
        // first see if there's a render order set - if so, this takes precedence
        if (a.object.renderOrder !== b.object.renderOrder) {
            return a.object.renderOrder - b.object.renderOrder;
            // If render order are the same, then use z distance.
            // We want to render from farthest to nearest.
        } else if (a.z !== b.z) {
            return a.z - b.z;
            // if z distances match, then use id, for a consistent result
        } else {
            return a.id - b.id;
        }
    }
    // This method is for opaque objects
    function reversePainterSortStable(a, b) {
        // first see if there's a render order set - if so, this takes precedence
        if (a.object.renderOrder !== b.object.renderOrder) {
            return a.object.renderOrder - b.object.renderOrder;
            // Next, sort by material, for efficiency, to avoid state changes.
            // (Note this is not done for transparency, as back to front order is more significant.)
        } else if (a.material.id !== b.material.id) {
            return a.material.id - b.material.id;
            // If render order and material are the same, then use z distance.
            // To minimize processing fragments, we render roughly from nearest to farthest.
            // In this way, the closer objects cover pixels and so hide more distance objects.
        }
        if (a.z !== b.z) {
            return b.z - a.z;
            // if z distances match, then use id, for a consistent sorted result
        } else {
            return a.id - b.id;
        }
    }
    /* currently not used
    function numericalSort ( a, b ) {
         return b[ 0 ] - a[ 0 ];
     }
    */
    // Rendering
    this.render = function (scene, camera, renderTarget, forceClear, customLights) {
        if (camera instanceof THREE$1.Camera === false) {
            THREE$1.error('THREE.WebGLRenderer.render: camera is not an instance of THREE.Camera.');
            return;
        }
        // reset caching for this frame
        _currentGeometryProgram = '';
        _currentMaterialId = -1;
        _currentCamera = null;
        if (customLights !== undefined) {
            lights.length = 0;
            _lightsNeedUpdate = true;
        }
        var fog = scene.fog;
        // update scene graph
        if (scene.autoUpdate === true) scene.updateMatrixWorld();
        // update camera matrices and frustum
        if (camera.parent === undefined) camera.updateMatrixWorld();
        camera.matrixWorldInverse.getInverse(camera.matrixWorld);
        if (camera.worldUpTransform) _viewInverseEnv.multiplyMatrices(camera.worldUpTransform, camera.matrixWorld);else _viewInverseEnv.copy(camera.matrixWorld);
        _projScreenMatrix.multiplyMatrices(camera.projectionMatrix, camera.matrixWorldInverse);
        _frustum.setFromMatrix(_projScreenMatrix);
        // update WebGL objects
        var renderImmediate = scene instanceof RenderBatch && scene.renderImmediate;
        if (!renderImmediate) {
            opaqueObjects.length = 0;
            transparentObjects.length = 0;
            projectObject(scene, _this.sortObjects === true, scene.forceVisible === true);
            // note: the following flag is never set in WebGLRenderer; this may change in the future
            if (_this.sortObjects === true) {
                opaqueObjects.sort(reversePainterSortStable);
                transparentObjects.sort(painterSortStable);
            }
        }
        if (_lightsNeedUpdate) {
            if (customLights && customLights.length) lights = customLights.slice();
            setupLights(lights);
        }
        //
        this.setRenderTarget(renderTarget);
        this.resetGLState();
        if (this.autoClear || forceClear) {
            this.clear(this.autoClearColor, this.autoClearDepth, this.autoClearStencil);
        }
        if (scene.overrideMaterial) {
            var overrideMaterial = scene.overrideMaterial;
            setMaterial(overrideMaterial);
            if (!renderImmediate) {
                renderObjects(opaqueObjects, camera, lights, fog, overrideMaterial);
                renderObjects(transparentObjects, camera, lights, fog, overrideMaterial);
            } else {
                renderObjectsImmediate(scene, "", camera, lights, fog, overrideMaterial);
            }
        } else {
            if (!renderImmediate) {
                // opaque pass (front-to-back order)
                state.setBlending(THREE$1.NoBlending);
                renderObjects(opaqueObjects, camera, lights, fog, null);
                // transparent pass (back-to-front order)
                renderObjects(transparentObjects, camera, lights, fog, null);
            } else {
                renderObjectsImmediate(scene, "", camera, lights, fog, null);
            }
        }
        // Generate mipmap if we're using any kind of mipmap filtering
        if (renderTarget && renderTarget.generateMipmaps && renderTarget.minFilter !== THREE$1.NearestFilter && renderTarget.minFilter !== THREE$1.LinearFilter) {
            updateRenderTargetMipmap(renderTarget);
        }
        this.resetGLState();
        // Ensure depth buffer writing is enabled so it can be cleared on next render
        state.setDepthTest(true);
        state.setDepthWrite(true);
        // _gl.finish();
    };
    this.clearBlend = function () {
        state.setBlending(THREE$1.NoBlending);
    };
    this.setProgramPrefix = function (index, vertexPrefix, fragmentPrefix) {
        _programIndex = index;
        _vertexPrefix = vertexPrefix;
        _fragmentPrefix = fragmentPrefix;
    };
    this.getProgramPrefix = function () {
        return { programPrefix: _programIndex,
            vertexPrefix: _vertexPrefix,
            fragmentPrefix: _fragmentPrefix };
    };
    function renderBatchIterSort(m) {
        projectObject(m, true);
    }
    function renderBatchIterNoSort(m) {
        projectObject(m, false);
    }
    function projectObject(object, sortObjects, forceVisible) {
        var i, len;
        if (!forceVisible && object.visible === false) return;
        if (object instanceof THREE$1.Scene || object instanceof THREE$1.Group) {
            // skip
        } else if (object instanceof RenderBatch) {
            object.forEach(sortObjects ? renderBatchIterSort : renderBatchIterNoSort);
        } else {
            initObject(object);
            if (object instanceof THREE$1.Light) {
                lights.push(object);
            } else {
                var webglObjects = _webglObjects[object.id];
                if (webglObjects && (object.frustumCulled === false || _frustum.intersectsObject(object) === true)) {
                    for (i = 0, len = webglObjects.length; i < len; i++) {
                        var webglObject = webglObjects[i];
                        unrollBufferMaterial(webglObject);
                        webglObject.render = true;
                        if (sortObjects === true) {
                            _vector3.setFromMatrixPosition(object.matrixWorld);
                            _vector3.applyProjection(_projScreenMatrix);
                            webglObject.z = _vector3.z;
                        }
                    }
                }
            }
        }
        if (object.children) {
            for (i = 0, len = object.children.length; i < len; i++) {
                projectObject(object.children[i], sortObjects, forceVisible);
            }
        }
    }
    // depending on the original material of a shape, we use either the main
    // override directly or a custom variant (if needed).
    function chooseOverrideMaterial(shapeMaterial, overrideMaterial) {
        // if override material does not define custom variants, there is nothing to do
        if (!overrideMaterial.getCustomOverrideMaterial) {
            return overrideMaterial;
        }
        // check if a custom override material should be used
        var customOverride = overrideMaterial.getCustomOverrideMaterial(shapeMaterial);
        if (!customOverride) {
            return overrideMaterial;
        }
        // use alternative variant
        return customOverride;
    }
    function renderObjects(renderList, camera, lights, fog, overrideMaterial) {
        var material;
        //TODO: we have to iterate upwards in order to preserve draw order for 2d
        //without having to sort the scene. Figure out how to keep the reverse iteration so that
        //we are consistent with three.js
        for (var i = 0, iEnd = renderList.length; i < iEnd; i++) {
            //for ( var i = renderList.length - 1; i !== - 1; i -- ) {
            var webglObject = renderList[i];
            var object = webglObject.object;
            var buffer = webglObject.buffer;
            if (overrideMaterial) {
                // either use overrideMaterial or a custom variant if needed for this render item
                material = chooseOverrideMaterial(webglObject.material, overrideMaterial);
            } else {
                material = webglObject.material;
                if (!material) continue;
                setMaterial(material);
            }
            // If the object is transparent, render it in two passes:
            // backfaces, then frontfaces. This helps avoid out-of-order sorting
            // transparency blending artifacts (these still can occur for pixels where
            // four or more triangles in a single mesh overlap the same pixel).
            // Also, check that depth testing is on; if not, we're in 2D mode and draw
            // order matters so we should not use this mode.
            // Else render normally.
            // See https://jira.autodesk.com/browse/LMV-1121
            if (material.twoPassTransparency) {
                var originalSide = material.side;
                // note we do NOT set material.needsUpdate to true, as the double-sided shader
                // works fine for back and front faces.
                material.side = THREE$1.BackSide;
                renderObjectsFace(material, camera, lights, fog, buffer, overrideMaterial, object);
                material.side = THREE$1.FrontSide;
                renderObjectsFace(material, camera, lights, fog, buffer, overrideMaterial, object);
                material.side = originalSide;
            } else {
                renderObjectsFace(material, camera, lights, fog, buffer, overrideMaterial, object);
            }
        }
    }
    function renderObjectsFace(material, camera, lights, fog, buffer, overrideMaterial, object) {
        _this.setMaterialFaces(material);
        if (buffer instanceof THREE$1.BufferGeometry) {
            _this.renderBufferDirect(camera, lights, fog, material, buffer, object);
        } else {
            _this.renderBuffer(camera, lights, fog, material, buffer, object);
        }
        if (material.decals) {
            var decals = material.decals;
            for (var di = 0, dlen = decals.length; di < dlen; di++) {
                var decal = decals[di];
                material = decal.material;
                setMaterial(material);
                _this.setMaterialFaces(material);
                if (buffer instanceof THREE$1.BufferGeometry) {
                    _this.renderBufferDirect(camera, lights, fog, material, buffer, object, decal.uv);
                }
            }
        }
    }
    var roi_camera, roi_lights, roi_fog, roi_overrideMaterial; // unused: roi_materialType, 
    function renderImmediateCallback(m, idx) {
        if (m.visible && !m.hide) {
            var material;
            if (roi_overrideMaterial) {
                // either use overrideMaterial or a custom variant if needed for this render item
                material = chooseOverrideMaterial(m.material, roi_overrideMaterial);
            } else {
                material = m.material;
                if (!material) return;
                setMaterial(material);
            }
            // If the object is transparent, render it in two passes:
            // backfaces, then frontfaces. This helps avoid out-of-order sorting
            // transparency blending artifacts (these still can occur for pixels where
            // four or more triangles in a single mesh overlap the same pixel).
            // Also, check that depth testing is on; if not, we're in 2D mode and draw
            // order matters so we should not use this mode.
            // Else render normally.
            // See https://jira.autodesk.com/browse/LMV-1121
            if (material.twoPassTransparency) {
                var originalSide = material.side;
                // note we do NOT set material.needsUpdate to true, as the double-sided shader
                // works fine for back and front faces.
                material.side = THREE$1.BackSide;
                renderImmediateFace(m, material);
                material.side = THREE$1.FrontSide;
                renderImmediateFace(m, material);
                material.side = originalSide;
            } else {
                renderImmediateFace(m, material);
            }
        }
    }
    function renderImmediateFace(m, material) {
        _this.setMaterialFaces(material);
        _this.renderBufferDirect(roi_camera, roi_lights, roi_fog, material, m.geometry, m);
        if (material.decals) {
            var decals = material.decals;
            for (var di = 0, dlen = decals.length; di < dlen; di++) {
                var decal = decals[di];
                material = decal.material;
                setMaterial(material);
                _this.setMaterialFaces(material);
                _this.renderBufferDirect(roi_camera, roi_lights, roi_fog, material, m.geometry, m, decal.uv);
            }
        }
    }
    function renderObjectsImmediate(renderList, materialType, camera, lights, fog, overrideMaterial) {
        //roi_materialType = materialType;
        roi_camera = camera;
        roi_lights = lights;
        roi_fog = fog;
        roi_overrideMaterial = overrideMaterial || null;
        // not really "forceVisible"
        // it's really only for ground shadows, or custom modelQueue iteration passes
        // In such cases we use the MESH_VISIBLE bit instead of the actual current visibility of the mesh (which is dependent on the render pass being done)
        renderList.forEach(renderImmediateCallback, renderList.forceVisible ? 1 : 0x80, false);
    }
    function unrollBufferMaterial(globject) {
        var object = globject.object;
        var buffer = globject.buffer;
        var geometry = object.geometry;
        var material = object.material;
        if (material instanceof THREE$1.MeshFaceMaterial) {
            var materialIndex = geometry instanceof THREE$1.BufferGeometry ? 0 : buffer.materialIndex;
            material = material.materials[materialIndex];
            globject.material = material;
            if (material.transparent) {
                transparentObjects.push(globject);
            } else {
                opaqueObjects.push(globject);
            }
        } else if (material) {
            globject.material = material;
            if (material.transparent) {
                transparentObjects.push(globject);
            } else {
                opaqueObjects.push(globject);
            }
        }
    }
    // Objects adding
    function initObject(object) {
        if (object.__webglInit === undefined) {
            object.__webglInit = true;
            object.addEventListener('removed', onObjectRemoved);
        }
        var geometry = object.geometry;
        if (geometry === undefined) {
            // ImmediateRenderObject
        } else if (geometry.__webglInit === undefined) {
            geometry.__webglInit = true;
            geometry.addEventListener('dispose', onGeometryDispose);
            if (geometry instanceof THREE$1.BufferGeometry) {
                //
            } else if (object instanceof THREE$1.Mesh) {
                initGeometryGroups(object, geometry);
            } else if (object instanceof THREE$1.Line) {
                if (geometry.__webglVertexBuffer === undefined) {
                    createLineBuffers(geometry);
                    initLineBuffers(geometry, object);
                    geometry.verticesNeedUpdate = true;
                    geometry.colorsNeedUpdate = true;
                    geometry.lineDistancesNeedUpdate = true;
                }
            } else if (object instanceof THREE$1.PointCloud) {
                if (geometry.__webglVertexBuffer === undefined) {
                    createPointCloudBuffers(geometry);
                    initPointCloudBuffers(geometry, object);
                    geometry.verticesNeedUpdate = true;
                    geometry.colorsNeedUpdate = true;
                }
            }
        }
        if (object.__webglActive === undefined) {
            object.__webglActive = true;
            if (object instanceof THREE$1.Mesh) {
                if (geometry instanceof THREE$1.BufferGeometry) {
                    addBuffer(_webglObjects, geometry, object);
                } else if (geometry instanceof THREE$1.Geometry) {
                    var geometryGroupsList = geometryGroups[geometry.id];
                    for (var i = 0, len = geometryGroupsList.length; i < len; i++) {
                        addBuffer(_webglObjects, geometryGroupsList[i], object);
                    }
                }
            } else if (object instanceof THREE$1.Line || object instanceof THREE$1.PointCloud) {
                addBuffer(_webglObjects, geometry, object);
            } else if (object instanceof THREE$1.ImmediateRenderObject || object.immediateRenderCallback) {
                addBufferImmediate(_webglObjectsImmediate, object);
            }
        }
    }
    // Geometry splitting
    var geometryGroups = {};
    var geometryGroupCounter = 0;
    function makeGroups(geometry, usesFaceMaterial) {
        var maxVerticesInGroup = extensions.get('OES_element_index_uint') ? 4294967296 : 65535;
        var groupHash,
            hash_map = {};
        var numMorphTargets = geometry.morphTargets ? geometry.morphTargets.length : 0;
        var numMorphNormals = geometry.morphNormals ? geometry.morphNormals.length : 0;
        var group;
        var groups = {};
        var groupsList = [];
        for (var f = 0, fl = geometry.faces.length; f < fl; f++) {
            var face = geometry.faces[f];
            var materialIndex = usesFaceMaterial ? face.materialIndex : 0;
            if (!(materialIndex in hash_map)) {
                hash_map[materialIndex] = { hash: materialIndex, counter: 0 };
            }
            groupHash = hash_map[materialIndex].hash + '_' + hash_map[materialIndex].counter;
            if (!(groupHash in groups)) {
                group = {
                    id: geometryGroupCounter++,
                    faces3: [],
                    materialIndex: materialIndex,
                    vertices: 0,
                    numMorphTargets: numMorphTargets,
                    numMorphNormals: numMorphNormals
                };
                groups[groupHash] = group;
                groupsList.push(group);
            }
            if (groups[groupHash].vertices + 3 > maxVerticesInGroup) {
                hash_map[materialIndex].counter += 1;
                groupHash = hash_map[materialIndex].hash + '_' + hash_map[materialIndex].counter;
                if (!(groupHash in groups)) {
                    group = {
                        id: geometryGroupCounter++,
                        faces3: [],
                        materialIndex: materialIndex,
                        vertices: 0,
                        numMorphTargets: numMorphTargets,
                        numMorphNormals: numMorphNormals
                    };
                    groups[groupHash] = group;
                    groupsList.push(group);
                }
            }
            groups[groupHash].faces3.push(f);
            groups[groupHash].vertices += 3;
        }
        return groupsList;
    }
    function initGeometryGroups(object, geometry) {
        var material = object.material,
            addBuffers = false;
        if (geometryGroups[geometry.id] === undefined || geometry.groupsNeedUpdate === true) {
            delete _webglObjects[object.id];
            geometryGroups[geometry.id] = makeGroups(geometry, material instanceof THREE$1.MeshFaceMaterial);
            geometry.groupsNeedUpdate = false;
        }
        var geometryGroupsList = geometryGroups[geometry.id];
        // create separate VBOs per geometry chunk
        for (var i = 0, il = geometryGroupsList.length; i < il; i++) {
            var geometryGroup = geometryGroupsList[i];
            // initialise VBO on the first access
            if (geometryGroup.__webglVertexBuffer === undefined) {
                createMeshBuffers(geometryGroup);
                initMeshBuffers(geometryGroup, object);
                geometry.verticesNeedUpdate = true;
                geometry.morphTargetsNeedUpdate = true;
                geometry.elementsNeedUpdate = true;
                geometry.uvsNeedUpdate = true;
                geometry.normalsNeedUpdate = true;
                geometry.tangentsNeedUpdate = true;
                geometry.colorsNeedUpdate = true;
                addBuffers = true;
            } else {
                addBuffers = false;
            }
            if (addBuffers || object.__webglActive === undefined) {
                addBuffer(_webglObjects, geometryGroup, object);
            }
        }
        object.__webglActive = true;
    }
    function addBuffer(objlist, buffer, object) {
        var id = object.id;
        objlist[id] = objlist[id] || [];
        objlist[id].push({
            id: id,
            buffer: buffer,
            object: object,
            material: null,
            z: 0
        });
    }
    function addBufferImmediate(objlist, object) {
        objlist.push({
            id: null,
            object: object,
            opaque: null,
            transparent: null,
            z: 0
        });
    }
    // Objects updates
    // Objects updates
    function updateObject(object) {
        var geometry = object.geometry,
            customAttributesDirty,
            material;
        if (geometry instanceof THREE$1.BufferGeometry) {
            setDirectBuffers(geometry);
        } else if (object instanceof THREE$1.Mesh) {
            // check all geometry groups
            if (geometry.groupsNeedUpdate === true) {
                initGeometryGroups(object, geometry);
            }
            var geometryGroupsList = geometryGroups[geometry.id];
            for (var i = 0, il = geometryGroupsList.length; i < il; i++) {
                var geometryGroup = geometryGroupsList[i];
                material = getBufferMaterial(object, geometryGroup);
                customAttributesDirty = material.attributes && areCustomAttributesDirty(material);
                if (geometry.verticesNeedUpdate || geometry.morphTargetsNeedUpdate || geometry.elementsNeedUpdate || geometry.uvsNeedUpdate || geometry.normalsNeedUpdate || geometry.colorsNeedUpdate || geometry.tangentsNeedUpdate || customAttributesDirty) {
                    setMeshBuffers(geometryGroup, object, _gl.DYNAMIC_DRAW, !geometry.dynamic, material);
                }
            }
            geometry.verticesNeedUpdate = false;
            geometry.morphTargetsNeedUpdate = false;
            geometry.elementsNeedUpdate = false;
            geometry.uvsNeedUpdate = false;
            geometry.normalsNeedUpdate = false;
            geometry.colorsNeedUpdate = false;
            geometry.tangentsNeedUpdate = false;
            material.attributes && clearCustomAttributes(material);
        } else if (object instanceof THREE$1.Line) {
            material = getBufferMaterial(object, geometry);
            customAttributesDirty = material.attributes && areCustomAttributesDirty(material);
            if (geometry.verticesNeedUpdate || geometry.colorsNeedUpdate || geometry.lineDistancesNeedUpdate || customAttributesDirty) {
                setLineBuffers(geometry, _gl.DYNAMIC_DRAW);
            }
            geometry.verticesNeedUpdate = false;
            geometry.colorsNeedUpdate = false;
            geometry.lineDistancesNeedUpdate = false;
            material.attributes && clearCustomAttributes(material);
        } else if (object instanceof THREE$1.PointCloud) {
            material = getBufferMaterial(object, geometry);
            customAttributesDirty = material.attributes && areCustomAttributesDirty(material);
            if (geometry.verticesNeedUpdate || geometry.colorsNeedUpdate || customAttributesDirty) {
                setPointCloudBuffers(geometry, _gl.DYNAMIC_DRAW);
            }
            geometry.verticesNeedUpdate = false;
            geometry.colorsNeedUpdate = false;
            material.attributes && clearCustomAttributes(material);
        }
    }
    // Objects updates - custom attributes check
    function areCustomAttributesDirty(material) {
        for (var name in material.attributes) {
            if (material.attributes[name].needsUpdate) return true;
        }
        return false;
    }
    function clearCustomAttributes(material) {
        for (var name in material.attributes) {
            material.attributes[name].needsUpdate = false;
        }
    }
    // Objects removal
    function removeObject(object) {
        if (object instanceof THREE$1.Mesh || object instanceof THREE$1.PointCloud || object instanceof THREE$1.Line) {
            delete _webglObjects[object.id];
        } else if (object instanceof THREE$1.ImmediateRenderObject || object.immediateRenderCallback) {
            removeInstances(_webglObjectsImmediate, object);
        }
        delete object.__webglInit;
        delete object.__webglActive;
    }
    function removeInstances(objlist, object) {
        for (var o = objlist.length - 1; o >= 0; o--) {
            if (objlist[o].object === object) {
                objlist.splice(o, 1);
            }
        }
    }
    // Materials
    function getPrismClampFlags(parameters, material) {
        if (!material.textureMaps) return;
        for (var i = 0; i < WebGLProgramUtils.PrismMaps.length; i++) {
            var name = WebGLProgramUtils.PrismMaps[i];
            // note this code keys off the fact that textures end with "_map";
            // any new PRISM map materials should end with this suffix.
            var map = material.textureMaps[name + "_map"];
            if (!map) continue;
            var bools = map.textureObj.properties.booleans;
            parameters[name] = {
                S: !bools.texture_URepeat.values[0],
                T: !bools.texture_VRepeat.values[0]
            };
        }
    }
    var shaderIDs = {
        MeshDepthMaterial: 'depth',
        MeshNormalMaterial: 'normal',
        MeshBasicMaterial: 'firefly_basic',
        MeshLambertMaterial: 'lambert',
        MeshPhongMaterial: 'firefly_phong',
        LineBasicMaterial: 'firefly_basic',
        LineDashedMaterial: 'dashed',
        PointCloudMaterial: 'firefly_basic'
    };
    function initMaterial(material, lights, fog, object) {
        material.addEventListener('dispose', onMaterialDispose);
        var shaderID = shaderIDs[material.type];
        if (shaderID) {
            var shader = THREE$1.ShaderLib[shaderID];
            material.__webglShader = {
                uniforms: THREE$1.UniformsUtils.clone(shader.uniforms),
                vertexShader: shader.vertexShader,
                fragmentShader: shader.fragmentShader
            };
        } else {
            material.__webglShader = {
                uniforms: material.uniforms,
                vertexShader: material.vertexShader,
                fragmentShader: material.fragmentShader
            };
        }
        // heuristics to create shader parameters according to lights in the scene
        // (not to blow over maxLights budget)
        var maxLightCount = allocateLights(lights);
        //var maxBones = 0;//allocateBones( object );
        var parameters = {
            precision: _precisionVertex,
            precisionFragment: _precisionFragment,
            supportsVertexTextures: _supportsVertexTextures,
            haveTextureLod: !!extensions.get("EXT_shader_texture_lod"),
            map: !!material.map,
            envMap: !!material.envMap,
            irradianceMap: !!material.irradianceMap,
            envIsSpherical: material.envMap && material.envMap.mapping == THREE$1.SphericalReflectionMapping,
            envGammaEncoded: material.envMap && material.envMap.GammaEncoded,
            irrGammaEncoded: material.irradianceMap && material.irradianceMap.GammaEncoded,
            envRGBM: material.envMap && material.envMap.RGBM,
            irrRGBM: material.irradianceMap && material.irradianceMap.RGBM,
            lightMap: !!material.lightMap,
            bumpMap: extensions.get("OES_standard_derivatives") && !!material.bumpMap,
            normalMap: extensions.get("OES_standard_derivatives") && !!material.normalMap,
            specularMap: !!material.specularMap,
            alphaMap: !!material.alphaMap,
            vertexColors: material.vertexColors,
            vertexIds: material.vertexIds,
            useInstancing: material.useInstancing,
            wideLines: material.wideLines,
            fog: fog,
            useFog: material.fog,
            fogExp: fog instanceof THREE$1.FogExp2,
            sizeAttenuation: material.sizeAttenuation,
            logarithmicDepthBuffer: _logarithmicDepthBuffer,
            maxDirLights: maxLightCount.directional,
            maxPointLights: maxLightCount.point,
            maxSpotLights: maxLightCount.spot,
            maxHemiLights: maxLightCount.hemi,
            alphaTest: material.alphaTest,
            metal: material.metal,
            clearcoat: material.clearcoat,
            wrapAround: material.wrapAround,
            doubleSided: material.side === THREE$1.DoubleSide,
            flipSided: material.side === THREE$1.BackSide,
            mrtNormals: material.mrtNormals,
            mrtIdBuffer: material.mrtIdBuffer,
            vertexPrefix: _vertexPrefix,
            fragmentPrefix: _fragmentPrefix,
            tonemapOutput: material.tonemapOutput,
            packedNormals: material.packedNormals,
            hatchPattern: !!material.hatchParams,
            // TODO_NOP should not be per mat
            numCutplanes: material.cutplanes ? material.cutplanes.length : 0,
            useTiling: material.useTiling,
            tilingRepeatRange: material.useTiling && material.tilingRepeatRange,
            hasRoundCorner: material.hasRoundCorner,
            useRandomOffset: material.useRandomOffset,
            // texture flags for clamp and invert for simple phong material
            // add as wanted/necessary
            mapInvert: material.map && material.map.invert,
            mapClampS: material.map && material.map.clampS,
            mapClampT: material.map && material.map.clampT,
            bumpMapClampS: material.bumpMap && material.bumpMap.clampS,
            bumpMapClampT: material.bumpMap && material.bumpMap.clampT,
            normalMapClampS: material.normalMap && material.normalMap.clampS,
            normalMapClampT: material.normalMap && material.normalMap.clampT,
            specularMapClampS: material.specularMap && material.specularMap.clampS,
            specularMapClampT: material.specularMap && material.specularMap.clampT,
            alphaMapInvert: material.alphaMap && material.alphaMap.invert,
            alphaMapClampS: material.alphaMap && material.alphaMap.clampS,
            alphaMapClampT: material.alphaMap && material.alphaMap.clampT
        };
        // texture flags for clamp for PRISM shader
        if (material.isPrismMaterial) {
            getPrismClampFlags(parameters, material);
            parameters.isPrism = true;
        }
        var chunks = [];
        if (shaderID) {
            chunks.push(shaderID);
        } else {
            chunks.push(material.fragmentShader);
            chunks.push(material.vertexShader);
        }
        //Append any custom defines to the shader cache key
        for (var d in material.defines) {
            chunks.push(d);
            chunks.push(material.defines[d]);
        }
        var p, pl;
        for (p in parameters) {
            chunks.push(p);
            chunks.push(parameters[p]);
        }
        var code = chunks.join();
        var program;
        // Check if code has been already compiled
        for (p = 0, pl = _programs.length; p < pl; p++) {
            var programInfo = _programs[p];
            if (programInfo.code === code) {
                program = programInfo;
                program.usedTimes++;
                break;
            }
        }
        if (program === undefined) {
            program = new WebGLProgramUtils.WebGLProgram(_this, code, material, parameters);
            _programs.push(program);
            _this.info.memory.programs = _programs.length;
        }
        if (!material.programs) material.programs = [];
        material.programs[_programIndex] = program;
        if (!material.uniformsLists) material.uniformsLists = [];
        material.uniformsList = material.uniformsLists[_programIndex] = [];
        // to see which uniform name is at what location, uncomment
        // let dump = true;
        //if (dump) {
        //    console.log("Uniform locations and names");
        //}
        for (var u in material.__webglShader.uniforms) {
            var location = program.uniforms[u];
            if (location) {
                //if (dump) {
                //    console.log("index: " + (ic++) + " has name: " + u);
                //}
                material.uniformsList.push([material.__webglShader.uniforms[u], location]);
            }
        }
    }
    function setMaterial(material) {
        if (material.transparent === true) {
            state.setBlending(material.blending, material.blendEquation, material.blendSrc, material.blendDst, material.blendEquationAlpha, material.blendSrcAlpha, material.blendDstAlpha);
        } else {
            state.setBlending(THREE$1.NoBlending);
        }
        state.setDepthTest(material.depthTest);
        state.setDepthWrite(material.depthWrite);
        state.setPolygonOffset(material.polygonOffset, material.polygonOffsetFactor, material.polygonOffsetUnits);
    }
    function setProgram(camera, lights, fog, material, object) {
        // clear previous bindings, as these can cause problems with shaders where the texture isn't
        // loaded or isn't used (and is never reset). Problems include the output target and input
        // target being the same, which some drivers (Quadro) flag as an error.
        //var prevUsedTextureUnits = _usedTextureUnits;
        _usedTextureUnits = 0;
        if (material.needsUpdate) {
            if (material.program) deallocateMaterial(material);
            initMaterial(material, lights, fog, object);
            material.needsUpdate = false;
        } else if (!material.programs[_programIndex]) initMaterial(material, lights, fog, object);
        var refreshProgram = false;
        var refreshMaterial = false;
        var refreshLights = false;
        material.uniformsList = material.uniformsLists[_programIndex];
        var program = material.program = material.programs[_programIndex],
            p_uniforms = program.uniforms,
            m_uniforms = material.__webglShader.uniforms;
        if (program.id !== _currentProgram) {
            _gl.useProgram(program.program);
            _currentProgram = program.id;
            refreshProgram = true;
            refreshMaterial = true;
            refreshLights = true;
        }
        if (material.id !== _currentMaterialId) {
            if (_currentMaterialId === -1) refreshLights = true;
            _currentMaterialId = material.id;
            refreshMaterial = true;
        }
        if (refreshProgram || camera !== _currentCamera) {
            _gl.uniformMatrix4fv(p_uniforms.projectionMatrix, false, camera.projectionMatrix.elements);
            if (_logarithmicDepthBuffer) {
                _gl.uniform1f(p_uniforms.logDepthBufFC, 2.0 / (Math.log(camera.far + 1.0) / Math.LN2));
            }
            if (camera !== _currentCamera) _currentCamera = camera;
            // load material specific uniforms
            // (shader material also gets them for the sake of genericity)
            if (material instanceof THREE$1.ShaderMaterial || material instanceof THREE$1.MeshPhongMaterial || material.isPrismMaterial || material.envMap) {
                if (p_uniforms.cameraPosition !== null) {
                    _vector3.setFromMatrixPosition(camera.matrixWorld);
                    _gl.uniform3f(p_uniforms.cameraPosition, _vector3.x, _vector3.y, _vector3.z);
                }
            }
            if (material instanceof THREE$1.MeshPhongMaterial || material instanceof THREE$1.MeshLambertMaterial || material instanceof THREE$1.ShaderMaterial || material.isPrismMaterial || material.skinning) {
                if (p_uniforms.viewMatrix !== null) {
                    _gl.uniformMatrix4fv(p_uniforms.viewMatrix, false, camera.matrixWorldInverse.elements);
                }
                //NOTE: viewMatrixInverse is only used for transforming normal vectors
                //for sampling environment textures. This is why we do not use camera.matrixWorld here,
                //but a combination of camera.matrixWorld plus a rotation to make Y the up vector, so that
                //the top of the scene (whichever axis is up) results in sampling the top of the environment map.
                //If viewMatrixInverse is needed for other things in the shader, then we will need a second
                //uniform that does not include the world-up rotation, or apply a consistent world up rotation
                //to all geometries in the scene.
                if (p_uniforms.viewMatrixInverse !== null) {
                    _gl.uniformMatrix4fv(p_uniforms.viewMatrixInverse, false, _viewInverseEnv.elements);
                }
                if (p_uniforms.mvpMatrix) {
                    _gl.uniformMatrix4fv(p_uniforms.mvpMatrix, false, _projScreenMatrix.elements);
                }
                if (refreshLights) {
                    refreshUniformsIBL(m_uniforms, material);
                    markUniformsIBLNeedsUpdate(m_uniforms, true);
                } else {
                    markUniformsIBLNeedsUpdate(m_uniforms, false);
                }
            }
        }
        if (refreshMaterial) {
            // refresh uniforms common to several materials
            if (fog && material.fog) {
                refreshUniformsFog(m_uniforms, fog);
            }
            if (material instanceof THREE$1.MeshPhongMaterial || material instanceof THREE$1.MeshLambertMaterial || material.isPrismMaterial || material.lights) {
                if (_lightsNeedUpdate) {
                    refreshLights = true;
                    setupLights(lights);
                    _lightsNeedUpdate = false;
                }
                if (refreshLights) {
                    refreshUniformsLights(m_uniforms, _lights);
                    markUniformsLightsNeedsUpdate(m_uniforms, true);
                } else {
                    markUniformsLightsNeedsUpdate(m_uniforms, false);
                }
            }
            if (material instanceof THREE$1.MeshBasicMaterial || material instanceof THREE$1.MeshLambertMaterial || material instanceof THREE$1.MeshPhongMaterial) {
                refreshUniformsCommon(m_uniforms, material);
                refreshUniformsIBL(m_uniforms, material);
            }
            // refresh single material specific uniforms
            if (material instanceof THREE$1.PointCloudMaterial) {
                refreshUniformsPointCloud(m_uniforms, material);
            } else if (material instanceof THREE$1.LineBasicMaterial) {
                refreshUniformsLine(m_uniforms, material);
            } else if (material instanceof THREE$1.LineDashedMaterial) {
                refreshUniformsLine(m_uniforms, material);
                refreshUniformsDash(m_uniforms, material);
            } else if (material instanceof THREE$1.MeshPhongMaterial) {
                refreshUniformsPhong(m_uniforms, material);
            } else if (material instanceof THREE$1.MeshLambertMaterial) {
                refreshUniformsLambert(m_uniforms, material);
            } else if (material instanceof THREE$1.MeshDepthMaterial) {
                m_uniforms.mNear.value = camera.near;
                m_uniforms.mFar.value = camera.far;
                m_uniforms.opacity.value = material.opacity;
            } else if (material instanceof THREE$1.MeshNormalMaterial) {
                m_uniforms.opacity.value = material.opacity;
            } else if (material.isPrismMaterial) {
                refreshUniformsPrism(m_uniforms, material);
                refreshUniformsIBL(m_uniforms, material);
            }
            if (material.wideLines) {
                m_uniforms.view_size.value = new THREE$1.Vector2(window.innerWidth, window.innerHeight);
            }
            if (ShadowMapUtils.ShadowRender && material.shadowMap) {
                ShadowMapUtils.ShadowRender.RefreshUniformsShadow(m_uniforms, material);
            }
            // TODO_NOP: direct assignment dangerous?
            var ucp = m_uniforms.cutplanes;
            if (material.cutplanes && material.cutplanes.length > 0 && ucp) {
                ucp.value = material.cutplanes;
                // Currently, Prism is implemented as shader material, its uniform is just init for once.
                // Remove the array component if cutplanes's length changed so it can be re-init.
                if (ucp._array && ucp._array.length != 4 * material.cutplanes) ucp._array = undefined;
            }
            if (material.hatchParams && m_uniforms.hatchParams) {
                m_uniforms.hatchParams.value.copy(material.hatchParams);
                m_uniforms.hatchTintColor.value.copy(material.hatchTintColor);
                m_uniforms.hatchTintIntensity.value = material.hatchTintIntensity;
            }
            // load common uniforms
            loadUniformsGeneric(material.uniformsList);
            // Clear out any unbound textures, to avoid driver problems.
            // Note: Chrome flags "RENDER WARNING: there is no texture bound to the unit 2"
            // but these are there because BlendPass has tOverlay, which does not always exist
            // and that we don't use if useOverlay is false. Firefox and Internet Explorer do
            // not flag warnings, only Chrome gives this warning.
            // The following code should not be needed, as now when textures are bound, they will be bound
            // to null if the texture is not available. However, it is here as a thing to try
            // if you see strange texture behavior.
            // for ( var i = _usedTextureUnits; i < prevUsedTextureUnits; i++ ) {
            //     _gl.activeTexture(_gl.TEXTURE0 + i);
            //     _gl.bindTexture(_gl.TEXTURE_2D, null);
            // }
        }
        loadUniformsMatrices(p_uniforms, object, camera);
        if (p_uniforms.modelMatrix !== null) {
            _gl.uniformMatrix4fv(p_uniforms.modelMatrix, false, object.matrixWorld.elements);
        }
        var dbId;
        if (p_uniforms.modelId) {
            if (p_uniforms.dbId) {
                dbId = object.dbId || object.fragId || 0;
                _gl.uniform3f(p_uniforms.dbId, (dbId & 0xff) / 255, (dbId >> 8 & 0xff) / 255, (dbId >> 16 & 0xff) / 255);
            }
            var modelId = object.modelId;
            _gl.uniform3f(p_uniforms.modelId, (modelId & 0xff) / 255, (modelId >> 8 & 0xff) / 255,
            //we can encode the highest bits of the ID here, since the model ID will not really need more than 2 bytes
            (dbId >> 24 & 0xff) / 255);
        } else if (p_uniforms.dbId !== null) {
            dbId = !_useFragBuffer && object.dbId || object.fragId || 0;
            //The dbId is rendered to an RGB target, so the
            //uppermost byte of the dbId is dropped. Use a modelId
            //target if the full range is desired
            _gl.uniform3f(p_uniforms.dbId, (dbId & 0xff) / 255, (dbId >> 8 & 0xff) / 255, (dbId >> 16 & 0xff) / 255 /*,
                                                                                                                    ((dbId >> 24) & 0xff) / 255*/);
        }
        // If a theming color uniform is defined, get it from the mesh.
        // Note that theming colors are Vector4 (not THREE.Color), because we need alpha for intensity.
        if (p_uniforms.themingColor) {
            var color = object.themingColor;
            if (color instanceof THREE$1.Vector4) {
                _gl.uniform4f(p_uniforms.themingColor, color.x, color.y, color.z, color.w);
            } else {
                _gl.uniform4f(p_uniforms.themingColor, 0.0, 0.0, 0.0, 0.0);
            }
        }
        return program;
    }
    // Uniforms (refresh uniforms objects)
    function refreshUniformsCommon(uniforms, material) {
        uniforms.opacity.value = material.opacity;
        uniforms.diffuse.value.copy(material.color);
        uniforms.map.value = material.map;
        uniforms.lightMap.value = material.lightMap;
        uniforms.specularMap.value = material.specularMap;
        uniforms.alphaMap.value = material.alphaMap;
        if (material.bumpMap) {
            uniforms.bumpMap.value = material.bumpMap;
            uniforms.bumpScale.value = material.bumpScale;
        }
        if (material.normalMap) {
            uniforms.normalMap.value = material.normalMap;
            uniforms.normalScale.value.copy(material.normalScale);
        }
        // uv repeat and offset setting priorities
        //  1. color map
        //  2. specular map
        //  3. normal map
        //  4. bump map
        //  5. alpha map
        //NOTE: We deviate from Three.js in that we allow
        //separate scales for diffuse/specular, alpha, and bump
        function setTexTransforms(uniforms, texMatrix, texture) {
            var offset = texture.offset;
            var repeat = texture.repeat;
            if (texMatrix) {
                var uMatrix = texMatrix.value;
                if (texture.matrix) uMatrix.copy(texture.matrix);else uMatrix.identity();
                uMatrix.elements[6] += offset.x;
                uMatrix.elements[7] += offset.y;
                uMatrix.elements[0] *= repeat.x;
                uMatrix.elements[3] *= repeat.x;
                uMatrix.elements[1] *= repeat.y;
                uMatrix.elements[4] *= repeat.y;
            } else {
                uniforms.offsetRepeat.value.set(offset.x, offset.y, repeat.x, repeat.y);
            }
        }
        if (material.alphaMap) {
            setTexTransforms(uniforms, uniforms.texMatrixAlpha, material.alphaMap);
        }
        var uvScaleMapBump;
        if (material.normalMap) {
            uvScaleMapBump = material.normalMap;
        } else if (material.bumpMap) {
            uvScaleMapBump = material.bumpMap;
        }
        if (uvScaleMapBump !== undefined) {
            setTexTransforms(uniforms, uniforms.texMatrixBump, uvScaleMapBump);
        }
        var uvScaleMap;
        if (material.map) {
            uvScaleMap = material.map;
        } else if (material.specularMap) {
            uvScaleMap = material.specularMap;
        }
        if (uvScaleMap !== undefined) {
            setTexTransforms(uniforms, uniforms.texMatrix, uvScaleMap);
        }
        uniforms.envMap.value = material.envMap;
        //uniforms.flipEnvMap.value = ( material.envMap instanceof THREE.WebGLRenderTargetCube ) ? 1 : -1;
        if (uniforms.irradianceMap) {
            uniforms.irradianceMap.value = material.irradianceMap;
        }
        uniforms.reflectivity.value = material.reflectivity;
        uniforms.refractionRatio.value = material.refractionRatio;
    }
    function refreshUniformsPointCloud(uniforms, material) {
        refreshUniformsLine(uniforms, material);
        uniforms.point_size.value = material.size;
    }
    function refreshUniformsLine(uniforms, material) {
        uniforms.diffuse.value = material.color;
        uniforms.opacity.value = material.opacity;
    }
    function refreshUniformsDash(uniforms, material) {
        uniforms.dashSize.value = material.dashSize;
        uniforms.totalSize.value = material.dashSize + material.gapSize;
        uniforms.scale.value = material.scale;
    }
    function refreshUniformsFog(uniforms, fog) {
        uniforms.fogColor.value = fog.color;
        if (fog instanceof THREE$1.Fog) {
            uniforms.fogNear.value = fog.near;
            uniforms.fogFar.value = fog.far;
        } else if (fog instanceof THREE$1.FogExp2) {
            uniforms.fogDensity.value = fog.density;
        }
    }
    function refreshUniformsIBL(uniforms, material) {
        if (uniforms.envMap) uniforms.envMap.value = material.envMap;
        //uniforms.flipEnvMap.value = ( material.envMap instanceof THREE.WebGLRenderTargetCube ) ? 1 : -1;
        if (uniforms.irradianceMap) uniforms.irradianceMap.value = material.irradianceMap;
        if (uniforms.envMapExposure) uniforms.envMapExposure.value = material.envMapExposure;
        if (uniforms.envRotationSin && uniforms.envRotationCos) {
            uniforms.envRotationSin.value = material.envRotationSin;
            uniforms.envRotationCos.value = material.envRotationCos;
        }
    }
    function markUniformsIBLNeedsUpdate(uniforms, boolean) {
        if (uniforms.envMap) uniforms.envMap.needsUpdate = boolean;
        //uniforms.flipEnvMap.value = ( material.envMap instanceof THREE.WebGLRenderTargetCube ) ? 1 : -1;
        if (uniforms.irradianceMap) uniforms.irradianceMap.needsUpdate = boolean;
        if (uniforms.envMapExposure) uniforms.envMapExposure.needsUpdate = boolean;
    }
    function refreshUniformsPhong(uniforms, material) {
        uniforms.shininess.value = material.shininess;
        //The environment cube map is blurred with the assumption that
        //max shininess is 2048 and every mip drops that by a factor of 4
        //"float MipmapIndex = log(shininess / 2048.0) / log(0.25);",
        //The simplification below was given in the original source for this method.
        //However, it does not seem to match the equation above, so we use a corrected one.
        //"float MipmapIndex = max(0.0, -1.66096404744368 * logShiny + 5.5);",
        //NOTE: Once roughness maps are supported, the computation will have to move to the shader.
        if (uniforms.reflMipIndex) {
            var logShiny = Math.log(Math.max(1.0 + 1e-10, material.shininess));
            uniforms.reflMipIndex.value = Math.max(0.0, -0.72134752 * logShiny + 5.5);
        }
        if (uniforms.emissive) uniforms.emissive.value.copy(material.emissive);
        uniforms.specular.value.copy(material.specular);
        //Not used by LMV
        /*
        if ( material.wrapAround ) {
             uniforms.wrapRGB.value.copy( material.wrapRGB );
         }
        */
        if (uniforms.exposureBias) uniforms.exposureBias.value = material.exposureBias;
    }
    function refreshUniformsPrism(uniforms, material) {
        function refreshPrismMapUniforms(uniforms, material, mapName) {
            uniforms[mapName].value = material[mapName];
            // yes, we want "!=" here, not "!==", as we test for both undefined and null
            if (material[mapName] != null) {
                uniforms[mapName + "_texMatrix"].value = material[mapName].matrix;
                uniforms[mapName + "_invert"].value = material[mapName].invert;
            }
        }
        function refreshPrismBumpMapUniforms(uniforms, material, mapName) {
            uniforms[mapName].value = material[mapName];
            // yes, we want "!=" here, not "!==", as we test for both undefined and null
            if (material[mapName] != null) {
                uniforms[mapName + "_texMatrix"].value = material[mapName].matrix;
                uniforms[mapName + "_bumpScale"].value = material[mapName].bumpScale;
                uniforms[mapName + "_bumpmapType"].value = material[mapName].bumpmapType;
            }
        }
        uniforms.exposureBias.value = material.exposureBias;
        uniforms.opacity.value = material.opacity;
        //Prism common properties.
        uniforms.surface_albedo.value = material.surface_albedo;
        uniforms.surface_roughness.value = material.surface_roughness;
        uniforms.surface_anisotropy.value = material.surface_anisotropy;
        uniforms.surface_rotation.value = material.surface_rotation;
        refreshPrismMapUniforms(uniforms, material, "surface_albedo_map");
        refreshPrismMapUniforms(uniforms, material, "surface_roughness_map");
        refreshPrismMapUniforms(uniforms, material, "surface_cutout_map");
        refreshPrismMapUniforms(uniforms, material, "surface_anisotropy_map");
        refreshPrismMapUniforms(uniforms, material, "surface_rotation_map");
        refreshPrismBumpMapUniforms(uniforms, material, "surface_normal_map");
        //Update Prism properties according to the material type.
        switch (material.prismType) {
            case 'PrismOpaque':
                uniforms.opaque_albedo.value = material.opaque_albedo;
                uniforms.opaque_luminance_modifier.value = material.opaque_luminance_modifier;
                uniforms.opaque_f0.value = material.opaque_f0;
                uniforms.opaque_luminance.value = material.opaque_luminance;
                refreshPrismMapUniforms(uniforms, material, "opaque_albedo_map");
                refreshPrismMapUniforms(uniforms, material, "opaque_luminance_modifier_map");
                refreshPrismMapUniforms(uniforms, material, "opaque_f0_map");
                break;
            case 'PrismMetal':
                uniforms.metal_f0.value = material.metal_f0;
                refreshPrismMapUniforms(uniforms, material, "metal_f0_map");
                break;
            case 'PrismLayered':
                uniforms.layered_f0.value = material.layered_f0;
                uniforms.layered_diffuse.value = material.layered_diffuse;
                uniforms.layered_fraction.value = material.layered_fraction;
                uniforms.layered_bottom_f0.value = material.layered_bottom_f0;
                uniforms.layered_roughness.value = material.layered_roughness;
                uniforms.layered_anisotropy.value = material.layered_anisotropy;
                uniforms.layered_rotation.value = material.layered_rotation;
                refreshPrismMapUniforms(uniforms, material, "layered_bottom_f0_map");
                refreshPrismMapUniforms(uniforms, material, "layered_f0_map");
                refreshPrismMapUniforms(uniforms, material, "layered_diffuse_map");
                refreshPrismMapUniforms(uniforms, material, "layered_fraction_map");
                refreshPrismMapUniforms(uniforms, material, "layered_roughness_map");
                refreshPrismMapUniforms(uniforms, material, "layered_anisotropy_map");
                refreshPrismMapUniforms(uniforms, material, "layered_rotation_map");
                refreshPrismBumpMapUniforms(uniforms, material, "layered_normal_map");
                break;
            case 'PrismTransparent':
                uniforms.transparent_color.value = material.transparent_color;
                uniforms.transparent_distance.value = material.transparent_distance;
                uniforms.transparent_ior.value = material.transparent_ior;
                break;
            case 'PrismGlazing':
                uniforms.glazing_f0.value = material.glazing_f0;
                uniforms.glazing_transmission_color.value = material.glazing_transmission_color;
                uniforms.glazing_transmission_roughness.value = material.glazing_transmission_roughness;
                refreshPrismMapUniforms(uniforms, material, "glazing_f0_map");
                refreshPrismMapUniforms(uniforms, material, "glazing_transmission_color_map");
                refreshPrismMapUniforms(uniforms, material, "glazing_transmission_roughness_map");
                break;
            case 'PrismWood':
                uniforms.wood_fiber_cosine_enable.value = material.wood_fiber_cosine_enable;
                uniforms.wood_fiber_cosine_bands.value = material.wood_fiber_cosine_bands;
                uniforms.wood_fiber_cosine_weights.value = material.wood_fiber_cosine_weights;
                uniforms.wood_fiber_cosine_frequencies.value = material.wood_fiber_cosine_frequencies;
                uniforms.wood_fiber_perlin_enable.value = material.wood_fiber_perlin_enable;
                uniforms.wood_fiber_perlin_bands.value = material.wood_fiber_perlin_bands;
                uniforms.wood_fiber_perlin_weights.value = material.wood_fiber_perlin_weights;
                uniforms.wood_fiber_perlin_frequencies.value = material.wood_fiber_perlin_frequencies;
                uniforms.wood_fiber_perlin_scale_z.value = material.wood_fiber_perlin_scale_z;
                uniforms.wood_growth_perlin_enable.value = material.wood_growth_perlin_enable;
                uniforms.wood_growth_perlin_bands.value = material.wood_growth_perlin_bands;
                uniforms.wood_growth_perlin_weights.value = material.wood_growth_perlin_weights;
                uniforms.wood_growth_perlin_frequencies.value = material.wood_growth_perlin_frequencies;
                uniforms.wood_latewood_ratio.value = material.wood_latewood_ratio;
                uniforms.wood_earlywood_sharpness.value = material.wood_earlywood_sharpness;
                uniforms.wood_latewood_sharpness.value = material.wood_latewood_sharpness;
                uniforms.wood_ring_thickness.value = material.wood_ring_thickness;
                uniforms.wood_earlycolor_perlin_enable.value = material.wood_earlycolor_perlin_enable;
                uniforms.wood_earlycolor_perlin_bands.value = material.wood_earlycolor_perlin_bands;
                uniforms.wood_earlycolor_perlin_weights.value = material.wood_earlycolor_perlin_weights;
                uniforms.wood_earlycolor_perlin_frequencies.value = material.wood_earlycolor_perlin_frequencies;
                uniforms.wood_early_color.value = material.wood_early_color;
                uniforms.wood_use_manual_late_color.value = material.wood_use_manual_late_color;
                uniforms.wood_manual_late_color.value = material.wood_manual_late_color;
                uniforms.wood_latecolor_perlin_enable.value = material.wood_latecolor_perlin_enable;
                uniforms.wood_latecolor_perlin_bands.value = material.wood_latecolor_perlin_bands;
                uniforms.wood_latecolor_perlin_weights.value = material.wood_latecolor_perlin_weights;
                uniforms.wood_latecolor_perlin_frequencies.value = material.wood_latecolor_perlin_frequencies;
                uniforms.wood_late_color_power.value = material.wood_late_color_power;
                uniforms.wood_diffuse_perlin_enable.value = material.wood_diffuse_perlin_enable;
                uniforms.wood_diffuse_perlin_bands.value = material.wood_diffuse_perlin_bands;
                uniforms.wood_diffuse_perlin_weights.value = material.wood_diffuse_perlin_weights;
                uniforms.wood_diffuse_perlin_frequencies.value = material.wood_diffuse_perlin_frequencies;
                uniforms.wood_diffuse_perlin_scale_z.value = material.wood_diffuse_perlin_scale_z;
                uniforms.wood_use_pores.value = material.wood_use_pores;
                uniforms.wood_pore_type.value = material.wood_pore_type;
                uniforms.wood_pore_radius.value = material.wood_pore_radius;
                uniforms.wood_pore_cell_dim.value = material.wood_pore_cell_dim;
                uniforms.wood_pore_color_power.value = material.wood_pore_color_power;
                uniforms.wood_pore_depth.value = material.wood_pore_depth;
                uniforms.wood_use_rays.value = material.wood_use_rays;
                uniforms.wood_ray_color_power.value = material.wood_ray_color_power;
                uniforms.wood_ray_seg_length_z.value = material.wood_ray_seg_length_z;
                uniforms.wood_ray_num_slices.value = material.wood_ray_num_slices;
                uniforms.wood_ray_ellipse_z2x.value = material.wood_ray_ellipse_z2x;
                uniforms.wood_ray_ellipse_radius_x.value = material.wood_ray_ellipse_radius_x;
                uniforms.wood_use_latewood_bump.value = material.wood_use_latewood_bump;
                uniforms.wood_latewood_bump_depth.value = material.wood_latewood_bump_depth;
                uniforms.wood_use_groove_roughness.value = material.wood_use_groove_roughness;
                uniforms.wood_groove_roughness.value = material.wood_groove_roughness;
                uniforms.wood_diffuse_lobe_weight.value = material.wood_diffuse_lobe_weight;
                refreshPrismMapUniforms(uniforms, material, "wood_curly_distortion_map");
                if (uniforms["wood_curly_distortion_map"].value != null) {
                    // This map constains tree space position offsets
                    uniforms["wood_curly_distortion_map"].value.minFilter = THREE$1.NearestFilter;
                    uniforms["wood_curly_distortion_map"].value.magFilter = THREE$1.NearestFilter;
                    uniforms.wood_curly_distortion_enable.value = material.wood_curly_distortion_enable;
                    uniforms.wood_curly_distortion_scale.value = material.wood_curly_distortion_scale;
                }
                var earlyWood = 1.0 - material.wood_latewood_ratio;
                var earlyWoodSharpness = material.wood_earlywood_sharpness * earlyWood;
                var lateWoodSharpness = material.wood_latewood_sharpness * material.wood_latewood_ratio;
                var riseStart = earlyWood + lateWoodSharpness;
                uniforms.wood_ring_fraction.value = new THREE$1.Vector4(earlyWood, earlyWoodSharpness, lateWoodSharpness, riseStart);
                uniforms.wood_fall_rise.value = new THREE$1.Vector2(earlyWood - earlyWoodSharpness, material.wood_latewood_ratio - lateWoodSharpness);
                break;
            default:
                THREE$1.warn('Unknown prism type: ' + material.prismType);
        }
        if (material.useTiling) {
            uniforms.tilingOverallTransform.value = material.tilingOverallTransform;
            uniforms.TilingMap.value = material.TilingMap;
            uniforms.TilingMap_texMatrix.value = material.TilingMap_texMatrix;
            if (material.hasRoundCorner) {
                uniforms.TilingNormalMap.value = material.TilingNormalMap;
                uniforms.TilingNormalMap_texMatrix.value = material.TilingNormalMap_texMatrix;
            }
            if (material.useRandomOffset) {
                uniforms.TilingRandomMap.value = material.TilingRandomMap;
                uniforms.TilingRandomMap_texMatrix.value = material.TilingRandomMap_texMatrix;
                uniforms.tilingRandomAxisS.value = material.tilingRandomAxisS;
                uniforms.tilingRandomAxisT.value = material.tilingRandomAxisT;
                uniforms.tilingRandomAlignmentOffset.value = material.tilingRandomAlignmentOffset;
            }
            // note there is no "invert" property that gets set on the tiling MSDF texture, as it makes little sense
            uniforms.uv2tile.value = material.uv2tile;
            uniforms.tile2uv.value = material.tile2uv;
            // not needed here, as these are built in to the shader loops, due to WebGL needing fixed values for loops.
            //uniforms.tilingRepeatRange.value = material.tilingRepeatRange;
            uniforms.tileAlignOffset.value = material.tileAlignOffset;
            uniforms.tilingUVTransform.value = material.tilingUVTransform;
        }
        uniforms.envExponentMin.value = material.envExponentMin;
        uniforms.envExponentMax.value = material.envExponentMax;
        uniforms.envExponentCount.value = material.envExponentCount;
    }
    function refreshUniformsLambert(uniforms, material) {
        uniforms.emissive.value.copy(material.emissive);
        if (material.wrapAround) {
            uniforms.wrapRGB.value.copy(material.wrapRGB);
        }
    }
    function refreshUniformsLights(uniforms, lights) {
        uniforms.ambientLightColor.value = lights.ambient;
        uniforms.directionalLightColor.value = lights.directional.colors;
        uniforms.directionalLightDirection.value = lights.directional.positions;
        uniforms.pointLightColor.value = lights.point.colors;
        uniforms.pointLightPosition.value = lights.point.positions;
        uniforms.pointLightDistance.value = lights.point.distances;
        uniforms.spotLightColor.value = lights.spot.colors;
        uniforms.spotLightPosition.value = lights.spot.positions;
        uniforms.spotLightDistance.value = lights.spot.distances;
        uniforms.spotLightDirection.value = lights.spot.directions;
        uniforms.spotLightAngleCos.value = lights.spot.anglesCos;
        uniforms.spotLightExponent.value = lights.spot.exponents;
        uniforms.hemisphereLightSkyColor.value = lights.hemi.skyColors;
        uniforms.hemisphereLightGroundColor.value = lights.hemi.groundColors;
        uniforms.hemisphereLightDirection.value = lights.hemi.positions;
    }
    // If uniforms are marked as clean, they don't need to be loaded to the GPU.
    function markUniformsLightsNeedsUpdate(uniforms, boolean) {
        uniforms.ambientLightColor.needsUpdate = boolean;
        uniforms.directionalLightColor.needsUpdate = boolean;
        uniforms.directionalLightDirection.needsUpdate = boolean;
        uniforms.pointLightColor.needsUpdate = boolean;
        uniforms.pointLightPosition.needsUpdate = boolean;
        uniforms.pointLightDistance.needsUpdate = boolean;
        uniforms.spotLightColor.needsUpdate = boolean;
        uniforms.spotLightPosition.needsUpdate = boolean;
        uniforms.spotLightDistance.needsUpdate = boolean;
        uniforms.spotLightDirection.needsUpdate = boolean;
        uniforms.spotLightAngleCos.needsUpdate = boolean;
        uniforms.spotLightExponent.needsUpdate = boolean;
        uniforms.hemisphereLightSkyColor.needsUpdate = boolean;
        uniforms.hemisphereLightGroundColor.needsUpdate = boolean;
        uniforms.hemisphereLightDirection.needsUpdate = boolean;
    }
    // Uniforms (load to GPU)
    function loadUniformsMatrices(uniforms, object, camera) {
        _objectModelViewMatrix.multiplyMatrices(camera.matrixWorldInverse, object.matrixWorld);
        _gl.uniformMatrix4fv(uniforms.modelViewMatrix, false, _objectModelViewMatrix.elements);
        if (uniforms.normalMatrix) {
            _objectNormalMatrix.getNormalMatrix(_objectModelViewMatrix);
            _gl.uniformMatrix3fv(uniforms.normalMatrix, false, _objectNormalMatrix.elements);
        }
    }
    function getTextureUnit() {
        var textureUnit = _usedTextureUnits;
        if (textureUnit >= _maxTextures) {
            THREE$1.warn("WebGLRenderer: trying to use " + textureUnit + " texture units while this GPU supports only " + _maxTextures);
        }
        _usedTextureUnits += 1;
        return textureUnit;
    }
    function loadUniformsGeneric(uniforms) {
        var texture, textureUnit, offset;
        for (var j = 0, jl = uniforms.length; j < jl; j++) {
            var uniform = uniforms[j][0];
            // needsUpdate property is not added to all uniforms.
            if (uniform.needsUpdate === false) continue;
            var type = uniform.type;
            var value = uniform.value;
            var location = uniforms[j][1];
            var i, il;
            switch (type) {
                case '1i':
                    _gl.uniform1i(location, value);
                    break;
                case '1f':
                    _gl.uniform1f(location, value);
                    break;
                case '2f':
                    _gl.uniform2f(location, value[0], value[1]);
                    break;
                case '3f':
                    _gl.uniform3f(location, value[0], value[1], value[2]);
                    break;
                case '4f':
                    _gl.uniform4f(location, value[0], value[1], value[2], value[3]);
                    break;
                case '1iv':
                    _gl.uniform1iv(location, value);
                    break;
                case '3iv':
                    _gl.uniform3iv(location, value);
                    break;
                case '1fv':
                    _gl.uniform1fv(location, value);
                    break;
                case '2fv':
                    _gl.uniform2fv(location, value);
                    break;
                case '3fv':
                    _gl.uniform3fv(location, value);
                    break;
                case '4fv':
                    _gl.uniform4fv(location, value);
                    break;
                case 'Matrix3fv':
                    _gl.uniformMatrix3fv(location, false, value);
                    break;
                case 'Matrix4fv':
                    _gl.uniformMatrix4fv(location, false, value);
                    break;
                //
                case 'i':
                    // single integer
                    _gl.uniform1i(location, value);
                    break;
                case 'f':
                    // single float
                    _gl.uniform1f(location, value);
                    break;
                case 'v2':
                    // single THREE.Vector2
                    _gl.uniform2f(location, value.x, value.y);
                    break;
                case 'v3':
                    // single THREE.Vector3
                    _gl.uniform3f(location, value.x, value.y, value.z);
                    break;
                case 'v4':
                    // single THREE.Vector4
                    _gl.uniform4f(location, value.x, value.y, value.z, value.w);
                    break;
                case 'c':
                    // single THREE.Color
                    _gl.uniform3f(location, value.r, value.g, value.b);
                    break;
                case 'iv1':
                    // flat array of integers (JS or typed array)
                    _gl.uniform1iv(location, value);
                    break;
                case 'iv':
                    // flat array of integers with 3 x N size (JS or typed array)
                    _gl.uniform3iv(location, value);
                    break;
                case 'fv1':
                    // flat array of floats (JS or typed array)
                    _gl.uniform1fv(location, value);
                    break;
                case 'fv':
                    // flat array of floats with 3 x N size (JS or typed array)
                    _gl.uniform3fv(location, value);
                    break;
                case 'v2v':
                    // array of THREE.Vector2
                    if (uniform._array === undefined) {
                        uniform._array = new Float32Array(2 * value.length);
                    }
                    for (i = 0, il = value.length; i < il; i++) {
                        offset = i * 2;
                        uniform._array[offset] = value[i].x;
                        uniform._array[offset + 1] = value[i].y;
                    }
                    _gl.uniform2fv(location, uniform._array);
                    break;
                case 'v3v':
                    // array of THREE.Vector3
                    if (uniform._array === undefined) {
                        uniform._array = new Float32Array(3 * value.length);
                    }
                    for (i = 0, il = value.length; i < il; i++) {
                        offset = i * 3;
                        uniform._array[offset] = value[i].x;
                        uniform._array[offset + 1] = value[i].y;
                        uniform._array[offset + 2] = value[i].z;
                    }
                    _gl.uniform3fv(location, uniform._array);
                    break;
                case 'v4v':
                    // array of THREE.Vector4
                    if (uniform._array === undefined) {
                        uniform._array = new Float32Array(4 * value.length);
                    }
                    for (i = 0, il = value.length; i < il; i++) {
                        offset = i * 4;
                        uniform._array[offset] = value[i].x;
                        uniform._array[offset + 1] = value[i].y;
                        uniform._array[offset + 2] = value[i].z;
                        uniform._array[offset + 3] = value[i].w;
                    }
                    _gl.uniform4fv(location, uniform._array);
                    break;
                case 'm3':
                    // single THREE.Matrix3
                    _gl.uniformMatrix3fv(location, false, value.elements);
                    break;
                case 'm3v':
                    // array of THREE.Matrix3
                    if (uniform._array === undefined) {
                        uniform._array = new Float32Array(9 * value.length);
                    }
                    for (i = 0, il = value.length; i < il; i++) {
                        value[i].flattenToArrayOffset(uniform._array, i * 9);
                    }
                    _gl.uniformMatrix3fv(location, false, uniform._array);
                    break;
                case 'm4':
                    // single THREE.Matrix4
                    _gl.uniformMatrix4fv(location, false, value.elements);
                    break;
                case 'm4v':
                    // array of THREE.Matrix4
                    if (uniform._array === undefined) {
                        uniform._array = new Float32Array(16 * value.length);
                    }
                    for (i = 0, il = value.length; i < il; i++) {
                        value[i].flattenToArrayOffset(uniform._array, i * 16);
                    }
                    _gl.uniformMatrix4fv(location, false, uniform._array);
                    break;
                case 't':
                    // single THREE.Texture (2d or cube)
                    texture = value;
                    textureUnit = getTextureUnit();
                    _gl.uniform1i(location, textureUnit);
                    if (!texture) {
                        // Unbind whatever leftover texture might be in this slot.
                        // The texture itself is not yet (or perhaps ever) assigned, so we want to avoid getting
                        // some random leftover bound texture from another material. See https://jira.autodesk.com/browse/LMV-2993
                        _gl.activeTexture(_gl.TEXTURE0 + textureUnit);
                        _gl.bindTexture(_gl.TEXTURE_2D, _nullTexture.__webglTexture);
                        continue;
                    }
                    if (Array.isArray(texture.image) && texture.image.length === 6 || texture instanceof THREE$1.CubeTexture) {
                        if (!texture.needsUpdate) {
                            _gl.activeTexture(_gl.TEXTURE0 + textureUnit);
                            _gl.bindTexture(_gl.TEXTURE_CUBE_MAP, texture.__webglTextureCube);
                        } else {
                            setCubeTexture(texture, textureUnit);
                        }
                    } else if (texture instanceof THREE$1.WebGLRenderTargetCube) {
                        setCubeTextureDynamic(texture, textureUnit);
                    } else {
                        _this.setTexture(texture, textureUnit);
                    }
                    break;
                case 'tv':
                    // array of THREE.Texture (2d)
                    if (uniform._array === undefined) {
                        uniform._array = [];
                    }
                    for (i = 0, il = uniform.value.length; i < il; i++) {
                        uniform._array[i] = getTextureUnit();
                    }
                    _gl.uniform1iv(location, uniform._array);
                    for (i = 0, il = uniform.value.length; i < il; i++) {
                        texture = uniform.value[i];
                        textureUnit = uniform._array[i];
                        if (!texture) continue;
                        _this.setTexture(texture, textureUnit);
                    }
                    break;
                default:
                    THREE$1.warn('THREE.WebGLRenderer: Unknown uniform type: ' + type);
            }
        }
    }
    //
    /* not used
    function setColorGamma( array, offset, color, intensitySq ) {
         array[ offset ]  = color.r * color.r * intensitySq;
        array[ offset + 1 ] = color.g * color.g * intensitySq;
        array[ offset + 2 ] = color.b * color.b * intensitySq;
     }
    */
    function setColorLinear(array, offset, color, intensity) {
        array[offset] = color.r * intensity;
        array[offset + 1] = color.g * intensity;
        array[offset + 2] = color.b * intensity;
    }
    function setupLights(lights) {
        var l,
            ll,
            light,
            r = 0,
            g = 0,
            b = 0,
            color,
            skyColor,
            groundColor,
            intensity,
            distance,
            zlights = _lights,
            dirColors = zlights.directional.colors,
            dirPositions = zlights.directional.positions,
            pointColors = zlights.point.colors,
            pointPositions = zlights.point.positions,
            pointDistances = zlights.point.distances,
            spotColors = zlights.spot.colors,
            spotPositions = zlights.spot.positions,
            spotDistances = zlights.spot.distances,
            spotDirections = zlights.spot.directions,
            spotAnglesCos = zlights.spot.anglesCos,
            spotExponents = zlights.spot.exponents,
            hemiSkyColors = zlights.hemi.skyColors,
            hemiGroundColors = zlights.hemi.groundColors,
            hemiPositions = zlights.hemi.positions,
            dirLength = 0,
            pointLength = 0,
            spotLength = 0,
            hemiLength = 0,
            dirCount = 0,
            pointCount = 0,
            spotCount = 0,
            hemiCount = 0,
            dirOffset = 0,
            pointOffset = 0,
            spotOffset = 0,
            hemiOffset = 0;
        for (l = 0, ll = lights.length; l < ll; l++) {
            light = lights[l];
            if (light.onlyShadow) continue;
            color = light.color;
            intensity = light.intensity;
            distance = light.distance;
            if (light instanceof THREE$1.AmbientLight) {
                if (!light.visible) continue;
                r += color.r;
                g += color.g;
                b += color.b;
            } else if (light instanceof THREE$1.DirectionalLight) {
                dirCount += 1;
                if (!light.visible) continue;
                _direction.setFromMatrixPosition(light.matrixWorld);
                _vector3.setFromMatrixPosition(light.target.matrixWorld);
                _direction.sub(_vector3);
                _direction.normalize();
                dirOffset = dirLength * 3;
                dirPositions[dirOffset] = _direction.x;
                dirPositions[dirOffset + 1] = _direction.y;
                dirPositions[dirOffset + 2] = _direction.z;
                setColorLinear(dirColors, dirOffset, color, intensity);
                dirLength += 1;
            } else if (light instanceof THREE$1.PointLight) {
                pointCount += 1;
                if (!light.visible) continue;
                pointOffset = pointLength * 3;
                setColorLinear(pointColors, pointOffset, color, intensity);
                _vector3.setFromMatrixPosition(light.matrixWorld);
                pointPositions[pointOffset] = _vector3.x;
                pointPositions[pointOffset + 1] = _vector3.y;
                pointPositions[pointOffset + 2] = _vector3.z;
                pointDistances[pointLength] = distance;
                pointLength += 1;
            } else if (light instanceof THREE$1.SpotLight) {
                spotCount += 1;
                if (!light.visible) continue;
                spotOffset = spotLength * 3;
                setColorLinear(spotColors, spotOffset, color, intensity);
                _vector3.setFromMatrixPosition(light.matrixWorld);
                spotPositions[spotOffset] = _vector3.x;
                spotPositions[spotOffset + 1] = _vector3.y;
                spotPositions[spotOffset + 2] = _vector3.z;
                spotDistances[spotLength] = distance;
                _direction.copy(_vector3);
                _vector3.setFromMatrixPosition(light.target.matrixWorld);
                _direction.sub(_vector3);
                _direction.normalize();
                spotDirections[spotOffset] = _direction.x;
                spotDirections[spotOffset + 1] = _direction.y;
                spotDirections[spotOffset + 2] = _direction.z;
                spotAnglesCos[spotLength] = Math.cos(light.angle);
                spotExponents[spotLength] = light.exponent;
                spotLength += 1;
            } else if (light instanceof THREE$1.HemisphereLight) {
                hemiCount += 1;
                if (!light.visible) continue;
                _direction.setFromMatrixPosition(light.matrixWorld);
                _direction.normalize();
                hemiOffset = hemiLength * 3;
                hemiPositions[hemiOffset] = _direction.x;
                hemiPositions[hemiOffset + 1] = _direction.y;
                hemiPositions[hemiOffset + 2] = _direction.z;
                skyColor = light.color;
                groundColor = light.groundColor;
                setColorLinear(hemiSkyColors, hemiOffset, skyColor, intensity);
                setColorLinear(hemiGroundColors, hemiOffset, groundColor, intensity);
                hemiLength += 1;
            }
        }
        // null eventual remains from removed lights
        // (this is to avoid if in shader)
        for (l = dirLength * 3, ll = Math.max(dirColors.length, dirCount * 3); l < ll; l++) {
            dirColors[l] = 0.0;
        }for (l = pointLength * 3, ll = Math.max(pointColors.length, pointCount * 3); l < ll; l++) {
            pointColors[l] = 0.0;
        }for (l = spotLength * 3, ll = Math.max(spotColors.length, spotCount * 3); l < ll; l++) {
            spotColors[l] = 0.0;
        }for (l = hemiLength * 3, ll = Math.max(hemiSkyColors.length, hemiCount * 3); l < ll; l++) {
            hemiSkyColors[l] = 0.0;
        }for (l = hemiLength * 3, ll = Math.max(hemiGroundColors.length, hemiCount * 3); l < ll; l++) {
            hemiGroundColors[l] = 0.0;
        }zlights.directional.length = dirLength;
        zlights.point.length = pointLength;
        zlights.spot.length = spotLength;
        zlights.hemi.length = hemiLength;
        zlights.ambient[0] = r;
        zlights.ambient[1] = g;
        zlights.ambient[2] = b;
    }
    // GL state setting
    this.setFaceCulling = function (cullFace, frontFaceDirection) {
        if (cullFace === THREE$1.CullFaceNone) {
            _gl.disable(_gl.CULL_FACE);
        } else {
            if (frontFaceDirection === THREE$1.FrontFaceDirectionCW) {
                _gl.frontFace(_gl.CW);
            } else {
                _gl.frontFace(_gl.CCW);
            }
            if (cullFace === THREE$1.CullFaceBack) {
                _gl.cullFace(_gl.BACK);
            } else if (cullFace === THREE$1.CullFaceFront) {
                _gl.cullFace(_gl.FRONT);
            } else {
                _gl.cullFace(_gl.FRONT_AND_BACK);
            }
            _gl.enable(_gl.CULL_FACE);
        }
    };
    // NOTE: if you change the .side value of a material itself, you need to set
    // material.needsUpdate = true, so that the material's shaders are recompiled.
    // You definitely want to avoid this recompilation per frame; usually the
    // THREE.DoubleSided setting works fine for both back and front side display,
    // even if the colors of the sides are different (which are simply uniforms
    // being changed, not the programs themselves).
    this.setMaterialFaces = function (material) {
        state.setDoubleSided(material.side === THREE$1.DoubleSide);
        state.setFlipSided(material.side === THREE$1.BackSide);
    };
    // Textures
    function setTextureParameters(textureType, texture, isImagePowerOfTwo) {
        var extension;
        if (isImagePowerOfTwo) {
            _gl.texParameteri(textureType, _gl.TEXTURE_WRAP_S, paramThreeToGL(texture.wrapS));
            _gl.texParameteri(textureType, _gl.TEXTURE_WRAP_T, paramThreeToGL(texture.wrapT));
            _gl.texParameteri(textureType, _gl.TEXTURE_MAG_FILTER, paramThreeToGL(texture.magFilter));
            _gl.texParameteri(textureType, _gl.TEXTURE_MIN_FILTER, paramThreeToGL(texture.minFilter));
        } else {
            _gl.texParameteri(textureType, _gl.TEXTURE_WRAP_S, _gl.CLAMP_TO_EDGE);
            _gl.texParameteri(textureType, _gl.TEXTURE_WRAP_T, _gl.CLAMP_TO_EDGE);
            if (texture.wrapS !== THREE$1.ClampToEdgeWrapping || texture.wrapT !== THREE$1.ClampToEdgeWrapping) {
                THREE$1.warn('THREE.WebGLRenderer: Texture is not power of two. Texture.wrapS and Texture.wrapT should be set to THREE.ClampToEdgeWrapping. ( ' + texture.sourceFile + ' )');
            }
            _gl.texParameteri(textureType, _gl.TEXTURE_MAG_FILTER, filterFallback(texture.magFilter));
            _gl.texParameteri(textureType, _gl.TEXTURE_MIN_FILTER, filterFallback(texture.minFilter));
            if (texture.minFilter !== THREE$1.NearestFilter && texture.minFilter !== THREE$1.LinearFilter) {
                THREE$1.warn('THREE.WebGLRenderer: Texture is not power of two. Texture.minFilter should be set to THREE.NearestFilter or THREE.LinearFilter. ( ' + texture.sourceFile + ' )');
            }
        }
        extension = extensions.get('EXT_texture_filter_anisotropic');
        if (extension && texture.type !== THREE$1.FloatType && texture.type !== THREE$1.HalfFloatType) {
            if (texture.anisotropy > 1 || texture.__oldAnisotropy) {
                _gl.texParameterf(textureType, extension.TEXTURE_MAX_ANISOTROPY_EXT, Math.min(texture.anisotropy, _this.getMaxAnisotropy()));
                texture.__oldAnisotropy = texture.anisotropy;
            }
        }
    }
    this.uploadTexture = function (texture) {
        if (texture.__webglInit === undefined) {
            texture.__webglInit = true;
            texture.addEventListener('dispose', onTextureDispose);
            texture.__webglTexture = _gl.createTexture();
            _this.info.memory.textures++;
        }
        _gl.bindTexture(_gl.TEXTURE_2D, texture.__webglTexture);
        _gl.pixelStorei(_gl.UNPACK_FLIP_Y_WEBGL, texture.flipY);
        _gl.pixelStorei(_gl.UNPACK_PREMULTIPLY_ALPHA_WEBGL, texture.premultiplyAlpha);
        _gl.pixelStorei(_gl.UNPACK_ALIGNMENT, texture.unpackAlignment);
        texture.image = clampToMaxSize(texture.image, _maxTextureSize);
        var image = texture.image,
            isImagePowerOfTwo = THREE$1.Math.isPowerOfTwo(image.width) && THREE$1.Math.isPowerOfTwo(image.height),
            glFormat = paramThreeToGL(texture.format),
            glType = paramThreeToGL(texture.type);
        setTextureParameters(_gl.TEXTURE_2D, texture, isImagePowerOfTwo);
        var mipmap,
            mipmaps = texture.mipmaps;
        var i, il;
        if (texture instanceof THREE$1.DataTexture) {
            // use manually created mipmaps if available
            // if there are no manual mipmaps
            // set 0 level mipmap and then use GL to generate other mipmap levels
            if (mipmaps.length > 0 && isImagePowerOfTwo) {
                for (i = 0, il = mipmaps.length; i < il; i++) {
                    mipmap = mipmaps[i];
                    _gl.texImage2D(_gl.TEXTURE_2D, i, glFormat, mipmap.width, mipmap.height, 0, glFormat, glType, mipmap.data);
                }
                texture.generateMipmaps = false;
            } else {
                _gl.texImage2D(_gl.TEXTURE_2D, 0, glFormat, image.width, image.height, 0, glFormat, glType, image.data);
            }
        } else if (texture instanceof THREE$1.CompressedTexture) {
            for (i = 0, il = mipmaps.length; i < il; i++) {
                mipmap = mipmaps[i];
                if (texture.format !== THREE$1.RGBAFormat && texture.format !== THREE$1.RGBFormat) {
                    if (getCompressedTextureFormats().indexOf(glFormat) > -1) {
                        _gl.compressedTexImage2D(_gl.TEXTURE_2D, i, glFormat, mipmap.width, mipmap.height, 0, mipmap.data);
                    } else {
                        THREE$1.warn("Attempt to load unsupported compressed texture format");
                    }
                } else {
                    _gl.texImage2D(_gl.TEXTURE_2D, i, glFormat, mipmap.width, mipmap.height, 0, glFormat, glType, mipmap.data);
                }
            }
            // make sure compressed texture pyramids are complete (i.e. include all levels 
            // between what ever was the coarsest level in file and 1x1)
            if (mipmaps.length > 1 && getCompressedTextureFormats().indexOf(glFormat) > -1) {
                var w = mipmap.width >> 1,
                    h = mipmap.height >> 1,
                    l = mipmaps.length;
                var view;
                while (w >= 1 || h >= 1) {
                    view = mipmap.width == 4 && mipmap.height == 4 ? mipmap.data : new DataView(mipmap.data.buffer, mipmap.data.byteOffset, mipmap.data.byteLength * (Math.max(w, 4) * Math.max(h, 4)) / (mipmap.width * mipmap.height));
                    _gl.compressedTexImage2D(_gl.TEXTURE_2D, l, glFormat, Math.max(w, 1), Math.max(h, 1), 0, view);
                    w = w >> 1;
                    h = h >> 1;
                    ++l;
                }
            }
        } else {
            // use manually created mipmaps if available
            // if there are no manual mipmaps
            // set 0 level mipmap and then use GL to generate other mipmap levels
            if (mipmaps.length > 0 && isImagePowerOfTwo) {
                for (i = 0, il = mipmaps.length; i < il; i++) {
                    mipmap = rescueFromPolymer(mipmaps[i]);
                    _gl.texImage2D(_gl.TEXTURE_2D, i, glFormat, glFormat, glType, mipmap);
                }
                texture.generateMipmaps = false;
            } else {
                _gl.texImage2D(_gl.TEXTURE_2D, 0, glFormat, glFormat, glType, rescueFromPolymer(texture.image));
            }
        }
        if (texture.generateMipmaps && isImagePowerOfTwo) _gl.generateMipmap(_gl.TEXTURE_2D);
        texture.needsUpdate = false;
        if (texture.onUpdate) texture.onUpdate();
    };
    this.setTexture = function (texture, slot) {
        _gl.activeTexture(_gl.TEXTURE0 + slot);
        if (texture.needsUpdate) {
            _this.uploadTexture(texture);
        } else if (texture.__webglTexture) {
            _gl.bindTexture(_gl.TEXTURE_2D, texture.__webglTexture);
        } else {
            // No texture available, so don't "use" the texture unit, but make sure the uniform is assigned to something.
            // This avoids headaches where the texture is bound as output this pass, but was an input last pass
            // and is still bound to the given texture unit.
            // Note that Chrome will flag warnings if you bind to null but are "using" the sampler (even though you're not).
            // So we bind to this bogus texture instead.
            // TODO Better for us might be to not have the unused uniforms in our shaders.
            _gl.bindTexture(_gl.TEXTURE_2D, _nullTexture.__webglTexture);
        }
    };
    // This function is finally defined, so we can use it now.
    _this.uploadTexture(_nullTexture);
    function clampToMaxSize(image, maxSize) {
        if (image.width <= maxSize && image.height <= maxSize) {
            return image;
        }
        // Warning: Scaling through the canvas will only work with images that use
        // premultiplied alpha.
        var maxDimension = Math.max(image.width, image.height);
        var newWidth = Math.floor(image.width * maxSize / maxDimension);
        var newHeight = Math.floor(image.height * maxSize / maxDimension);
        var canvas = document.createElement('canvas');
        canvas.width = newWidth;
        canvas.height = newHeight;
        var ctx = canvas.getContext("2d");
        ctx.drawImage(image, 0, 0, image.width, image.height, 0, 0, newWidth, newHeight);
        return canvas;
    }
    function setCubeTexture(texture, slot) {
        if (texture.image.length === 6) {
            if (texture.needsUpdate) {
                if (!texture.__webglTextureCube) {
                    texture.addEventListener('dispose', onTextureDispose);
                    texture.__webglTextureCube = _gl.createTexture();
                    _this.info.memory.textures++;
                }
                _gl.activeTexture(_gl.TEXTURE0 + slot);
                _gl.bindTexture(_gl.TEXTURE_CUBE_MAP, texture.__webglTextureCube);
                _gl.pixelStorei(_gl.UNPACK_FLIP_Y_WEBGL, texture.flipY);
                var isCompressed = texture instanceof THREE$1.CompressedTexture;
                var isDataTexture = texture.image[0] instanceof THREE$1.DataTexture;
                var cubeImage = [];
                var i;
                for (i = 0; i < 6; i++) {
                    if (_this.autoScaleCubemaps && !isCompressed && !isDataTexture) {
                        cubeImage[i] = clampToMaxSize(texture.image[i], _maxCubemapSize);
                    } else {
                        cubeImage[i] = isDataTexture ? texture.image[i].image : texture.image[i];
                    }
                }
                var image = cubeImage[0],
                    isImagePowerOfTwo = THREE$1.Math.isPowerOfTwo(image.width) && THREE$1.Math.isPowerOfTwo(image.height),
                    glFormat = paramThreeToGL(texture.format),
                    glType = paramThreeToGL(texture.type);
                setTextureParameters(_gl.TEXTURE_CUBE_MAP, texture, isImagePowerOfTwo);
                for (i = 0; i < 6; i++) {
                    if (!isCompressed) {
                        if (isDataTexture) {
                            _gl.texImage2D(_gl.TEXTURE_CUBE_MAP_POSITIVE_X + i, 0, glFormat, cubeImage[i].width, cubeImage[i].height, 0, glFormat, glType, cubeImage[i].data);
                        } else {
                            _gl.texImage2D(_gl.TEXTURE_CUBE_MAP_POSITIVE_X + i, 0, glFormat, glFormat, glType, cubeImage[i]);
                        }
                    } else {
                        var mipmap,
                            mipmaps = cubeImage[i].mipmaps;
                        for (var j = 0, jl = mipmaps.length; j < jl; j++) {
                            mipmap = mipmaps[j];
                            if (texture.format !== THREE$1.RGBAFormat && texture.format !== THREE$1.RGBFormat) {
                                if (getCompressedTextureFormats().indexOf(glFormat) > -1) {
                                    _gl.compressedTexImage2D(_gl.TEXTURE_CUBE_MAP_POSITIVE_X + i, j, glFormat, mipmap.width, mipmap.height, 0, mipmap.data);
                                } else {
                                    THREE$1.warn("Attempt to load unsupported compressed texture format");
                                }
                            } else {
                                _gl.texImage2D(_gl.TEXTURE_CUBE_MAP_POSITIVE_X + i, j, glFormat, mipmap.width, mipmap.height, 0, glFormat, glType, mipmap.data);
                            }
                        }
                    }
                }
                if (texture.generateMipmaps && isImagePowerOfTwo) {
                    _gl.generateMipmap(_gl.TEXTURE_CUBE_MAP);
                }
                texture.needsUpdate = false;
                if (texture.onUpdate) texture.onUpdate();
            } else {
                _gl.activeTexture(_gl.TEXTURE0 + slot);
                _gl.bindTexture(_gl.TEXTURE_CUBE_MAP, texture.__webglTextureCube);
            }
        }
    }
    function setCubeTextureDynamic(texture, slot) {
        _gl.activeTexture(_gl.TEXTURE0 + slot);
        _gl.bindTexture(_gl.TEXTURE_CUBE_MAP, texture.__webglTexture);
    }
    // Render targets
    this.initFrameBufferMRT = function (renderTargets, verifyFrameBufferWorks) {
        var primaryTarget = renderTargets[0];
        var clearState = false;
        //For MRT, the frame and depth buffer are owned
        //by the first target.
        if (primaryTarget && !primaryTarget.__webglFramebuffer) {
            if (primaryTarget.depthBuffer === undefined) primaryTarget.depthBuffer = true;
            if (primaryTarget.stencilBuffer === undefined) primaryTarget.stencilBuffer = true;
            primaryTarget.__webglFramebuffer = _gl.createFramebuffer();
            _gl.bindFramebuffer(_gl.FRAMEBUFFER, primaryTarget.__webglFramebuffer);
            var renderbuffer;
            //Allocate depth buffer if needed
            if (primaryTarget.shareDepthFrom) {
                renderbuffer = primaryTarget.__webglRenderbuffer = primaryTarget.shareDepthFrom.__webglRenderbuffer;
            } else {
                // Below we can delete the frame buffer from a render target without deleting the render buffer
                // Use the existing render buffer if it is present. This fixes problems with shared depth buffers.
                // The problem is that the color depth buffer could get changed after it was bound to the frame
                // buffer a target that shares the depth buffer. Using the existing depth buffer, keep it consistent.
                renderbuffer = primaryTarget.__webglRenderbuffer;
                if (primaryTarget.depthBuffer && !primaryTarget.stencilBuffer) {
                    if (!renderbuffer) {
                        renderbuffer = primaryTarget.__webglRenderbuffer = _gl.createRenderbuffer();
                    }
                    _gl.bindRenderbuffer(_gl.RENDERBUFFER, renderbuffer);
                    _gl.renderbufferStorage(_gl.RENDERBUFFER, _gl.DEPTH_COMPONENT16, primaryTarget.width, primaryTarget.height);
                } else if (primaryTarget.depthBuffer && primaryTarget.stencilBuffer) {
                    if (!renderbuffer) {
                        renderbuffer = primaryTarget.__webglRenderbuffer = _gl.createRenderbuffer();
                    }
                    _gl.bindRenderbuffer(_gl.RENDERBUFFER, renderbuffer);
                    _gl.renderbufferStorage(_gl.RENDERBUFFER, _gl.DEPTH_STENCIL, primaryTarget.width, primaryTarget.height);
                } else {
                    //_gl.renderbufferStorage( _gl.RENDERBUFFER, _gl.RGBA4, primaryTarget.width, primaryTarget.height );
                }
            }
            //Bind depth buffer
            if (primaryTarget.depthBuffer && !primaryTarget.stencilBuffer) {
                _gl.framebufferRenderbuffer(_gl.FRAMEBUFFER, _gl.DEPTH_ATTACHMENT, _gl.RENDERBUFFER, renderbuffer);
            } else if (primaryTarget.depthBuffer && primaryTarget.stencilBuffer) {
                _gl.framebufferRenderbuffer(_gl.FRAMEBUFFER, _gl.DEPTH_STENCIL_ATTACHMENT, _gl.RENDERBUFFER, renderbuffer);
            }
            clearState = true;
        }
        var tmpBuf = _currentFramebuffer;
        _gl.bindFramebuffer(_gl.FRAMEBUFFER, primaryTarget.__webglFramebuffer);
        //Create backing textures for all the targets and attach them
        //to the frame buffer.
        var i;
        for (i = 0; i < renderTargets.length; i++) {
            var rt = renderTargets[i];
            if (rt && !rt.__webglTexture) {
                var isTargetPowerOfTwo = THREE$1.Math.isPowerOfTwo(rt.width) && THREE$1.Math.isPowerOfTwo(rt.height),
                    glFormat = paramThreeToGL(rt.format),
                    glType = paramThreeToGL(rt.type);
                rt.addEventListener('dispose', onRenderTargetDispose);
                rt.__webglTexture = _gl.createTexture();
                _this.info.memory.textures++;
                _gl.bindTexture(_gl.TEXTURE_2D, rt.__webglTexture);
                setTextureParameters(_gl.TEXTURE_2D, rt, isTargetPowerOfTwo);
                _gl.texImage2D(_gl.TEXTURE_2D, 0, glFormat, rt.width, rt.height, 0, glFormat, glType, null);
                if (isTargetPowerOfTwo && rt.generateMipmaps) _gl.generateMipmap(_gl.TEXTURE_2D);
            }
            _gl.framebufferTexture2D(_gl.FRAMEBUFFER, _gl.COLOR_ATTACHMENT0 + i, _gl.TEXTURE_2D, rt && rt.__webglTexture, 0);
        }
        if (this.supportsMRT()) {
            /*
             * IMPORTANT: Up until recently, whenever we would switch from a framebuffer with 3 attachments
             * to a framebuffer with 2 attachments, we would just ignore the extraneous attachment, and it
             * worked fine.
             * As of Chrome version 54, we can no longer do that. If we try to keep the extra attachment
             * linked to the framebuffer, Chrome errors out with "framebuffer incomplete".
             */
            var maxColorAttachments = _gl.getParameter(_glExtensionDrawBuffers.MAX_COLOR_ATTACHMENTS_WEBGL);
            while (i < maxColorAttachments) {
                _gl.framebufferTexture2D(_gl.FRAMEBUFFER, _gl.COLOR_ATTACHMENT0 + i, _gl.TEXTURE_2D, null, 0);
                i++;
            }
            var bufs = [_glExtensionDrawBuffers.COLOR_ATTACHMENT0_WEBGL];
            for (i = 1; i < renderTargets.length; i++) {
                bufs.push(_glExtensionDrawBuffers.COLOR_ATTACHMENT0_WEBGL + i);
            }
            _glExtensionDrawBuffers.drawBuffersWEBGL(bufs);
        }
        if (verifyFrameBufferWorks) {
            var status = _gl.checkFramebufferStatus(_gl.FRAMEBUFFER);
            if (status !== _gl.FRAMEBUFFER_COMPLETE) {
                THREE$1.log("Can't use multiple render targets. Falling back to two passes. " + status);
                // Delete the frame buffer before removing the __webglFramebuffer property.
                // I think you could keep the frame buffer if you just cleared the color attachments.
                if (tmpBuf === primaryTarget.__webglFramebuffer) {
                    // Make sure we don't bind the delete frame buffer.
                    tmpBuf = _currentFramebuffer = null;
                }
                // Bind the old frame buffer. Don't know if deleting a bound frame buffer is a good idea.
                _gl.bindFramebuffer(_gl.FRAMEBUFFER, tmpBuf);
                _gl.deleteFramebuffer(primaryTarget.__webglFramebuffer);
                delete primaryTarget.__webglFramebuffer;
                verifyFrameBufferWorks = false;
            }
        }
        _gl.bindFramebuffer(_gl.FRAMEBUFFER, tmpBuf);
        if (clearState) {
            // Release everything
            _gl.bindTexture(_gl.TEXTURE_2D, null);
            _gl.bindRenderbuffer(_gl.RENDERBUFFER, null);
            _gl.bindFramebuffer(_gl.FRAMEBUFFER, null);
        }
        return verifyFrameBufferWorks;
    };
    //[Firefly] This function is different from Three.js -- it adds
    //support for binding multiple render targets.
    this.setRenderTarget = function (renderTargets) {
        var renderTarget;
        if (Array.isArray(renderTargets)) {
            this.initFrameBufferMRT(renderTargets);
            renderTarget = renderTargets[0];
        } else if (renderTargets) {
            var fb = renderTargets.__webglFramebuffer;
            if (!fb || _currentFramebuffer !== fb) {
                this.initFrameBufferMRT([renderTargets]);
            }
            renderTarget = renderTargets;
        }
        var framebuffer, width, height, vx, vy;
        if (renderTarget) {
            framebuffer = renderTarget.__webglFramebuffer;
            width = renderTarget.width;
            height = renderTarget.height;
            vx = 0;
            vy = 0;
        } else {
            framebuffer = null;
            width = _viewportWidth;
            height = _viewportHeight;
            vx = _viewportX;
            vy = _viewportY;
        }
        if (framebuffer !== _currentFramebuffer) {
            _gl.bindFramebuffer(_gl.FRAMEBUFFER, framebuffer);
            _gl.viewport(vx, vy, width, height);
            _currentFramebuffer = framebuffer;
        }
        //_currentWidth = width;
        //_currentHeight = height;
    };
    //We need to use more than WebGL 1.0 technically allows -- we use
    //different bit depth sizes for the render targets, which is not
    //legal WebGL 1.0, but will work eventually and some platforms/browsers
    //already allow it. For others, we have to try, check for failure, and disable use of MRT dynamically.
    this.verifyMRTWorks = function (renderTargets) {
        if (this.supportsMRT()) {
            return this.initFrameBufferMRT(renderTargets, true);
        }
        return false;
    };
    this.readRenderTargetPixels = function (renderTarget, x, y, width, height, buffer) {
        if (!(renderTarget instanceof THREE$1.WebGLRenderTarget)) {
            THREE$1.error('THREE.WebGLRenderer.readRenderTargetPixels: renderTarget is not THREE.WebGLRenderTarget.');
            return;
        }
        // Allocate a buffer for the pixels
        // In order to support floating point targets, we need to ask webgl what buffer format
        // we should use. To support this, readRenderTargetPixels allows you to not pass a
        // buffer into the method, and let it allocate one. This routine does the allocation.
        // If a buffer is passed in it also verifies that the buffer format is correct.
        function getBuffer(renderTarget, format, w, h, buffer) {
            // Assume RGBA unsigned byte
            format.format = _gl.RGBA;
            format.type = _gl.UNSIGNED_BYTE;
            var fmt = {
                format: THREE$1.RGBAFormat,
                type: THREE$1.UnsignedByteType,
                align: _gl.getParameter(_gl.PACK_ALIGNMENT)
            };
            var arrayType = Uint8Array;
            var len = 4;
            var size = 1;
            // If the render target isn't unsigned byte or the format isn't RGB or RGBA,
            // then we need to ask webgl what format and type we should use to read the pixels.
            // WebGL uses the currently bound framebuffer to return the type and format.
            if (renderTarget.type != THREE$1.UnsignedByteType || renderTarget.format !== THREE$1.RGBAFormat && renderTarget.format !== THREE$1.RGBFormat) {
                var error$$1 = _gl.getError(); // clear error
                format.format = _gl.getParameter(_gl.IMPLEMENTATION_COLOR_READ_FORMAT);
                if ((error$$1 = _gl.getError()) != _gl.NO_ERROR) {
                    return null;
                }
                format.type = _gl.getParameter(_gl.IMPLEMENTATION_COLOR_READ_TYPE);
                if ((error$$1 = _gl.getError()) != _gl.NO_ERROR) {
                    return null;
                }
                // What type does it want?
                switch (format.type) {
                    case _gl.FLOAT:
                        arrayType = Float32Array;
                        fmt.type = THREE$1.FloatType;
                        size = 4;
                        break;
                    case _gl.UNSIGNED_SHORT_5_6_5:
                        arrayType = Uint16Array;
                        fmt.type = THREE$1.UnsignedShort565Type;
                        size = 2;
                        break;
                    case _gl.UNSIGNED_SHORT_4_4_4_4:
                        arrayType = Uint16Array;
                        fmt.type = THREE$1.UnsignedShort4444Type;
                        size = 2;
                        break;
                    case _gl.UNSIGNED_SHORT_5_5_5_1:
                        arrayType = Uint16Array;
                        fmt.type = THREE$1.UnsignedShort5551Type;
                        size = 2;
                        break;
                    case _gl.UNSIGNED_BYTE:
                        arrayType = Uint8Array;
                        fmt.type = THREE$1.UnsignedByteType;
                        size = 1;
                        break;
                    default:
                        // Half floats require an extension.
                        var ext = extensions.get('OES_texture_half_float');
                        if (!ext || format.type != ext.HALF_FLOAT_OES) {
                            // We don't support the type
                            return null;
                        }
                        arrayType = Uint16Array;
                        fmt.type = THREE$1.HalfFloatType;
                        size = 2;
                        break;
                }
                // What is the format
                switch (format.format) {
                    case _gl.LUMINANCE:
                        len = 1;
                        fmt.format = THREE$1.LuminanceFormat;
                        break;
                    case _gl.LUMINANCE_ALPHA:
                        len = 2;
                        fmt.format = THREE$1.LuminanceAlphaFormat;
                        break;
                    case _gl.ALPHA:
                        len = 1;
                        fmt.format = THREE$1.AlphaFormat;
                        break;
                    case _gl.RGB:
                        fmt.format = THREE$1.RGBFormat;
                        len = 3;
                        break;
                    case _gl.RGBA:
                        fmt.format = THREE$1.RGBAFormat;
                        len = 4;
                        break;
                    default:
                        // Unknown format
                        return null;
                }
            }
            // If the buffer was passed in make sure it is the right type.
            var bufferLen = len * w * size;
            bufferLen = (bufferLen + fmt.align - 1 & ~(fmt.align - 1)) / size;
            bufferLen *= h;
            if (buffer) {
                if (buffer instanceof arrayType && buffer.length >= bufferLen) {
                    return buffer;
                }
                return null;
            }
            // Allocate a new buffer
            buffer = new arrayType(bufferLen);
            // Same the THREE format information on the buffer, so we can use it later
            buffer.lmv__format = fmt;
            return buffer;
        }
        if (renderTarget.__webglFramebuffer) {
            var restore = false;
            if (renderTarget.__webglFramebuffer !== _currentFramebuffer) {
                _gl.bindFramebuffer(_gl.FRAMEBUFFER, renderTarget.__webglFramebuffer);
                restore = true;
            }
            if (renderTarget.canReadPixels || _gl.checkFramebufferStatus(_gl.FRAMEBUFFER) === _gl.FRAMEBUFFER_COMPLETE) {
                // Make sure the buffer works for the target, or allocate a new buffer
                var format = {};
                buffer = getBuffer(renderTarget, format, width, height, buffer);
                // If buffer is null, then the format is unsupported or doesn't match the target
                if (buffer) {
                    _gl.readPixels(x, y, width, height, format.format, format.type, buffer);
                    // Make sure there wasn't an error
                    var error$$1;
                    if ((error$$1 = _gl.getError()) != _gl.NO_ERROR) {
                        buffer = null;
                        THREE$1.error('THREE.WebGLRenderer.readRenderTargetPixels: readPixels from renderTarget failed. readPixels error ' + error$$1);
                    }
                } else {
                    THREE$1.error('THREE.WebGLRenderer.readRenderTargetPixels: readPixels from renderTarget failed. Buffer format is invalid.');
                }
            } else {
                THREE$1.error('THREE.WebGLRenderer.readRenderTargetPixels: readPixels from renderTarget failed. Framebuffer not complete.');
            }
            if (restore) {
                _gl.bindFramebuffer(_gl.FRAMEBUFFER, _currentFramebuffer);
            }
            return buffer;
        }
        return null;
    };
    function updateRenderTargetMipmap(renderTarget) {
        _gl.bindTexture(_gl.TEXTURE_2D, renderTarget.__webglTexture);
        _gl.generateMipmap(_gl.TEXTURE_2D);
        _gl.bindTexture(_gl.TEXTURE_2D, null);
    }
    // Fallback filters for non-power-of-2 textures
    function filterFallback(f) {
        if (f === THREE$1.NearestFilter || f === THREE$1.NearestMipMapNearestFilter || f === THREE$1.NearestMipMapLinearFilter) {
            return _gl.NEAREST;
        }
        return _gl.LINEAR;
    }
    // Map three.js constants to WebGL constants
    function paramThreeToGL(p) {
        var extension;
        if (p === THREE$1.RepeatWrapping) return _gl.REPEAT;
        if (p === THREE$1.ClampToEdgeWrapping) return _gl.CLAMP_TO_EDGE;
        if (p === THREE$1.MirroredRepeatWrapping) return _gl.MIRRORED_REPEAT;
        if (p === THREE$1.NearestFilter) return _gl.NEAREST;
        if (p === THREE$1.NearestMipMapNearestFilter) return _gl.NEAREST_MIPMAP_NEAREST;
        if (p === THREE$1.NearestMipMapLinearFilter) return _gl.NEAREST_MIPMAP_LINEAR;
        if (p === THREE$1.LinearFilter) return _gl.LINEAR;
        if (p === THREE$1.LinearMipMapNearestFilter) return _gl.LINEAR_MIPMAP_NEAREST;
        if (p === THREE$1.LinearMipMapLinearFilter) return _gl.LINEAR_MIPMAP_LINEAR;
        if (p === THREE$1.UnsignedByteType) return _gl.UNSIGNED_BYTE;
        if (p === THREE$1.UnsignedShort4444Type) return _gl.UNSIGNED_SHORT_4_4_4_4;
        if (p === THREE$1.UnsignedShort5551Type) return _gl.UNSIGNED_SHORT_5_5_5_1;
        if (p === THREE$1.UnsignedShort565Type) return _gl.UNSIGNED_SHORT_5_6_5;
        if (p === THREE$1.ByteType) return _gl.BYTE;
        if (p === THREE$1.ShortType) return _gl.SHORT;
        if (p === THREE$1.UnsignedShortType) return _gl.UNSIGNED_SHORT;
        if (p === THREE$1.IntType) return _gl.INT;
        if (p === THREE$1.UnsignedIntType) return _gl.UNSIGNED_INT;
        if (p === THREE$1.FloatType) return _gl.FLOAT;
        if (p === THREE$1.HalfFloatType) return 0x8D61; //_gl.HALF_FLOAT_OES;
        if (p === THREE$1.AlphaFormat) return _gl.ALPHA;
        if (p === THREE$1.RGBFormat) return _gl.RGB;
        if (p === THREE$1.RGBAFormat) return _gl.RGBA;
        if (p === THREE$1.LuminanceFormat) return _gl.LUMINANCE;
        if (p === THREE$1.LuminanceAlphaFormat) return _gl.LUMINANCE_ALPHA;
        if (p === THREE$1.AddEquation) return _gl.FUNC_ADD;
        if (p === THREE$1.SubtractEquation) return _gl.FUNC_SUBTRACT;
        if (p === THREE$1.ReverseSubtractEquation) return _gl.FUNC_REVERSE_SUBTRACT;
        if (p === THREE$1.ZeroFactor) return _gl.ZERO;
        if (p === THREE$1.OneFactor) return _gl.ONE;
        if (p === THREE$1.SrcColorFactor) return _gl.SRC_COLOR;
        if (p === THREE$1.OneMinusSrcColorFactor) return _gl.ONE_MINUS_SRC_COLOR;
        if (p === THREE$1.SrcAlphaFactor) return _gl.SRC_ALPHA;
        if (p === THREE$1.OneMinusSrcAlphaFactor) return _gl.ONE_MINUS_SRC_ALPHA;
        if (p === THREE$1.DstAlphaFactor) return _gl.DST_ALPHA;
        if (p === THREE$1.OneMinusDstAlphaFactor) return _gl.ONE_MINUS_DST_ALPHA;
        if (p === THREE$1.DstColorFactor) return _gl.DST_COLOR;
        if (p === THREE$1.OneMinusDstColorFactor) return _gl.ONE_MINUS_DST_COLOR;
        if (p === THREE$1.SrcAlphaSaturateFactor) return _gl.SRC_ALPHA_SATURATE;
        extension = extensions.get('WEBGL_compressed_texture_s3tc');
        if (extension !== null) {
            if (p === THREE$1.RGB_S3TC_DXT1_Format) return extension.COMPRESSED_RGB_S3TC_DXT1_EXT;
            if (p === THREE$1.RGBA_S3TC_DXT1_Format) return extension.COMPRESSED_RGBA_S3TC_DXT1_EXT;
            if (p === THREE$1.RGBA_S3TC_DXT3_Format) return extension.COMPRESSED_RGBA_S3TC_DXT3_EXT;
            if (p === THREE$1.RGBA_S3TC_DXT5_Format) return extension.COMPRESSED_RGBA_S3TC_DXT5_EXT;
        }
        extension = extensions.get('WEBGL_compressed_texture_pvrtc');
        if (extension !== null) {
            if (p === THREE$1.RGB_PVRTC_4BPPV1_Format) return extension.COMPRESSED_RGB_PVRTC_4BPPV1_IMG;
            if (p === THREE$1.RGB_PVRTC_2BPPV1_Format) return extension.COMPRESSED_RGB_PVRTC_2BPPV1_IMG;
            if (p === THREE$1.RGBA_PVRTC_4BPPV1_Format) return extension.COMPRESSED_RGBA_PVRTC_4BPPV1_IMG;
            if (p === THREE$1.RGBA_PVRTC_2BPPV1_Format) return extension.COMPRESSED_RGBA_PVRTC_2BPPV1_IMG;
        }
        extension = extensions.get('EXT_blend_minmax');
        if (extension !== null) {
            if (p === THREE$1.MinEquation) return extension.MIN_EXT;
            if (p === THREE$1.MaxEquation) return extension.MAX_EXT;
        }
        return 0;
    }
    // Allocations
    function allocateLights(lights) {
        var dirLights = 0;
        var pointLights = 0;
        var spotLights = 0;
        var hemiLights = 0;
        for (var l = 0, ll = lights.length; l < ll; l++) {
            var light = lights[l];
            if (light.onlyShadow) continue;
            if (light instanceof THREE$1.DirectionalLight) dirLights++;
            if (light instanceof THREE$1.PointLight) pointLights++;
            if (light instanceof THREE$1.SpotLight) spotLights++;
            if (light instanceof THREE$1.HemisphereLight) hemiLights++;
        }
        return { 'directional': dirLights, 'point': pointLights, 'spot': spotLights, 'hemi': hemiLights };
    }
};

function RenderBatchLess(frags, fragOrder, start, count) {
    RenderBatch.call(this, frags, fragOrder, start, count);
    // visibility flag for scene batch. -1: not check yet, 0: not visible, 1: visible
    // this is useful when travserse the same batch again in a re-render without reset the iterator, 
    // that won't apply visibility again.
    this.visibleStats = 0;
}
RenderBatchLess.prototype = Object.create(RenderBatch.prototype);
RenderBatchLess.prototype.constructor = RenderBatchLess;
RenderBatchLess.prototype.resetVisStatus = function () {
    this.visibleStats = 0;
};
RenderBatchLess.prototype.forEach = function (callback, drawMode, includeEmpty) {
    var indices = this.getIndices();
    var frags = this.frags;
    var sortByShaderPossible = !this.sortByShaderDone;
    var pageOutGeometryEnabled = frags.pageOutGeometryEnabled();
    var onDemandLoadingEnabled = frags.onDemandLoadingEnabled();
    //var showPF = (frags.showPF === undefined ) ? -1 : frags.showPF;
    for (var i = this.start, iEnd = this.lastItem; i < iEnd; i++) {
        var idx = indices ? indices[i] : i;
        var m = frags.getVizmesh(idx, this.renderImportance, true);
        if (sortByShaderPossible && (!m || !m.material || !m.material.program || m.geometry_proxy)) sortByShaderPossible = false;
        // Only do this when on demand loading enabled.
        if (onDemandLoadingEnabled) {
            // If already traversed for rendering, ignore this fragment.
            if (frags.isFlagSet(idx, MESH_TRAVERSED) && drawMode == MESH_RENDERFLAG) {
                continue;
            }
            // for debug only, if the PF is to be displayed, then check if this fragment is in the designated PF
            //if ((showPF !== -1) && (showPF !== frags.fragments.packIds[idx])) {
            //    continue;
            //}
            // If geometry of this fragment is required...
            if (!includeEmpty && drawMode && frags.isFlagSet(idx, drawMode)) {
                if (!m.geometry) {
                    // Require geometry only when we truly need it, so that it is available on later runs.
                    // Note that m.geometry will usually be null here.
                    m.geometry = frags.requireGeometry(idx);
                    if (idx < this.drawOrderRender) this.drawOrderRender = idx;
                    if (!m.geometry && m.geometry_proxy) m.geometry = m.geometry_proxy;
                }
                // geometry may now be set, if retrieved or a proxy box is to be displayed.
                if (m.geometry) {
                    // Set traversed flag for this fragment. Don't set it if we are drawing
                    // fragments out of order. Then they will be drawn again over anything
                    // that might have been drawn.
                    var drawn = drawMode == MESH_RENDERFLAG && frags.isFlagSet(idx, MESH_DRAWN);
                    if (drawMode == MESH_RENDERFLAG) {
                        if (this.drawOrderRender == undefined || idx < this.drawOrderRender) frags.setFlagFragment(idx, MESH_DRAWN, true);else {
                            continue; // Don't draw out of order
                        }
                    }
                    // For fragments that may be paged out, check if this fragment was the
                    // last one 
                    // Only record candidates for paging if it is enabled. 
                    if (!drawn && pageOutGeometryEnabled) {
                        if (frags.pagingProxy) {
                            var mtl = frags.getMaterial(idx);
                            // no material means the object is not actually loaded yet, it's a box proxy, so should be ignored.
                            if (mtl) {
                                frags.pagingProxy.onGeomTraversed(m.geometry, mtl.transparent);
                            }
                        }
                    }
                }
            }
        }
        // if drawMode is given, iterate vizflags that match
        if ((includeEmpty || m && m.geometry) && (!drawMode || frags.isFlagSet(idx, drawMode))) {
            callback(m, idx);
        }
    }
    //If all materials shaders are already available, we can sort by shader
    //to minimize shader switches during rendering. This sort will only
    //execute once and changing materials later will break the sorted order again.
    if (sortByShaderPossible) this.sortByShader();
};
RenderBatchLess.prototype.applyVisibility = function () {
    var frags, vizflags, frustum, drawMode, fragIdCb, checkCull, allHidden, _tmpBox, done;
    function evalCulling(checkCull, frustum, frags, idx) {
        var culled = false;
        if (!_tmpBox) _tmpBox = new THREE$1.Box3();
        frags.getWorldBounds(idx, _tmpBox);
        var intersects = frustum.intersectsBox(_tmpBox);
        if (checkCull && intersects === FrustumIntersector.OUTSIDE) {
            culled = true;
        } else if (frags.pixelCullingEnable()) {
            // Check whether the projected area is smaller than a threshold,
            // if yes, do not render it.
            // ??? This may impact rendering that need to profile further.
            var area = frustum.projectedBoxArea(_tmpBox, intersects === FrustumIntersector.CONTAINS);
            area *= frustum.areaConv;
            if (area < frags.pixelCullingThreshold()) {
                culled = true;
            }
        }
        return culled;
    }
    function applyVisCB(m, idx) {
        if (!m && frags.useThreeMesh) {
            if (fragIdCb) fragIdCb(idx);
            return;
        }
        var culled = done || evalCulling(checkCull, frustum, frags, idx);
        if (culled) {
            if (m) {
                m.visible = false;
            } else {
                THREE$1.warn("Unexpected null mesh");
            }
            vizflags[idx] = vizflags[idx] & ~MESH_RENDERFLAG;
            if (frags.pageOutGeometryEnabled()) {
                // Record culled geometries for paging out.
                // This fragment is culled, then move its geometry to culled geometry list.
                var geomId = frags.geomids[idx];
                var geometry = frags.geoms.getGeometry(geomId);
                if (frags.pagingProxy) {
                    frags.pagingProxy.onGeomCulled(geometry);
                }
            }
            return;
        }
        var v = this.evalVisbility(drawMode, vizflags, idx);
        if (m) m.visible = !!v;
        allHidden = allHidden && !v;
    }
    return function (drawModeIn, frustumIn, fragIdCbIn) {
        //Used when parts of the same scene
        //have to draw in separate passes (e.g. during isolate).
        //Consider maintaining two render queues instead if the
        //use cases get too complex, because this approach
        //is not very scalable as currently done (it traverses
        //the entire scene twice, plus the flag flipping for each item).
        allHidden = true;
        done = false;
        frustum = frustumIn;
        drawMode = drawModeIn;
        fragIdCb = fragIdCbIn;
        frags = this.frags;
        //Check if the entire render batch is contained inside
        //the frustum. This will save per-object checks.
        var bbox = drawMode === RENDER_HIDDEN ? this.boundingBoxHidden : this.boundingBox;
        var containment = frustum.intersectsBox(bbox);
        if (containment === FrustumIntersector.OUTSIDE) done = true; //nothing to draw
        checkCull = containment !== FrustumIntersector.CONTAINS;
        if (frags.pixelCullingEnable()) {
            // if this scene get culled by projected area pixel, 
            // can bail out earlier. 
            var area = this.renderImportance;
            if (area == 0) {
                area = frustum.projectedBoxArea(bbox, !checkCull);
            }
            area *= frustum.areaConv;
            if (area < frags.pixelCullingThreshold()) {
                done = true;
            }
        }
        vizflags = this.frags.vizflags;
        // There is another version of forEach: forEachNoMesh which won't be used in this case.
        // Also, it seems even in RenderBatch's implementation, forEachNoMesh logic never get called (on 3d or 2d).
        this.forEach(applyVisCB.bind(this), null, fragIdCb);
        return allHidden;
    };
}();

//TODO: better heuristic for group size might be needed
//But it should be based on polygon count as well as
//fragment count. But polygon count is not known
//until we get the meshes later on.
var MAX_FRAGS_PER_GROUP = 500;
var calculateFragsPerScene = function calculateFragsPerScene(is2d) {
    // choose _fragsPerScene based on scene type and device
    var fragsPerScene = MAX_FRAGS_PER_GROUP;
    if (is2d) fragsPerScene /= 3; //2d meshes are all fully packed, so we can't draw so many per batch.
    if (isMobileDevice()) {
        fragsPerScene /= 3; //This is tuned for ~15fps on Nexus 7.
        // 2d on mobile is even slower, draw fewer. This assumes that the
        // 2d buffer size is 32K. If you change the buffer size, you need
        // to adjust this too.
        if (is2d) fragsPerScene /= 2;
    }
    fragsPerScene = Math.floor(fragsPerScene);
    return fragsPerScene > 0 ? fragsPerScene : MAX_FRAGS_PER_GROUP;
};
function cameraHash(camera) {
    return camera.matrix.elements[2] + camera.matrix.elements[12];
}
/**
 * Linear Iterator
 */
var IteratorLinear = function () {
    function IteratorLinear(renderModel, fragmentCount, fillLast) {
        classCallCheck(this, IteratorLinear);

        this._fragOrder = [];
        this._currentScene = 0;
        this._geomScenes = [];
        this._resetVisStatus = true;
        // Perform raycast on all batches. See RenderBatch.raycast() for params.
        this.rayCast = function (raycaster, intersects, dbIdFilter) {
            var len = this.getSceneCount();
            for (var i = 0; i < len; i++) {
                this._geomScenes[i].raycast(raycaster, intersects, dbIdFilter);
            }
        };
        this._frags = renderModel.getFragmentList();
        this._model = renderModel;
        this._fillLast = fillLast;
        this._fragsPerScene = calculateFragsPerScene(renderModel.is2d());
        //Trivial largest to smallest order
        var fragOrder = new Int32Array(fragmentCount);
        for (var i = 0; i < this._fragCount; i++) {
            fragOrder[i] = i;
        }
        this.setFragmentOrder(fragOrder, fragmentCount);
    }

    createClass(IteratorLinear, [{
        key: 'setFragmentOrder',
        value: function setFragmentOrder(fragOrder, fragmentCount) {
            this._fragCount = fragmentCount;
            this._fragOrder[0] = fragOrder;
            //Create a RenderBatch for each batch of fragments.
            //We will then draw each batch in turn to get a progressive
            //effect. The number of fragments per batch should be close
            //to what we can draw in a single frame while maintaining interactivity.
            //This linear list of batches is used for 2D scenes and for 3D scenes
            //while they are loading. After load is done, the linear traversal is replaced
            //by a view-based bounding volume hierarchy traversal.
            // Given the maximum fragCount per batch, compute the required number of batches to fit in all fragments
            var numScenes = Math.ceil(this._fragCount / this._fragsPerScene);
            // Choose a different render batch class if fragments on demand loading enabled.
            var onDemandLoadingEnabled = this._frags.onDemandLoadingEnabled();
            var _RBClass = this._RBClass = onDemandLoadingEnabled ? RenderBatchLess : RenderBatch;
            // Note that this will only create all batches if the full fragCount is known in advance. Otherwise, they have to be created 
            // later via addFragment() calls.
            var startLen = this._geomScenes.length;
            this._geomScenes.length = numScenes;
            var geomScenes = this._geomScenes;
            var fragsPerScene = this._fragsPerScene;
            for (var i = 0; i < numScenes; i++) {
                var startIndex = i * fragsPerScene;
                var scene = i < startLen ? geomScenes[i] : geomScenes[i] = new _RBClass(this._frags, this._fragOrder, startIndex, this._fragsPerScene);
                var lastIndex = startIndex + this._fragsPerScene;
                // Crop last batch at the end, so that it does not exceed the fragment count. The last batch has usually not full
                // length, unless fragCount is a multiple of 
                if (lastIndex > this._fragCount) lastIndex = this._fragCount;
                scene.lastItem = lastIndex;
                if (onDemandLoadingEnabled) {
                    // Only try to calculate bounds when it needs to (on demand load need batch bounding box ready ahead of geom loading)
                    scene.calculateBounds();
                }
            }
        }
        // Only needed if the full fragment count is not known in advance.
        // For incremental loading, this method makes sure that 
        //  - fragOrder has required size 
        //  - fragOrder defines trivial orderning of all frags added so far
        //  - _geomScenes contains a batch containing the new fragment
        //
        // Assumptions: Fragments are currently added by increasing fragId. Otherwise, _geomScenes might contain null-elements,
        //              which may cause exceptions, e.g., in nextBatch() and getVisibleBounds().

    }, {
        key: 'addFragment',
        value: function addFragment(fragId) {
            //The frag order indices array will not auto-resize (it's ArrayBuffer)
            //so we have to do it manually
            if (this._fragOrder[0].length <= fragId) {
                var nlen = 2 * this._fragOrder[0].length;
                if (nlen <= fragId) nlen = fragId + 1;
                var ninds = new Int32Array(nlen);
                ninds.set(this._fragOrder[0]);
                this._fragOrder[0] = ninds;
            }
            //Note: this assumes trivial ordering
            //We cannot set/add meshes if reordering of the indices has already happened.
            //This is OK, because trivial ordering with unknown initial fragment count
            //happens only for 2D models where we preserve trivial draw order anyway.
            this._fragOrder[0][fragId] = fragId;
            //Find a parent for the mesh -- in the case of SVF
            //fragments we just map fragment index to increasing
            //scene index, since fragments are already ordered
            //in the way we want to draw them
            var sceneIndex = Math.floor(fragId / this._fragsPerScene);
            if (this._geomScenes) {
                var scene = this._geomScenes[sceneIndex];
                if (!scene) {
                    // Note that it's okay that the batch may also reference fragments that were not added yet. 
                    // The RenderBatch does not require all fragments to be in memory already.
                    this._geomScenes[sceneIndex] = scene = new this._RBClass(this._frags, this._fragOrder, sceneIndex * this._fragsPerScene, this._fragsPerScene);
                }
                // did scene get set reasonably?
                if (scene) {
                    // notify batch about new fragment, so that the batch updates internal state like summed bbox and material sorting
                    scene.onFragmentAdded(fragId, fragId);
                }
            }
        }
    }, {
        key: 'getFragmentCount',
        value: function getFragmentCount() {
            if (!this._geomScenes.length) {
                return 0;
            }
            var lastItem = this._geomScenes[this._geomScenes.length - 1].lastItem;
            while (--lastItem >= 0) {
                if (this._frags.geomids[lastItem] >= 0) break;
            }
            return lastItem + 1;
        }
    }, {
        key: 'reset',
        value: function reset(frustum, camera) {
            this._currentScene = 0;
            if (this._fillLast && this._geomScenes[0]) {
                this._geomScenes[0].drawEnd = 0;
            }
            if (this._resetVisStatus) {
                var scenes = this._geomScenes;
                var len = scenes.length;
                for (var i = 0; i < len; ++i) {
                    var scene = scenes[i];
                    if (scene && scene.resetVisStatus) {
                        scene.resetVisStatus();
                    }
                }
                this._resetVisStatus = false;
            }
        }
    }, {
        key: 'getSceneCount',
        value: function getSceneCount() {
            return this._geomScenes.length;
        }
    }, {
        key: 'getGeomScenes',
        value: function getGeomScenes() {
            return this._geomScenes;
        }
    }, {
        key: 'resetVisStatus',
        value: function resetVisStatus() {
            this._resetVisStatus = true;
        }
    }, {
        key: 'done',
        value: function done() {
            // If we are filling f2d batches, then we aren't done until the model is loaded
            if (this._fillLast && !this._model.isLoadDone()) return false;
            // Once the model is loaded, we are done when the last batch is drawn
            var res;
            return this._currentScene >= this._geomScenes.length - 1 && (!(res = this._geomScenes[this._currentScene]) || res.drawStart >= res.lastItem);
        }
    }, {
        key: 'nextBatch',

        // Returns the next RenderBatch from _geomScenes or null when reaching the end.
        value: function nextBatch() {
            if (this._currentScene >= this.getSceneCount()) return null;
            // as long as fragments are added in order of increasing id, res will never be null.
            var res = this._geomScenes[this._currentScene];
            if (!this._fillLast) ++this._currentScene;else {
                // 2D scene, so we only want to procede to the next batch when this
                // current batch is filled.
                if (res.lastItem >= res.start + res.count) {
                    ++this._currentScene;
                    if (this._geomScenes[this._currentScene]) this._geomScenes[this._currentScene].drawEnd = this._geomScenes[this._currentScene].start;
                }
                res.drawStart = res.drawEnd;
                res.drawEnd = res.lastItem;
                if (res.hasOwnProperty("drawStart") && res.lastItem <= res.drawStart) return null; // all object in the batch have been drawn
            }
            // Render importance is used to decide what to render next when using progressive rendering with multiple models. (see RenderScene.renderSome)
            // For linear iterator, is treated as equally important.
            res.renderImportance = 0;
            return res;
        }
    }, {
        key: 'getVisibleBounds',

        // Computes the summed bboxes of all batches of the iterator and writes them to the out params:
        // - visibleBounds:           instanceof THREE.Box3, bbox of all fragments excluding the ghosted ones.
        // - visibleBoundsWithHidden: instanceof THREE.Box3, bbox of all fragments 
        //
        // [HB:] BBoxes are computed without considering MESH_HIDE flag in any way, see RenderBatch.calculateBounds(). Is this intended?
        value: function getVisibleBounds(visibleBounds, visibleBoundsWithHidden) {
            //Case where we are not using BVH
            var len = this.getSceneCount();
            for (var i = 0; i < len; i++) {
                // make sure that the bboxes of the batch is up-to-date
                this._geomScenes[i].calculateBounds();
                // sum up bbox of fragments excluding ghosted
                visibleBounds.union(this._geomScenes[i].boundingBox);
                // sum up bbox of all fragments
                visibleBoundsWithHidden.union(this._geomScenes[i].boundingBox);
                visibleBoundsWithHidden.union(this._geomScenes[i].boundingBoxHidden);
            }
        }
    }]);
    return IteratorLinear;
}();
/**
 * All rendering and other scene related data associated with a 3D model or 2D Drawing.
 * The "linear" variant uses simple non-hierarchical linear scene traversal when rendering a frame.
 * Good for small scenes, incrementally loaded scenes, and 2D drawings where draw order matters.
 * @constructor
 */
var ModelIteratorLinear = function (_IteratorLinear) {
    inherits(ModelIteratorLinear, _IteratorLinear);

    function ModelIteratorLinear(renderModel) {
        classCallCheck(this, ModelIteratorLinear);

        var frags = renderModel.getFragmentList();
        var fillLast = renderModel.is2d() && !frags.onDemandLoadingEnabled();

        var _this = possibleConstructorReturn(this, (ModelIteratorLinear.__proto__ || Object.getPrototypeOf(ModelIteratorLinear)).call(this, renderModel, frags.getCount(), fillLast));

        _this._lastCameraHash = 0;
        _this._cameraChanged = false;
        return _this;
    }

    createClass(ModelIteratorLinear, [{
        key: 'calculateFragOrder',
        value: function calculateFragOrder(isLoadDone) {
            if (!this._model.isvizCacheEnabled) return;
            var idbuf = this._model.readbackTargetIdCallback();
            var counts = {},
                len = idbuf.width * idbuf.height,
                buffer = idbuf.buffer,
                i;
            for (i = 0; i < len; i++) {
                var id = buffer[4 * i + 2] << 16 | buffer[4 * i + 1] << 8 | buffer[4 * i];
                if (id != 16777215) counts[id] = (counts[id] | 0) + 1; // undefined | 0 == 0
            }
            // list of PropId's
            var vizFragIds = Object.keys(counts).sort(function (a, b) {
                return counts[b] - counts[a];
            }).map(Number);
            // save and persist fast-load list for home-View
            this._model.setFastLoadList(vizFragIds, this._lastCameraObj);
            var order = this._fragOrder[0];
            order.set(vizFragIds);
            var to = vizFragIds.length;
            for (i = 0; i < this._fragCount; ++i) {
                if (!counts[i]) order[to++] = i;
            }
        }
    }, {
        key: 'reset',

        // restart iterator
        value: function reset(frustum, camera) {
            get(ModelIteratorLinear.prototype.__proto__ || Object.getPrototypeOf(ModelIteratorLinear.prototype), 'reset', this).call(this, frustum, camera);
            if (this._lastCameraHash != cameraHash(camera)) this._cameraChanged = true;
            this._lastCameraHash = cameraHash(camera);
            this._lastCameraObj = camera;
        }
    }, {
        key: 'nextBatch',

        // Returns the next RenderBatch from _geomScenes or null when reaching the end.
        value: function nextBatch() {
            // if vizCache is enabled, then trigger a 'snapshot' and change the fragOrder, when...
            // ...the camera is idle and we have finished drawing the scene.
            // Additionally, to improve the user experience for a large scene, we take three snapshots...
            // First one at ~800ms, then at ~3secs and finally at 100% progress.
            // so 800ms is roughly the delay between consecutive mouse-up + drag operations (mouse pumping)
            // while 3 seconds is for people who are hovering to see more detail
            // finally, 100% is the catch all, for people who may have to wait 20mins for things to render.
            if (this._model.isvizCacheEnabled && this._cameraChanged && (this._currentScene == 90 || this._currentScene == 400 || this._currentScene == this.getSceneCount() - 1)) {
                if (this._currentScene == this.getSceneCount() - 1 && this._model.isLoadDone()) this._cameraChanged = false;
                this.calculateFragOrder(this._currentScene >= this.getSceneCount() - 1);
            }
            return get(ModelIteratorLinear.prototype.__proto__ || Object.getPrototypeOf(ModelIteratorLinear.prototype), 'nextBatch', this).call(this);
        }
    }]);
    return ModelIteratorLinear;
}(IteratorLinear);
/**
 * All rendering and other scene related data associated with a 3D model or 2D Drawing.
 * The "linear" variant uses simple non-hierarchical linear scene traversal when rendering a frame.
 * Good for small scenes, incrementally loaded scenes, and 2D drawings where draw order matters.
 * @constructor
 */
var HighlightIteratorLinear = function (_IteratorLinear2) {
    inherits(HighlightIteratorLinear, _IteratorLinear2);

    function HighlightIteratorLinear(renderModel) {
        classCallCheck(this, HighlightIteratorLinear);

        var frags = renderModel.getFragmentList();

        var _this2 = possibleConstructorReturn(this, (HighlightIteratorLinear.__proto__ || Object.getPrototypeOf(HighlightIteratorLinear)).call(this, renderModel, 0, false));

        _this2._ids = {};
        _this2._curCount = 0;
        _this2._dirty = false;
        return _this2;
    }
    // Only needed if the full fragment count is not known in advance.
    // For incremental loading, this method makes sure that 
    //  - fragOrder has required size 
    //  - fragOrder defines trivial orderning of all frags added so far
    //  - _geomScenes contains a batch containing the new fragment
    //
    // Assumptions: Fragments are currently added by increasing fragId. Otherwise, _geomScenes might contain null-elements,
    //              which may cause exceptions, e.g., in nextBatch() and getVisibleBounds().


    createClass(HighlightIteratorLinear, [{
        key: 'addFragment',
        value: function addFragment(fragId) {
            if (!this._ids[fragId]) {
                this._ids[fragId] = true;
                ++this._curCount;
                this._dirty = true;
            }
        }
    }, {
        key: 'removeFragment',
        value: function removeFragment(fragId) {
            if (this._ids[fragId]) {
                delete this._ids[fragId];
                --this._curCount;
                this._dirty = true;
            }
        }
    }, {
        key: 'reset',
        value: function reset(frustum, camera) {
            if (this._dirty) {
                var ids = Object.keys(this._ids);
                var array = new Int32Array(ids.length);
                for (var i = ids.length; --i >= 0;) {
                    array[i] = parseInt(ids[i]);
                }
                this.setFragmentOrder(array, ids.length);
                this._dirty = false;
            }
            get(HighlightIteratorLinear.prototype.__proto__ || Object.getPrototypeOf(HighlightIteratorLinear.prototype), 'reset', this).call(this, frustum, camera);
        }
    }, {
        key: 'getSceneCount',
        value: function getSceneCount() {
            return Math.ceil(this._curCount / this._fragsPerScene);
        }
    }]);
    return HighlightIteratorLinear;
}(IteratorLinear);

/**
 * This file contains code to create a Consolidation (see Consolidation.js) from all fraqments of a FragmentList.
 * Rendering the consolidation instead of the individual fragments can improve rendering performance
 * for models containing a large number of small objects.
 */
var MATERIAL_VARIANT$1 = MaterialManager.MATERIAL_VARIANT;
/**
 *  Creates a consolidated representation for a given list of fragment ids. Consolidation is only done for the
 *  first n elements of the fragIds array, where n is chosen in a way that we stop if a given memory cost limit is reached.
 *
 *  Consolidation is done here by merging fragment Geometries into larger vertex buffers. If multiple fragments share
 *  the same geometry, the geometry is replicated. Therefore, this step is only used for the smaller fragments
 *  with not too many instances.
 *
 *   @param {FragmentList}    fragList
 *   @param {MaterialManager} materials
 *   @param {Int32Array[]}    fragIds
 *   @param {number}          limitInBytes
 *
 *   @returns {Object} Result object containing...
 *                      result.consolidation: Instance of Consolidation
 *                      result.fragIdCount:   Defines a range within fragIds:
 *                                            Only fragIds[0], ... , fragIds[result.fragIdCount-1] were consolidated.
 */
function createConsolidationMap(fragList, materials, fragIds, limitInBytes) {
    // reused in loop below
    var fragBox = new THREE$1.Box3();
    var mc = new ConsolidationBuilder();
    var i = 0;
    for (; i < fragIds.length; i++) {
        // stop if we reached our memory limit.
        if (mc.costs >= limitInBytes) {
            break;
        }
        // get fragId and world box
        var fragId = fragIds[i];
        fragList.getWorldBounds(fragId, fragBox);
        // add mesh to consolidation
        var geometry = fragList.getGeometry(fragId);
        var material = fragList.getMaterial(fragId);
        mc.addGeom(geometry, material, fragBox, fragId);
    }
    // create ConsolidationMap
    return mc.createConsolidationMap(fragIds, i);
}
/**
 * Combines a sequence of fragments with shared geometry and material into an instanced mesh.
 * This instanced mesh is added to 'result'.
 *
 * For fragments that cannot be instanced, we add an individual mesh instead that shares
 * original geometry and material. This happens if:
 *
 *  a) The is just a single instance (range length 1)
 *  b) The instance has a matrix that cannot be decomposed into pos/scale/rotation.
 *
 *  @param {FragmentList}    fragList
 *  @param {MaterialManager} materials  - needed to create new materials for instanced shapes
 *  @param {Int32Array}      fragIds
 *  @param {number}          rangeStart - defines a range within the fragIds array
 *  @param {number}          rangeEnd
 *  @param {Consolidation}   result     - collects the resulting mesh.
 */
var applyInstancingToRange = function () {
    var _tempMatrix = null;
    var _tempSkippedFragments = [];
    return function (fragList, materials, fragIds, rangeStart, rangeEnd, result) {
        // init temp matrix
        if (!_tempMatrix) {
            _tempMatrix = new THREE$1.Matrix4();
        }
        var firstFrag = fragIds[rangeStart];
        // get geometry and material (must be the same for all frags in the range)
        var geom = fragList.getGeometry(firstFrag);
        var mat = fragList.getMaterial(firstFrag);
        // just a single instance? => add it directly
        var rangeLength = rangeEnd - rangeStart;
        if (rangeLength == 1) {
            result.addSingleFragment(fragList, firstFrag);
            return;
        }
        // Special-case handling: Use temp array to collect fragIds that we had to skip
        _tempSkippedFragments.length = 0;
        // create instanced geometry from geom and all transforms
        var builder = new InstanceBufferBuilder(geom, rangeLength);
        for (var i = rangeStart; i < rangeEnd; i++) {
            var fragId = fragIds[i];
            // world matrix and dbId
            fragList.getOriginalWorldMatrix(fragId, _tempMatrix);
            var dbId = fragList.fragments.fragId2dbId[fragId];
            // try to process as instanced mesh
            var valid = builder.addInstance(_tempMatrix, dbId);
            // If adding this instance failed, its matrix did not allow to
            // be represented as pos/rotation/scale. In this case, add
            // the mesh individually.
            if (!valid) {
                _tempSkippedFragments.push(fragId);
            }
        }
        var instGeom = builder.finish();
        // instGeom might be null if all instances had matrices that could not be decomposed.
        // In this case, all frags have been skipped and will be added individually below
        if (instGeom) {
            // create instancing material
            var instMat = materials.getMaterialVariant(mat, MATERIAL_VARIANT$1.INSTANCED, fragList.model);
            // add instanced mesh
            result.addContainerMesh(instGeom, instMat, fragIds, rangeStart, rangeLength);
        }
        // if we had to skip any fragment, add it separately. Note that this must be done after
        // adding the container, so that fragId2MeshIndex finally refers to the individual geometry.
        for (i = 0; i < _tempSkippedFragments.length; i++) {
            fragId = _tempSkippedFragments[i];
            result.addSingleFragment(fragList, fragId);
        }
    };
}();
/**
 * Combines fragments with shared geometries into instanced meshes. Note that creating instanced meshes
 * only makes sense for fragments that share geometry and material. All other fragments will also be
 * added to the result, but the meshes will share original geometry and material.
 *
 * Requirement: fragIds must already be sorted in a way that meshes with identical geometry and material form
 *              a contiguous range.
 *
 * @param {FragmentList}   fragList
 * @param {MaterialManager} materials
 * @param {Int32Array}     fragIds
 * @param [number}         startIndex - Defines the range in fragIds that we process:
 *                                      fragIds[startIndex], ..., fragIds[fragIds.length-1]
 * @param {Consolidation} result      - collects all output meshes
 */
function applyInstancing(fragList, materials, fragIds, startIndex, result) {
    if (startIndex >= fragIds.length) {
        // range empty
        // This may happen if we could consolidate all fragments per mesh merging already, so
        // that instancing is not needed anymore.
        return;
    }
    // track ranges of equal geometry and material
    var rangeStart = startIndex;
    var lastGeomId = -1;
    var lastMatId = -1;
    for (var i = startIndex; i < fragIds.length; i++) {
        var fragId = fragIds[i];
        var geomId = fragList.getGeometryId(fragId);
        var matId = fragList.getMaterialId(fragId);
        // check if a new range starts here
        if (geomId != lastGeomId || matId != lastMatId) {
            // a new range starts at index i
            // => process previous range [rangeStart, ..., i-1]
            if (i != startIndex) {
                applyInstancingToRange(fragList, materials, fragIds, rangeStart, i, result);
            }
            // start new range
            rangeStart = i;
            lastGeomId = geomId;
            lastMatId = matId;
        }
    }
    // process final range
    applyInstancingToRange(fragList, materials, fragIds, rangeStart, fragIds.length, result);
}
/**
 * Creates an array that provides the number of instance for each geometry id.
 *
 * @param {FragmentList} fragList
 * @returns {number[]}   geomInstanceCount
 */
function countGeometryInstances(fragList) {
    var fragCount = fragList.getCount();
    // count instances of each geometry
    var geomInstanceCount = [];
    for (var fragId = 0; fragId < fragCount; fragId++) {
        var geomId = fragList.getGeometryId(fragId);
        var numInstances = geomInstanceCount[geomId] | 0;
        geomInstanceCount[geomId] = numInstances + 1;
    }
    return geomInstanceCount;
}
/**
 * Returns an array that enumerates all fragIds in a way that...
 *
 *  1. They are ordered by increasing memory costs that it takes to consolidate them.
 *  2. FragIds with equal geometry and material form a contiguous range.
 *
 *   @param {FragmentList} fragList
 *   @param {number[]}     geomInstanceCount (see countGeometryInstances)
 *   @returns {Int32Array} ordered list of fragment ids
 */
function sortByConsolidationCosts(fragList, geomInstanceCount) {
    // define sort predicate
    function fragCompare(fragId1, fragId2) {
        // compute consolidation costs of both fragments
        var geom1 = fragList.getGeometry(fragId1);
        var geom2 = fragList.getGeometry(fragId2);
        var instCount1 = geomInstanceCount[geom1.id];
        var instCount2 = geomInstanceCount[geom2.id];
        var memCost1 = instCount1 * geom1.byteSize;
        var memCost2 = instCount2 * geom2.byteSize;
        // 1. memCost
        if (memCost1 != memCost2) {
            return memCost1 - memCost2;
        }
        // 2. geom id
        if (geom1.id != geom2.id) {
            return geom1.id - geom2.id;
        }
        // 3. material id
        var mat1 = fragList.getMaterialId(fragId1);
        var mat2 = fragList.getMaterialId(fragId2);
        return mat1 - mat2;
    }
    // a single missing geometry shouldn't make the whole consolidation fail.
    // therefore, we exclude any null-geometry fragemnts.
    var validFrags = 0;
    // create fragId array [0,1,2,...]
    var fragCount = fragList.getCount();
    var fragIds = new Int32Array(fragCount);
    for (var i = 0; i < fragCount; i++) {
        // exclude fragments without valid geometry
        if (!fragList.getGeometry(i)) {
            continue;
        }
        fragIds[validFrags] = i;
        validFrags++;
    }
    // resize array if we had to skip fragments
    if (validFrags < fragCount) {
        fragIds = new Int32Array(fragIds.buffer, fragIds.byteOffset, validFrags);
    }
    // sort by costs
    if (!fragIds.sort) {
        // Unfortunately, there is no official polyfill for TypedArray.sort.
        // Therefore, we just use Array.sort. The extra copy makes it inappropriate
        // for a general polyfill, but it's sufficient for this case.
        var thanksIE11ForWastingOurTime = new Array(fragCount);
        // Just copy by hand to avoid even more compatibility issues
        for (i = 0; i < fragCount; i++) {
            thanksIE11ForWastingOurTime[i] = fragIds[i];
        }
        thanksIE11ForWastingOurTime.sort(fragCompare);
        for (i = 0; i < fragIds.length; i++) {
            fragIds[i] = thanksIE11ForWastingOurTime[i];
        }
    } else {
        fragIds.sort(fragCompare);
    }
    return fragIds;
}
/**
 * Determines for each geometry whether to store it on GPU or only CPU-side. The heuristic is the same that is
 * always used by GeometryList. However, when using consolidation, we first spend GPU Ram for the consolidated
 * meshes (with are used more for rendering). The original fragment geometry is only stored on GPU
 * if enough budget is left.
 *
 *   @param {FragmentList}         fragList
 *   @param {Consolidation}        consolidation
 *   @param {number[]}             geomInstanceCount - see countGeometryInstances().
 *   @param {FireFlyWebGLRenderer} glRenderer        - needed to free GPU memory if needed
 */
function chooseMemoryTypes(fragList, consolidation, geomInstanceCount, glRenderer) {
    var geomList = fragList.geoms;
    // some geometries are shared by consolidation and original fragments. We track their ids to
    // make sure that we don't process them twice.
    var geomShared = [];
    // track required GPU memory and number of meshes on GPU, because both are restricted (see geomList.chooseMemoryType)
    var gpuNumMeshes = 0;
    var gpuMeshMemory = 0;
    for (var i = 0; i < consolidation.meshes.length; i++) {
        var mesh = consolidation.meshes[i];
        var geom = mesh.geometry;
        // compute byteSize if not available.
        if (!geom.byteSize) {
            geom.byteSize = (geom.vb.byteLength || 0) + (geom.ib.byteLength || 0);
        }
        // If the mesh has a well-defined fragId, this geometry is shared with a fragment that could
        // not be consolidated with others.
        var isSharedFragmentGeometry = Number.isInteger(mesh.fragId);
        // choose whether to store on GPU or CPU
        geomList.chooseMemoryType(geom, geom.numInstances, gpuNumMeshes, gpuMeshMemory);
        // track overall GPU workload
        if (!geom.streamingDraw) {
            gpuMeshMemory += geom.byteSize;
            gpuNumMeshes += 1;
            // consolidated meshes are purely used for rendering. So, we can discard
            // the CPU-side copy as soon as the data are on GPU. Note that we must not
            // do this for shared original fragment geometry - which is exposed to the client.
            if (!isSharedFragmentGeometry) {
                geom.discardAfterUpload = true;
            }
        }
        if (isSharedFragmentGeometry) {
            // this mesh is sharing original fragment geometry.
            geomShared[geom.id] = true;
        }
    }
    // Finally, revise the memory type for the original GeometryList again. This time, we consider
    // the workload that we already spent on for the consolidation and only allow geometry to be stored on GPU if
    // our budget is not consumed yet.
    for (i = 1; i < geomList.geoms.length; i++) {
        // get next geom
        geom = geomList.geoms[i];
        if (!geom) {
            continue;
        }
        // if this geometry is shared by the consolidation, the memory type has already been set in the loop above.
        if (geomShared[i]) {
            continue;
        }
        // determine nen tyoe for this geom
        var numInstances = geomInstanceCount[i];
        geomList.chooseMemoryType(geom, numInstances, gpuNumMeshes, gpuMeshMemory);
        if (geom.streamingDraw) {
            // A geometry might already have been GPU-uploaded and displayed during progressive loading.
            // If we now decided to keep this geometry CPU side, make sure that we don't keep any of these on GPU anymore.
            glRenderer.deallocateGeometry(geom);
        }
        // track overall GPU workload
        if (!geom.streamingDraw) {
            gpuMeshMemory += geom.byteSize;
            gpuNumMeshes += 1;
        }
    }
}
/**
 *  Creates a consolidated representation of a fragments. For each fragment f, there will be a mesh in the result that
 *  contains it - or shares its geometry if was not mergeable with any other fragment.
 *
 *   @param {FragmentList}    fraglist
 *   @param {MaterialManager} materials           - needed to create new material variants for consolidated/instanced meshes
 *   @param {number}          [byteLimit = 100MB] - Restricts the amount of memory that we spend in mesh consolidation.
 *                                                  Note that without this limit, consolidation may consume several times more memory
 *                                                  than the original model itself, because shared geometries must be replicated.
 *   @param {ConsolidationMap} [consMap]          - Optional: If available, the intermediate results can be reused from a previous
 *                                                  consolidation to accelerate preprocessing. Note that a ConsolidationMap
 *                                                  can only be reused if the FragmentList is exactly the same.
 *   @param {FireFlyWebGLRenderer} glRenderer
 *
 *   @returns {Consolidation}
 */
function consolidateFragmentList(fragList, materials, byteLimit, glRenderer, consMap) {
    // check if we can use hardware instancing
    var enableInstancing = glRenderer.supportsInstancedArrays();
    // by default, restrict extra memory consumption to 100 MB
    byteLimit = byteLimit || 100 << 20;
    // check number of instances for each geometry id
    var geomInstanceCount = countGeometryInstances(fragList);
    // If not available yet, create ConsolidationMap that describes the mapping from src fragments
    // into consolidated meshes.
    if (!consMap) {
        // sort by costs
        var sortedFragIds = sortByConsolidationCosts(fragList, geomInstanceCount);
        // create consolidation map
        consMap = createConsolidationMap(fragList, materials, sortedFragIds, byteLimit);
    }
    // Create Consolidation
    var result = consMap.buildConsolidation(fragList, materials, fragList.model); // {Consolidation}
    // the first n=numConsolidated fragments in fragIds are consolidated already.
    // The remaining fragIds are now processed using instancing.
    var fragIds = consMap.fragOrder;
    var numConsolidated = consMap.numConsolidated;
    if (enableInstancing) {
        // Optimize the rest with instancing (takes less extra memory)
        applyInstancing(fragList, materials, fragIds, numConsolidated, result);
    } else {
        // We cannot use instancing => Add all remaining fragments individually
        for (var i = numConsolidated; i < fragIds.length; i++) {
            var fragId = fragIds[i];
            result.addSingleFragment(fragList, fragId);
        }
    }
    // determine which geometries we upload to GPU. All remaining ones are stored CPU-side
    // and rendered using streaming-draw (slower, but better than GPU memory overload)
    chooseMemoryTypes(fragList, result, geomInstanceCount, glRenderer);
    // Set modelId for all consolidated meshes (needed to distinguish multiple models via ID-buffer)
    var modelId = fragList.model.getModelId();
    for (i = 0; i < result.meshes.length; i++) {
        var mesh = result.meshes[i];
        mesh.modelId = modelId;
    }
    return result;
}

/**
 *  ConsolidationIterator is used by by RenderModel to replace groups of fragments by consolidated meshes whenever possible.
 *
 *  Note that it is not a ModelIterator - just a helper to iterate over the consolidation in parallel to replace the
 *  results of ModelIterators.
 *
 * Why is it needed?
 * -----------------
 *
 * A consolidated fragment list can strongly accelerate rendering for some models by reducing the per-shape work of the
 * WebGLRenderer.
 *
 * However, just putting the consolidated meshes into a scene and rendering it would introduce several problems:
 *  1. Progressive rendering would not work anymore.
 *  2. We could not use the BVH for hierarchical visibility culling anymore.
 *  3. All individual stuff (setFragOff, ghosting, theming) would stop working.
 *
 * These problems are addressed by ConsolidationIterator.
 *
 * How does it work?
 * -----------------
 *
 * There is no perfect solution for the problems above. E.g., progressive rendering with a fine-grained BVH would require
 * to permanently vary the shape order - which would completely revert the performance benefit of consolidation.
 * Therefore, the goal is to achieve a balanced trade-off between a) consolidating as much as possible and b) keeping
 * the advantages of the BVH traversal that is used normally.
 *
 * For this, the BVHIterator traverses the scene as usual. The normal behavior is to return a RenderBatch with
 * individual fragments on each nextBatch call. When using consolidation, we replace each such RenderBatch
 * by a THREE scene in a way that:
 *
 *  - For each fragment f that has not been rendered yet, it contains the consolidated mesh containing f
 *  - It is ensured that each consolidated batch is only used once in a traversal.
 *
 * Note that this means that we have a bit less granularity, i.e., some fragments will be rendered that would be
 * culled otherwise, and progressive rendering will render some fragments earlier than normally. However,
 * this is a necessary trade-off as explained above.
 *
 * What about hiding/ghosting/theming?
 * ------------------------------------
 *
 * Another purpose of this class is to keep per-fragment hiding/ghosting/theming working when using a consolidated FragmentList.
 * At the moment, we use a very simple fallback for this: Whenever a fragment needs any special treatment
 * (e.g., is ghosted), we temporarily disable consolidated meshes and fall back to individual fragments.
 *
 * Limitation: An obvious drawback of this straightforward solution is that consolidation only improves the
 * rendering speed as long as no fragment needs special treatment. As soon as any ghosting/hiding/theming is used,
 * we fall back to original speed.
 *
 * Supporting consolidation and individual fragment modification at once will require some extra work.
 *
 *
 * @constructor
 *  @param {FragmentList}  fragList          - Original fragment list
 *  @param {Consolidation} fragConsolidation - Consolidated representation of a full FragmentList
 */
function ConsolidationIterator(fragList, fragConsolidation) {
    // FragmentList
    var _frags = fragList;
    // Consolidated fragment list
    var _fragConsolidation = fragConsolidation;
    // {Bool[]} Used to track which consolidated shapes have been rendered in the current traversal.
    var _shapeDone = [];
    // If true, we must use original fragments in the current traversal. This flag is determined at the beginning
    // of a traversal and is set whenever a fragment needs special treatment (ghosting/hiding etc.).
    var _consolidationDisabled = false;
    // Each scene replaces a RenderBatch that represents a node in the BVH hierarchy.
    // The RenderBatch of a BVHNode is always the same object. This allows RenderScene to track
    // average fragment times by attaching the avgFrameTime to each object.
    // To keep this working when replacing RenderBatches by THREE.Scenes, the THREE.Scene object of a BVHNode
    // must also keep the same object per bvh node. Therefore, we index the cache by bvhNode index.
    var _sceneCache = []; // {THREE.Scene[]} Reused per traversal
    // some reused temp objects
    var _tempMatrix = new THREE$1.Matrix4();
    var _tempBox = new THREE$1.Box3();
    // get next scene from cache
    function acquireScene(index) {
        // create new scee on first use
        if (!_sceneCache[index]) {
            _sceneCache[index] = new THREE$1.Scene();
        }
        var scene = _sceneCache[index];
        scene.children.length = 0;
        return scene;
    }
    this.getConsolidation = function () {
        return _fragConsolidation;
    };
    /**
     * Called at the beginning of a scene traversal.
     */
    this.reset = function () {
        // reset state to "not used yet" for all consolidated meshes
        _shapeDone.length = null;
        var fragCount = _frags.getCount();
        // Check if any fragment needs special treatment for this traversal.
        // If not, we can use consolidation.
        _consolidationDisabled = false;
        var themingActive = _frags.db2ThemingColor.length > 0;
        for (var fragId = 0; fragId < fragCount; fragId++) {
            var flags = _frags.vizflags[fragId];
            var isGhosted = (flags & MESH_VISIBLE) == 0;
            var isHidden = (flags & MESH_HIDE) != 0;
            var isMoved = (flags & MESH_MOVED) != 0;
            // consider color theming
            var isColored = false;
            if (themingActive) {
                var dbId = _frags.fragments.fragId2dbId[fragId];
                isColored = !!_frags.db2ThemingColor[dbId];
            }
            if (isGhosted || isHidden || isColored || isMoved) {
                // one or more fragments of this container need individual handling.
                // => Fall back to individual fragment rendering.
                _consolidationDisabled = true;
                break;
            }
        }
    };
    this.dispose = function () {
        for (var i = 0; i < _fragConsolidation.meshes.length; i++) {
            var mesh = _fragConsolidation.meshes[i];
            var geom = mesh.geometry;
            if (geom) {
                // In case of later reuse, setting needsUpdate is essential to render it again.
                geom.dispose();
                geom.needsUpdate = true;
            }
        }
        // Note that all consolidation materials are associated with the owning RenderModel and
        // are automatically disposed with the other RenderModel resources.
        // Therefore, we don't dispose them here.
    };
    /**
     * Given a RenderBatch that would normally be rendered next, this function
     * creates a consolidated scene to replace it in a way that:
     *
     *  1. Each fragment f in the batch is included (unless it has already been rendered in this traveral)
     *  2. During traversal, each consolidated mesh is only used once.
     *
     *  @param   {RenderBatch}          renderBatch
     *  @param   {FrustumInstersector}  frustum
     *  @returns {THREE.Scene|RenderBatch} If fragments must be rendered individually, the input RenderBatch
     *           is returned. This happens, e.g., if one or more fragments is ghosted.
     */
    this.consolidateNextBatch = function (renderBatch, frustum) {
        // get bvh node index associated with this RenderBatch. We need this to make sure that
        // a RenderBatch is always replaced by the same THREE.Scene object.
        var nodeIndex = renderBatch.nodeIndex;
        // Fallback: Just use original fragments to make sure that ghosting/hiding/theming keeps working.
        if (_consolidationDisabled || nodeIndex === undefined) {
            return renderBatch;
        }
        // If we used multithreaded consolidation, we must use standard geometry until precomputation is finished.
        if (_fragConsolidation.inProgress) {
            return renderBatch;
        }
        var scene = acquireScene(nodeIndex);
        // For each fragment: Find the consolidated shape that contains it and add it to the scene.
        for (var i = renderBatch.start; i < renderBatch.lastItem; i++) {
            var fragId = renderBatch.indices ? renderBatch.indices[i] : i;
            // find consolidated shape containing this fragment
            var meshIndex = _fragConsolidation.fragId2MeshIndex[fragId];
            var mesh = null;
            if (meshIndex === -1) {
                // If the original geometry was missing already, just skip the fragment
                if (!_frags.getGeometry(fragId)) {
                    continue;
                }
                // By design, a FragmentList consolidation must always have replacements for
                // each fragment. So, something must have failed here.
                // Note that we cannot simply add single meshes by _frags.getVisMesh(),
                // because getVizMesh() always return the same (reused) object.
                THREE$1.warn("Warning: Missing fragment in consolidation. Consolidation disabled.");
                return renderBatch;
            }
            // Skip consolidated shape if it has already been used in this traversal.
            if (_shapeDone[meshIndex]) {
                continue;
            }
            // Apply frustum culling. Some related considerations:
            //
            //  1. Instead of culling per container mesh, we apply culling based on original fragments.
            //     Advantages:
            //      - Since merged fragments may be arbitrarily distributed, the culling granularity
            //        of original fragments is significantly higher.
            //      - When using progressive rendering, the per-fragment culling avoids that we
            //        are rendering containers too early if only distant fragments of them are visible.
            //
            //  2. Simply using RenderBatch.applyVisibility() on the original batch caused some noticable
            //     frame rate hickups for some test models (e.g. NWD with ~284K fragments). Also because the
            //     BVH cannot be too fine-grained when using consolidation.
            //
            //     The advantage of doing it here is: As soon as a single fragment of a consolidated mesh
            //     passes the frustum test, the frustum check is skipped for all other contained fragments.
            _frags.getWorldBounds(fragId, _tempBox);
            if (!frustum.intersectsBox(_tempBox)) {
                continue;
            }
            // use this consolidated mesh
            mesh = _fragConsolidation.meshes[meshIndex];
            // mark container mesh as used so that we don't render it again in this traversal
            _shapeDone[meshIndex] = true;
            // add container
            scene.children.push(mesh);
        }
        // use original bbox, renderImportance, and camera distance. Note that the consolidation may actually have another bbox,
        // because it doesn't contain exactly the same fragments. However, recomputing it would
        // just inappropriately distort priorities, because it may contain instances far outside
        // the current bvh node.
        scene.boundingBox = renderBatch.boundingBox;
        scene.renderImportance = renderBatch.renderImportance;
        // adopt sortObjects flag from original RenderBatch - so that RenderScene can use it to detect which
        // scenes contain transparency.
        scene.sortObjects = renderBatch.sortObjects;
        return scene;
    };
    // enum to describe in which way a fragment has been rendered.
    var ConsolidationType = {
        Merged: 1,
        Instanced: 2,
        // are sharing the same geometry.
        Original: 3 // Fragment was not combined with others and is still sharing the original fragment's geometry
        // and material.
    };
    /**
     *  Checks if a given geometry is instanced, the result of merging, or original fragment geometry.
     *
     *   @param {THREE.Mesh} currently used render proxy
     *   @param {Number}     fragId represented by this proxy
     **/
    function getConsolidationType(geom) {
        if (geom.numInstances) {
            // This geom combines multiple fragments using instancing
            // Note that we also enter this section if numInstances==1. This is correct, because numInstances
            // is always undef if no instance buffer is used.
            return ConsolidationType.Instanced;
        } else if (geom.attributes.id) {
            // When merging fragments, we always use per-vertex ids.
            return ConsolidationType.Merged;
        }
        return ConsolidationType.Original;
    }
    /**
     *   Checks which type of consolidation has been used to represent a given fragment in the last
     *  rendering traversal.
     *
     *   @returns {ConsolidationType}
     */
    function getFragmentConsolidationType(fragId) {
        // Check if consolidation was used for this fragment in last frame.
        if (_consolidationDisabled) {
            // The container was not used last frame. The fragment was rendered with original geometry.
            return ConsolidationType.Original;
        }
        // Find consolidated mesh that contains fragId.
        var meshIndex = _fragConsolidation.fragId2MeshIndex[fragId];
        // This fragment was represented using a container mesh from the consolidated scene.
        // If this mesh was created by instancing or merging, it is tagged with a consolidation type.
        var container = _fragConsolidation.meshes[meshIndex];
        var geom = container.geometry;
        return getConsolidationType(geom);
    }
    /** Updates a given render proxy mesh to make sure that it matches exactly with the fragment's representation
     *  used in the last rendered frame.
     *
     *   @param {THREE.Mesh} currently used render proxy
     *   @param {Number}     fragId represented by this proxy
     **/
    this.updateRenderProxy = function (proxy, fragId) {
        // if the proxy has no valid geometry, do nothing
        if (!proxy.geometry || !proxy.geometry.attributes) {
            return;
        }
        // check which type of geometry has been used in last rendering traversal (See ConsolidationType enum)
        var requiredType = getFragmentConsolidationType(fragId);
        var currentType = getConsolidationType(proxy.geometry);
        // if type is already correct, we are done.
        if (currentType == requiredType) {
            return;
        }
        // get original fragment geometry
        var origGeom = _frags.getGeometry(fragId);
        // get container geometry that represents the fragment in the consolidation
        var containerIndex = _fragConsolidation.fragId2MeshIndex[fragId];
        var container = _fragConsolidation.meshes[containerIndex];
        if (requiredType === ConsolidationType.Original) {
            // recover original geometry, material, and matrix
            proxy.geometry = origGeom;
            proxy.material = _frags.getMaterial(fragId);
            _frags.getWorldMatrix(fragId, proxy.matrix);
        } else if (requiredType === ConsolidationType.Instanced) {
            // This fragment was rendered using an instanced shape.
            // replace proxy geometry by instanced mesh with single instance
            _frags.getWorldMatrix(fragId, _tempMatrix);
            var dbId = _frags.fragments.fragId2dbId[fragId];
            // create proxy mesh with 1-element instance buffer
            var builder = new InstanceBufferBuilder(origGeom, 1);
            builder.addInstance(_tempMatrix, dbId);
            proxy.geometry = builder.finish();
            // use container material (needed to activate instancing)
            proxy.material = container.material;
            // reset matrix to identity, because the transform is done per instance
            proxy.matrix.identity();
        } else {
            // This fragment was rendered using a merged shape
            // create consolidation proxy which just contains the single fragment with baked matrix
            _frags.getWorldMatrix(fragId, _tempMatrix);
            _frags.getWorldBounds(fragId, _tempBox);
            dbId = _frags.fragments.fragId2dbId[fragId];
            proxy.geometry = mergeGeometries([origGeom], _tempMatrix.elements, [dbId], _tempBox);
            // share container material
            proxy.material = container.material;
            // reset matrix to identity, because the transform is baked into the vertex buffer
            proxy.matrix.identity();
        }
        // make sure that WebGLRenderer does not keep an outdated cache object. Without this line,
        // WebGLRenderer will still use the previous GeometryBuffer if it is already cached.
        proxy.dispatchEvent({ type: 'removed' });
    };
}

function ModelIteratorBVH() {
    var _frags;
    // Nodes in the BVH, in an array for easy access to all of them.
    // There are up to two trees, one for opaques, one for transparent objects.
    // These are normally listed top-down, in a flattened list, e.g., if all the objects
    // in the scene were transparent, _bvhNodes[0] = 0, and the 0 node would have not
    // children and no primitives, as this node would contain all the opaque fragments,
    // of which there are none. The transparent tree is always in _bvhNodes[1], and might
    // look something like this:
    //     1
    //  2     3
    // 4 5   6 7
    // with the children 4-7 each containing a RenderBatch of some number of fragments. Note
    // that inner nodes can also have RenderBatches.
    var _bvhNodes = null;
    // There's indirection for each RenderBatch. A RenderBatch contains a number of fragments.
    // Rather than an array per RenderBatch, a single array is accessed by all RenderBatches.
    // The primitives are in a list sorted by surface area. We preserve this. In this
    // _bvhFragOrder array we by a flattened list of children fragment indices. So child 4,
    // above, might have 3 objects, and their indices might be [291 12 55].
    // primStart and primCount access this array.
    // Also see bvh_partition and the comment there.
    var _bvhFragOrder = null;
    // _bvhScenes is a sparse array of RenderBatches, each RenderBatch has a few fragments.
    // Only those elements in the array that have a RenderBatch are defined.
    var _bvhScenes = null;
    // What is the containment state of this node, if known? Is either CONTAINMENT_UNKNOWN
    // or INTERSECTS or CONTAINS. If CONTAINS, we don't have to run the frustum cull
    // test, saving a few percent in speed.
    var _bvhContainment = null;
    var _bvhNodeQueue = null,
        _bvhNodeAreas = null,
        _bvhHead,
        _bvhTail;
    var _bvhLIFO = 1;
    var _bvhPrioritizeScreenSize = true;
    var _bvhOpaqueDone = false;
    var _bvhOpaqueSkipped = false; // true if skipOpaqueShapes has been called in the current traversal.
    var _tmpBox = new THREE$1.Box3();
    var _tmpBox2 = new THREE$1.Box3();
    var _frustum;
    var _done = false;
    var _resetVisStatus = true;
    //var _time0 = 0;
    this.initialize = function (renderModelLinear, nodes, primitives, options) {
        _frags = renderModelLinear.getFragmentList();
        if (options && options.hasOwnProperty("prioritize_screen_size")) {
            _bvhPrioritizeScreenSize = options.prioritize_screen_size;
        }
        _bvhFragOrder = primitives;
        _bvhScenes = new Array(nodes.nodeCount);
        _bvhContainment = new Int8Array(nodes.nodeCount);
        _bvhNodes = nodes;
        _bvhNodeQueue = new Int32Array(nodes.nodeCount + 1);
        _bvhNodeAreas = new Float32Array(nodes.nodeCount);
        // Choose a different render batch class if fragments on demand loading enabled.
        var RBClass = _frags.onDemandLoadingEnabled() ? RenderBatchLess : RenderBatch;
        // walk through all the nodes in the BVH
        for (var i = 0; i < nodes.nodeCount; i++) {
            var primCount = nodes.getPrimCount(i);
            // does this node have real objects in it?
            if (primCount) {
                // This node has real objects in it, typically 2-4, in some arbitrary order.
                _bvhScenes[i] = new RBClass(_frags, _bvhFragOrder, nodes.getPrimStart(i), primCount);
                // These are set manually, because we will not be adding fragments to the
                // render batch one by one -- the fragments are already loaded.
                _bvhScenes[i].lastItem = _bvhScenes[i].start + primCount;
                _bvhScenes[i].numAdded = primCount;
                _bvhScenes[i].nodeIndex = i;
                if (nodes.getFlags(i) & 8) {
                    _bvhScenes[i].sortObjects = true; //scene contains transparent objects
                }
                nodes.getBoxThree(i, _bvhScenes[i].boundingBox);
            }
        }
    };
    // note: fragId and mesh are not used in this function
    this.addFragment = function (fragId, mesh) {};
    this.reset = function (frustum) {
        _frustum = frustum;
        _bvhHead = 0;
        _bvhTail = 0;
        // means "unknown containment state"
        _bvhContainment[0] = _bvhContainment[1] = FrustumIntersector.CONTAINMENT_UNKNOWN;
        // prime the pump: the first entry is set to BVH node 0,
        // which is the first node in the first hierarchy (the opaque one) that we'll examine.
        // The ++ here is just for consistency; we could have set tail to 1
        // and used 0 as the index. _bvhTail will immediately get decremented to 0 by nextBatch;
        // it's incremented here to initially pass the while() loop there.
        _bvhNodeQueue[_bvhTail++] = 0;
        _bvhOpaqueDone = false;
        _bvhOpaqueSkipped = false;
        _done = false;
        //_time0 = Date.now();
        if (_resetVisStatus) {
            var scenes = _bvhScenes;
            var len = scenes.length;
            for (var i = 0; i < len; ++i) {
                var scene = scenes[i];
                if (scene && scene.resetVisStatus) {
                    scene.resetVisStatus();
                }
            }
            _resetVisStatus = false;
        }
    };
    // Used to insert nodes into the (sorted) render queue based on
    // a heuristic other than strict front to back or back to front order.
    // Currently we always use this for sorting by screen area.
    function insertNode(idx) {
        //This is basically a single sub-loop of an insertion sort.
        var val = _bvhNodeAreas[idx];
        var j = _bvhTail;
        if (_bvhLIFO) {
            // For LIFO we insert the largest at the end of the list, since they
            // are the first to be popped
            while (j > _bvhHead && _bvhNodeAreas[_bvhNodeQueue[j - 1]] > val) {
                _bvhNodeQueue[j] = _bvhNodeQueue[j - 1];
                j--;
            }
        } else {
            // For FIFO we insert the largest at the front of the list.
            while (j > _bvhHead && _bvhNodeAreas[_bvhNodeQueue[j - 1]] < val) {
                _bvhNodeQueue[j] = _bvhNodeQueue[j - 1];
                j--;
            }
        }
        _bvhNodeQueue[j] = idx;
        _bvhTail++;
    }
    this.nextBatch = function () {
        if (!_bvhOpaqueSkipped && !_bvhOpaqueDone && _bvhHead === _bvhTail) {
            //If we are done with the opaque nodes, queue the transparent ones
            //before processing the contents of the last opaque node
            _bvhNodeQueue[_bvhTail++] = 1; //root of transparent subtree is at index 1
            _bvhOpaqueDone = true;
        }
        // _bvhHead and _bvhTail are indices into the BVH node list. For the opaque objects
        // these start at 0 and 1, respectively. The idea here is to work through the bounding
        // volume hierarchy, with inner nodes sorted into the list by large-to-small screen area
        // (or front-to-back, or back-to-front) order as we go. The way this loop ends is when
        // nothing is on the BVH node stack, or a render batch of stuff to render is found.
        // The next time this method is called, the current _bvhHead and _bvhTail values pick
        // up where they left off, continuing to traverse the tree, until another batch is found
        // or the stack (list) is emptied.
        // Note: this is a breadth-first traversal, but render batches can and do get returned
        // before the whole tree is traversed, because these can be found in inner nodes.
        // This means that there may be nodes with larger screen areas that come later on.
        while (_bvhHead !== _bvhTail) {
            // Retrieve node index for what to process in the BVH. _bvhNodeQueue contains the indices
            // of the node(s) in the BVH that are to be processed. 
            // For LIFO, for example, when the nodeIdx is first retrieved, _bvhTail initially
            // goes to 0, and so grabs the index at location 0 in _bvhNodeQueue, typically the top of
            // the opaque tree. The rest of this loop may add to this queue, and/or return fragments to
            // render, in which case it exits. If nothing got returned (yet) and the loop continues,
            // the next time around through this loop, the last
            // BVH node put on this _bvhNodeQueue stack (if LIFO is true) is retrieved (if not LIFO,
            // the first object on the list is retrieved and _bvhHead is incremented).
            // Inner nodes will add their two children in proper order to _bvhNodeQueue and increment _bvhTail, twice.
            var nodeIdx = _bvhLIFO || _bvhOpaqueDone ? _bvhNodeQueue[--_bvhTail] : _bvhNodeQueue[_bvhHead++];
            // Is box already found to be contained? This happens when a box's parent is fully contained.
            // We can then avoid the frustum test.
            var intersects = _bvhContainment[nodeIdx];
            if (intersects !== FrustumIntersector.CONTAINS) {
                // could be outside or intersecting, so do test
                _bvhNodes.getBoxThree(nodeIdx, _tmpBox);
                intersects = _frustum.intersectsBox(_tmpBox);
            }
            //Node is entirely outside, go on to the next node
            if (intersects !== FrustumIntersector.OUTSIDE) {
                var child = _bvhNodes.getLeftChild(nodeIdx);
                var isInner = child !== -1;
                var firstIdx, secondIdx;
                //Is it inner node? Add children for processing.
                if (isInner) {
                    var flags = _bvhNodes.getFlags(nodeIdx);
                    var reverseAxis = _frustum.viewDir[flags & 3] < 0 ? 1 : 0;
                    var firstChild = flags >> 2 & 1;
                    var transparent = flags >> 3 & 1;
                    var depthFirst = _bvhLIFO || _bvhOpaqueDone ? 1 : 0;
                    var areaFirst = 0,
                        areaSecond = 0;
                    // For opaque objects, use the screen size to sort the two children,
                    // or front to back order (back to front for transparent objects).
                    if (_bvhPrioritizeScreenSize && !_bvhOpaqueDone) {
                        //If traversing based on visible screen area, we have to
                        //compute the area for each child and insert them into
                        //the queue accordingly.
                        firstIdx = child + firstChild;
                        secondIdx = child + 1 - firstChild;
                        _bvhNodes.getBoxThree(firstIdx, _tmpBox);
                        _bvhNodeAreas[firstIdx] = areaFirst = _frustum.projectedBoxArea(_tmpBox, intersects === FrustumIntersector.CONTAINS);
                        _bvhNodes.getBoxThree(secondIdx, _tmpBox);
                        _bvhNodeAreas[secondIdx] = areaSecond = _frustum.projectedBoxArea(_tmpBox, intersects === FrustumIntersector.CONTAINS);
                        // "worst case" containment is recorded for later examination.
                        _bvhContainment[firstIdx] = _bvhContainment[secondIdx] = intersects;
                        // Insert each node in the right place based on screen area,
                        // so that the queue (or stack, if LIFO traversal) is kept sorted
                        // at every step of the way.
                        // Note that with LIFO, for example, the larger object is put last on
                        // the list (a stack), since we want to pop this one off first.
                        if (areaFirst > 0) insertNode(firstIdx);
                        if (areaSecond > 0) insertNode(secondIdx);
                    } else {
                        //Traversal by view direction.
                        //Reverse order if looking in the negative of the child split axis
                        //Reverse order if we are traversing last first
                        //If node contains transparent objects, then reverse the result so we traverse back to front.
                        //In other words, reverse the order if an odd number of flags are true.
                        if (reverseAxis ^ depthFirst ^ transparent) firstChild = 1 - firstChild;
                        firstIdx = child + firstChild;
                        secondIdx = child + 1 - firstChild;
                        _bvhNodeQueue[_bvhTail++] = firstIdx;
                        _bvhNodeAreas[firstIdx] = -1; //TODO: This has to be something based on camera distance
                        //so that we can draw transparent back to front when multiple models are mixed
                        _bvhNodeQueue[_bvhTail++] = secondIdx;
                        _bvhNodeAreas[secondIdx] = -1;
                        // "worst case" containment is recorded for later examination.
                        _bvhContainment[firstIdx] = _bvhContainment[secondIdx] = intersects;
                    }
                }
                // Are there graphics in the node? Then return its scene, i.e. its RenderBatch.
                // Inner nodes with children can and do have render batches of their own.
                // This works against a pure screen=area or front-to-back ordering, as
                // these fragments will always get returned first, before further traversal of the tree.
                var prims = _bvhNodes.getPrimCount(nodeIdx);
                if (prims !== 0) {
                    var scene = _bvhScenes[nodeIdx];
                    scene.renderImportance = _frustum.projectedBoxArea(scene.boundingBox, intersects === FrustumIntersector.CONTAINS);
                    //NOTE: Frustum culling for the RenderBatch is done in
                    //RenderBatch.applyVisibility, so we don't need it here.
                    //Just return the batch and it will get cull checked later.
                    //TODO: May be we want to move the check to here, but then the linear iterator will also need to start checking.
                    /*
                     var whichBox = (_drawMode === RENDER_HIDDEN) ? scene.boundingBoxHidden : scene.boundingBox;
                      //If the geometry is attached to an inner node and we know
                     //it's not fully contained, we can narrow down the intersection
                     //by checking the box of just the inner node's geometry.
                     //The check for the node box itself also includes the children so it could be bigger.
                     if (intersects !== CONTAINS && isInner)
                     intersects = _frustum.intersectsBox(whichBox);
                      //Turn off frustum culling for the batch if it's fully contained
                     scene.frustumCulled = (intersects !== FrustumIntersector.CONTAINS);
                      if (intersects !== FrustumIntersector.OUTSIDE)
                     return scene;
                     */
                    return scene;
                }
            }
            if (!_bvhOpaqueDone && !_bvhOpaqueSkipped && _bvhHead === _bvhTail) {
                //If we are done with the opaque nodes, queue the transparent ones
                //before processing the contents of the last opaque node
                _bvhNodeQueue[_bvhTail++] = 1; //root of transparent subtree is at index 1
                _bvhOpaqueDone = true;
            }
        }
        //var time1 = Date.now();
        //var msg = "BVH traversal time: " + (time1 - _time0);
        //console.log(msg);
        _done = true;
        return null;
    };
    this.skipOpaqueShapes = function () {
        if (!_bvhOpaqueDone && !_bvhOpaqueSkipped) {
            // start traversal of transparent hierarchy
            _bvhHead = 0;
            _bvhTail = 0;
            _bvhNodeQueue[_bvhTail++] = 1; //root of transparent subtree is at index 1
            _bvhOpaqueSkipped = true;
        }
    };
    function updateBVHRec(nodeIdx) {
        var child = _bvhNodes.getLeftChild(nodeIdx);
        if (child !== -1) {
            updateBVHRec(child);
            updateBVHRec(child + 1);
        }
        _tmpBox.makeEmpty();
        if (child !== -1) {
            _bvhNodes.getBoxThree(child, _tmpBox2);
            _tmpBox.union(_tmpBox2);
            _bvhNodes.getBoxThree(child + 1, _tmpBox2);
            _tmpBox.union(_tmpBox2);
        }
        var prims = _bvhNodes.getPrimCount(nodeIdx);
        if (prims) {
            _tmpBox.union(_bvhScenes[nodeIdx].boundingBox);
            _tmpBox.union(_bvhScenes[nodeIdx].boundingBoxHidden);
        }
        _bvhNodes.setBoxThree(nodeIdx, _tmpBox);
    }
    this.getVisibleBounds = function (visibleBounds, visibleBoundsWithHidden) {
        for (var i = 0; i < _bvhScenes.length; i++) {
            var s = _bvhScenes[i];
            if (!s) continue;
            s.calculateBounds();
            visibleBounds.union(s.boundingBox);
            visibleBoundsWithHidden.union(s.boundingBox);
            visibleBoundsWithHidden.union(s.boundingBoxHidden);
        }
        //Also update all bounding volume tree nodes' bounds.
        //If objects move too much this will make the BVH less effective.
        //However, this only happens during explode or animation, so it shouldn't
        //be an issue. We can always rebuild the BVH in case objects really move a lot.
        updateBVHRec(0); //opaque root
        updateBVHRec(1); //transparent root
    };
    this.rayCast = function (raycaster, intersects, dbIdFilter) {
        var nodeStack = [1, 0];
        var pt = new THREE$1.Vector3();
        while (nodeStack.length) {
            var nodeIdx = nodeStack.pop();
            _bvhNodes.getBoxThree(nodeIdx, _tmpBox);
            // Expand bounding box a bit, to take into account axis aligned lines
            _tmpBox.expandByScalar(0.5);
            var xPt = raycaster.ray.intersectBox(_tmpBox, pt);
            if (xPt === null) continue;
            var child = _bvhNodes.getLeftChild(nodeIdx);
            if (child !== -1) {
                nodeStack.push(child);
                nodeStack.push(child + 1);
            }
            var prims = _bvhNodes.getPrimCount(nodeIdx);
            if (prims !== 0) {
                var scene = _bvhScenes[nodeIdx];
                scene.raycast(raycaster, intersects, dbIdFilter);
            }
        }
    };
    /*
        this.getRenderProgress = function() {
            return _renderCounter / _bvhScenes.length;
        };
    */
    this.getSceneCount = function () {
        return _bvhScenes.length;
    };
    this.getGeomScenes = function () {
        return _bvhScenes;
    };
    this.resetVisStatus = function () {
        _resetVisStatus = true;
    };
    this.done = function () {
        return _done;
    };
}

/**
 * RenderScene
 * Represents the full graphical scene.
 * Used for iterating through the scene for progressive rendering,
 * hit testing, etc.
 * @constructor
 * */
function RenderScene() {
    var _needsRender = false; // if true, scene needs a re-render due to a paging-failure in last render traversal
    var _done = false; // true indicates that progressive rendering has finished 
    // since last reset call, i.e. all batches have been traversed.
    var _renderCounter = 0; // counts RenderBatches processed so far in the current render traversal.
    var _models = []; // {RenderModel[]} - All RenderModels to be rendered.
    var _candidateScenes = []; // {RenderBatch[]} - _candidateScenes[i] points to the next batch to be rendered from _models[i]. Same length as _models.
    var _previousScenes = []; // {RenderBatch[]} - _previousScenes[i] points to the previous batch rendered from _models[i]. Same length as _models.
    var _tmpBox = new THREE$1.Box3(); // Reused for return values of getVisibleBounds() 
    var _hiddenModels = []; // {RenderModel[]} - All models that are currently loaded, but excluded from rendering/selection etc.
    var _frustum = new FrustumIntersector(); // updated for current camera in this.reset().
    var _raycaster = new THREE$1.Raycaster();
    //var _frameStamp    = 0;             // increased with each render traversal restart; set, not used. For debug?
    var _perf = performance; // shortcut to browser-provided performance object
    var _prevPagingStatus = PAGEOUT_NONE;
    // During motion, we usually restart rendering at any frame, i.e. a frame is never resumed. When setting this
    // option, we exploit this to render transparent shapes earlier. (and skip less important opaque ones)
    this.enableNonResumableFrames = false;
    // Determines how much of the render budget is reserved for transparent shapes.
    // E.g., a value of 0.1 means that 10% of the render budget is spent for transparent shapes.
    this.budgetForTransparent = 0.1;
    // If true, we assume the current frame not to be resumed and
    // render some transparent shapes before the opaque ones are done.
    var _frameWillNotBeResumed = false;
    // If _frameWillNotBeResumed is true, this array collects transparent scenes and renders them
    // back-to-front at the end of a frame.
    var _transparentScenes = []; // {THREE.Scene|RenderBatch}[]
    // needed for back-to-front sorting of transparent objects (see renderTransparentScenes)
    var _camera = null;
    this.frustum = function () {
        return _frustum;
    };
    this.addModel = function (renderModel) {
        _models.push(renderModel);
        _candidateScenes.length = _models.length;
        _previousScenes.length = _models.length;
    };
    this.removeModel = function (renderModel) {
        var idx = _models.indexOf(renderModel);
        if (idx >= 0) {
            _models.splice(idx, 1);
        }
        _candidateScenes.length = _models.length;
        _previousScenes.length = _models.length;
        return idx >= 0;
    };
    this.addHiddenModel = function (renderModel) {
        var idx = _hiddenModels.indexOf(renderModel);
        if (idx < 0) {
            _hiddenModels.push(renderModel);
        }
        return idx < 0;
    };
    this.removeHiddenModel = function (renderModel) {
        var idx = _hiddenModels.indexOf(renderModel);
        if (idx >= 0) {
            _hiddenModels.splice(idx, 1);
        }
        return idx >= 0;
    };
    this.isEmpty = function () {
        return _models.length === 0;
    };
    this.needsRender = function () {
        return _needsRender;
    };
    this.resetNeedsRender = function () {
        _needsRender = false;
    };
    /**
     *  For each sub-scene, keep a running average of how long it took to render over the
     *  last few frames.
     *   @param {THREE.Scene|RenderBatch} scene
     *   @param {number}                  frameTime - last measured rendering time in ms
     */
    function updateAvgFrameTime(scene, frameTime) {
        if (scene.avgFrameTime === undefined) scene.avgFrameTime = frameTime;else {
            scene.avgFrameTime = 0.8 * scene.avgFrameTime + 0.2 * frameTime;
        }
    }
    /**
     *  Renders transparent scenes in back-to-front order.
     *
     *  @param {RenderCB}      renderObjectsCB - Called for each element of the scenes array
     *  @param {UnifiedCamera} camera
     *  @param {RenderBatch[]} scenes          - Array of RenderBatches (or THREE.Scene with .boundingBox property)
     */
    function renderTransparentScenes(scenes, camera, renderObjectCB) {
        // compute camera distance for each scene
        var i, scene;
        for (i = 0; i < scenes.length; i++) {
            scene = scenes[i];
            scene.cameraDistance = scene.boundingBox.distanceToPoint(camera.position);
        }
        // sort by decreasing camera distance
        var sortOrder = function sortOrder(a, b) {
            return b.cameraDistance - a.cameraDistance;
        };
        scenes.sort(sortOrder);
        // render each scene and update average frame time
        var t0 = performance.now();
        for (i = 0; i < scenes.length; i++) {
            // render scene
            scene = scenes[i];
            renderObjectCB(scene);
            // measure elapsed time
            var t1 = performance.now();
            var delta = t1 - t0;
            t0 = t1;
            // track average frame time
            updateAvgFrameTime(scene, delta);
        }
    }
    /**
     * Indicates if the current traversal is done with the assumption that this frame will not be resumed.
     *  @returns {boolean}
     */
    this.frameResumePossible = function () {
        return !_frameWillNotBeResumed;
    };
    /**
      * Incrementally render some meshes until we run out of time.
      *  @param {RenderCB} cb            - Called that does the actual rendering. Called for each RenderBatch to be rendered.
      *  @param {number}   timeRemaining - Time in milliseconds that can be spend in this function call.
      *  @param {object}   pagingOptions - Options passed to the paging method
      *  @returns {number} Remaining time left after the call. Usually <=0.0 if the frame could not be fully finished yet.
      *
      * @callback RenderScene~RenderCB
      * @param {RenderBatch} scene
      */
    this.renderSome = function (renderObjectCB, timeRemaining, pagingOptions) {
        var t0 = _perf.now(),
            t1;
        //If the render queue is just starting to render
        //we will remember how many items we draw on the first pass
        //and keep drawing the same number of items on subsequent first passes,
        //until we get to a second renderSome pass. This is to make sure that
        //while moving the camera in a single motion, the number of items we draw
        //does not vary, which causes some ugly flashing -- because the render time
        //per item varies a little from frame to frame.
        var isBeginFrame = _renderCounter === 0;
        // reserve some time for transparent shapes.
        var timeForTransparent = this.budgetForTransparent * timeRemaining;
        // repeat until time budget is consumed...
        var model;
        while (1) {
            //Find the best candidate render batch to render now -- in case
            //there are multiple models.
            //TODO: In case a huge number of models is loaded, we may have to
            //rethink the linear loop below and use some priority heap or somesuch.
            var candidateIdx = 0;
            var scene = null;
            for (var iq = 0; iq < _candidateScenes.length; iq++) {
                // candidate is the next RenderBatch to be processed from _models[q] 
                var candidate = _candidateScenes[iq];
                model = _models[iq];
                if (!candidate) _candidateScenes[iq] = candidate = model.nextBatch();
                // If the camera is in motion and the time for opaque scenes is over, continue with transparent shapes.
                var skipOpaque = _frameWillNotBeResumed && timeRemaining < timeForTransparent;
                if (skipOpaque) {
                    // check if the next candidate is still an opaque one. Note that the .sortObjects
                    // flag indicates whether a RenderBatch contains transparent objects.
                    var isOpaque = candidate && !candidate.sortObjects;
                    if (isOpaque) {
                        // skip current candidate and use the first available transparent scene instead
                        model.skipOpaqueShapes();
                        candidate = model.nextBatch();
                    }
                }
                if (candidate === null) {
                    // No more batches to render from this model
                    continue;
                }
                // If all previous candidates were null, _candidateScenes[q] is obviously the best one so far.
                if (!scene) {
                    candidateIdx = iq;
                    scene = candidate;
                }
                // Choose current candidate only if its renderImportance is higher.
                // The renderImportance of RenderBatches is set by model iterators.
                if (candidate.renderImportance > scene.renderImportance) {
                    candidateIdx = iq;
                    scene = candidate;
                }
            }
            // Render the batch we chose above and determine whether to continue the loop
            if (scene) {
                // If this is a 2d scene, with onDemandLoading, then we need to
                // worry about skipping buffers in draw order.
                if (_models[candidateIdx].is2d() && _models[candidateIdx].getFragmentList() && _models[candidateIdx].getFragmentList().onDemandLoadingEnabled()) {
                    var previousScene = _previousScenes[candidateIdx];
                    // drawOrderRender keeps track of where fragments were drawn out
                    // of order. If previous buffers drew fragments out of order, then
                    // all fragments in the buffer are out of order, so we mark the
                    // out of order position at the start of the scene. Otherwise mark
                    // the out of order at the end of the scene, where it may be
                    // modified by RenderBatchLess.forEach. 
                    scene.drawOrderRender = previousScene && previousScene.drawOrderRender < previousScene.lastItem ? scene.start : scene.lastItem;
                    _previousScenes[candidateIdx] = scene;
                }
                //Fetch a new render batch from the model that we took the
                //current batch from.
                _candidateScenes[candidateIdx] = _models[candidateIdx].nextBatch();
                // track how many batches we processed in the current traversal.
                _renderCounter++;
                // If we are in a non-resumable frame, we try to get the most important ones of opaque and
                // transparent scenes. Therefore, the traversal of transparent scenes will also be ordered
                // by decreasing priority just like for opaque ones. For correct rendering, however,
                // we cannot render them directly here. Instead, we must collect them first and render them
                // back-to-front at the end of the function.
                if (scene.sortObjects && _frameWillNotBeResumed) {
                    // defer to the end of the frame
                    _transparentScenes.push(scene);
                    // reserve frame time based on past rendering times. Just for the very first use,
                    // we use an initial guess value as fallback.
                    timeRemaining -= scene.avgFrameTime === undefined ? 0.05 : scene.avgFrameTime;
                } else {
                    // do the actual rendering
                    renderObjectCB(scene);
                    if (scene.hasOwnProperty("drawEnd")) scene.drawEnd = scene.lastItem;
                    // get time that we spent for rendering of the last batch
                    t1 = _perf.now();
                    var delta = t1 - t0; // in milliseconds
                    t0 = t1;
                    //For each sub-scene, keep a running average
                    //of how long it took to render over the
                    //last few frames.
                    updateAvgFrameTime(scene, delta);
                    // update remaining time
                    // Note that we don't do accurate timing here, but compute with average values instead.
                    // In this way, the number of rendered batches is more consistent across different frames
                    timeRemaining -= scene.avgFrameTime;
                }
                if (_models[candidateIdx].getFragmentList() && _models[candidateIdx].getFragmentList().onDemandLoadingEnabled()) {
                    var start = scene.start,
                        end = scene.lastItem;
                    var vizflags = _models[candidateIdx].getFragmentList().vizflags;
                    var indices = scene.getIndices();
                    var idx;
                    while (start < end) {
                        idx = indices ? indices[start] : start;
                        if (vizflags[idx] & MESH_DRAWN) vizflags[idx] = (vizflags[idx] | MESH_TRAVERSED) & ~MESH_DRAWN;
                        ++start;
                    }
                }
                // Check if we should exit the loop...
                if (timeRemaining <= 0) {
                    break;
                }
            } else {
                // No more batches => Frame rendering finished, if all models are loaded
                // While 2d models are loading we don't consider them done. This means
                // that the model iterators and loaders can't add a batch to their
                // scene list, until the batch is filled.
                _done = true;
                for (var i = 0; i < _models.length; ++i) {
                    model = _models[i];
                    if (model && model.is2d() && !model.isLoadDone() && !model.getFragmentList().onDemandLoadingEnabled()) {
                        _done = false;
                        break;
                    }
                }
                break;
            }
        }
        // TODO - need to make this stuff below a separate thing?
        // Doesn't quite work on multiple models yet, so now only do paging update on whatever first model.
        // ??? Some possible ways of improving this, 
        // ??? 1. always do paging on the biggest one according to fragments count.
        // ??? 2. or can try to paging equal percentage of geometry from each model until the totally number below the limit.
        // ??? 
        var pagingStatus = _models[0].frameUpdatePaging(isBeginFrame, pagingOptions);
        if (_prevPagingStatus != pagingStatus || _models[0].needResumeNextFrame()) {
            _needsRender = true;
            _prevPagingStatus = pagingStatus;
        }
        // Render some deferred transparent shapes (_transparentShapes). Note that this array will
        // usually be empty if _frameWillNotBeResumed is false
        if (_transparentScenes.length > 0) {
            renderTransparentScenes(_transparentScenes, _camera, renderObjectCB);
            // all scenes processed. Clear array.
            _transparentScenes.length = 0;
        }
        return timeRemaining;
    };
    /** Resets the scene traversal
     *   @param  {UnifiedCamera}
     *   @param  {number}        drawMode     - E.g., globals.RENDER_NORMAL. See Viewer3DImpl.js
     *   @param: {number}        [resetType]  - Must be one of globals.RESET_NORMAL, globals.RESET_REDRAW or globals.RESET_RELOAD.
     *                                          Only used when on demand loading is enabled. RESET_RELOAD will reload and redraw
     *                                          geometry. RESET_REDRAW will redraw geometry. RESET_NORMAL will only redraw geometry
     *                                          that hasn't already been drawn. If undefined RESET_NORMAL is used.
     *   @param: {boolean}       [highlight]  - True if the reset is done for highlighting.
     */
    this.reset = function (camera, drawMode, resetType, highlight) {
        //_frameStamp++;
        _done = false;
        _renderCounter = 0;
        this.resetNeedsRender();
        //Calculate the viewing frustum
        //TODO: same math is done in the renderer also. We could unify
        _frustum.reset(camera);
        _frustum.areaCullThreshold = PIXEL_CULLING_THRESHOLD;
        if (!_models.length) return;
        // If the camera is in-motion, we assume the frame not to be resumed. This allows us to render transparent shapes
        // earlier. This special treatment is only used/needed for the main scene pass.
        _frameWillNotBeResumed = this.enableNonResumableFrames && resetType == RESET_RELOAD && drawMode === RENDER_NORMAL;
        _camera = camera;
        //Begin the frustum based scene iteration process per model.
        //A "Model" is all the objects to display. There's typically one model in a scene, so length is 1. 
        for (var i = 0; i < _models.length; i++) {
            // decide what iterator to use, usually the BVH iterator
            _models[i].resetIterator(camera, _frustum, drawMode, resetType, highlight);
            // get the first RenderBatch (some set of fragments) to render.
            _candidateScenes[i] = _models[i].nextBatch();
            _previousScenes[i] = null;
        }
    };
    this.isDone = function () {
        return _done || this.isEmpty();
    };
    // Visibility and highlighting methods: see RenderModel.js for details.
    this.setAllVisibility = function (value) {
        for (var i = 0; i < _models.length; i++) {
            _models[i].setAllVisibility(value);
        }
    };
    this.hideLines = function (hide) {
        for (var i = 0; i < _models.length; i++) {
            _models[i].hideLines(hide);
        }
    };
    this.hidePoints = function (hide) {
        for (var i = 0; i < _models.length; i++) {
            _models[i].hidePoints(hide);
        }
    };
    this.hasHighlighted = function () {
        for (var i = 0; i < _models.length; i++) {
            if (_models[i].hasHighlighted()) return true;
        }return false;
    };
    this.areAllVisible = function () {
        for (var i = 0; i < _models.length; i++) {
            if (!_models[i].areAllVisible()) return false;
        }return true;
    };
    /** Trigger bbox recomputation. See RenderModel.js for details. */
    this.invalidateVisibleBounds = function () {
        for (var i = 0; i < _models.length; i++) {
            _models[i].visibleBoundsDirty = true;
        }
    };
    /**
    * @param:  {bool}        includeGhosted
    * @returns {THREE.Box3}
    *
    * NOTE: The returned box object is always the same, i.e. later calls
    *       affect previously returned values. E.g., for
    *        var box1 = getVisibleBounds(true);
    *        var box2 = getVisibleBounds(false);
    *       the second call would also change box1.
    */
    this.getVisibleBounds = function (includeGhosted) {
        if (_models.length === 1) return _models[0].getVisibleBounds(includeGhosted);
        _tmpBox.makeEmpty();
        for (var i = 0; i < _models.length; i++) {
            _tmpBox.union(_models[i].getVisibleBounds(includeGhosted));
        }return _tmpBox;
    };
    function findById(models, modelId) {
        for (var i = 0; i < models.length; i++) {
            var model = models[i];
            if (model && model.id === modelId) {
                return model;
            }
        }
        return null;
    }
    this.findModel = function (modelId) {
        return findById(_models, modelId);
    };
    this.findHiddenModel = function (modelId) {
        return findById(_hiddenModels, modelId);
    };
    /**
     * @param {THREE.Vector3} position            - Ray origin.
     * @param {THREE.Vector3} direction           - Ray direction.
     * @param {bool}          [ignoreTransparent] - Shoot trough transparent objects.
     * @param {number[]}      [dbIds]             - Optional filter of fragments to be considered for testing. see RenderModel.rayIntersect().
     *
     * @returns {Object|null} Intersection result obect (see RenderModel.rayIntersect)
     */
    // Add "meshes" parameter, after we get meshes of the object using id buffer,
    // then we just need to ray intersect this object instead of all objects of the model.
    this.rayIntersect = function (position, direction, ignoreTransparent, dbIds, modelIds, intersections) {
        // init raycaster
        _raycaster.set(position, direction);
        // For multiple RenderModels, perform raytest on each of them and find the closest one.
        var i;
        if (_models.length > 1) {
            // Collect raytest result objects from each 3D model
            var modelHits = [];
            if (modelIds) {
                for (i = 0; i < modelIds.length; i++) {
                    var model = this.findModel(modelIds[i]);
                    if (model) {
                        model.rayIntersect(_raycaster, ignoreTransparent, [dbIds[i]]);
                    }
                }
            } else {
                for (i = 0; i < _models.length; i++) {
                    // Skip 2D models
                    if (_models[i].is2d()) continue;
                    // Perform raytest on model i                        
                    var res = _models[i].rayIntersect(_raycaster, ignoreTransparent, dbIds, intersections);
                    if (res) modelHits.push(res);
                }
            }
            if (!modelHits.length) return null;
            // return closest hit
            modelHits.sort(function (a, b) {
                return a.distance - b.distance;
            });
            return modelHits[0];
        } else {
            // If we don't have any 3D RenderModel, just return null.
            if (!_models.length || _models[0].is2d()) return null;
            // If we only have a single 3D RenderModel, just call rayIntersect() on it.
            return _models[0].rayIntersect(_raycaster, ignoreTransparent, dbIds, intersections);
        }
    };
    /**
     *  Progress of current frame rendering.
     *  @returns {number} Value in [0,1], where 1 means finished.
     */
    this.getRenderProgress = function () {
        return _models[0].getRenderProgress();
    };
    /** @returns {RenderModel[]} */
    this.getModels = function () {
        return _models;
    };
    /** @returns {RenderModel[]} */
    this.getHiddenModels = function () {
        return _hiddenModels;
    };
    // ----------------------------
    // Warning: The methods in the section below assume that there is exactly one RenderModel.
    //          They will ignore any additional models and cause an exception if the model list is empty.
    // 
    // Direct access to FragmentList, GeometryList, and total number of RenderBatches.
    //
    // Note: 
    //  - The methods do only care for model 0 and ignore any additional ones.
    //  - Will cause an error when called if the RenderModel array is empty.
    this.getFragmentList = function () {
        return _models[0].getFragmentList();
    };
    this.getGeometryList = function () {
        return _models[0].getGeometryList();
    };
    this.getSceneCount = function () {
        return _models[0].getSceneCount();
    };
    //Used by ground shadow update
    //TODO: we need to allow multiple iterators over the render queue        
    this.getGeomScenes = function () {
        // Note that ground shadow will currently only work on RenderModel 0.
        return _models[0].getGeomScenes();
    };
    /** Used by SvfLoader to decide which fragments to load next.  */
    this.geomPacksMissingLastFrame = function () {
        return _models[0].geomPacksMissingLastFrame();
    };
    // ---------------- End of section of functions without support for multiple RenderModels
    /** Sets animation transforms for all fragments to create an "exploded view": Each fragment is displaced
      * away from the model bbox center, so that you can distuinguish separate components.
      *
      * If the model data provides a model hierarchy (given via model.getData().instanceTree), it is also considered for the displacement.
      * In this case, we recursively shift each object away from the center of its parent node's bbox.
      *
      * @param {number} scale - In [0,1]. 0 means no displacement (= reset animation transforms).
      *                                   1 means maximum displacement, where the shift distance of an object varies
      *                                   depending on distance to model center and hierarchy level.
      */
    this.explode = function (scale) {
        if (!_models.length) return;
        var pt = new THREE$1.Vector3();
        for (var q = 0; q < _models.length; q++) {
            var model = _models[q];
            var it = model.getData().instanceTree;
            var fragList = model.getFragmentList();
            var mc = model.getVisibleBounds(true).center();
            //Input scale is in the range 0-1, where 0
            //means no displacement, and 1 maximum reasonable displacement.
            scale *= 2;
            //If we have a full part hierarchy we can use a
            //better grouping strategy when exploding
            if (it && it.nodeAccess.nodeBoxes && scale !== 0) {
                // If scale is small (close to 0), the shift is only applied to the topmost levels of the hierarchy.
                // With increasing s, we involve more and more hierarchy levels, i.e., children are recursively shifted 
                // away from their parent node centers.
                // Since explodeValue is integer, it will behave discontinous during a transition from s=0 to s=1.
                // To keep the overall transition continuous, we use the fractional part of scaledExplodeDepth
                // to smoothly fade-in the transition at each hierarchy level. 
                // levels beyond explodeDepth, we stop shifting children away from their parent.
                // 
                var scaledExplodeDepth = scale * (it.maxDepth - 1) + 1;
                var explodeDepth = 0 | scaledExplodeDepth;
                var currentSegmentFraction = scaledExplodeDepth - explodeDepth;
                var tmpBox = new Float32Array(6);
                // Define recursive function to traverse object hierarchy. Each object is shifted away 
                // from the bbox center of its parent.
                //  number nodeId:   dbId of the current instanceTree node
                //  int depth:       tracks hierarchy level (0 for root)
                //  vec3 (cx,cy,cz): center of the parent object (after applying the displacement to the parent object) 
                //  vec3 (ox,oy,oz): accumuled displacement from all parents on the path to root
                (function explodeRec(nodeId, depth, cx, cy, cz, ox, oy, oz) {
                    var oscale = scale * 2; //TODO: also possibly related to depth
                    if (depth == explodeDepth) oscale *= currentSegmentFraction; //smooth transition of this tree depth from non-exploded to exploded state
                    // get bbox center of this node
                    it.getNodeBox(nodeId, tmpBox);
                    var mycx = 0.5 * (tmpBox[0] + tmpBox[3]);
                    var mycy = 0.5 * (tmpBox[1] + tmpBox[4]);
                    var mycz = 0.5 * (tmpBox[2] + tmpBox[5]);
                    // The root node (depth==0) has no parent to shift away from.
                    // For child nodes with level > explodDepth, we don't apply additional displacement anymore - just pass the displacement of the parents.
                    if (depth > 0 && depth <= explodeDepth) {
                        // add displacement to move this object away from its parent's bbox center (cx, cy, cz)
                        var dx = (mycx - cx) * oscale;
                        var dy = (mycy - cy) * oscale;
                        var dz = (mycz - cz) * oscale;
                        //var omax = Math.max(dx, Math.max(dy, dz));
                        // sum up offsets: The final displacement of a node is accumulated by its own shift and 
                        // the shifts of all nodes up to the root.
                        ox += dx;
                        oy += dy;
                        oz += dz;
                    }
                    // continue recursion with child objects (if any)
                    it.enumNodeChildren(nodeId, function (dbId) {
                        explodeRec(dbId, depth + 1, mycx, mycy, mycz, ox, oy, oz);
                    }, false);
                    pt.x = ox;
                    pt.y = oy;
                    pt.z = oz;
                    // set translation as anim transform for all fragments associated with the current node
                    it.enumNodeFragments(nodeId, function (fragId) {
                        fragList.updateAnimTransform(fragId, null, null, pt);
                    }, false);
                })(it.getRootId(), 0, mc.x, mc.y, mc.x, 0, 0, 0); // run on root to start recursion
            } else {
                // Float32Array array with 6 floats per bbox.
                var boxes = fragList.fragments.boxes;
                for (var i = 0, iEnd = fragList.getCount(); i < iEnd; i++) {
                    if (scale == 0) {
                        // reset to unexploded state, i.e., remove all animation transforms
                        fragList.updateAnimTransform(i);
                    } else {
                        // get start index of the bbox for fragment i. 
                        var box_offset = i * 6;
                        // get bbox center of fragment i
                        var cx = 0.5 * (boxes[box_offset] + boxes[box_offset + 3]);
                        var cy = 0.5 * (boxes[box_offset + 1] + boxes[box_offset + 4]);
                        var cz = 0.5 * (boxes[box_offset + 2] + boxes[box_offset + 5]);
                        // compute translation vector for this fragment:
                        // We shift the fragment's bbox center c=(cx,cy,cz) away from the overall model center mc,
                        // so that the distance between the two will finally be scaled up by a factor of (1.0 + scale).
                        //
                        pt.x = scale * (cx - mc.x);
                        pt.y = scale * (cy - mc.y);
                        pt.z = scale * (cz - mc.z);
                        fragList.updateAnimTransform(i, null, null, pt);
                    }
                }
            }
        }
        this.invalidateVisibleBounds();
    };
    /**
     *  @params  {number} timeStamp
     *  @returns {bool}   true if any of the models needs a redraw
     */
    this.update = function (timeStamp) {
        // call update for all RenderModels and track
        // if any of these needs a redraw
        var needsRedraw = false;
        for (var q = 0; q < _models.length; q++) {
            var model = _models[q];
            needsRedraw = needsRedraw || model.update(timeStamp);
        }
        return needsRedraw;
    };
    /*
     *  Move model from visible models to hidden models
     *   @param {number} modelId - id of a currently visible model
     *   @returns {bool} true on success
     */
    this.hideModel = function (modelId) {
        // find model in the list of visible ones
        for (var i = 0; i < _models.length; i++) {
            var model = _models[i];
            if (model && model.id === modelId) {
                // move model from visible to hidden models
                this.removeModel(model);
                _hiddenModels.push(model);
                return true;
            }
        }
        // modelID does not refer to any visible model
        return false;
    };
    /*
     * Move previously hidden model to the array of rendered models.
     *  @param {number} modelId - id of a RenderModel in hiddenModels array
     *  @returns {bool} true on success
     */
    this.showModel = function (modelId) {
        // find model in list of hidden models
        for (var i = 0; i < _hiddenModels.length; ++i) {
            var model = _hiddenModels[i];
            if (model && model.id === modelId) {
                // mode model from hidden to visible models
                this.addModel(model);
                _hiddenModels.splice(i, 1);
                return true;
            }
        }
        // modelId does not refer to a hidden model
        return false;
    };
    /**
     * Get the memory stats when using on demand loading.
     * @returns {object|null} Object containing the total limit and total loaded memory usage for all models.
     *                        Return null if no model is being loaded on demand.
     */
    this.getMemoryInfo = function () {
        var lastMem;
        var returnValue = {
            limit: 0,
            effectiveLimit: 0,
            loaded: 0
        };
        function addStats(models) {
            for (var i = 0; i < models.length; ++i) {
                var mem = models[i].getMemoryInfo();
                if (mem) {
                    lastMem = mem;
                    returnValue.limit += mem.limit;
                    returnValue.effectiveLimit += mem.effectiveLimit;
                    returnValue.loaded += mem.loaded;
                }
            }
        }
        addStats(_models);
        addStats(_hiddenModels);
        return lastMem ? returnValue : null;
    };
}

/**
 * Maintains a sorted list of objects or values.
 * If objects are used, less must be a function(a,b) that
 * defines an order on all objects.
 *
 * It is valid to add multiple object that are equal wrt. to less operator.
 *
 * @constructor
 */
/**
 * Maintains a sorted list of objects or values.
 * If objects are used, less must be a function(a,b) that
 * defines an order on all objects.
 *
 * It is valid to add multiple object that are equal wrt. to less operator.
 *
 * @constructor
 */var SortedList = function SortedList(less) {
    // use custom or default less operator
    var _less = less ? less : function (a, b) {
        return a < b;
    };
    // all inserted objects, not sorted
    var _values = [];
    // array of indices into values, sorted by less operator
    var _orderIndices = [];
    // Returns an index to the first element in this.orderIndices that points to
    // an object o that is greater or equal than the given value, i.e. !less(o, value)
    // If no such object is found, it returns the range end index.
    var _binarySearch = function _binarySearch(value, // object to search for
    rangeBegin, // int: define range in this.orderIndices. highEnd is exclusive
    rangeEnd //
    ) {
        // use full array by default
        if (!rangeBegin) {
            rangeBegin = 0;
        }
        if (!rangeEnd) {
            rangeEnd = _orderIndices.length;
        }
        // handle empty range
        if (rangeBegin >= rangeEnd) {
            return rangeEnd;
        }
        // simple case: range contains just a single value
        if (rangeEnd === rangeBegin + 1) {
            // get only elem in this range
            var elem = _values[_orderIndices[rangeBegin]];
            if (_less(elem, value)) {
                // object is still smaller.
                return rangeEnd;
            } else {
                return rangeBegin;
            }
        }
        // split range in the middle
        var mid = parseInt(rangeBegin + (rangeEnd - rangeBegin) / 2);
        // Note: mid-1 is always valid, because the rangeLength is always >2 when reaching this
        // get last value of lower half-range
        var lowerRangeMax = _values[_orderIndices[mid - 1]];
        if (_less(value, lowerRangeMax)) {
            // max of lower range is already greater => result index must be in the lower half
            return _binarySearch(value, rangeBegin, mid);
        } else if (_less(lowerRangeMax, value)) {
            // evenl lower-range max is still smaller => mid object must be in the upper range
            return _binarySearch(value, mid, rangeEnd);
        } else {
            // last object in the lower range is identical with value
            return mid - 1;
        }
    };
    this.add = function (val) {
        // find index into this.orderIndices that points to the last
        // object with identical or lower value.
        var index = _binarySearch(val);
        if (index === _orderIndices.length) {
            // value is not in the list yet and is larger than all values so far
            // => append order index
            _values.push(val);
            _orderIndices.push(_values.length - 1);
            return;
        }
        // append new object and insert sort index at the right position
        _values.push(val);
        _orderIndices.splice(index, 0, _values.length - 1);
    };
    this.size = function () {
        return _orderIndices.length;
    };
    // enables to traverse by ascending order using indices 0,...,size()-1
    this.get = function (index) {
        return _values[_orderIndices[index]];
    };
    // removes the element at the given index in 0,...,size()-1.
    // Note that the index of an object may vary when inserting others,
    // because the indices are defined via the sorting order.
    // E.g., removeAt(0) removes the smallest value.
    this.removeAt = function (i) {
        var index = _orderIndices[i];
        // remove value at index. Note that the indexing of this.values
        // must not be changed, because our sort-indices would become invalid.
        _values[index] = undefined;
        // remove order index
        _orderIndices.splice(i, 1);
    };
    // returns a string that enumerates all values.
    // (only works for numeric values)
    this.toString = function () {
        var string = "";
        for (var i = 0, iEnd = this.size(); i < iEnd; ++i) {
            string += this.get(i);
            if (i < iEnd - 1) {
                string += ", ";
            }
        }
        return string;
    };
};

/**
 * Represents the full list of all geometry instances associated with
 * a particular model. The order in the list is 1:1 with fragment list
 * in the source LMV/SVF package file.
 * @param {Object} fragments - Fragment data parsed from an SVF file.
 * @param {GeometryList} geoms - Geometry data parsed from an SVF file.
 * @param {Object} [pagingProxy] - Object used to manage memory and paging
 * @constructor
 */
function FragmentList(model, pagingProxy) {
    this.model = model;
    this.fragments = model.getData().fragments;
    this.geoms = model.getGeometryList();
    this.pagingProxy = pagingProxy;
    //3D SVF files are of known initial size and known world bounds.
    //2D F2D files start out with nothing and get filled up as we load.
    //NOTE: There is a bug here when we have an SVF file with known zero fragments -- it will
    //go into the slower non-fixed size code path. But it doesn't matter, because it's an empty file.
    this.isFixedSize = this.fragments.length > 0;
    if (this.isFixedSize) {
        this.boxes = this.fragments.boxes; // Float32Array, stores Boxes as 6 floats per fragment (after applying mesh matrix)
        this.transforms = this.fragments.transforms; // Float32Array, stores transforms as 12 floats per fragment (Matrix4 with omitted last row)
        this.useThreeMesh = !exports.memoryOptimizedLoading;
    } else {
        this.boxes = null;
        this.transforms = null;
        this.useThreeMesh = !pagingProxy || !pagingProxy.onDemandLoadingEnabled(); // Don't use THREE mesh when on demand loading
    }
    // initial length for arrays of meshes/geometries/flags
    // Can be zero.
    var initialSize = this.fragments.length;
    this.vizflags = new Uint16Array(initialSize); // visibility/highlight mode flags
    //This will be the list of all mesh instances in the model.
    //Corresponds to all fragments in the case of SVF.
    if (this.useThreeMesh) this.vizmeshes = new Array(initialSize);
    this.geomids = new Int32Array(initialSize); // geomid per fragId. geomids are resolved by this.geoms.GetGeometry(geomid) to obtain BufferGeometry.
    this.materialids = new Int32Array(initialSize); // material per fragId. matIds  are resolved by this.materialmap[matId] 
    this.materialmap = {}; // map from material ids to THREE.ShaderMaterial instances
    // theming (coloring based on id)
    this.db2ThemingColor = []; // empty if no theming is applied. A theming color db2ThemingColor[dbId] is stored as THREE.Vector4 with values in [0,1].
    this.originalColors = []; // if vizmesh[i] has modified vertex-colors  due to theming,  originalColors[i]  stores a copy of the original colors.
    this.themingOrGhostingNeedsUpdate = []; // indicates if vertex-colors of vizmesh[i] needs to be updated based on recent theming or ghosting changes.
    this.dbIdIsHidden = []; // ids that we hide by setting alpha to 0
    // ghosting for 2d objects: A ghosted object is reduced in transparency and blended with the pageColor. This
    this.dbIdIsGhosted = [];
    // used for on-demand loading and paging
    // TODO Paging: refactor below three variables to the proxy object of 2d loader.
    this.reachLimit = false; // Controlled from outside when maximum number of geometries 
    // in memory is reached (see RenderModel.pageOutIfNeeded). If true, load-requests via requestGeometryCallback are blocked.
    this.animxforms = null; // If animation is used, this is a Float32Array storing 10 floats per fragment to describe scale (3), rotation (4), and translation (3).
    // See this.updateAnimTransform.
    for (var i = 0; i < initialSize; i++) {
        this.vizflags[i] = 1; //MESH_VISIBLE initially
        this.geomids[i] = -1; //0 is a valid geom index, so use -1 as starting value
    }
    // Set the visflags from the fragment visibility, if there is any
    if (this.fragments.visibilityFlags) {
        this.vizflags.set(this.fragments.visibilityFlags);
        // these flags have done their job
        delete this.fragments.visibilityFlags;
    }
    this.allVisible = true; // see this.areAllVisible(..). Indicates if MESH_VISIBLE flag is set for all meshes (i.e., not considering culling)
    this.allVisibleDirty = true; // if true, this.allVisible is outdated and must be recomputed in this.areAllVisible.
    this.nextAvailableFragID = initialSize;
    this.boxTransform = [];
    this.boxCount = 0;
    // TODO: comment out; for debug
    //this.geomCount = 0;
    //this.geomMax = 100;
}
FragmentList.prototype.resetBoxRun = function () {
    // TODO - this is buggy with reflection, probably SSAO, etc.
    // We should render boxes only in the main render pass, nothing else. This needs to be signalled.
    this.boxCount = 0;
    //this.geomCount = 0;
};
// [HB:] This method is only used in RenderModel.setFragment(), which seems to be not called at all. Can we remove this?
//       (including the nextAvailableFragID member and RenderModel.setFragment).
FragmentList.prototype.getNextAvailableFragmentId = function () {
    return this.nextAvailableFragID++;
};
// [HB:] When does this method ever return true? vizflags is resized in SetMesh, which only used in RenderModel.activateFragment and 
//       RenderModel.setFragment (never called). RenderModel.activateFragment(..) is only used by loaders when new fragments have been loaded.
//       However, for SvfLoader, fragments.length is always the full fragments count and for F2D, new stuff is first added to fragments, then
//       to VisFlags. 
//       Maybe this should actually be a "<" and is only relevant for F2D case?
FragmentList.prototype.fragmentsHaveBeenAdded = function () {
    return this.vizflags.length > this.fragments.length;
};
// Returns undefined if fragId has no material 
FragmentList.prototype.getSvfMaterialId = function (fragId) {
    var mat = this.getMaterial(fragId);
    return mat ? mat.svfMatId : undefined;
};
// Return true of false, whether on demand loading enabled.
// This mainly controls how the geometries referenced by the fagments
// are going to load. 
//
// If false, then geometry pack files will load in sequence all at once.
// if true, then only those geometry pack files that are request to render,
//          can they start to load *on demand*
FragmentList.prototype.onDemandLoadingEnabled = function () {
    return this.pagingProxy && this.pagingProxy.onDemandLoadingEnabled();
};
FragmentList.prototype.pageOutGeometryEnabled = function () {
    return this.pagingProxy && this.pagingProxy.pageOutGeometryEnabled();
};
FragmentList.prototype.pixelCullingEnable = function () {
    return this.pagingProxy && this.pagingProxy.pixelCullingEnable();
};
FragmentList.prototype.pixelCullingThreshold = function () {
    return this.pagingProxy ? this.pagingProxy.pixelCullingThreshold() : 0;
};
// Requests the geometry of a fragment for loading, unless it is already in memory or the request limit is reached.
// If already in memory, it just returns the geometry directly.
FragmentList.prototype.requireGeometry = function (fragId) {
    var geom = null;
    var geomId = this.geomids[fragId];
    if (geomId >= 0) {
        // A valid geometry id, then get corresponding geometry
        geom = this.geoms.getGeometry(geomId);
    }
    if (geom == null) {
        // Request to load this geometry.
        var packId = this.fragments.packIds ? this.fragments.packIds[fragId] : fragId;
        if (this.pagingProxy) {
            this.pagingProxy.loadPackFile(packId);
        }
    }
    return geom;
};
/**
 * Create a promise to download geometry asynchronously
 *
 * This method can be called multiple times and will return a different promise
 * each time it is called. When the promise fulfills, the argument to the fulfillment
 * function is an object with model and fragId properties that identify the geometry.
 *
 * Promises returned by this function can be canceled using
 * FragmentList.cancelPromisedGeometry(promise). A canceled promise is always rejected.
 * The canceled property of the argument to the rejection function is true when a
 * promise is canceled.
 * @param {number} fragId - Fragment whose geometry is to be downloaded
 * @returns {Promise} - The created promise.
 */
FragmentList.prototype.promiseGeometry = function (fragId) {
    function cancelChain(promise, value) {
        var then;
        then = promise.then(function () {
            if (then) {
                delete then.lmv_loader_promise;
                // If this was canceled, then just toss it up the chain
                if (then.lmv_geom_canceled) {
                    return Promise.reject({ canceled: true });
                }
            }
            return value;
        }, function (error$$1) {
            if (then) {
                delete then.lmv_loader_promise;
                // If this was canceled, then just toss it up the chain
                if (then.lmv_geom_canceled) {
                    return Promise.reject({ canceled: true });
                }
            }
            // Pass the rejection up the chain
            return Promise.reject(error$$1);
        });
        then.lmv_loader_promise = promise;
        return then;
    }
    var geom = this.getGeometry(fragId);
    if (geom) return cancelChain(Promise.resolve(), { model: this.model, fragId: fragId });
    // Request to load this geometry.
    //var _this = this;
    // See if this packId is already promised
    var packId = this.fragments.packIds ? this.fragments.packIds[fragId] : fragId;
    // Reject the promise, if not supported, but allow the rejection to be canceled
    if (!this.pagingProxy || !this.pagingProxy.promisePackFile) return cancelChain(Promise.reject({ reason: "Not supported" }));
    // Not promised, so load it
    var promise = this.pagingProxy.promisePackFile(packId);
    // Initialize the count of dependant promises
    if (!promise.hasOwnProperty("lmv_promise_count")) promise.lmv_promise_count = 0;
    ++promise.lmv_promise_count;
    // Do a page out just in case we need it to satisfy the promise.
    this.pagingProxy.pageOut(false, false);
    return cancelChain(promise, { model: this.model, fragId: fragId });
};
/**
 * Cancel a promise returned by promiseGeometry
 *
 * Canceled promised always reject and the canceled property of the argument
 * to the rejection function is set to true.
 * @param {Promise} promise - Promise to be canceled
 * @returns {boolean} - True if the promise is canceled. False if it isn't canceled.
 */
FragmentList.prototype.cancelPromisedGeometry = function (then) {
    if (!then) return false;
    var promise = then.lmv_loader_promise;
    if (!promise) return false; // Finished, or not create by promiseGeometry()
    if (then.lmv_geom_canceled) return true; // Already canceled
    then.lmv_geom_canceled = true;
    // If this is the last cancel, then call the loader
    if (promise.hasOwnProperty("lmv_promise_count") && --promise.lmv_promise_count <= 0) {
        // Cancel the promise in the loader. If the pagingProxy supports
        // promisePackFile, then it must also support cancelPromisedPackFile
        if (this.pagingProxy && this.pagingProxy.promisePackFile) this.pagingProxy.cancelPromisedPackFile(promise);
    }
    return true;
};
/**
 * Set mesh for a fragment, replacing any temporary previous one.
 * @param {number} fragId - Fragment ID
 * @param {Object} meshinfo - Contains:
 *      geometry: instanceof BufferGeometry
 *      material: instance of THREE.Material
 *      matrix:   instanceof THREE.Matrix4
 *      isLine:   bool to mark line geometry
 *      isWideLine: bool to mark wide line geometry
 *      isPoint:   bool to mark point geometry
 *      is2D:     bool to indicate 2D geometry (e.g., set by F2DLoader)
 * @param {bool} updateFragmentData - If true, this.bbox and this.transforms is also updated for this fragment.
 *      Only allowed if this.isFixedSize==true. (otherwise, this.boxes and this.transforms is null)
 */
FragmentList.prototype.setMesh = function (fragId, meshInfo, updateFragmentData) {
    //Remove any temporary geometry we used for the fragment
    //while it was loading
    if (this.vizmeshes) {
        var oldGeom = this.vizmeshes[fragId];
        if (oldGeom && oldGeom.parent) {
            oldGeom.parent.remove(oldGeom);
        }
    }
    //The various data arrays need to be re-sized if the fragment is new
    //so we have to do it manually in case this happens. 
    if (this.vizflags.length <= fragId) {
        // Gradually should only used if isFixedSize is false (as used for F2D geometry)
        if (this.isFixedSize) {
            THREE$1.warn("Attempting to resize a fragments list that was initialized with fixed data. This will have a performance impact.");
            this.isFixedSize = false;
        }
        // determine new length of all per-fragmentId arrays
        var nlen = Math.ceil(1.5 * this.vizflags.length) || 1;
        if (this.useThreeMesh && nlen < this.vizmeshes.length) nlen = this.vizmeshes.length;
        // re-allocate vizflags
        var nflags = new Uint16Array(nlen);
        nflags.set(this.vizflags);
        this.vizflags = nflags;
        // re-allocate other per-fragmentId arrays...
        if (this.transforms) {
            var ntransforms = new Float32Array(nlen * 12);
            ntransforms.set(this.transforms);
            this.transforms = ntransforms;
        }
        if (this.boxes) {
            var nboxes = new Float32Array(nlen * 6);
            nboxes.set(this.boxes);
            this.boxes = nboxes;
        }
        if (this.geomids) {
            var nids = new Int32Array(nlen);
            nids.set(this.geomids);
            this.geomids = nids;
        }
        if (this.materialids) {
            var nmids = new Int32Array(nlen);
            nmids.set(this.materialids);
            this.materialids = nmids;
        }
    }
    //Remember the mesh in the frag->viz mesh array
    if (this.useThreeMesh) {
        var mesh = new THREE$1.Mesh(meshInfo.geometry, meshInfo.material);
        // Copy matrix to mesh.matrix and mesh.matrixWorld
        // [HB:] Why copying twice?
        if (meshInfo.matrix) {
            if (mesh.matrix) {
                mesh.matrix.copy(meshInfo.matrix);
            }
            mesh.matrixWorld.copy(meshInfo.matrix);
        }
        mesh.is2d = meshInfo.is2d;
        mesh.isLine = meshInfo.isLine;
        mesh.isWideLine = meshInfo.isWideLine;
        mesh.isPoint = meshInfo.isPoint;
        // If we would leave that true, THREE.js would call UpdateMatrix() for this mesh and 
        // overwrite the matrix with another one computed by position, scale, and quaternion.
        mesh.matrixAutoUpdate = false;
        //Add the mesh to the render group for this fragment
        //Note each render group renders potentially many fragments.
        mesh.frustumCulled = false; //we do our own culling in RenderQueue, the renderer doesn't need to
        // keep fragId and dbId
        mesh.fragId = fragId;
        mesh.dbId = this.fragments.fragId2dbId[fragId] | 0;
        mesh.modelId = this.model.getModelId();
        // cache the mesh in this.vizmeshes
        this.vizmeshes[fragId] = mesh;
    } else {
        // When not using THREE.Mesh, store ids of BufferGeometry and material instead
        // Handle shared Otg geoms: If the geometry contains a hash, it is a shareable Otg geometry. For these,
        // we cannot use svfid, because the geomId may vary per model.
        //  => For this case, the geomId must be provided separately by the meshInfo
        var geomId = undefined;
        if (meshInfo.geometry.hash) {
            // shared otg geom
            if (meshInfo.geomId === undefined) {
                console.error("meshInfo must provide geomId");
            }
            geomId = meshInfo.geomId;
        } else {
            // svf geom
            geomId = meshInfo.geometry.svfid;
        }
        this.geomids[fragId] = geomId;
        this.materialids[fragId] = meshInfo.material.id;
        // add material to the map (if not known already)
        if (!this.materialmap[meshInfo.material.id]) this.materialmap[meshInfo.material.id] = meshInfo.material;
    }
    // Don't override the visibility flag which could be set before geometry is ready.
    // This can improve the performance when streaming geometry and rendering happen together.
    var typeFlags = 0;
    if (meshInfo.isLine) typeFlags = MESH_ISLINE;else if (meshInfo.isWideLine) typeFlags = MESH_ISWIDELINE;else if (meshInfo.isPoint) typeFlags = MESH_ISPOINT;
    if (!this.isFixedSize) {
        this.vizflags[fragId] |= MESH_VISIBLE | typeFlags;
    } else {
        this.vizflags[fragId] |= typeFlags;
    }
    if (updateFragmentData) {
        // Update transform and bb
        var transform = meshInfo.matrix;
        // Copy the transform to the fraglist array
        // We store in column-major order like the elements of the Matrix4, but skip row 3.
        var i = fragId * 12;
        var cur = transform.elements;
        var orig = this.transforms;
        orig[i] = cur[0];
        orig[i + 1] = cur[1];
        orig[i + 2] = cur[2];
        orig[i + 3] = cur[4];
        orig[i + 4] = cur[5];
        orig[i + 5] = cur[6];
        orig[i + 6] = cur[8];
        orig[i + 7] = cur[9];
        orig[i + 8] = cur[10];
        orig[i + 9] = cur[12];
        orig[i + 10] = cur[13];
        orig[i + 11] = cur[14];
        // Transform the local BB to world
        var b = new THREE$1.Box3();
        if (meshInfo.geometry && meshInfo.geometry.boundingBox) {
            b.copy(meshInfo.geometry.boundingBox);
        } else {
            this.geoms.getModelBox(this.geomids[fragId], b);
        }
        b.applyMatrix4(transform);
        // Write bounding box to this.boxes
        var boffset = fragId * 6;
        var bb = this.boxes;
        bb[boffset] = b.min.x;
        bb[boffset + 1] = b.min.y;
        bb[boffset + 2] = b.min.z;
        bb[boffset + 3] = b.max.x;
        bb[boffset + 4] = b.max.y;
        bb[boffset + 5] = b.max.z;
    }
};
FragmentList.prototype.isFlagSet = function (fragId, flag) {
    return !!(this.vizflags[fragId] & flag);
};
/**
 * Set/unset flag of a fragment.
 * Note: Changing MESH_VISIBLE requires to update allVisibleDirty as well => Use setVisibility() for this case.
 * @param {number} fragId - Fragment ID.
 * @param {number} flag - Must be one of the flags defined at the beginning of this file, e.g., MESH_HIGHLIGHTED.
 * @returns {bool} False if nothing changed.
 */
FragmentList.prototype.setFlagFragment = function (fragId, flag, value) {
    // If flag is already defined and has this value, just return false.
    var old = this.vizflags[fragId];
    if (!!(old & flag) == value) return false;
    // set or unset flag
    if (value) this.vizflags[fragId] = old | flag;else this.vizflags[fragId] = old & ~flag;
    return true;
};
/**
 * Set/unset flag for all fragments, e.g. setFlagGlobal(MESH_VISIBLE, true);
 * Note: Changing MESH_VISIBLE requires to update allVisibleDirty as well => use setAllVisibility() for this case.
 * @param {number} flag - Must be one of the flags defined at the beginning of this file, e.g., MESH_HIGHLIGHTED.
 * @param {bool} value - Value to be set to the flag
 */
FragmentList.prototype.setFlagGlobal = function (flag, value) {
    var vizflags = this.vizflags;
    var i = 0,
        iEnd = vizflags.length;
    if (value) {
        for (; i < iEnd; i++) {
            vizflags[i] = vizflags[i] | flag;
        }
    } else {
        var notflag = ~flag;
        for (; i < iEnd; i++) {
            vizflags[i] = vizflags[i] & notflag;
        }
    }
};
/**
 * Marks all lines as visible or hidden.
 * Works like this.setFlagGlobal(MESH_HIDE, hide), but only affects fragments with MESH_ISLINE flag.
 * @param {bool} hide - Desired visibility status.
 */
FragmentList.prototype.hideLines = function (hide) {
    this.hideFragments(MESH_ISLINE, hide);
    this.hideFragments(MESH_ISWIDELINE, hide);
};
/**
 * Marks all points as visible or hidden.
 * Works like this.setFlagGlobal(MESH_HIDE, hide), but only affects fragments with MESH_ISPOINT flag.
 * @param {bool} hide - Desired visibility status.
 */
FragmentList.prototype.hidePoints = function (hide) {
    this.hideFragments(MESH_ISPOINT, hide);
};
/**
 * Marks all fragments with the given flag as visible or hidden.
 * Works like this.setFlagGlobal(MESH_HIDE, hide), but only affects fragments with given flag.
 * @param {number} typeFlag - visibility flag of fragments to change
 * @param {bool} hide - Desired visibility status.
 */
FragmentList.prototype.hideFragments = function (typeFlag, hide) {
    var flag = MESH_HIDE;
    var vizflags = this.vizflags;
    var i = 0,
        iEnd = vizflags.length;
    if (hide) {
        for (; i < iEnd; i++) {
            if (vizflags[i] & typeFlag) vizflags[i] = vizflags[i] | flag;
        }
    } else {
        var notflag = ~flag;
        for (; i < iEnd; i++) {
            if (vizflags[i] & typeFlag) vizflags[i] = vizflags[i] & notflag;
        }
    }
    // Mark allVisible as outdated        
    this.allVisibleDirty = true;
};
/**
 * Checks visibility of a fragment.
 * @param {number} frag - Fragment ID.
 * @returns {bool} True if the fragment is visible and not highlighted nor hidden.
 */
FragmentList.prototype.isFragVisible = function (frag) {
    return (this.vizflags[frag] & (MESH_VISIBLE | MESH_HIDE)) == 1;
};
FragmentList.prototype.isFragOff = function (frag) {
    return !!(this.vizflags[frag] & MESH_HIDE);
};
FragmentList.prototype.isLine = function (frag) {
    return !!(this.vizflags[frag] & MESH_ISLINE /*MESH_VISIBLE|MESH_HIGHLIGHTED*/);
};
FragmentList.prototype.isWideLine = function (frag) {
    return this.isFlagSet(frag, MESH_ISWIDELINE);
};
FragmentList.prototype.isPoint = function (frag) {
    return this.isFlagSet(frag, MESH_ISPOINT);
};
// [HB:] This method does not consider the MESH_HIDE flag, but this.setFragOff seems to expect this, because it sets allVisibleDirty.
//       Is this a bug?
FragmentList.prototype.areAllVisible = function () {
    // update allVisible if any flags have changed
    if (this.allVisibleDirty) {
        // allVisible <=> MESH_VISIBLE is set for all fragments
        var vizflags = this.vizflags;
        var allVisible = true;
        for (var i = 0, iEnd = vizflags.length; i < iEnd; i++) {
            if ((vizflags[i] & 1 /*MESH_VISIBLE*/) === 0) {
                allVisible = false;
                break;
            }
        }
        this.allVisible = allVisible;
        this.allVisibleDirty = false;
    }
    return this.allVisible;
};
// Swaps r/b channels in a THREE.Color object.
function swapRBChannels(color) {
    var tmp = color.r;
    color.r = color.b;
    color.b = tmp;
    return color;
}
/** Linear interpolation between original color and theming color based on theming intensity.
 * @param origColor    {number}        original uint32 color from vertex-buffer. alpha is vertex-opacity
 * @param themingColor {THREE.Vector4} theming color as vec4f. Channels are (r,g,b,a) where alpha is theming intensity.
 * @returns finalColor {number}        final color as uint32
 */
var applyThemingColorAndVisibility = function () {
    var tmp1 = null;
    var tmp2 = null;
    var rgbMask = parseInt("00FFFFFF", 16);
    var alphaMask = parseInt("FF000000", 16);
    return function (origColor, themingColor) {
        if (!tmp1) {
            tmp1 = new THREE$1.Color();
            tmp2 = new THREE$1.Color();
        }
        tmp1.set(origColor & rgbMask);
        // THREE.Color denotes uint color in BGRA order (i.e., Blue in the lowest byte).
        // In the vertex-buffer, we use RGBA - so we have to swap when converting between these two.
        swapRBChannels(tmp1);
        if (themingColor) {
            // set tmp2 to theming color
            tmp2.setRGB(themingColor.x, themingColor.y, themingColor.z);
            // blend original color with theming color
            tmp1.lerp(tmp2, themingColor.w);
        }
        // convert back to color-buffer uint32 and preserve original alpha bits
        return swapRBChannels(tmp1).getHex() | origColor & alphaMask;
    };
}();
// Updates the per-vertex array of a mesh to reflect latest theming and ghosting state.
// Note that this can only work on F2D meshes with known attributes and interleaved vertex buffer.
function updateVertexBufferForThemingAndGhosting(fragList, fragId) {
    // get backup of original per-vertex colors (undef if color array is currently not modified)
    var origColors = fragList.originalColors[fragId];
    // check if anything changed
    if (!fragList.themingOrGhostingNeedsUpdate[fragId]) {
        return;
    }
    // get values to access colors and ids
    var geom = fragList.getGeometry(fragId);
    var attr = geom ? geom.attributes : null;
    var atColors = attr ? attr.color4b : null;
    var atIds = attr ? attr.dbId4b : null;
    var atLayerVp = attr ? attr.layerVp4b : null;
    var atFlags = attr ? attr.flags4b : null;
    if (!atColors || !atIds || !geom.vb || !atLayerVp || !atFlags) {
        // we cannot work on this mesh.
        return;
    }
    // get uint32 view on interleaved vertex buffer
    var vertexData = new Uint32Array(geom.vb.buffer);
    var stride = geom.vbstride; // elems per vertex
    var vertexCount = vertexData.length / geom.vbstride;
    // Track if any colors/layers are affected by theming/ghosting. If not, we can drop the color/layer array backup at the end.
    var themingApplied = false;
    // Constants used for ghosting of 2D objects
    var PaperLayer = 0; // we use the paper layer to determine the paper sheet background (see F2d.js initSheet). This shape must be excluded from ghosting.
    // update vertex-color for each vertex
    var colOffset = atColors.itemOffset;
    var idOffset = atIds.itemOffset;
    var layerOffset = atLayerVp.itemOffset;
    var flagsOffset = atFlags.itemOffset;
    for (var i = 0; i < vertexCount; i++) {
        // get vertex-id and original color
        var dbId = vertexData[i * stride + idOffset];
        var color = origColors ? origColors[i] : vertexData[i * stride + colOffset];
        var layerVp = vertexData[i * stride + layerOffset];
        // sign extend the upper byte to get back negative numbers (since per-vertex ids are clamped from 32 bit to 24 bit)
        dbId = dbId << 8 >> 8;
        var isPaper = dbId == -1 && (layerVp & parseInt("FFFF", 16)) == PaperLayer;
        // is this id affected by theming?
        var themeColor = fragList.db2ThemingColor[dbId];
        var isHidden = fragList.dbIdIsHidden[dbId];
        if (!themeColor && !isHidden) {
            // no theming for this vertex
            if (origColors) {
                // restore original color
                color = origColors[i];
            } // else: if there is no backup array, the vertex-color is already the original.
        } else {
            // this vertex-color will be affected by theming.
            // make sure that we have backup.
            if (!origColors) {
                // backup original colors before we modify them.
                origColors = new Uint32Array(vertexCount);
                for (var j = 0; j < vertexCount; j++) {
                    origColors[j] = vertexData[j * stride + colOffset];
                }
                fragList.originalColors[fragId] = origColors;
            }
            // replace vertex-color based on theming and visibility
            if (isHidden) {
                color = 0;
            } else {
                color = applyThemingColorAndVisibility(color, themeColor);
            }
            // signal that the color backup array is still needed
            themingApplied = true;
        }
        // color -> vertexBuffer
        vertexData[i * stride + colOffset] = color;
        // is this id affected by theming?
        var isGhosted = fragList.dbIdIsGhosted[dbId] && !isPaper;
        var flags = vertexData[i * stride + flagsOffset];
        if (isGhosted) flags |= 0xff << 24;else flags &= ~(0xff << 24);
        // layer -> vertexBuffer
        vertexData[i * stride + flagsOffset] = flags;
    }
    // if theming is off for all vertices, drop the backup array
    if (!themingApplied) {
        fragList.originalColors[fragId] = null;
    }
    // trigger refresh of GPU-side vertex buffer
    geom.vbNeedsUpdate = true;
    // don't touch this mesh again until new theming changes are done
    fragList.themingOrGhostingNeedsUpdate[fragId] = false;
}
/**
 * Provides an actual mesh for specific fragment.
 * NOTE: For (this.useThreeMesh==false), the returned value is volatile and will be overwritten on next call!
 * @param {number} fragId - Fragment ID.
 * @returns {THREE.Mesh} Mesh for the given fragment.
 */
FragmentList.prototype.getVizmesh = function () {
    //A scratch object that we fill in and return in the case
    //we don't use THREE.Mesh for persistent storage. If the caller
    //needs to hold on to the mesh outside the callback scope, it has to clone it.
    var m;
    var defaultMaterial;
    var _tmpBox;
    var translation3, scale3;
    var box_vertices;
    // current shader does not need:
    //var box_normals;
    var canonical_box;
    function init_three() {
        if (!m) {
            m = new THREE$1.Mesh(undefined, undefined, true);
            m.isTemp = true;
            m.dbId = 0;
            m.modelId = 0;
            m.fragId = -1;
            m.hide = false;
            m.isLine = false;
            m.isWideLine = false;
            m.isPoint = false;
            // TODO convert to LMV material!
            // Also TODO: why does BasicMaterial not work? I put in the trick to dither, but it doesn't seem to work
            // for the basic material. I cheat here by using lambert and cranking the emissive, but there are no normals and the
            // normals matrix is empty, which three.js tries to invert and so gives a warning.
            //defaultMaterial  = new THREE.MeshBasicMaterial({color: 0x777777,depthWrite: false});   // {color: 0xff0000},wireframe:true
            defaultMaterial = new THREE$1.MeshLambertMaterial({ color: 0x0, depthWrite: false, emissive: 0xcccccc }); // {color: 0xff0000},wireframe:true
            //defaultMaterial  = new THREE.MeshLambertMaterial({color: 0xcccccc,depthWrite: false});   // {color: 0xff0000},wireframe:true
            // doesn't work for some reason... defaultMaterial  = new THREE.MeshBasicMaterial({color: 0xcccccc,depthWrite: false});   // {color: 0xff0000},wireframe:true
            // LMV-specific stuff - we need to really have a method here instead.
            defaultMaterial.cutplanes = null;
            _tmpBox = new THREE$1.Box3();
            translation3 = new THREE$1.Vector3();
            scale3 = new THREE$1.Vector3();
            // TODO: could do a better job of sharing vertices here at corners, would reduce load to
            // 24 vertices instead of 36. Index buffer might cost more?
            box_vertices = new Float32Array([1, -1, -1, -1, -1, -1, 1, 1, -1, -1, 1, -1, 1, 1, -1, -1, -1, -1, -1, -1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, -1, -1, 1,
            // y
            -1, -1, -1, 1, -1, -1, 1, -1, 1, 1, -1, 1, -1, -1, 1, -1, -1, -1, 1, 1, -1, -1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, 1, -1,
            // x
            -1, -1, -1, -1, -1, 1, -1, 1, 1, -1, 1, 1, -1, 1, -1, -1, -1, -1, 1, -1, 1, 1, -1, -1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, -1]);
            /*
            box_normals = new Float32Array( [
                0,0,-1,
                0,0,-1,
                0,0,-1,
                 0,0,-1,
                0,0,-1,
                0,0,-1,
                 0,0,1,
                0,0,1,
                0,0,1,
                 0,0,1,
                0,0,1,
                0,0,1,
                 // y
                0,-1,0,
                0,-1,0,
                0,-1,0,
                 0,-1,0,
                0,-1,0,
                0,-1,0,
                 0,1,0,
                0,1,0,
                0,1,0,
                 0,1,0,
                0,1,0,
                0,1,0,
                 // x
                -1,0,0,
                -1,0,0,
                -1,0,0,
                 -1,0,0,
                -1,0,0,
                -1,0,0,
                 1,0,0,
                1,0,0,
                1,0,0,
                 1,0,0,
                1,0,0,
                1,0,0
             ] );
            */
            canonical_box = new THREE$1.BufferGeometry();
            // create a cube. We duplicate the top left and bottom right
            // vertices because each vertex needs to appear once per triangle.
            // itemSize = 3 because there are 3 values (components) per vertex
            canonical_box.addAttribute('position', new THREE$1.BufferAttribute(box_vertices, 3));
            // not needed if not shading:
            // m.geometry.addAttribute( 'normal', new THREE.BufferAttribute( normals, 3 ) );
        }
    }
    function getFragmentBox(index, stride, dst, fragList) {
        var off = index * stride;
        var src = fragList.boxes;
        dst.min.x = src[off];
        dst.min.y = src[off + 1];
        dst.min.z = src[off + 2];
        dst.max.x = src[off + 3];
        dst.max.y = src[off + 4];
        dst.max.z = src[off + 5];
    }
    function renderBox(m, fragId, fragList) {
        // debug: if geom exists, look at its bounds.
        // if ( m.geometry ) {
        //     m.geometry.boundingBox = new THREE.Box3();
        //     for (var v = 0; v < m.geometry.vb.length; v += m.geometry.vbstride) {
        //         pt.set(
        //             m.geometry.vb[v],
        //             m.geometry.vb[v+1],
        //             m.geometry.vb[v+2]
        //         );
        //         m.geometry.boundingBox.expandByPoint(pt);
        //     }
        // }
        // Did we already make a box?
        if (!fragList.boxTransform[fragId]) {
            // Boxes are actually centered coming in, to help minimize precision problems.
            // We might decide to not trust this someday, but it seems to work.
            // Use one box and scale it up by these dimensions.
            getFragmentBox(fragId, 6, _tmpBox, fragList);
            // TODO: would like to test box against frustum, then get size on screen. If too small,
            // don't instatiate the box.
            // dump info about the bounding box
            // var area = pt.x * pt.y + pt.x *  1 + pt.y * pt.z ;
            // var volume = pt.x * pt.y * pt.z;
            // var dbIds = fragList.getDbIds(fragId);
            // // dump if less than max count
            // if ( fragList.fragCount++ < fragList.fragMaxCount ) {
            //     console.log( "FragID: " + fragId + "  dbIds: " + dbIds + "  vertices: " + realGeometry.vb.length / realGeometry.vbstride, "  box area: " + area + "  box volume: " + volume + " " );
            // }
            var matrix = new THREE$1.Matrix4();
            scale3.subVectors(_tmpBox.max, _tmpBox.min);
            scale3.multiplyScalar(0.5); // get box size
            matrix.makeScale(scale3.x, scale3.y, scale3.z);
            translation3.addVectors(_tmpBox.max, _tmpBox.min);
            translation3.multiplyScalar(0.5); // get box center
            // don't waste time, just shove the translation values into the right spots
            var te = matrix.elements;
            te[12] = translation3.x;
            te[13] = translation3.y;
            te[14] = translation3.z;
            // store this info away
            fragList.boxTransform[fragId] = matrix;
        }
        m.geometry_proxy = canonical_box;
        m.matrixWorld.copy(fragList.boxTransform[fragId]);
    }
    return function (fragId, renderImportance, putInProxy) {
        // make sure that vertex-colors reflect the latest theming-state
        if (this.model.is2d()) updateVertexBufferForThemingAndGhosting(this, fragId);
        if (this.useThreeMesh) {
            return this.vizmeshes[fragId];
        } else {
            // create temporary mesh object
            init_three();
            // init temp mesh object from geometry, material etc. 
            // TODO - this seems inefficient, that these fields are created each and every call.
            // True? Might be better to have "m" created once and kept ready to return.
            // Also, if no geometry, some of these don't need to be filled in, or can be done without
            // a call. TODO
            this.getWorldMatrix(fragId, m.matrixWorld);
            m.visible = true;
            m.hide = this.isFragOff(fragId);
            m.fragId = fragId;
            m.dbId = this.getDbIds(fragId);
            m.themingColor = this.db2ThemingColor[m.dbId];
            m.modelId = this.model.getModelId();
            m.geometry = this.getGeometry(fragId); // BufferGeometry
            //this.geomCount++;
            //if ( this.geomCount*2 === this.geomMax ) {
            //    console.log("hit this.geomCount " + this.geomCount);
            //}
            //if ( this.geomCount > this.geomMax ) {
            //    m.geometry = null;
            //}
            // if there's no geometry, and we haven't rendered enough boxes this render, create & render some
            //if ( !m.geometry && this.boxCount < this.boxMax ) {   // || true to keep boxes on the screen, && false to turn off feature
            //var showBoxes = !!this.showBox;
            var displayBox = false; //showBoxes;
            if (!displayBox) {
                // feature is off if no proxy option
                var boxProxyMaxCount = this.pagingProxy ? this.pagingProxy.options.debug.boxProxyMaxCount : 0;
                if (!m.geometry && this.boxCount < boxProxyMaxCount) {
                    // check if screen space covered is enough (TODO? doesn't work for SBL iterator, which doesn't set importance)
                    var boxProxyMinScreen = this.pagingProxy ? this.pagingProxy.options.debug.boxProxyMinScreen : 0.1;
                    if (renderImportance === undefined || renderImportance == 0.0 || renderImportance !== undefined && renderImportance > boxProxyMinScreen) {
                        displayBox = true;
                    }
                }
            }
            if (displayBox) {
                // get mesh proxy for the box.
                // TODO - unruly children will give bad boxes. Oh well.
                renderBox(m, fragId, this);
                // really, box is always put in geometry_proxy for now. Not efficient, but minimizes changes to RenderBatchLess.
                // Copy to geometry location if proxy is not needed.
                if (!putInProxy) {
                    // the proxy box is used is used for 
                    m.geometry = m.geometry_proxy;
                }
                this.boxCount++;
                // use the proxy material
                m.material = defaultMaterial;
                // alternate: set the material and, if not found, then use the proxy material
                // Possibly of interest if we ever load the materials before the meshes.
                //if ( m.material === undefined ) {   // || true to keep default color on the screen
                //}
                m.isLine = false;
                m.isWideLine = false;
                m.isPoint = false;
            } else {
                m.material = this.getMaterial(fragId); // THREE.ShaderMaterial
                m.isLine = this.isLine(fragId);
                m.isWideLine = this.isWideLine(fragId);
                m.isPoint = this.isPoint(fragId);
                // Don't set boxTransform if not needed. Setting it to null can take space if it hasn't ever been used
                if (m.geometry && this.boxTransform[fragId]) {
                    // free data, item is loaded
                    this.boxTransform[fragId] = null;
                }
            }
            return m;
        }
    };
}();
/**
 * Create a promise for a mesh with downloaded geometry
 *
 * When the promise fulfills the argument to the fulfillment function is an
 * object with model and fragId properties that identify the mesh. We cannot
 * fulfill using the mesh, because it may be shared and we can't guarantee
 * execution order of independent promises.
 *
 * Promises returned by this function can be canceled using
 * FragmentList.cancelPromisedVizmesh(promise). A canceled promise is always rejected.
 * The canceled property of the argument to the rejection function is true when a
 * promise is canceled.
 * @param {number} fragId - Fragment ID.
 * @returns {Promise} Promise for the mesh for the given fragment.
 */
FragmentList.prototype.promiseVizmesh = function (fragId) {
    // Get a promise for the geometry
    return this.promiseGeometry(fragId);
};
/**
 * Cancel a promise returned by promiseVizmesh
 *
 * Canceled promised always rejects and the canceled property of the argument
 * to the rejection function is set to true.
 * @param {Promise} promise - Promise to be canceled
 * @returns {boolean} - True if the promise is canceled. False if it isn't canceled.
 */
FragmentList.prototype.cancelPromisedVizmesh = function (promise) {
    return this.cancelPromisedGeometry(promise);
};
FragmentList.prototype.getMaterialId = function (fragId) {
    return this.useThreeMesh ? this.vizmeshes[fragId].material.id : this.materialids[fragId];
};
FragmentList.prototype.getMaterial = function (fragId) {
    // material ids are either stored with vizmeshes or in the material map.
    return this.useThreeMesh ? this.vizmeshes[fragId].material : this.materialmap[this.materialids[fragId]];
};
FragmentList.prototype.getGeometry = function (fragId) {
    // geometry is either stored in with vizmoeshes or obtained from this.geoms.
    // Make sure this.vizmesh[fragId] isn't null or undefined
    var mesh;
    return this.useThreeMesh ? (mesh = this.vizmeshes[fragId]) ? mesh.geometry : null : this.geoms.getGeometry(this.geomids[fragId]);
};
/**
 * Locks the geometry for fragment with fragment id 'fragId'.
 * Locked geometry will not be removed when paging out.
 * Use sparingly if on demand loading is enabled.
 * @param {int} fragId - Fragment ID
 * @returns {boolean} True if the geometry was in memory and was locked.
 */
FragmentList.prototype.lockGeometry = function (fragId) {
    // When using THREE.Meshes, all geometry must memory resident
    return this.useThreeMesh ? true : this.geoms.lockGeometry(this.geomids[fragId]);
};
/**
 * Unlocks the geometry for fragment with fragment id 'fragId'.
 * Locked geometry will not be removed when paging out.
 * Call once for each time you call lockGeometry.
 * @param {int} fragId - Fragment ID
 * @returns {boolean} True if the geometry was in memory and was locked.
 */
FragmentList.prototype.unlockGeometry = function (fragId) {
    // When using THREE.Meshes, all geometry must memory resident
    return this.useThreeMesh ? true : this.geoms.unlockGeometry(this.geomids[fragId]);
};
/**
 * Gets the lock count for the geometry for fragment with fragment id 'fragId'.
 * Geometry is locked if the lock count is > 0.
 * Locked geometry will not be removed when paging out.
 * @param {int} fragId - Fragment ID
 * @returns {int} The lock count of the geometry, or -1 if the geometry is not in memory.
 */
FragmentList.prototype.getLockCount = function (fragId) {
    // When using THREE.Meshes, all geometry must memory resident
    return this.useThreeMesh ? 0 : this.geoms.getLockCount(this.geomids[fragId]);
};
FragmentList.prototype.getGeometryId = function (fragId) {
    // When using THREE.Meshes, fragIds and geomids are the same and this.geomids is not used.
    return this.useThreeMesh ? fragId : this.geomids[fragId];
};
FragmentList.prototype.setMaterial = function (fragId, material) {
    if (this.useThreeMesh) {
        this.vizmeshes[fragId].material = material;
    } else {
        this.materialids[fragId] = material.id;
        this.materialmap[material.id] = material;
    }
};
FragmentList.prototype.getCount = function () {
    return this.vizmeshes ? this.vizmeshes.length : this.vizflags.length;
};
FragmentList.prototype.getDbIds = function (fragId) {
    return this.fragments.fragId2dbId[fragId];
};
// glRenderer: instanceof WebGLRenderer (only neeeded when for this.useThreeMesh==false)
FragmentList.prototype.dispose = function (glrenderer) {
    if (this.useThreeMesh) {
        // dispatch remove event to all meshes and dispose events to all BufferGeometry buffers
        // This will trigger EventListeners added by WebGLRenderer that deallocate the geometry later.
        // (see onGeometryDispose(..) in WebGLRenderer.js)
        var DISPOSE_EVENT = { type: 'dispose' };
        var REMOVED_EVENT = { type: 'removed' };
        for (var i = 0; i < this.vizmeshes.length; i++) {
            var m = this.vizmeshes[i];
            if (m) {
                m.dispatchEvent(REMOVED_EVENT);
                m.geometry.dispatchEvent(DISPOSE_EVENT);
            }
        }
    } else {
        // Delete all geometry data immediately (see WebGLRenderer.deallocateGeometry)
        this.geoms.dispose(glrenderer);
    }
};
// This function should probably not be called outside VisibityManager
// in order to maintain node visibility state.
FragmentList.prototype.setVisibility = function (fragId, value) {
    this.setFlagFragment(fragId, MESH_VISIBLE, value);
    this.allVisibleDirty = true;
};
// Note that this function switches whole meshes on/off. It cannot be used to toggle visibility of
// single 2D objects within a single mesh. For this one, use setObject2DVisible instead.
FragmentList.prototype.setFragOff = function (fragId, value) {
    this.setFlagFragment(fragId, MESH_HIDE, value);
    this.allVisibleDirty = true; // [HB:] Either this should be removed or this.areAllVisible should consider MESH_HIDE
};
FragmentList.prototype.setAllVisibility = function (value) {
    if (this.model.is2d()) {
        var frags = this.fragments;
        if (frags && frags.dbId2fragId) {
            for (var id in frags.dbId2fragId) {
                this.setObject2DGhosted(id, !value);
            }
        }
    } else {
        this.setFlagGlobal(MESH_VISIBLE, value);
        this.allVisible = value;
        this.allVisibleDirty = false;
    }
};
/**
 * Updates animation transform of a specific fragment.
 * Note:
 *      - If scale/rotation/translation are all null, the call resets the whole transform, i.e., no anim transform is assigned anymore.
 *      - Leaving some of them null means to leave them unchanged.
 * @param {number} fragId - Fragment ID.
 * @param {Vector3=} scale
 * @param {Quaternion=} rotationQ
 * @param {Vector3=} translation
 */
FragmentList.prototype.updateAnimTransform = function (fragId, scale, rotationQ, translation) {
    var ax = this.animxforms;
    var off;
    //Allocate animation transforms on first use.
    if (!ax) {
        var count = this.getCount();
        ax = this.animxforms = new Float32Array(10 * count); //3 scale + 4 rotation + 3 translation
        for (var i = 0; i < count; i++) {
            // get start index of the anim transform of fragment i
            off = i * 10;
            // init as identity transform
            ax[off] = 1; // scale.x
            ax[off + 1] = 1; // scale.y
            ax[off + 2] = 1; // scale.z
            ax[off + 3] = 0; // rot.x
            ax[off + 4] = 0; // rot.y
            ax[off + 5] = 0; // rot.z
            ax[off + 6] = 1; // rot.w
            ax[off + 7] = 0; // trans.x
            ax[off + 8] = 0; // trans.y
            ax[off + 9] = 0; // trans.z
        }
    }
    off = fragId * 10;
    var moved = false;
    if (scale) {
        ax[off] = scale.x;
        ax[off + 1] = scale.y;
        ax[off + 2] = scale.z;
        moved = true;
    }
    if (rotationQ) {
        ax[off + 3] = rotationQ.x;
        ax[off + 4] = rotationQ.y;
        ax[off + 5] = rotationQ.z;
        ax[off + 6] = rotationQ.w;
        moved = true;
    }
    if (translation) {
        ax[off + 7] = translation.x;
        ax[off + 8] = translation.y;
        ax[off + 9] = translation.z;
        moved = true;
    }
    // Set MESH_MOVED if an animation transform has been assigned. Just if scale/rotation/translation are all null, unset the flag.
    this.setFlagFragment(fragId, MESH_MOVED, moved);
    //Assume that if we are called with null everything the caller wants to reset the transform.
    if (!moved) {
        // reset to identity transform
        ax[off] = 1;
        ax[off + 1] = 1;
        ax[off + 2] = 1;
        ax[off + 3] = 0;
        ax[off + 4] = 0;
        ax[off + 5] = 0;
        ax[off + 6] = 1;
        ax[off + 7] = 0;
        ax[off + 8] = 0;
        ax[off + 9] = 0;
    }
};
/**
 * Returns animation transform of a specific fragment.
 * @param {number} fragId - Fragment ID.
 * @param {Vector3=} scale - Output param.
 * @param {Quaternion=} rotationQ - Output param.
 * @param {Vector3=} translation - Output param.
 * @returns {bool} True if an anim transform is assigned to the given fragment.
 *      If so, it is written to the given out params. False otherwise (outparams not changed).
 */
FragmentList.prototype.getAnimTransform = function (fragId, scale, rotationQ, translation) {
    if (!this.animxforms) return false;
    if (!this.isFlagSet(fragId, MESH_MOVED)) return false;
    var off = fragId * 10;
    var ax = this.animxforms;
    if (scale) {
        scale.x = ax[off];
        scale.y = ax[off + 1];
        scale.z = ax[off + 2];
    }
    if (rotationQ) {
        rotationQ.x = ax[off + 3];
        rotationQ.y = ax[off + 4];
        rotationQ.z = ax[off + 5];
        rotationQ.w = ax[off + 6];
    }
    if (translation) {
        translation.x = ax[off + 7];
        translation.y = ax[off + 8];
        translation.z = ax[off + 9];
    }
    return true;
};
/**
 * Returns world matrix of a fragment.
 * @param {number} index - Fragment ID.
 * @param {THREE.Matrix4} dstMtx - Out param to receive the matrix.
 */
FragmentList.prototype.getOriginalWorldMatrix = function (index, dstMtx) {
    var i = index * 12;
    var cur = dstMtx.elements;
    var orig = this.transforms;
    if (orig) {
        // If this.transforms is defined, copy transform from this array            
        // In this.transforms, we only store the upper 3 rows explicitly. 
        // The last row is alway (0,0,0,1).
        cur[0] = orig[i];
        cur[1] = orig[i + 1];
        cur[2] = orig[i + 2];
        cur[3] = 0;
        cur[4] = orig[i + 3];
        cur[5] = orig[i + 4];
        cur[6] = orig[i + 5];
        cur[7] = 0;
        cur[8] = orig[i + 6];
        cur[9] = orig[i + 7];
        cur[10] = orig[i + 8];
        cur[11] = 0;
        cur[12] = orig[i + 9];
        cur[13] = orig[i + 10];
        cur[14] = orig[i + 11];
        cur[15] = 1;
    } else if (this.useThreeMesh) {
        // get matrix directly from THREE.Mesh
        var m = this.getVizmesh(index);
        if (m) dstMtx.copy(m.matrixWorld);else dstMtx.identity();
    } else {
        dstMtx.identity();
    }
};
/**
 * Writes the final world matrix of a fragment to out param dstMtx.
 * The world matrix results from original transform and anim transform (if any).
 * @param {number} index - Fragment ID.
 * @param {THREE.Matrix4} dstMtx - Out param to receive the matrix.
 */
FragmentList.prototype.getWorldMatrix = function () {
    var tmp, pos, rot, scale;
    function init_three() {
        tmp = new THREE$1.Matrix4();
        pos = new THREE$1.Vector3();
        rot = new THREE$1.Quaternion();
        scale = new THREE$1.Vector3();
    }
    return function (index, dstMtx) {
        if (!tmp) init_three();
        this.getOriginalWorldMatrix(index, dstMtx);
        //If mesh hasn't moved from its original location, just use that.
        if (!this.isFlagSet(index, MESH_MOVED)) {
            return;
        }
        //Otherwise construct the overall world matrix
        this.getAnimTransform(index, scale, rot, pos);
        // compose matrix from pos, rotation, and scale
        tmp.compose(pos, rot, scale);
        // First apply original matrix (in dstMtx), then anim matrix (in tmp).
        // Note that tmp muist be multipled from left for this.
        dstMtx.multiplyMatrices(tmp, dstMtx);
    };
}();
/**
 * Writes the world box to dstBox outparams, considering matrix and anim transform (if specified).
 * @param {number} index - Fragment ID.
 * @param {THREE.Box3|LmvBox3}
 */
FragmentList.prototype.getWorldBounds = function () {
    var tmp;
    function init_three() {
        tmp = new THREE$1.Matrix4();
    }
    return function (index, dstBox) {
        if (!tmp) init_three();
        //Check if the world transform of the mesh is unchanged from
        //the original LMV file -- in such case we can use the original
        //bounding box from the LMV package, which is presumably more precise (tighter)
        //than just transforming the model box.
        //This is important if we want to keep our bounding volume hierarchy efficient.
        if (this.boxes && !this.isFlagSet(index, MESH_MOVED)) {
            var b = this.boxes;
            var boffset = index * 6;
            dstBox.min.x = b[boffset];
            dstBox.min.y = b[boffset + 1];
            dstBox.min.z = b[boffset + 2];
            dstBox.max.x = b[boffset + 3];
            dstBox.max.y = b[boffset + 4];
            dstBox.max.z = b[boffset + 5];
            return;
        }
        // get original model box
        if (this.useThreeMesh) {
            // either from THREE.Mesh
            var m = this.getVizmesh(index);
            if (m && m.geometry) {
                dstBox.copy(m.geometry.boundingBox);
            }
        } else {
            // or from GeometryList
            this.geoms.getModelBox(this.geomids[index], dstBox);
        }
        if (!dstBox.empty()) {
            // apply world matrix to dstBox
            this.getWorldMatrix(index, tmp);
            dstBox.applyMatrix4(tmp);
        }
    };
}();
// set themingNeedsUpdate flag for all vizmeshes that contain a given dbId
function setThemingOrGhostingNeedsUpdateFlag(fragList, dbId) {
    if (!fragList.model.is2d()) {
        // In this case (3D model), we just have theming colors per mesh and don't need to update vertex buffers.
        return;
    }
    // get id(s) of affected mesh(es) that needs a vertex-color update
    var fragIds = fragList.fragments.dbId2fragId[dbId];
    //  trigger update for single id or an array of ids
    if (Array.isArray(fragIds)) {
        for (var i = 0; i < fragIds.length; i++) {
            fragList.themingOrGhostingNeedsUpdate[fragIds[i]] = true;
        }
    } else if (typeof fragIds === 'number') {
        fragList.themingOrGhostingNeedsUpdate[fragIds] = true;
    }
}
/**
 * Applies a theming color that is blended with the final fragment color of a material shader.
 * @param {number}        dbId
 * @param {THREE.Vector4} [color] - theming color (in xyz) and intensity (in w). All components in [0,1].
 *                                  Set to undefined for 'no theming'
 */
FragmentList.prototype.setThemingColor = function (dbId, color) {
    // Stop if color keeps the same
    var oldColor = this.db2ThemingColor[dbId];
    var colorsEqual = oldColor === color || oldColor && color && oldColor.equals(color);
    if (!colorsEqual) {
        this.db2ThemingColor[dbId] = color;
        setThemingOrGhostingNeedsUpdateFlag(this, dbId);
    }
};
/** Restore original colors for all themed shapes. */
FragmentList.prototype.clearThemingColors = function () {
    // When using F2D (model.is2d()==true), we have to update the restore the original
    // per-vertex colors. For 3D, we can use per-shape colors, so that this step is not
    // needed.
    if (this.model.is2d()) {
        // trigger update for all meshes that were affected by theming before
        // Note that dbId2fragId only exists for F2D models.
        for (var i = 1, iEnd = this.fragments.dbId2fragId.length; i < iEnd; i++) {
            setThemingOrGhostingNeedsUpdateFlag(this, i);
        }
    }
    // clear theming-color map
    this.db2ThemingColor.length = 0;
};
/** Set ghosting flag for a 2D object. This reduces the objects opacity, blends it with pageColor, and excludes it from selection.
 *  @param {number} dbId
 *  @param {bool}   state
 */
FragmentList.prototype.setObject2DGhosted = function (dbId, state) {
    var oldState = this.dbIdIsGhosted[dbId];
    if (!!state !== !!oldState) {
        this.dbIdIsGhosted[dbId] = state;
        setThemingOrGhostingNeedsUpdateFlag(this, dbId);
    }
};
/** Set hide flag for a 2D object. This sets opacity to 0.0, which also excludes it from selection.
 *  @param {number} dbId
 *  @param {bool}   visible
 */
FragmentList.prototype.setObject2DVisible = function (dbId, visible) {
    var wasVisible = !this.dbIdIsHidden[dbId];
    if (visible !== wasVisible) {
        this.dbIdIsHidden[dbId] = !visible;
        setThemingOrGhostingNeedsUpdateFlag(this, dbId);
    }
};
/**
 * Get the memory stats when using on demand loading.
 * @returns {object|null} Object containing the limit and loaded memory usage for the model.
 *                        Return null if the model isn't being loaded on demand.
 */
FragmentList.prototype.getMemoryInfo = function () {
    return this.pagingProxy ? this.pagingProxy.getMemoryInfo() : null;
};
/**
 * Convenience class encapsulating a single fragment in a given FragmentList.
 * Use sparingly, as it is expensive to have those for every fragment in memory.
 * @constructor
 */
function FragmentPointer(frags, fragId) {
    this.frags = frags; // fragment list
    this.fragId = fragId; // id of a fragment in frags
    // used by MeshAnimation
    this.scale = null;
    this.quaternion = null;
    this.position = null;
}
FragmentPointer.prototype.getWorldMatrix = function (dst) {
    this.frags.getWorldMatrix(this.fragId, dst);
};
FragmentPointer.prototype.getOriginalWorldMatrix = function (dst) {
    this.frags.getOriginalWorldMatrix(this.fragId, dst);
};
FragmentPointer.prototype.getWorldBounds = function (dst) {
    return this.frags.getWorldBounds(this.fragId, dst);
};
/**
 * Sets this.scale / this.quaternion / this.position to the anim transform of the the fragment this.fragId.
 * @returns {bool} True if an animation transform is set. Otherwise, it returns false and transform is set to identity.
 */
FragmentPointer.prototype.getAnimTransform = function () {
    if (!this.scale) {
        this.scale = new THREE$1.Vector3(1, 1, 1);
        this.quaternion = new THREE$1.Quaternion(0, 0, 0, 1);
        this.position = new THREE$1.Vector3(0, 0, 0);
    }
    return this.frags.getAnimTransform(this.fragId, this.scale, this.quaternion, this.position);
};
// Applies current scale/quaternion/position to the fragment.
FragmentPointer.prototype.updateAnimTransform = function () {
    if (!this.scale) {
        this.scale = new THREE$1.Vector3(1, 1, 1);
        this.quaternion = new THREE$1.Quaternion(0, 0, 0, 1);
        this.position = new THREE$1.Vector3(0, 0, 0);
    }
    this.frags.updateAnimTransform(this.fragId, this.scale, this.quaternion, this.position);
};
FragmentPointer.prototype.getMaterial = function () {
    return this.frags.getMaterial(this.fragId);
};
FragmentPointer.prototype.setMaterial = function (material) {
    return this.frags.setMaterial(this.fragId, material);
};
var FragmentListUtils = {
    FragmentPointer: FragmentPointer,
    FragmentList: FragmentList
};

/**
 * Helper struct to work with tile quadtree structure.
 * @constructor
 */
/**
 * Helper struct to work with tile quadtree structure.
 * @constructor
 */function TileCoords(level, x, y) {
    this.level = level;
    this.x = x;
    this.y = y;
}
TileCoords.prototype = {
    constructor: TileCoords,
    copy: function copy() {
        return new TileCoords(this.level, this.x, this.y);
    },
    /** returns {bool} */
    isValid: function isValid() {
        return Number.isInteger(this.level) && this.level >= 0 && Number.isInteger(this.x) && Number.isInteger(this.y);
    },
    /* @param   {number}     child - must be in [0,3]
     * @returns {TileCoords}
     */
    getChild: function getChild(child) {
        var xOffset = child & 1 ? 1 : 0;
        var yOffset = child & 2 ? 1 : 0;
        return new TileCoords(this.level + 1, this.x * 2 + xOffset, this.y * 2 + yOffset);
    },
    /**
     *  @returns {TileCoords|null} Parent tile or null if this tile was root or invalid.
     */
    getParent: function getParent() {
        if (this.level == 0) {
            return null;
        }
        return new TileCoords(this.level - 1, Math.floor(this.x / 2), Math.floor(this.y / 2));
    },
    /**
     *   Computes the subtree root at a given level. 'level' must be <= the current level.
     *    @param {number} level
     *    @returns {TileCoords|null}
     */
    getParentAtLevel: function getParentAtLevel(level) {
        if (level < 0 || level > this.level) {
            return null;
        }
        // compute level difference
        var levelDiff = this.level - level;
        // compute column and row at this level
        var c = Math.floor(this.x >> levelDiff);
        var r = Math.floor(this.y >> levelDiff);
        return new TileCoords(level, c, r);
    },
    /** @returns {string} E.g., "(1,1,2)" */
    toString: function toString() {
        return "(" + this.level + ", " + this.x + ", " + this.y + ")";
    },
    /**
     * Can be called either with a single TileCoords param or with (level, x, y) as integers.
     *   @param {TileCoords|number} levelOrTile
     *   @param {number}            [x]
     *   @param {number}            [y]
     *   @returns {bool}
     */
    equals: function equals(levelOrTile, x, y) {
        if (levelOrTile instanceof TileCoords) {
            return this.equals(levelOrTile.level, levelOrTile.x, levelOrTile.y);
        }
        return this.level === levelOrTile && this.x === x && this.y === y;
    }
};
/**
 * Inverse of index2Tile (see below).
 * Note that this is only possible as long as all tiles share a common root tile (0,0,0).
 *  @param   {TileCoords}
 *  @returns {number}
 */
var tile2Index = function tile2Index(tile) {
    // level 0 has 1 tile and the number of tiles grows by factor 4 with each level.
    // Using geometric sum formular, we obtain the summed number of tiles for 
    // levels 0,...,tile.level-1 as:
    var firstTileInLevel = ((1 << 2 * tile.level) - 1) / 3;
    // compute individual index per row/column pair
    var tilesPerRow = 1 << tile.level;
    return firstTileInLevel + tile.y * tilesPerRow + tile.x;
};
/**
 * Enumerates all tiles of a complete quadtree in breadth-first order.
 *  @param   {number} int >= 0
 *  @returns {TileCoords}
 */
var index2Tile = function index2Tile(index) {
    var tile = new TileCoords(0, 0, 0);
    // find level maximum level for which the index is <= the target index
    while (tile2Index(tile) <= index) {
        tile.level++;
    }
    tile.level--;
    // compute the local index inside this level
    var localIndex = index - tile2Index(tile);
    // Having the level, we can compute index and column
    var tilesPerRow = 1 << tile.level;
    tile.y = Math.floor(localIndex / tilesPerRow);
    tile.x = localIndex % tilesPerRow;
    return tile;
};
var TileUtils = {
    TileCoords: TileCoords,
    tile2Index: tile2Index,
    index2Tile: index2Tile
};

/**
 * @author mrdoob / http://mrdoob.com/
 * @author supereggbert / http://www.paulbrunt.co.uk/
 * @author philogb / http://blog.thejit.org/
 * @author jordi_ros / http://plattsoft.com
 * @author D1plo1d / http://github.com/D1plo1d
 * @author alteredq / http://alteredqualia.com/
 * @author mikael emtinger / http://gomo.se/
 * @author timknip / http://www.floorplanner.com/
 * @author bhouston / http://exocortex.com
 * @author WestLangley / http://github.com/WestLangley
 */
/* Pruned version of THREE.Matrix4, for use in the LMV web worker */
/**
 * @author mrdoob / http://mrdoob.com/
 * @author supereggbert / http://www.paulbrunt.co.uk/
 * @author philogb / http://blog.thejit.org/
 * @author jordi_ros / http://plattsoft.com
 * @author D1plo1d / http://github.com/D1plo1d
 * @author alteredq / http://alteredqualia.com/
 * @author mikael emtinger / http://gomo.se/
 * @author timknip / http://www.floorplanner.com/
 * @author bhouston / http://exocortex.com
 * @author WestLangley / http://github.com/WestLangley
 */var LmvMatrix4 = function LmvMatrix4(useDoublePrecision) {
    if (useDoublePrecision) {
        this.elements = new Float64Array([1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1]);
    } else {
        this.elements = new Float32Array([1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1]);
    }
};
LmvMatrix4.prototype = {
    constructor: LmvMatrix4,
    set: function set(n11, n12, n13, n14, n21, n22, n23, n24, n31, n32, n33, n34, n41, n42, n43, n44) {
        var te = this.elements;
        te[0] = n11;
        te[4] = n12;
        te[8] = n13;
        te[12] = n14;
        te[1] = n21;
        te[5] = n22;
        te[9] = n23;
        te[13] = n24;
        te[2] = n31;
        te[6] = n32;
        te[10] = n33;
        te[14] = n34;
        te[3] = n41;
        te[7] = n42;
        te[11] = n43;
        te[15] = n44;
        return this;
    },
    identity: function identity() {
        this.set(1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1);
        return this;
    },
    copy: function copy(m) {
        this.elements.set(m.elements);
        return this;
    },
    makeRotationFromQuaternion: function makeRotationFromQuaternion(q) {
        var te = this.elements;
        var x = q.x,
            y = q.y,
            z = q.z,
            w = q.w;
        var x2 = x + x,
            y2 = y + y,
            z2 = z + z;
        var xx = x * x2,
            xy = x * y2,
            xz = x * z2;
        var yy = y * y2,
            yz = y * z2,
            zz = z * z2;
        var wx = w * x2,
            wy = w * y2,
            wz = w * z2;
        te[0] = 1 - (yy + zz);
        te[4] = xy - wz;
        te[8] = xz + wy;
        te[1] = xy + wz;
        te[5] = 1 - (xx + zz);
        te[9] = yz - wx;
        te[2] = xz - wy;
        te[6] = yz + wx;
        te[10] = 1 - (xx + yy);
        // last column
        te[3] = 0;
        te[7] = 0;
        te[11] = 0;
        // bottom row
        te[12] = 0;
        te[13] = 0;
        te[14] = 0;
        te[15] = 1;
        return this;
    },
    multiply: function multiply(n) {
        return this.multiplyMatrices(this, n);
    },
    multiplyMatrices: function multiplyMatrices(a, b) {
        var ae = a.elements;
        var be = b.elements;
        var te = this.elements;
        var a11 = ae[0],
            a12 = ae[4],
            a13 = ae[8],
            a14 = ae[12];
        var a21 = ae[1],
            a22 = ae[5],
            a23 = ae[9],
            a24 = ae[13];
        var a31 = ae[2],
            a32 = ae[6],
            a33 = ae[10],
            a34 = ae[14];
        var a41 = ae[3],
            a42 = ae[7],
            a43 = ae[11],
            a44 = ae[15];
        var b11 = be[0],
            b12 = be[4],
            b13 = be[8],
            b14 = be[12];
        var b21 = be[1],
            b22 = be[5],
            b23 = be[9],
            b24 = be[13];
        var b31 = be[2],
            b32 = be[6],
            b33 = be[10],
            b34 = be[14];
        var b41 = be[3],
            b42 = be[7],
            b43 = be[11],
            b44 = be[15];
        te[0] = a11 * b11 + a12 * b21 + a13 * b31 + a14 * b41;
        te[4] = a11 * b12 + a12 * b22 + a13 * b32 + a14 * b42;
        te[8] = a11 * b13 + a12 * b23 + a13 * b33 + a14 * b43;
        te[12] = a11 * b14 + a12 * b24 + a13 * b34 + a14 * b44;
        te[1] = a21 * b11 + a22 * b21 + a23 * b31 + a24 * b41;
        te[5] = a21 * b12 + a22 * b22 + a23 * b32 + a24 * b42;
        te[9] = a21 * b13 + a22 * b23 + a23 * b33 + a24 * b43;
        te[13] = a21 * b14 + a22 * b24 + a23 * b34 + a24 * b44;
        te[2] = a31 * b11 + a32 * b21 + a33 * b31 + a34 * b41;
        te[6] = a31 * b12 + a32 * b22 + a33 * b32 + a34 * b42;
        te[10] = a31 * b13 + a32 * b23 + a33 * b33 + a34 * b43;
        te[14] = a31 * b14 + a32 * b24 + a33 * b34 + a34 * b44;
        te[3] = a41 * b11 + a42 * b21 + a43 * b31 + a44 * b41;
        te[7] = a41 * b12 + a42 * b22 + a43 * b32 + a44 * b42;
        te[11] = a41 * b13 + a42 * b23 + a43 * b33 + a44 * b43;
        te[15] = a41 * b14 + a42 * b24 + a43 * b34 + a44 * b44;
        return this;
    },
    multiplyToArray: function multiplyToArray(a, b, r) {
        var te = this.elements;
        this.multiplyMatrices(a, b);
        r[0] = te[0];
        r[1] = te[1];
        r[2] = te[2];
        r[3] = te[3];
        r[4] = te[4];
        r[5] = te[5];
        r[6] = te[6];
        r[7] = te[7];
        r[8] = te[8];
        r[9] = te[9];
        r[10] = te[10];
        r[11] = te[11];
        r[12] = te[12];
        r[13] = te[13];
        r[14] = te[14];
        r[15] = te[15];
        return this;
    },
    multiplyScalar: function multiplyScalar(s) {
        var te = this.elements;
        te[0] *= s;
        te[4] *= s;
        te[8] *= s;
        te[12] *= s;
        te[1] *= s;
        te[5] *= s;
        te[9] *= s;
        te[13] *= s;
        te[2] *= s;
        te[6] *= s;
        te[10] *= s;
        te[14] *= s;
        te[3] *= s;
        te[7] *= s;
        te[11] *= s;
        te[15] *= s;
        return this;
    },
    determinant: function determinant() {
        var te = this.elements;
        var n11 = te[0],
            n12 = te[4],
            n13 = te[8],
            n14 = te[12];
        var n21 = te[1],
            n22 = te[5],
            n23 = te[9],
            n24 = te[13];
        var n31 = te[2],
            n32 = te[6],
            n33 = te[10],
            n34 = te[14];
        var n41 = te[3],
            n42 = te[7],
            n43 = te[11],
            n44 = te[15];
        //TODO: make this more efficient
        //( based on http://www.euclideanspace.com/maths/algebra/matrix/functions/inverse/fourD/index.htm )
        return n41 * (+n14 * n23 * n32 - n13 * n24 * n32 - n14 * n22 * n33 + n12 * n24 * n33 + n13 * n22 * n34 - n12 * n23 * n34) + n42 * (+n11 * n23 * n34 - n11 * n24 * n33 + n14 * n21 * n33 - n13 * n21 * n34 + n13 * n24 * n31 - n14 * n23 * n31) + n43 * (+n11 * n24 * n32 - n11 * n22 * n34 - n14 * n21 * n32 + n12 * n21 * n34 + n14 * n22 * n31 - n12 * n24 * n31) + n44 * (-n13 * n22 * n31 - n11 * n23 * n32 + n11 * n22 * n33 + n13 * n21 * n32 - n12 * n21 * n33 + n12 * n23 * n31);
    },
    transpose: function transpose() {
        var te = this.elements;
        var tmp;
        tmp = te[1];
        te[1] = te[4];
        te[4] = tmp;
        tmp = te[2];
        te[2] = te[8];
        te[8] = tmp;
        tmp = te[6];
        te[6] = te[9];
        te[9] = tmp;
        tmp = te[3];
        te[3] = te[12];
        te[12] = tmp;
        tmp = te[7];
        te[7] = te[13];
        te[13] = tmp;
        tmp = te[11];
        te[11] = te[14];
        te[14] = tmp;
        return this;
    },
    flattenToArrayOffset: function flattenToArrayOffset(array, offset) {
        var te = this.elements;
        array[offset] = te[0];
        array[offset + 1] = te[1];
        array[offset + 2] = te[2];
        array[offset + 3] = te[3];
        array[offset + 4] = te[4];
        array[offset + 5] = te[5];
        array[offset + 6] = te[6];
        array[offset + 7] = te[7];
        array[offset + 8] = te[8];
        array[offset + 9] = te[9];
        array[offset + 10] = te[10];
        array[offset + 11] = te[11];
        array[offset + 12] = te[12];
        array[offset + 13] = te[13];
        array[offset + 14] = te[14];
        array[offset + 15] = te[15];
        return array;
    },
    setPosition: function setPosition(v) {
        var te = this.elements;
        te[12] = v.x;
        te[13] = v.y;
        te[14] = v.z;
        return this;
    },
    getInverse: function getInverse(m, throwOnInvertible) {
        // based on http://www.euclideanspace.com/maths/algebra/matrix/functions/inverse/fourD/index.htm
        var te = this.elements;
        var me = m.elements;
        var n11 = me[0],
            n12 = me[4],
            n13 = me[8],
            n14 = me[12];
        var n21 = me[1],
            n22 = me[5],
            n23 = me[9],
            n24 = me[13];
        var n31 = me[2],
            n32 = me[6],
            n33 = me[10],
            n34 = me[14];
        var n41 = me[3],
            n42 = me[7],
            n43 = me[11],
            n44 = me[15];
        te[0] = n23 * n34 * n42 - n24 * n33 * n42 + n24 * n32 * n43 - n22 * n34 * n43 - n23 * n32 * n44 + n22 * n33 * n44;
        te[4] = n14 * n33 * n42 - n13 * n34 * n42 - n14 * n32 * n43 + n12 * n34 * n43 + n13 * n32 * n44 - n12 * n33 * n44;
        te[8] = n13 * n24 * n42 - n14 * n23 * n42 + n14 * n22 * n43 - n12 * n24 * n43 - n13 * n22 * n44 + n12 * n23 * n44;
        te[12] = n14 * n23 * n32 - n13 * n24 * n32 - n14 * n22 * n33 + n12 * n24 * n33 + n13 * n22 * n34 - n12 * n23 * n34;
        te[1] = n24 * n33 * n41 - n23 * n34 * n41 - n24 * n31 * n43 + n21 * n34 * n43 + n23 * n31 * n44 - n21 * n33 * n44;
        te[5] = n13 * n34 * n41 - n14 * n33 * n41 + n14 * n31 * n43 - n11 * n34 * n43 - n13 * n31 * n44 + n11 * n33 * n44;
        te[9] = n14 * n23 * n41 - n13 * n24 * n41 - n14 * n21 * n43 + n11 * n24 * n43 + n13 * n21 * n44 - n11 * n23 * n44;
        te[13] = n13 * n24 * n31 - n14 * n23 * n31 + n14 * n21 * n33 - n11 * n24 * n33 - n13 * n21 * n34 + n11 * n23 * n34;
        te[2] = n22 * n34 * n41 - n24 * n32 * n41 + n24 * n31 * n42 - n21 * n34 * n42 - n22 * n31 * n44 + n21 * n32 * n44;
        te[6] = n14 * n32 * n41 - n12 * n34 * n41 - n14 * n31 * n42 + n11 * n34 * n42 + n12 * n31 * n44 - n11 * n32 * n44;
        te[10] = n12 * n24 * n41 - n14 * n22 * n41 + n14 * n21 * n42 - n11 * n24 * n42 - n12 * n21 * n44 + n11 * n22 * n44;
        te[14] = n14 * n22 * n31 - n12 * n24 * n31 - n14 * n21 * n32 + n11 * n24 * n32 + n12 * n21 * n34 - n11 * n22 * n34;
        te[3] = n23 * n32 * n41 - n22 * n33 * n41 - n23 * n31 * n42 + n21 * n33 * n42 + n22 * n31 * n43 - n21 * n32 * n43;
        te[7] = n12 * n33 * n41 - n13 * n32 * n41 + n13 * n31 * n42 - n11 * n33 * n42 - n12 * n31 * n43 + n11 * n32 * n43;
        te[11] = n13 * n22 * n41 - n12 * n23 * n41 - n13 * n21 * n42 + n11 * n23 * n42 + n12 * n21 * n43 - n11 * n22 * n43;
        te[15] = n12 * n23 * n31 - n13 * n22 * n31 + n13 * n21 * n32 - n11 * n23 * n32 - n12 * n21 * n33 + n11 * n22 * n33;
        var det = n11 * te[0] + n21 * te[4] + n31 * te[8] + n41 * te[12];
        if (det == 0) {
            var msg = "Matrix4.getInverse(): can't invert matrix, determinant is 0";
            if (throwOnInvertible || false) {
                throw new Error(msg);
            } else {
                console.warn(msg);
            }
            this.identity();
            return this;
        }
        this.multiplyScalar(1 / det);
        return this;
    },
    scale: function scale(v) {
        var te = this.elements;
        var x = v.x,
            y = v.y,
            z = v.z;
        te[0] *= x;
        te[4] *= y;
        te[8] *= z;
        te[1] *= x;
        te[5] *= y;
        te[9] *= z;
        te[2] *= x;
        te[6] *= y;
        te[10] *= z;
        te[3] *= x;
        te[7] *= y;
        te[11] *= z;
        return this;
    },
    makeTranslation: function makeTranslation(x, y, z) {
        this.set(1, 0, 0, x, 0, 1, 0, y, 0, 0, 1, z, 0, 0, 0, 1);
        return this;
    },
    makeRotationX: function makeRotationX(theta) {
        var c = Math.cos(theta),
            s = Math.sin(theta);
        this.set(1, 0, 0, 0, 0, c, -s, 0, 0, s, c, 0, 0, 0, 0, 1);
        return this;
    },
    makeRotationY: function makeRotationY(theta) {
        var c = Math.cos(theta),
            s = Math.sin(theta);
        this.set(c, 0, s, 0, 0, 1, 0, 0, -s, 0, c, 0, 0, 0, 0, 1);
        return this;
    },
    makeRotationZ: function makeRotationZ(theta) {
        var c = Math.cos(theta),
            s = Math.sin(theta);
        this.set(c, -s, 0, 0, s, c, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1);
        return this;
    },
    makeRotationAxis: function makeRotationAxis(axis, angle) {
        // Based on http://www.gamedev.net/reference/articles/article1199.asp
        var c = Math.cos(angle);
        var s = Math.sin(angle);
        var t = 1 - c;
        var x = axis.x,
            y = axis.y,
            z = axis.z;
        var tx = t * x,
            ty = t * y;
        this.set(tx * x + c, tx * y - s * z, tx * z + s * y, 0, tx * y + s * z, ty * y + c, ty * z - s * x, 0, tx * z - s * y, ty * z + s * x, t * z * z + c, 0, 0, 0, 0, 1);
        return this;
    },
    makeScale: function makeScale(x, y, z) {
        this.set(x, 0, 0, 0, 0, y, 0, 0, 0, 0, z, 0, 0, 0, 0, 1);
        return this;
    },
    compose: function compose(position, quaternion, scale) {
        this.makeRotationFromQuaternion(quaternion);
        this.scale(scale);
        this.setPosition(position);
        return this;
    },
    //Added for LMV
    transformPoint: function transformPoint(pt) {
        // input: THREE.Matrix4 affine matrix
        var x = pt.x,
            y = pt.y,
            z = pt.z;
        var e = this.elements;
        pt.x = e[0] * x + e[4] * y + e[8] * z + e[12];
        pt.y = e[1] * x + e[5] * y + e[9] * z + e[13];
        pt.z = e[2] * x + e[6] * y + e[10] * z + e[14];
        return pt;
    },
    //Added for LMV
    transformDirection: function transformDirection(v) {
        // input: THREE.Matrix4 affine matrix
        // vector interpreted as a direction
        var x = v.x,
            y = v.y,
            z = v.z;
        var e = this.elements;
        v.x = e[0] * x + e[4] * y + e[8] * z;
        v.y = e[1] * x + e[5] * y + e[9] * z;
        v.z = e[2] * x + e[6] * y + e[10] * z;
        var len = Math.sqrt(v.x * v.x + v.y * v.y + v.z * v.z);
        if (len > 0) {
            var ilen = 1.0 / len;
            v.x *= ilen;
            v.y *= ilen;
            v.z *= ilen;
        }
        return v;
    },
    fromArray: function fromArray(array) {
        this.elements.set(array);
        return this;
    },
    toArray: function toArray() {
        var te = this.elements;
        return [te[0], te[1], te[2], te[3], te[4], te[5], te[6], te[7], te[8], te[9], te[10], te[11], te[12], te[13], te[14], te[15]];
    },
    clone: function clone() {
        return new LmvMatrix4(this.elements instanceof Float64Array).fromArray(this.elements);
    }
};

// Simple helper to describe uv offset and scale
function UVTransform() {
    this.offsetX = 0.0;
    this.offsetY = 0.0;
    this.scaleX = 1.0;
    this.scaleY = 1.0;
}
UVTransform.prototype.toVec4 = function () {
    return new THREE$1.Vector4(this.offsetX, this.offsetY, this.scaleX, this.scaleY);
};
UVTransform.prototype.copyTo = function (otherUV) {
    otherUV.offsetX = this.offsetX;
    otherUV.offsetY = this.offsetY;
    otherUV.scaleX = this.scaleX;
    otherUV.scaleY = this.scaleY;
};
function GeometryManager() {
    // reused geometry for on-the-fly generated fallback tiles, which require individual uv-coords
    // It would be better to share _quadGeom for these as well. But this is would require a solution
    // first how we can use the same texture with different uvTransforms in a single frame.
    var _reusedGeoms = []; // {THREE.Geometry}
    // index to the first elem in _reusedGeoms that has not been used for the current frame yet.
    var _nextFreeGeom = 0;
    var _uvTransformIdentity = new UVTransform();
    /** Updates the uv-coords for a given quad geometry.
     *   @param {THREE.Geometry} geom
     *   @param {UVTransform}    [uvTransform] - default: identity
     */
    function setUVCoords(geom, uvTransform) {
        var tf = uvTransform ? uvTransform : _uvTransformIdentity;
        var uvs = [];
        uvs.push(new THREE$1.Vector2(tf.offsetX, tf.offsetY));
        uvs.push(new THREE$1.Vector2(tf.offsetX + tf.scaleX, tf.offsetY));
        uvs.push(new THREE$1.Vector2(tf.offsetX + tf.scaleX, tf.offsetY + tf.scaleY));
        uvs.push(new THREE$1.Vector2(tf.offsetX, tf.offsetY + tf.scaleY));
        geom.faceVertexUvs[0].length = 0;
        geom.faceVertexUvs[0].push([uvs[0], uvs[1], uvs[2]]);
        geom.faceVertexUvs[0].push([uvs[0], uvs[2], uvs[3]]);
        geom.uvTransform = tf;
        geom.uvsNeedUpdate = true;
    }
    /**
     * Returns a reusable geometry and recomputes its uv coords based on given scale and offset.
     *  @param   {UVTransform}    [uvOffsetX]
     *  @returns {THREE.Geometry} A geometry from _reusedGeoms
     */
    this.acquireQuadGeom = function (uvTransform) {
        // get next reusable mesh and increase counter
        var geom = _reusedGeoms[_nextFreeGeom];
        // if not available yet, create it
        if (!geom) {
            geom = this.createQuadGeom(uvTransform);
            // keep it for reuse in later frames
            _reusedGeoms[_nextFreeGeom] = geom;
        } else {
            // reuse old geom and just update uv
            setUVCoords(geom, uvTransform);
        }
        // inc counter so that this geom is not used again in this frame
        _nextFreeGeom++;
        return geom;
    };
    /**
     *  @param {UVTransform} [uvTransform]
     *  @returns {THREE.Geometry}
     */
    this.createQuadGeom = function (uvTransform) {
        // vertices
        var geom = new THREE$1.Geometry();
        geom.vertices.push(new THREE$1.Vector3(0.0, 0.0, 0.0), new THREE$1.Vector3(1.0, 0.0, 0.0), new THREE$1.Vector3(1.0, 1.0, 0.0), new THREE$1.Vector3(0.0, 1.0, 0.0));
        // indices
        geom.faces.push(new THREE$1.Face3(0, 1, 2));
        geom.faces.push(new THREE$1.Face3(0, 2, 3));
        setUVCoords(geom, uvTransform);
        geom.computeFaceNormals();
        return geom;
    };
    this.reset = function () {
        _nextFreeGeom = 0;
    };
    this.dispose = function () {
        for (var i = 0; i < _reusedGeoms.length; i++) {
            var geom = _reusedGeoms[i];
            if (geom) {
                geom.dispose();
                geom.needsUpdate = true;
            }
        }
    };
}

var tc = TileUtils;
var TileState_Missing = 0;
var TileState_Loading = 1;
var TileState_Loaded = 2;
var TileInfo = function TileInfo(timeStamp, mesh) {
    this.timeStamp = timeStamp; // {number} frame timeStamp of last usage 
    this.mesh = mesh; // {THREE.Mesh}
    this.state = TileState_Missing;
};
// @param {THREE.Vector3} p
// @param {THREE.Vector3} bboxMin
// @param {THREE.Vector3} bboxMax
// @returns {Number} Squared distance of the bbox to p
function point2BoxDistance2(p, boxMin, boxMax) {
    // compute the point within bbox that is nearest to p by clamping against box
    var nearest = p.clone();
    nearest.max(boxMin);
    nearest.min(boxMax);
    // return squared length of the difference vector
    return nearest.distanceToSquared(p);
}
// @param {THREE.Vector3} camPos
// @param {THREE.Vector3} camDir - must be normalized
// @param {THREE.Vector3} bboxMin
// @param {THREE.Vector3} bboxMax
// @returns {Number} Projected z-distance of a bbox from the camera
function projectedBoxDistance(camPos, camDir, boxMin, boxMax) {
    // compute the point within bbox that is nearest to p by clamping against box
    var nearest = camPos.clone();
    nearest.max(boxMin);
    nearest.min(boxMax);
    return nearest.sub(camPos).dot(camDir);
}
function TexQuadConfig() {
    this.urlPattern = null; // string pattern for image URLs, e.g., http://otile1.mqcdn.com/tiles/1.0.0/sat/{z}/{x}/{y}.jpg
    this.tileSize = null; // in;  width/height of tile images (always squared) in pixels. E.g., 256
    this.maxLevel = null; // int; maximum hierarchy level, e.g., 10    
    this.textureLoader = null; // user-provided function for loading images
    // texture extent at max resolution. Must be integer between 1 and 2^(maxLevel)
    this.texWidth = 0;
    this.texHeight = 0;
    // Restrict number of tiles that are forced keep in memory at once. As a minimum, we only keep in memory
    // what we need to display the currently visible tiles. Higher values allow to spend more memory
    // on prefetching tiles.
    this.maxActiveTiles = isMobileDevice() ? 0 : 400;
    // LRU cache size (given as max number of tiles)
    this.cacheSize = isMobileDevice() ? 0 : 150;
    // {function()} optional callback that is triggered when the root image is loaded.
    // This is used when loading single images (maxLevel=0), where we obtain texWidth, texHeight, and tileSize
    // are obtained from the image dimensions.
    this.onRootLoaded = null;
    // In this code, root level 0 contains is defined as the largest miplevel for which whole image fits into a single tile. The translation service
    // currently produces additional levels with smaller mipmaps of this single tiles, which we don't use here. E.g., the actual root tile of our hierarchy
    // might be in a folder "9" instead of "0". Therefore, whenever we do image load requests, we add this level offset to the tile level to derive the image URL.
    this.levelOffset = 0;
    // On some devices, render targets may be larger than indicated by canvasWidth/canvasHeight. E.g., retina displays
    // often have a pixelRatio of 2.0. To make full use of the available display resolution, pixelRatio should be
    // set to the same value that is used by WebGLRenderer/RenderContext.
    this.pixelRatio = 1.0;
    this.getRootTileSize = function () {
        // the root tile covers a squared pixel region of size tileSize * 2^maxLevel
        return 1.0 * (this.tileSize << this.maxLevel);
    };
    this.getQuadWidth = function () {
        return 1.0 * this.texWidth / this.getRootTileSize();
    };
    this.getQuadHeight = function () {
        return 1.0 * this.texHeight / this.getRootTileSize();
    };
    /** @returns {LmvMatrix4} Converts from quad geometry coords to paper units. */
    this.getPageToModelTransform = function (paperWidth, paperHeight) {
        // scale from page to model units
        var sx = paperWidth / this.getQuadWidth();
        var sy = paperHeight / this.getQuadHeight();
        return new LmvMatrix4(true).set(sx, 0, 0, 0, 0, sy, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1);
    };
    // The root tile corresponds to [0,1] in x/y. The actual image may be smaller.
    this.getBBox = function () {
        // the image dimensions determine which fraction of the root tile is actually used.
        var quadWidth = this.getQuadWidth();
        var quadHeight = this.getQuadHeight();
        // If quadHeight is <1.0, it means that not the full root tile height is used by the image.
        // Since pixel y and worldY directions are opposite, the unused part of the [0,1] region is at 
        // the lower end of the y-range. 
        var cropYShift = 1.0 - quadHeight;
        return new THREE$1.Box3(new THREE$1.Vector3(0, cropYShift, 0), new THREE$1.Vector3(quadWidth, 1.0, 0.0));
    };
    this.valid = function () {
        return typeof this.urlPattern == 'string' && this.urlPattern.length > 0 && typeof this.tileSize == 'number' && this.tileSize > 0 && typeof this.maxLevel == 'number' && this.maxLevel > 0 && typeof this.texWidth == 'number' && this.texWidth > 0 && typeof this.texHeight == 'number' && this.texHeight > 0;
    };
    /** Configures the iterator to display a single image file without leaflet hierarchy.
     *  For this case, the image dimensions are not known in advance, but set as soon as
     *  the root tile is loaded.
     *   @params {string}     imagePath
     *   @params {function()} [onImageLoaded] Called as soon as the root has been loaded and
     *                        the image dimensions are available.
     */
    this.initForSimpleImage = function (imagePath, onImageLoaded) {
        // The urlPattern read from bubble may have been URL encoded.
        // This can happen if the bubble comes from EMEA data center.
        this.urlPattern = decodeURIComponent(imagePath);
        this.maxLevel = 0;
        this.levelOffset = 0;
        // indicate that these values are not available yet.
        // The iterator will set them based on the image extensions as soon as it is loaded
        this.tileSize = -1;
        this.texWidth = -1;
        this.texHeight = -1;
        // inform caller when actual extents are avaialble
        this.onRootLoaded = onImageLoaded;
    };
    // Returns the required maxLevel for a given texture resolution.
    // All params are int.
    function computeMaxLevel(w, h, tileSize) {
        // compute maxLevel that we would get for 1x1 resolution at level 0
        var lx = Math.ceil(Math.log2(w));
        var ly = Math.ceil(Math.log2(h));
        var maxLevel = Math.max(lx, ly);
        // since the actual root tile has tileSize x tileSize, we subtract the skipped levels.
        return maxLevel - Math.log2(tileSize);
    }
    // If a maxLevel is specified that is smaller than the one that we computed for the given
    // resolution, texWidth and texHeight must be set to the smaller resolution at this level.
    function applyMaxLevel(config, actualMaxLevel, restrictedMaxLevel) {
        var levelDiff = actualMaxLevel - restrictedMaxLevel;
        if (levelDiff > 0) {
            config.texWidth >>= levelDiff;
            config.texHeight >>= levelDiff;
            config.maxLevel = restrictedMaxLevel;
        }
    }
    /** Extracts all required params from a given options dictionary.
     * @param {string} urlPattern
     * @param {Object} options Parameter dictionary
     * @param {function} textureLoader User-provided function for loading image resources.
     *   The function has the following signature: function(imageURL, onSuccess, onError).
     *   In case of success, `onSuccess` callback should be called with the texture as a single argument.
     *   In case of failure, `onError` callback should be called with a description of the error.
     */
    this.initFromLoadOptions = function (urlPattern, options, textureLoader) {
        // The urlPattern read from bubble may have been URL encoded.
        // This can happen if the bubble comes from EMEA data center.
        this.urlPattern = decodeURIComponent(urlPattern);
        this.textureLoader = textureLoader;
        if (options) {
            this.tileSize = options.tileSize;
            this.maxLevel = computeMaxLevel(options.texWidth, options.texHeight, options.tileSize);
            this.texWidth = options.texWidth;
            this.texHeight = options.texHeight;
            this.levelOffset = options.levelOffset;
            // If maxLevel is specified, scale down texSize to the resolution at this level
            if (typeof options.maxLevel == 'number') {
                applyMaxLevel(this, this.maxLevel, options.maxLevel);
            }
            // allow to override default memory settings via load options
            this.maxActiveTiles = options.maxActiveTiles || this.maxActiveTiles;
            this.cacheSize = options.cacheSize || this.cacheSize;
            this.zips = options.zips;
        }
    };
}
/** @classDesc Produces a quad that is textured with a large image.
 *             The image is stored as a hierarchy of image tiles, where each tile is stored as a separate file (e.g. jpg or png).
 *             Each hierarchy level represents a miplevel of the overall texture, subdivided into squared tiles
 *             of fixed size (e.g., 256 x 256). Level 0 contains a single tile that represents the whole texture as a single tile at lowest resolution.
 *             At the leaf level n, the texture is represented at full resolution as a tile grid of up to (2^n x 2^n) tiles.
 *
 *             Note that some tiles may be unused or cropped if the overall resolution is not squared and a pow2-multiple of the tilesize.
 *
 * @class
 *   @param {TexQuadConfig}   config
 *   @param {MaterialManager} materials
 */
function ModelIteratorTexQuad(config, materials) {
    var _config = config;
    // The bbox of the quad keeps the same, because it is independent on how we subdivide the quad geometry.
    // However, for single images, its correct initialization will be deferred until the image is loaded.
    var _bbox = config.getBBox();
    // reused scene that we reconfigure on each iterator reset.
    var _scene = new THREE$1.Scene();
    // {MaterialManager}
    var _materials = materials;
    // This iterator returns only a single scene. Therefore, _done is set to false when on iteration start (this.reset()) 
    // and set to true again after first call of nextBatch. 
    var _done = true;
    // array of TileInfos for all tiles that are currently available for rendering.
    // caching of generated tiles. Tiles are addressed by int indices
    // computed by tile2Index (see TileCoords.js)
    var _tiles = [];
    // increased with each iterator reset. used for LRU timestamps.
    var _timeStamp = 0;
    // for each update cycle, we track the number of tiles for which we updated the timeStamp.
    // The purpose of this is to control the memory consumption, because all active tiles are
    // kept in memory and protected from cache cleanup.
    var _numActiveTiles = 0;
    // used to limit the number of simultaneously loaded tiles
    var _maxRequests = 5;
    var _numRequests = 0; // currently running requests
    // For each frame, limit the number of new textures that enter the scene.
    // Otherwise, texture decode/upload in FireFlyRenderer may take too long.
    var _maxTextureUpdatesPerFrame = 5;
    // used to trigger redraw when new tiles are loaded
    var _needsRedraw = false;
    // each callback is called once when the scene is fully refined.
    var _onRefinedCallbacks = [];
    // Shared THREE.Geometry. A unit quad in xy plane with uv coords. Used for all tiles.
    var _quadGeom = null;
    var _aggressivePrefetching = false;
    var gm = new GeometryManager();
    // get image resolution at a given hierarchy level. We have full resolution at maxLevel and reduce it by half with each level.
    function getMipmapWidth(level) {
        var levelDiff = _config.maxLevel - level;
        return _config.texWidth >> levelDiff;
    }
    function getMipmapHeight(level) {
        var levelDiff = _config.maxLevel - level;
        return _config.texHeight >> levelDiff;
    }
    // returns true if the pixel region of the tile is outside the given image dimensions.
    //  @param {TileCoords} tile
    //  @returns {bool}
    function tileOutside(tile) {
        // get dimensions
        var levelWidth = getMipmapWidth(tile.level);
        var levelHeight = getMipmapHeight(tile.level);
        // compute minPixel of the tile's pixel region
        var minPixelX = tile.x * _config.tileSize;
        var minPixelY = tile.y * _config.tileSize;
        return minPixelX >= levelWidth || minPixelY >= levelHeight;
    }
    // The width/height of a mipLevel cannot be assumed to be a multiple of tileSize. Therefore, tiles containing the image boundary 
    // are cropped to the relevant pixels. E.g., the width of a boundary tile might be 500 while the tileSize is 512.
    // Since the image is cropped, we have to scale down the geometry as well to avoid stretching. This function contains the scale
    // factor in x/y to be applied to the geometry.
    //
    // @returns {THREE.Vector2} 
    function getCropScale(tile) {
        // get dimensions
        var levelWidth = getMipmapWidth(tile.level);
        var levelHeight = getMipmapHeight(tile.level);
        // compute first minPixel covered by this tile
        var minPixelX = tile.x * _config.tileSize;
        var minPixelY = tile.y * _config.tileSize;
        // crop tile to image dimensions
        var croppedWidth = Math.max(0, Math.min(_config.tileSize, levelWidth - minPixelX));
        var croppedHeight = Math.max(0, Math.min(_config.tileSize, levelHeight - minPixelY));
        var ts = 1.0 * _config.tileSize;
        return new THREE$1.Vector2(croppedWidth / ts, croppedHeight / ts);
    }
    /**
     * Sets aggressive prefetching mode. When enabled more tiles will be retrieved on each reset.
     * @param {boolean} enable
     */
    this.setAggressivePrefetching = function (enable) {
        _aggressivePrefetching = enable;
    };
    this.getScene = function () {
        return _scene;
    };
    /** @returns {THREE.Scene|null} */
    this.nextBatch = function () {
        // first call since reset => return _scene 
        if (!_done) {
            _done = true;
            return _scene;
        }
        return null;
    };
    this.getSceneCount = function () {
        // TexQuadIterators are always rendered as a single batch
        return 1;
    };
    /** @returns {bool} */
    this.done = function () {
        return _done;
    };
    /** Perform raycast on the quad.
      * @param {THREE.RayCaster} raycaster
      * @param {Object[]}        intersects - An object array that contains intersection result objects.
      *                                       Each result r stores properties like r.point, r.fragId, r.dbId. (see VBIntersector.js for details)
      */
    this.rayCast = function (raycaster, intersects) {
        // not implemented yet
        return null;
    };
    /** Copies visible bbox into the given output params. Since per-fragment visibility is not supported
     *  by this iterator, both bboxes are always identical.
     *
     *   @param {THREE.Box3} [visibleBounds]
     *   @param {THREE.Box3} [visibleBoundsWithHidden]
     */
    this.getVisibleBounds = function (visibleBounds, visibleBoundsWithHidden) {
        if (visibleBounds) visibleBounds.copy(_bbox);
        if (visibleBoundsWithHidden) visibleBoundsWithHidden.copy(_bbox);
    };
    // compute width/height of a tile, assuming that the root corresponds to [0,1]^2 in xy.
    // level is int.
    function getTileScale(level) {
        return 1.0 / (1 << level);
    }
    // Given a tile to be rendered and a (n-th-order) parent from which we use the material,
    // this method computes offset and scale in uv coords that we need to compute the texture coords.
    //  @returns {UVTransform}
    function getUVOffsetAndScale(tile, parentTile) {
        // compute the level difference between tile and parent
        var levelDiff = tile.level - parentTile.level;
        // at tile.level, compute the number of tiles in x and y that share the same parent tile
        var levelDiffScale = 1 << levelDiff;
        // compute width/height in uv-space
        var uvScaleX = 1.0 / levelDiffScale;
        var uvScaleY = uvScaleX;
        // uvScale means here: "which extent in the uv-space of the parent corresponds to a the size of a single tile at tile.level"
        // If the parent tile is cropped, the uvScale needs to be upscaled accordingly.        
        var parentCropScale = getCropScale(parentTile);
        uvScaleX /= parentCropScale.x; // Note that cropScale.x and cropScale.y are always >0. Otherwise, the whole parent tile would 
        uvScaleY /= parentCropScale.y; // be outside the image extent and it wouldn't make sense to compute any uv coords.
        // For l=tile.level, find the minimum x and y among all subtiles of parent at level l.
        var firstX = parentTile.x * levelDiffScale;
        var firstY = parentTile.y * levelDiffScale;
        // compute offsetX/Y within the subtile grid of size [levelDiffScale]^2
        var offsetX = tile.x - firstX;
        var offsetY = tile.y - firstY;
        // uvScale as computed above is the size of a full tile at tile.level, given in uv space of the parent.
        // If the (child) tile is cropped, its geometry will be cropped as well, so that its extent is less than a full tile
        // at this level. Therefore, we have to consider the cropScale of the tile for the final scale factor.
        var cropScale = getCropScale(tile);
        // transform offset from tile-grid to uv
        offsetX *= uvScaleX;
        offsetY *= uvScaleY;
        // apply y-flip. Note that a simple y-flip (1.0-val) swaps min/max v-value of the tile.
        // E.g., the uv-offset of the first tile would be 1.0 after the swap - which should actually 
        // the max-v of the tile. Since offset has to be the min-uv, we have to subtract the
        // v-extent of the tile afterwards.
        offsetY = 1.0 - offsetY - uvScaleY * cropScale.y;
        var result = new UVTransform();
        result.offsetX = offsetX;
        result.offsetY = offsetY;
        result.scaleX = uvScaleX * cropScale.x;
        result.scaleY = uvScaleY * cropScale.y;
        return result;
    }
    // tile: TileCoords
    // Returns: float
    function getTileMinX(tile) {
        var tileScale = getTileScale(tile.level);
        return tileScale * tile.x;
    }
    // see getTileMinX
    function getTileMinY(tile) {
        var tileScale = getTileScale(tile.level);
        // invert tile order to match image layout.
        var maxY = (1 << tile.level) - 1;
        var yFlipped = maxY - tile.y;
        return tileScale * yFlipped;
    }
    // @returns {TileInfo|null}
    function getTileInfo(tile) {
        return _tiles[tc.tile2Index(tile)];
    }
    // Returns a true if a tile texture is in memory
    function tileLoaded(tile) {
        var tileInfo = getTileInfo(tile);
        return tileInfo instanceof TileInfo && tileInfo.state == TileState_Loaded;
    }
    // Finds a parent tile for which a texture is a available
    // Takes and returns TileCoord (or null if nothing found)
    //  @param {bool} [disableNewTextures] if true, we enforce to use a texture that
    //                                     has been used before and doesn't need to be decoded/uloaded anymore.
    function findLoadedParent(tile, disableNewTextures) {
        // step up the parent path until we find one in memory
        var parent = tile.getParent();
        while (parent) {
            var info = getTileInfo(parent);
            // tile loaded?
            var found = info && info.state == TileState_Loaded;
            // if loaded, are we allowed to use the texture?
            if (found && disableNewTextures) {
                // don't allow adding new tiles. Just the root is always accepted.
                if (info.mesh.material.map.needsUpdate && parent.level > 0) {
                    found = false;
                }
            }
            // stop if we found a usable parent
            if (found) {
                break;
            }
            // Continue with next parent. Latest at the root,
            // we will usually succeed.
            parent = parent.getParent();
        }
        return parent;
    }
    // creates a single quad shape (THREE.Mesh) representing a tile of the image.
    // If no image is provided, we use the material of a lower-resolution tile.
    function createTileShape(tile, // TileCoords
    material, // THREE.Material
    disableNewTextures // If material is null, this optional flag enforces that 
    // we use a fallback texture that does not require decode/upload
    ) {
        var geom;
        // for tiles with own texture, we can use the shared quad shape
        if (material) {
            // create shared quad geom on first use
            if (!_quadGeom) {
                _quadGeom = gm.createQuadGeom();
            }
            geom = _quadGeom;
        } else {
            // share texture of lower-resolution tile
            // if we have no image, find a parent tile from which we can reuse the material as a fallback
            var parentTile = findLoadedParent(tile);
            // by construction, parent is the first parent with texture 
            // in memory. So, parentShape must always be available.            
            var parentShape = getTileShape(parentTile);
            material = parentShape.material;
            // configure uv transform, because we are only using a subset of 
            // the texture for this tile
            var tmp = getUVOffsetAndScale(tile, parentTile);
            geom = gm.acquireQuadGeom(tmp);
        }
        var mesh = new THREE$1.Mesh(geom, material);
        mesh.tile = tile;
        var tileScale = getTileScale(tile.level);
        // for boundary tiles with cropped images, scale down geometry accordingly. No effect for non-cropped tiles.
        var cropScaleFactor = getCropScale(tile);
        // since pixel y and worldY directions are opposite, y-cropped tiles also needs to be shifted.
        var cropYShift = (1.0 - cropScaleFactor.y) * tileScale;
        // compute offset and scale of the tile, where [0,1]^2 corresponds to the root
        var tileOffsetX = getTileMinX(tile);
        var tileOffsetY = getTileMinY(tile);
        mesh.position.set(tileOffsetX, tileOffsetY + cropYShift, 0.0);
        mesh.scale.set(tileScale * cropScaleFactor.x, tileScale * cropScaleFactor.y, 1.0);
        return mesh;
    }
    // Returns the URL string to request a single tile image
    function getTileTextureURL(tile) {
        var levelOffset = _config.levelOffset ? _config.levelOffset : 0;
        var url = _config.urlPattern.replace("{x}", tile.x).replace("{y}", tile.y).replace("{z}", tile.level + levelOffset);
        return url;
    }
    var _this = this;
    // As soon as a tile is loaded, it will be available via getTileShape(tile).
    function requestTile(tile) {
        // get tileInfo
        var tileIndex = tc.tile2Index(tile);
        var tileInfo = _tiles[tileIndex];
        // if tile is already loading or in memory, do nothing
        if (tileInfo && tileInfo.state != TileState_Missing) {
            return;
        }
        // make sure that tileInfo exists
        if (!tileInfo) {
            tileInfo = new TileInfo(_timeStamp);
            _tiles[tileIndex] = tileInfo;
        }
        // mark tile as loading, so that we don't request it again
        tileInfo.state = TileState_Loading;
        var path = getTileTextureURL(tile);
        // Callback that updates the tile-shape as soon as the texture is loaded
        var onTexLoaded = function onTexLoaded(tex) {
            // drop texture if the iterator has been deleted meanwhile
            if (!_this || !tex) {
                return;
            }
            // when using the iterator for displaying a single image, we get texWidth/texHeihgt/tileSize
            // from the actual image dimensions.
            if (_config.maxLevel == 0) {
                if (_config.texWidth == -1) _config.texWidth = tex.image.width;
                if (_config.texHeight == -1) _config.texHeight = tex.image.height;
                if (_config.tileSize == -1) _config.tileSize = Math.max(tex.image.width, tex.image.height);
                // update bbox - which depends on texture dimensions
                _bbox = config.getBBox();
            }
            // use linear filter, so that we can use non-pow2 textures.
            tex.minFilter = THREE$1.LinearFilter;
            tex.magFilter = THREE$1.LinearFilter;
            // create material
            var material = new THREE$1.MeshBasicMaterial({ color: 0xFFFFFFFF });
            material.map = tex;
            // set material name that we use to find and unregister 
            // this material in MaterialManager later
            // NOTE: Using the image URL as material name is simple,
            //       but would produce a trap if we ever use different 
            //       RenderModels that load from the same source.
            //       It would be safer to find some individual prefix for
            //       this iterator.
            material.name = path;
            material.tile = tile;
            // By default, MaterialManager assigns the environment texture for reflection to all
            // materials that support it. Setting this flag avoids this.
            material.disableEnvMap = true;
            // Activate transparency for PNG images - which might make use of the alpha channel.
            // This is the same heuristic as we apply for F2D/SVF materials (see MaterialManager.addMaterial)
            if (path.toLowerCase().indexOf(".png")) {
                material.transparent = true;
                material.alphaTest = 0.01;
            }
            // add material to material manager to make sure that the shader is
            // correctly configured. E.g., to configure in which render targets to write etc.
            _materials.addMaterial(material.name, material, true);
            // create tile mesh
            var mesh = createTileShape(tile, material);
            // make new tile available
            tileInfo.mesh = mesh;
            // mark tile as loaded, so that we know that its own texture is in memory.
            tileInfo.state = TileState_Loaded;
            // request finished
            _numRequests--;
            // trigger scene update
            _needsRedraw = true;
            // we take care of caching ourselves. To keep consumed memory under control, make sure
            // that no texture is left behind in THREE's internal loader cache
            // Note that we cannot always use 'path' here, because the final image url might differ due
            // to additional credential stuff.
            var texUrl = tex && tex.image ? tex.image.src : null;
            if (texUrl && THREE$1.Cache && THREE$1.Cache.get(texUrl)) {
                THREE$1.Cache.remove(texUrl);
            }
            // trigger custom callback when root is available
            if (tile.level == 0 && _config.onRootLoaded) {
                _config.onRootLoaded();
            }
        };
        // track number of open requests
        _numRequests++;
        // load tile texture
        _config.textureLoader(path, function (texture) {
            onTexLoaded(texture);
        }, function (err) {
            console.error(err);
        });
    }
    // root tile is always needed
    requestTile(new tc.TileCoords(0, 0, 0));
    // returns a tile shape from memory cache. Returns null if the tile's own
    // texture is not loaded yet.
    function getTileShape(tile) {
        var index = tc.tile2Index(tile);
        var tileInfo = _tiles[index];
        if (!tileInfo || tileInfo.state != TileState_Loaded) {
            return null;
        }
        return tileInfo.mesh;
    }
    // tile:   TileCoords
    // outMin: Vector3 (z=0.0)
    function getTileMin(tile, outMin) {
        var x = getTileMinX(tile);
        var y = getTileMinY(tile);
        outMin.set(x, y, 0);
    }
    function getTileMax(tile, outMax) {
        var scale = getTileScale(tile.level);
        var x = getTileMinX(tile) + scale;
        var y = getTileMinY(tile) + scale;
        outMax.set(x, y, 0);
    }
    // Returns true if a tile intersects the view frustum
    var tileInFrustum = function () {
        var tileMin = new THREE$1.Vector3();
        var tileMax = new THREE$1.Vector3();
        var tileBox = new THREE$1.Box3();
        return function (tile, // {TileCoords}
        frustum // {FrustumIntersector}
        ) {
            // get tile box
            getTileMin(tile, tileMin);
            getTileMax(tile, tileMax);
            tileBox.set(tileMin, tileMax);
            return frustum.intersectsBox(tileBox) > 0;
        };
    }();
    // Computes the priority of a tile based on camera distance and tile size.
    var computeTilePriority = function () {
        var tileMin = new THREE$1.Vector3();
        var tileMax = new THREE$1.Vector3();
        return function (tile, // {TileCoords}
        frustum, // {FrustumIntersector}
        camPos // {THREE.Vector3}
        ) {
            // compute xy-distance from camera
            var tileScale = getTileScale(tile.level);
            getTileMin(tile, tileMin);
            getTileMax(tile, tileMax);
            var dist2 = point2BoxDistance2(camPos, tileMin, tileMax);
            // scale-up priority for visible tiles
            var tileVisible = tileInFrustum(tile, frustum);
            var frustumFactor = tileVisible ? 100.0 : 1.0;
            // avoid division by zero: for tiles below this distance, 
            // we only distinguish based on tile level
            var MinDist2 = 0.0001;
            dist2 = Math.max(dist2, MinDist2);
            // squared tile size
            var tileScale2 = tileScale * tileScale;
            // Priority = tileSize/dist 
            var priority = frustumFactor * tileScale2 / dist2;
            return priority;
        };
    }();
    // Estimates for a tile the current screen size in pixels 
    var estimateScreenSize = function () {
        var tileMin = new THREE$1.Vector3();
        var tileMax = new THREE$1.Vector3();
        return function (tile, // {TileCoords}
        camPos, // {THREE.Vector3}
        camDir, // {THREE.Vector3]
        camFov, // in degrees
        canvasHeight // in pixels
        ) {
            // get tile distance - projected along the view direction
            getTileMin(tile, tileMin);
            getTileMax(tile, tileMax);
            var dist = projectedBoxDistance(camPos, camDir, tileMin, tileMax);
            var edgeLength = tileMax.x - tileMin.x;
            // get tan(phi/2) for horizontal aperture angle
            // Note that the same code keeps correct for OrthoCameras, because tanPhiHalf is 0.5 for this case.
            var tanPhiHalf = Math.tan(THREE$1.Math.degToRad(camFov / 2.0));
            var projLength = edgeLength / (tanPhiHalf * dist);
            return 0.5 * projLength * canvasHeight;
        };
    }();
    // helper struct used to order tiles based on refinement priority
    function Candidate(tile, prio) {
        this.tile = tile;
        this.prio = prio;
    }
    // compare op to sort candidates by decreasing priority
    function moreImportant(c1, c2) {
        return c1.prio > c2.prio;
    }
    // Updates the timeStamp of the tile to the latest value.
    // If the tile is unknown, it has no effect.
    function updateTimeStamp(tile) {
        var tileInfo = _tiles[tc.tile2Index(tile)];
        if (tileInfo) {
            if (tileInfo.timeStamp != _timeStamp) {
                tileInfo.timeStamp = _timeStamp;
                // track number of tiles for which we updated the
                _numActiveTiles++;
            }
        }
    }
    // Given a list of required tiles, this method determines the most
    // important ones and triggers as many requests as simultaneously allowed.
    // Returns the number of newly sent requests
    function requestTiles(tiles, frustum, camPos) {
        // sort by decreasing priority
        tiles.sort(function (a, b) {
            var pa = computeTilePriority(a, frustum, camPos);
            var pb = computeTilePriority(b, frustum, camPos);
            return pb - pa;
        });
        // send as many requests as simultaneously allowed
        var newRequests = 0;
        for (var i = 0; i < tiles.length; i++) {
            // skip tiles for which there is already a running request
            var tileInfo = getTileInfo(tiles[i]);
            if (tileInfo && tileInfo.state == TileState_Loading) {
                continue;
            }
            // wait for some requests to finish before we request more
            if (_numRequests >= _maxRequests) {
                break;
            }
            requestTile(tiles[i]);
            newRequests++;
        }
        return newRequests;
    }
    function disposeMaterial(tileInfo) {
        // nothing to do if there is no material
        if (!tileInfo || !tileInfo.mesh || !tileInfo.mesh.material) {
            return;
        }
        // don't leak material in MaterialManager
        var mat = tileInfo.mesh.material;
        _materials.removeMaterial(mat.name);
        // free GPU resource. We need the memory right now and should
        // not wait for the garbage collector.
        mat.map.dispose();
        mat.map.needsUpdate = true;
        // dispose shader program etc.
        var DISPOSE_EVENT = { type: 'dispose' };
        mat.dispatchEvent(DISPOSE_EVENT);
        mat.needsUpdate = true;
    }
    /** Unregister all material from material texture and disposes textures.
        Must be called when removing a RenderModel with this iterator.
     */
    this.dispose = function () {
        var i;
        for (i in _tiles) {
            disposeMaterial(_tiles[i]);
        }
        if (_quadGeom) {
            _quadGeom.dispose();
            _quadGeom.needsUpdate = true;
        }
        gm.dispose();
    };
    this.dtor = function () {
        this.dispose();
        // ignore any remaining textureLoad callbacks
        _this = null;
        // unref MaterialManager right now in case we are the last one holding it.
        _materials = null;
    };
    // Delete tiles cached from previous frames to give space for new ones without
    // exceeding the maximum cache size.
    //
    //  @param {number}             requiredFreeSlots 
    //  @param {FrustumIntersector} frustum
    //  @param {THREE.Vector3}      camPos
    function cacheCleanup(requiredFreeSlots, frustum, camPos) {
        // collect indices of all tiles in memory
        var tileIndices = Object.keys(_tiles);
        // check how many free slots we have already
        var numTilesInMemory = tileIndices.length;
        var availableSlots = _config.cacheSize - numTilesInMemory;
        var missingSlots = requiredFreeSlots - availableSlots;
        if (missingSlots <= 0) {
            // No need to delete any tile from cache
            return;
        }
        // sort by increasing timeStamp and tile priority
        tileIndices.sort(function (a, b) {
            // compare based on timeStamps
            var tsa = _tiles[a].timeStamp;
            var tsb = _tiles[b].timeStamp;
            if (tsa != tsb) return tsa - tsb;
            // if timeStamps are equal, use priorites instead
            var tileA = tc.index2Tile(a);
            var tileB = tc.index2Tile(b);
            var prioA = computeTilePriority(tileA, frustum, camPos);
            var prioB = computeTilePriority(tileB, frustum, camPos);
            return prioA - prioB;
        });
        // delete tiles 
        var tilesToDelete = Math.min(missingSlots, tileIndices.length);
        for (var i = 0; i < tilesToDelete; i++) {
            var index = tileIndices[i];
            // protect root tile from being deleted
            var tileCoords = tc.index2Tile(index);
            if (tileCoords.level === 0) {
                continue;
            }
            // Skip any tile that is not in memory. Deleting anything else
            // would not make sense here anyway. But, more important, it is essential never to delete
            // _tiles[] entries for tiles in loading state. Otherwise, the newly arriving textures
            // would get lost.
            if (_tiles[index].state != TileState_Loaded) {
                continue;
            }
            // don't remove tiles that are currently in use. It's better to
            // exceed the cache limit a bit than to permanently delete and load
            // the same tiles.
            if (_tiles[index].timeStamp == _timeStamp) {
                break;
            }
            // dispose texture and unregister material from MaterialManager
            // Note that it is important here that each material is unique per tile.
            disposeMaterial(_tiles[index]);
            delete _tiles[index];
        }
    }
    /** Start iterator
     *   @param: {FrustumIntersector} frustum
     *   @param: {UnifiedCamera}      camera
     */
    this.reset = function (frustum, camera) {
        // Make sure that no mesh objects are leaked in WebGLRenderer. It would be more efficient to do this
        // only once per tile. But since we also create temporary placeholder meshes for tiles displayed at lower
        // resolution, this solution is the simplest and safest. The overhead is not signficiant, because
        // the number of rendered tiles is limited and these events do not dispose geometry or material
        // (which would be expensive)
        var i, tile;
        for (i = 0; i < _scene.children.length; i++) {
            var obj = _scene.children[i];
            obj.dispatchEvent({ type: 'removed' });
        }
        // clear scene
        _scene.children.length = 0;
        // track iterator restarts for LRU cache cleanup
        _timeStamp++;
        // reset counter of tiles that we mark as "currently used" by updating their timestamp
        _numActiveTiles = 0;
        // reset counter for reused temp geometry.
        gm.reset();
        // scene is empty as long as the root tile is not loaded
        var root = new tc.TileCoords(0, 0, 0);
        if (!tileLoaded(root)) {
            _done = true;
            return false;
        }
        // Set of candidates, sorted by decreasing priority.                
        var candidates = new SortedList(moreImportant);
        // start with root tile as only candidate
        var rootTile = new tc.TileCoords(0, 0, 0);
        var prio = computeTilePriority(rootTile, frustum, camera.position);
        candidates.add(new Candidate(rootTile, prio));
        // normalized view direction
        var camDir = camera.getWorldDirection();
        // get canvas height - measured in phyisical device pixels
        var canvasHeight = 0 | camera.clientHeight * _config.pixelRatio;
        // In this loop, we recursively traverse the tile hierarchy to find relevant tiles for the current view.
        // As a result, the three arrays below will be filled.
        // By construction, all arrays will be sorted by decreasing priority.
        var visibleTiles = []; // visible tiles that we will use for rendering
        var culledTiles = []; // tiles at appropriate resolution, but outside the view frustum (good prefetching candidates)
        var missingTiles = []; // tiles that are not in memory, but required for current view. This includes parents of tiles in use.
        while (candidates.size() > 0) {
            // get and remove max-priority candidate
            var candidate = candidates.get(0);
            tile = candidate.tile;
            candidates.removeAt(0);
            // skip tiles outside the image dimensions
            if (tileOutside(tile)) {
                continue;
            }
            var refine = true;
            // stop if we reached a leaf tile
            if (tile.level == _config.maxLevel) {
                // this is a leaf tile.
                refine = false;
            }
            // if the screen size of the tile is already smaller than its
            // image resolution, there is no point in further refinement.
            var screenSize = estimateScreenSize(tile, camera.position, camDir, camera.fov, canvasHeight);
            if (screenSize < _config.tileSize) {
                // tile does not need more refinement
                refine = false;
            }
            // For all tiles in frustum...
            var visible = tileInFrustum(tile, frustum);
            if (visible) {
                // Request tile if missing
                if (!tileLoaded(tile)) {
                    missingTiles.push(tile);
                }
                // protect it from removal due to cleanuop
                updateTimeStamp(tile);
            }
            // Block refinement if we collected enough tiles
            if (!visible && visibleTiles.length + culledTiles.length > _config.maxActiveTiles) {
                refine = false;
            }
            // Note that we also refine tiles that are not in memory. This is done to ensure that the
            // traversal is stable: In this way, required tiles always get the latest timeStamp,
            // no matter whether their parents are missing or not.
            // Traverse children or collect the tile
            if (refine) {
                // refine tile into its 4 children
                for (var c = 0; c < 4; c++) {
                    var child = tile.getChild(c);
                    prio = computeTilePriority(child, frustum, camera.position);
                    // consider child as new candidate
                    candidates.add(new Candidate(child, prio));
                }
            } else {
                // Collect tile and stop refinement
                if (visible) {
                    visibleTiles.push(tile);
                } else {
                    culledTiles.push(tile);
                }
            }
        }
        // track how many new textures we add in this frame.
        var numNewTextures = 0;
        // any redraws would produce the same result until a new tile arrives.
        _needsRedraw = false;
        // track if all required tiles are available for rendering
        var sceneComplete = true;
        // add tile shapes for all visible tiles to the scene
        for (i = 0; i < visibleTiles.length; ++i) {
            tile = visibleTiles[i];
            var shape = getTileShape(tile);
            if (shape && shape.material.map.needsUpdate && !_aggressivePrefetching) {
                // this shape will trigger a new texture decode/upload in FireFlyRenderer
                if (numNewTextures < _maxTextureUpdatesPerFrame) {
                    // just track number of new textures
                    numNewTextures++;
                } else {
                    // don't allow more texture upload in this frame.
                    // use a fallback texture instead.
                    shape = createTileShape(tile, null, true);
                    // trigger redraw, so that the remaining texture uploads
                    // are done in subsequent frames.
                    _needsRedraw = true;
                    // don't fire sceneComplete callback yet, before all
                    // required textures are uploaded.
                    sceneComplete = false;
                }
            }
            // Some tiles might not be loaded yet, but already needed in 
            // order to show their loaded siblings at higher resolution.
            if (!shape) {
                // For these tiles, we create a "fallback" tile that
                // is using the material of a lower-resolution parent,
                // but is instantly available. This makes tile loading significantly 
                // faster, because we don't have wait for all siblings of tiles we need.
                shape = createTileShape(tile, null);
                sceneComplete = false;
            }
            _scene.add(shape);
        }
        // return _scene in next nextBatch() call.
        _done = false;
        // send requests for missing visible tiles
        var numNewRequests = requestTiles(missingTiles, frustum, camera.position);
        // tiles that are currently being loaded are also considered as being active, because
        // they will soon require some memory as well
        _numActiveTiles += _numRequests;
        // Process some tiles outside the frustum for prefetching (if our budget allows it)
        var prefetchRequests = [];
        for (i = 0; i < culledTiles.length; i++) {
            // stop if our active tile limit is reached
            if (_numActiveTiles >= _config.maxActiveTiles) {
                break;
            }
            tile = culledTiles[i];
            if (!tileLoaded(tile)) {
                // tile is not in memory yet => consider for request
                prefetchRequests.push(tile);
                _numActiveTiles++;
            } else {
                // tile is already in memory. Just set its timestamp to keep it in memory
                // mark this tile and its parents as active if our budget allows it.
                for (var level = 0; level <= tile.level; level++) {
                    // mark parent as active
                    var parent = tile.getParentAtLevel(level);
                    updateTimeStamp(parent);
                    // stop if we reached the limit
                    if (_numActiveTiles > _config.maxActiveTiles) {
                        break;
                    }
                }
            }
        }
        // add some more requests for prefetching of tiles close to the view frustum
        numNewRequests += requestTiles(prefetchRequests, frustum, camera.position);
        if (_aggressivePrefetching) {
            // Get some of the children for faster zooming
            prefetchRequests = [];
            for (i = 0; i < visibleTiles.length; ++i) {
                tile = visibleTiles[i];
                if (tile.level == _config.maxLevel) {
                    continue;
                }
                for (var c = 0; c < 4; c++) {
                    var child = tile.getChild(c);
                    if (tileOutside(child) || !tileInFrustum(child, frustum)) {
                        continue;
                    }
                    if (!tileLoaded(child)) {
                        // tile is not in memory yet => consider for request
                        prefetchRequests.push(child);
                        _numActiveTiles++;
                    }
                }
            }
            numNewRequests += requestTiles(prefetchRequests, frustum, camera.position);
        }
        // clear tiles from LRU cache if needed
        // Note that we must not dispose any material that is used in this
        // frame. This is ensured, because we never delete tiles with
        // the current frame timestamp.
        cacheCleanup(numNewRequests, frustum, camera.position);
        // trigger callback if
        if (sceneComplete && _onRefinedCallbacks.length > 0) {
            // Note: At this point, we are usually in the middle of a rendering cycle. Although the scene is now
            // fully refined, it is not visible on screen yet. Therefore, we defer the event so that the
            // current animation cycle can be finished first.
            var callbacks = _onRefinedCallbacks.splice(0, _onRefinedCallbacks.length);
            setTimeout(function () {
                for (var i = 0; i < callbacks.length; i++) {
                    callbacks[i]();
                }
            }, 1);
        }
        return sceneComplete;
    };
    /** @param {function} cb - A callback without params or return value. Called once as soon as all textures have
     *                         been refined to the required resolution for the current view. */
    this.callWhenRefined = function (cb) {
        _onRefinedCallbacks.push(cb);
    };
    /** @returns {bool} Indicates that a full redraw is required to see the latest state. */
    this.update = function () {
        return _needsRedraw;
    };
}
var ModelIteratorTexQuadUtils = {
    ModelIteratorTexQuad: ModelIteratorTexQuad,
    TexQuadConfig: TexQuadConfig
};

var MAX_HIGHLIGHT_ITERATOR = 10;

// TODO: move the logic that decides whether or not to stream somewhere closer to SVF;
// Ideally, RenderModel and GeometryList should be agnostic to the file format.
/*
 * Helper function to determine whether we should enable streamingDraw or upload the whole model to GPU.
 *
 * This function uses values from an SVF package to estimate the expected GPU load. If it is
 * small enough, it returns false. This means that the whole model is uploaded to GPU.
 *
 * If the model size is larger or unknown, we use a heuristic to determine which models are uploaded
 * to GPU and which are rendered from CPU-memory using the (slower) streamingDraw.
 *  @param {number} packFileTotalSize
 *  @param {number} numPrimitives
 *  @param {number} numObjects
 */
function needsStreamingDraw(packFileTotalSize, numPrimitives, numObjects) {
    if (packFileTotalSize) {
        //In pack files, primitive indices use 4 byte integers,
        //while we use 2 byte integers for rendering, so make this
        //correction when estimating GPU usage for geometry
        var estimatedGPUMem = packFileTotalSize - numPrimitives * 3 * 2;
        //If the model is certain to be below a certain size,
        //we will skip the heuristics that upload some meshes to
        //GPU and keep other in system mem, and just push it all to the GPU.
        if (estimatedGPUMem <= GPU_MEMORY_LIMIT && numObjects < GPU_OBJECT_LIMIT) {
            // We don't need streaming draw - model is small enough
            return false;
        }
    }
    return true;
}
// Counter to assign individual numbers to RenderModel in order of their creation
var nextModelId = 1;
// Use 16 bits to store the visibility for draw modes (render phases)
// Different phases can share the same bits if the visibility is the same.
// Phases past the end of the array use the visibility for RENDER_NORMAL
var PHASE_VISIBILITY = [0x0001, 0x0008, 0x0008, 0x0002, 0x0004];
/** @class Extends application Model class by functionality for WebGL rendering.
 *         Currently produced by loaders (F2DLoader, SvfLoader)
 *
 *  @constructor
 */
function RenderModel(_svf) {
    var _this = this;
    // Cached bboxes.
    var _visibleBounds = new THREE$1.Box3(); // excluding ghosted once
    var _visibleBoundsWithHidden = new THREE$1.Box3(); // full bbox
    var _tmpBox = new THREE$1.Box3(); // temp for internal use
    this.visibleBoundsDirty = false; // triggers recomputation of _visibleBounds and _visibleBoundsWithHidden, e.g., if fragment visibility changes.
    this.enforceBvh = false; // currently ignored, see this.resetIterator()
    this.isvizCacheEnabled = false;
    var _numHighlighted = 0; // number of currently highlighted fragments.    
    this.id = nextModelId++; // use next free Model id
    var _geoms = null; // {GeometryList} 
    var _frags = null; // {FragmentList}
    // Iterators used for scene traversal. 
    var _linearIterator = null; // {ModelIteratorLinear}, used by default and created in this.initialize()
    var _bvhIterator = null; // {ModelIteratorBVH},    used if setBVH() has been called and no new fragments have been added since then.
    var _iterator = null; // currently used iterator. points to one of the iterators above
    var _highlightIterator = null;
    var _drawIterator = null;
    // Only used for consolidated models.
    var _consolidationIterator = null; // {ConsolidationIterator}
    var _consolidationMap = null; // cached intermediate results of consolidation pre-processing. Enables to quickly rebuild
    // _consolidationIterator when we had to temporarily remove it to free memory.
    // Maintained per scene traversal, initialized in ResetIterator()
    var _renderCounter = 0; // number of batches rendered since last resetIterator() call. Used to indicate rendering progress for progressive rendering.
    var _frustum = null; // {FrustumIntersector}. Assigned in this.ResetIterator(). Passed to RenderBatches for culling and depth-sorting. 
    var _drawMode = RENDER_NORMAL; // drawMode used in this traversal. See Viewer3DImpl.js
    var _visibilityMode = PHASE_VISIBILITY[RENDER_NORMAL]; // Allows different passes to have different visibility (e.g. hidden and normal)
    var _bvhOn = false; // true when using _bvhiterator in the current traversal. [HB:] Shouldn't this better be local variable in ResetIterator()?
    // Paging variables maintained per scene traversal:
    var _pageOutStatus = PAGEOUT_NONE; // always PAGEOUT_NONE when starting to draw. During traveral, it may change to
    //  - PAGEOUT_SUCCESS: if any geometry has been paged out
    //  - PAGEOUT_FAIL:    geometry has been paged out, but not enough yet.
    this.getData = function () {
        return _svf;
    };
    // Note: GeometryList or FragmentList are maintained by the RenderModel and should not be modified from outside.
    //       E.g., setting visibility or highlighting flags on FragmentList directly would break some state tracking. (e.g. see this.setVibility or this.setHighlighted)
    //       The only current exception is done by loaders that add geometry to _geoms directly.
    this.getGeometryList = function () {
        return _geoms;
    };
    this.getFragmentList = function () {
        return _frags;
    };
    this.getModelId = function () {
        return this.id;
    };
    /**
    *  @param {Object} [pagingProxy] - Object used to manage memory and paging
    */
    this.initialize = function (pagingProxy) {
        // alloc GeometryList. Initially empty, but exposed via GetGeometryList().
        // The loaders use this to add LmvGeometryBuffers directly to the GeometryList later.
        // TODO: Make RenderModel agnostic to the SVF file format.
        var svf = this.getData();
        var numObjects = svf.numGeoms || 0;
        var disableStreaming = !needsStreamingDraw(svf.packFileTotalSize, svf.primitiveCount, numObjects);
        _geoms = new GeometryList(numObjects, this.is2d(), disableStreaming);
        _frags = new FragmentList(this, pagingProxy);
        var initialBbox = this.getBoundingBox();
        if (initialBbox) {
            _visibleBounds.copy(initialBbox);
            _visibleBoundsWithHidden.copy(initialBbox);
        }
        _drawIterator = _iterator = _linearIterator = new ModelIteratorLinear(this);
        _highlightIterator = new HighlightIteratorLinear(this);
    };
    this.getIterator = function () {
        return _iterator;
    };
    /**
     * Initialize from custom iterator. In this case, _geoms and _frags are not used and the
     * iterator implementation is responsible for producing and maintaining the geometry.
     *
     *  @param {ModelIterator} iterator - iterator.nextBatch may return RenderBatch or THREE.Scene instances.
     *
     * Note: When using a custom iterator, per-fragment visiblity is not supported.
     */
    this.initFromCustomIterator = function (iterator) {
        _drawIterator = _iterator = iterator;
        this.visibleBoundsDirty = true; // make sure that bbox is obtained from iterator
    };
    /**
     *  Deletes all GPU resources.
     *
     *  @param {FireflyWebGLRenderer} glRenderer
     */
    this.dtor = function (glrenderer) {
        if (_frags) {
            _frags.dispose(glrenderer);
        }
        // Custom iterators may have own GPU resources (see ModelIteratorTexQuad)
        if (_iterator && _iterator.dtor) {
            _iterator.dtor();
        }
        // If this model was consolidated, dispose GPU memory of consolidation as well
        if (_consolidationIterator) {
            _consolidationIterator.dispose();
        }
    };
    /**
     * Activating a fragment means:
     *  - Store geometry in the FragmentList
     *  - Update summed RenderModel boxes
     *  - Add fragment to iterator, so that it is considered in next traversal
     * See FragmentList.setMesh(..) for param details.
     *
     * Note:
     *  - Can only be used with LinearIterator
     */
    this.activateFragment = function (fragId, meshInfo, overrideTransform) {
        if (!_frags) {
            return;
        }
        _frags.setMesh(fragId, meshInfo, overrideTransform);
        //The linear iterator can be updated to add meshes incrementally.
        //The BVH iterator is not mutable, yet.
        _iterator.addFragment(fragId);
        //update the world bbox
        {
            _frags.getWorldBounds(fragId, _tmpBox);
            _visibleBounds.union(_tmpBox);
            _visibleBoundsWithHidden.union(_tmpBox);
        }
    };
    // Used by the Fusion collaboration client
    this.setFragment = function (fragId, mesh) {
        if (fragId === undefined) fragId = this.getFragmentList().getNextAvailableFragmentId();
        _frags.setMesh(fragId, mesh, true);
        //The linear iterator can be updated to add meshes incrementally.
        //The BVH iterator is not mutable, yet.
        if (_linearIterator) _linearIterator.addFragment(fragId);
        if (_bvhIterator && !_frags.fragmentsHaveBeenAdded()) _bvhIterator.addFragment(fragId);
        //update the world bbox
        {
            _frags.getWorldBounds(fragId, _tmpBox);
            _visibleBounds.union(_tmpBox);
            _visibleBoundsWithHidden.union(_tmpBox);
        }
        return fragId;
    };
    /** Replaces the default LinearIterator by a BVH iterator. */
    this.setBVH = function (nodes, primitives, options) {
        // Note that ResetIterator() might still set _iterator back to 
        // the linear one if the BVH one cannot be used.
        _drawIterator = _iterator = _bvhIterator = new ModelIteratorBVH();
        _iterator.initialize(this, nodes, primitives, options);
    };
    /**
     *  Starts the scene draw traversal, so that nextBatch() will return the first batch to render.
     *   @param: {UnifiedCamera}      camera       - camera.position was needed for the heuristic to choose between linear iterator and BVH.
     *                                               [HB:] The code is currently outcommented, so the param is currently unused.
     *   @param: {FrustumIntersector} frustum      - used by RenderBatches for frustum culling and z-sorting.
     *   @param: {number}             drawMode     - E.g., RENDER_NORMAL. See Viewer3DImpl.js
     *   @param: {number}             [resetType]  - Must be one of globals.RESET_NORMAL, globals.RESET_REDRAW or globals.RESET_RELOAD.
     *                                               Only used when on demand loading is enabled. RESET_RELOAD will reload and redraw
     *                                               geometry. RESET_REDRAW will redraw geometry. RESET_NORMAL will only redraw geometry
     *                                               that hasn't already been drawn. If undefined RESET_NORMAL is used.
     */
    this.resetIterator = function (camera, frustum, drawMode, resetType, highlighting) {
        resetType = resetType || RESET_NORMAL;
        _frags && _frags.pagingProxy && _frags.pagingProxy.resetIterator(camera, resetType);
        // If scene/camera has changed, we have to rebuild some data that we collected for paging, because the set of currently 
        // needed fragments may change.
        // Note that frags will be null when using a custom iterator. In this case, this
        // paging-related code is not used and can be skipped.
        if (resetType != RESET_NORMAL) {
            if (resetType >= RESET_REDRAW && _frags && _frags.onDemandLoadingEnabled()) {
                // reset MESH_TRAVERSED flag 
                _frags.setFlagGlobal(MESH_TRAVERSED, false);
                _iterator.resetVisStatus();
                _highlightIterator && _highlightIterator.resetVisStatus();
            }
            if (resetType >= RESET_RELOAD && _frags && _frags.pageOutGeometryEnabled()) {
                // restart tracking of paging status
                _pageOutStatus = PAGEOUT_NONE;
                // reset lists of culled and traversed geometry
                _frags.pagingProxy && _frags.pagingProxy.reset();
            }
        }
        //Decide whether to use the BVH for traversal
        //If we are far out from the scene, use pure big-to-small
        //importance order instead of front to back.
        _bvhOn = false;
        if (_bvhIterator && !_frags.fragmentsHaveBeenAdded()) {
            //TODO: BVH always on when available, because the linear iteration
            //does not respect transparent objects drawing last -- it just
            //draws in the order the fragments come in the SVF package
            /*
                if(this.enforceBvh || !_linearIterator) {
                    _bvhOn = true;
                } else {
                    var diag = _visibleBoundsWithHidden.size().length();
                    var center = _visibleBoundsWithHidden.center();
                    var dist = camera.position.distanceTo(center);
                    if (dist < diag * 0.5)
                        _bvhOn = true;
                }
                */
            _bvhOn = true;
        }
        if (this.isvizCacheEnabled) _bvhOn = false;
        // Note _linearIterator may also be null if a custom iterator is used.
        // in this case, we must leave _iterator unchanged.
        if (_bvhOn) {
            _iterator = _bvhIterator;
        } else if (_linearIterator) {
            _iterator = _linearIterator;
        }
        _drawIterator = highlighting && _highlightIterator.getSceneCount() < MAX_HIGHLIGHT_ITERATOR ? _highlightIterator : _iterator;
        _renderCounter = 0;
        _drawMode = drawMode;
        // For visibility, two highlight passes are the same.
        _visibilityMode = drawMode < PHASE_VISIBILITY.length ? PHASE_VISIBILITY[drawMode] : PHASE_VISIBILITY[RENDER_NORMAL];
        _frustum = frustum;
        _drawIterator.reset(frustum, camera);
        // reset box counter for proxy display
        if (_frags) _frags.resetBoxRun();
        // notify consolidation iterator that a new traversal has started
        if (_consolidationIterator) {
            _consolidationIterator.reset();
        }
        return _drawIterator;
    };
    // Used for accumulating geom pack IDs that were needed in this frame, but were not in memory.
    function fragIdCallback(fragId) {
        var packId = _this.getFragmentList().fragments.packIds[fragId];
        if (_frags.pagingProxy) {
            _frags.pagingProxy.addGeomPackMissingLastFrame(packId);
        }
    }
    /** Returns the next RenderBatch for scene rendering travseral. Used in RenderScene.renderSome().
     *   Use this.resetIterator() to start traversal first.
     *
     *   @returns {RenderBatch|null} Next batch to render or null if traversal is finished.
     */
    this.nextBatch = function () {
        // If the next batch of the iterator is fully invisble, we inc it until we 
        // find a relevant batch to render or reach the end.
        while (1) {
            // get next batch from iterator
            var scene = _drawIterator.nextBatch();
            // update render progress counter
            _renderCounter++;
            // stop if iterator reached the end           
            if (!scene) return null;
            // replace RenderBatch (= individual fragments) by consolidated scene, if available
            if (_consolidationIterator && scene instanceof RenderBatch) {
                scene = _consolidationIterator.consolidateNextBatch(scene, _frustum);
            }
            if (scene instanceof THREE$1.Scene) {
                // The code for fragment visibility and sorting is only defined if scene is a RenderBatch.
                // For the case of THREE.Scene, we are done here, because
                //   - Sorting in THREE.Scene is done by FireFlyRenderer.
                //   - Per-fragment visiblity is not supported in this case
                return scene;
            }
            // If visible stats for _visibilityMode is 0 then apply visibility check
            if (!(scene.visibleStats & _visibilityMode)) {
                //TODO: move this into the iterator?
                var allHidden = scene.applyVisibility(_drawMode, _frustum, this.getFragmentList().fragments.packIds ? fragIdCallback : function () {});
                if (scene.visibleStats !== undefined) {
                    // Assume clear visibility calculated clears both bits
                    scene.visibleStats |= _visibilityMode;
                    if (!allHidden) scene.visibleStats |= _visibilityMode << 16;
                }
                // For 3D scenes, sort fragments of this batch. 
                // Note that fragments of F2D scenes must be drawn in original order.
                //TODO: Move this to the iterator?
                if (!allHidden && !this.is2d()) {
                    //Generally opaque batches are sorted once by material, while
                    //transparent batches are sorted back to front each frame
                    if (scene.sortObjects && !this.getFragmentList().useThreeMesh) scene.sortByDepth(_frustum);else if (!scene.sortDone) scene.sortByMaterial();
                }
            } else {
                allHidden = !(scene.visibleStats & _visibilityMode << 16);
            }
            if (!allHidden) return scene;
        }
    };
    /**
     * @param:  {bool}        includeGhosted
     * @returns {THREE.Box3}
     *
     * NOTE: The returned box is just a pointer to a member, not a copy!
     */
    this.getVisibleBounds = function (includeGhosted) {
        if (this.visibleBoundsDirty) {
            _visibleBounds.makeEmpty();
            _visibleBoundsWithHidden.makeEmpty();
            _iterator.getVisibleBounds(_visibleBounds, _visibleBoundsWithHidden, includeGhosted);
            this.visibleBoundsDirty = false;
        }
        return includeGhosted ? _visibleBoundsWithHidden : _visibleBounds;
    };
    /**
     * Performs a raytest and returns an object providing information about the closest hit.
     *
     * NOTE: We currently ignore hitpoints of fragments that are visible (MESH_VISIBLE==true) and not highlighted (MESH_HIGHLIGHTED==false).
     *
     * @param {THREE.RayCaster} raycaster
     * @param [bool]            ignoreTransparent
     * @param {number[]}       [dbIds]             - Array of dbIds. If specified, only fragments with dbIds inside the filter are checked.
     *                                                If the model data has no instanceTree, this is just a whitelist of explicit fragment ids.
     *                                                Note that a hitpoint will also be returned if it's actually occluded by a fragment outside the filter.
     *
     * @returns {Object|null}   Intersection result object r providing information about closest hit point. Properties:
     *                           - {number}   fragId
     *                           - {Vector3}  point
     *                           - {number}   dbId
     *                           - {model}    model - pointer to this RenderModel
     *                          (created/filled in VBIntersector.js, see for details)
     */
    // Add "meshes" parameter, after we get meshes of the object using id buffer,
    // then we just need to ray intersect this object instead of all objects of the model.
    this.rayIntersect = function (raycaster, ignoreTransparent, dbIds, intersections) {
        // make sure that the cached overall bboxes are up-to-date.
        // [HB:] Why are they updated here, but not used in this method?
        if (this.visibleBoundsDirty) this.getVisibleBounds();
        // alloc array to collect intersection results
        var intersects = [];
        var i;
        // Restrict search to certain dbIds if specified...
        if (dbIds && dbIds.length > 0) {
            //Collect the mesh fragments for the given database ID node filter.
            var map = this.getFragmentMap();
            var fragIds = [];
            if (map) {
                for (i = 0; i < dbIds.length; i++) {
                    map.enumNodeFragments(dbIds[i], function (fragId) {
                        fragIds.push(fragId);
                    }, true);
                }
            } else {
                //No instance tree -- treat dbIds as fragIds
                fragIds = dbIds;
            }
            //If there are multiple fragments it pays to still use
            //the bounding volume hierarchy to do the intersection,
            //because it can cull away entire fragments by bounding box,
            //instead of checking every single fragment triangle by triangle
            if (fragIds.length > 2) {
                _iterator.rayCast(raycaster, intersects, dbIds);
            } else {
                // The filter restricted the search to a very small number of fragments.
                // => Perform raytest on these fragments directly instead.
                for (i = 0; i < fragIds.length; i++) {
                    var mesh = _frags.getVizmesh(fragIds[i]);
                    if (!mesh) continue;
                    var res = VBIntersector.rayCast(mesh, raycaster, intersects);
                    if (res) {
                        intersects.push(res);
                    }
                }
            }
        } else {
            // no filter => perform raytest on all fragments
            _iterator.rayCast(raycaster, intersects);
        }
        // stop here if no hit was found
        if (!intersects.length) return null;
        // sort results by distance. 
        intersects.sort(function (a, b) {
            return a.distance - b.distance;
        });
        //pick the nearest object that is visible as the selected.
        var allIntersections = !!intersections;
        intersections = intersections || [];
        for (i = 0; i < intersects.length; i++) {
            var fragId = intersects[i].fragId;
            //skip past f2d consolidated meshes.
            //TODO: we should completely avoid intersecting those in the ray caster.
            if (this.is2d()) continue;
            var isVisible = this.isFragVisible(fragId); //visible set,
            // [HB:] Since we skip all meshes that are not flagged as visible, shouldn't we 
            //       better exclude them from the raycast in the first place?
            if (isVisible) {
                // skip transparent hits if specified
                var material = _frags.getMaterial(fragId);
                if (ignoreTransparent && material.transparent) continue;
                var intersect = intersects[i];
                // check against cutplanes
                var isCut = false;
                var intersectPoint = intersect.point;
                if (material && material.cutplanes) {
                    for (var j = 0; j < material.cutplanes.length; j++) {
                        isCut = isCut || material.cutplanes[j].dot(new THREE$1.Vector4(intersectPoint.x, intersectPoint.y, intersectPoint.z, 1.0)) > 1e-6;
                    }
                }
                if (!isCut) {
                    intersections.push(intersect);
                }
                intersect.model = this;
                if (!allIntersections && intersections.length > 0) {
                    // result is the closest hit that passed all tests => done.
                    break;
                }
            }
        }
        var result = intersections[0] || null;
        if (result) {
            // We might use multiple RenderModels => add this pointer as well.
            result.model = this;
        }
        return result;
    };
    /** Set highlighting flag for a fragment.
     *   @param   {number} fragId
     *   @param   {bool}   value
     *   @returns {bool}   indicates if flag state changed
     */
    this.setHighlighted = function (fragId, value) {
        if (!_frags) {
            return false;
        }
        var changed = _frags.setFlagFragment(fragId, MESH_HIGHLIGHTED, value);
        if (changed) {
            if (value) {
                _highlightIterator.addFragment(fragId);
                _numHighlighted++;
            } else {
                _highlightIterator.removeFragment(fragId);
                _numHighlighted--;
            }
        }
        return changed;
    };
    /** Sets MESH_VISIBLE flag for a fragment (true=visible, false=ghosted) */
    // This function should probably not be called outside VisibityManager
    // in order to maintain node visibility state.
    this.setVisibility = function (fragId, value) {
        if (_frags) {
            _frags.setVisibility(fragId, value);
            this.visibleBoundsDirty = true;
        }
    };
    /** Sets MESH_VISIBLE flag for all fragments (true=visible, false=ghosted) */
    this.setAllVisibility = function (value) {
        if (_frags) {
            _frags.setAllVisibility(value);
            this.visibleBoundsDirty = true;
        }
    };
    /** Sets the MESH_HIDE flag for all fragments that a flagged as line geometry.
     *  Note that the MESH_HIDE flag is independent of the MESH_VISIBLE flag (which switches between ghosted and fully visible)
     *
     *  @param {bool} hide - value to which the MESH_HIDE flag will be set. Note that omitting this param would SHOW the lines, so
     *                       that you should always provide it to avoid confusion.
     */
    this.hideLines = function (hide) {
        if (_frags) {
            _frags.hideLines(hide);
        }
    };
    /** Sets the MESH_HIDE flag for all fragments that a flagged as point geometry.
     *  Note that the MESH_HIDE flag is independent of the MESH_VISIBLE flag (which switches between ghosted and fully visible)
     *
     *  @param {bool} hide - value to which the MESH_HIDE flag will be set. Note that omitting this param would SHOW the points, so
     *                       that you should always provide it to avoid confusion.
     */
    this.hidePoints = function (hide) {
        if (_frags) {
            _frags.hidePoints(hide);
        }
    };
    /** Returns if one or more fragments are highlighed.
     *   returns {bool}
     *
     * Note: This method will only work correctly as long as all highlighting changes are done via this.setHighlighted, not on FragmentList directly.
     */
    this.hasHighlighted = function () {
        return !!_numHighlighted;
    };
    /** Returns true if a fragment is tagged as MESH_VISIBLE and not as MESH_HIGHLIGHTED. */
    // 
    // [HB:] It's seems a bit unintuitive that the MESH_HIGHLIGHTED flag is checked here, but not considered by the other visibility-related methods.
    //       For instance, consider the following scenarioes:
    //        - After calling setVibility(frag, true), isFragVisible(frag) will still return false if frag was highlighed.
    //        - If areAllVisible() returns true, there may still be fragments for which isFragVisible(frag) returns false.
    this.isFragVisible = function (frag) {
        return _frags.isFragVisible(frag);
    };
    /** Returns true if MESH_VISIBLE flag is set for all fragments. */
    this.areAllVisible = function () {
        // When using a custom iterator, we don't have per-fragment visibility control. 
        // We assume constantly true in this case.
        if (!_frags) {
            return true;
        }
        return _frags.areAllVisible();
    };
    /*
        this.getRenderProgress = function() {
            return _iterator.getRenderProgress();
        };
    */
    /** Direct access to all RenderBatches. Used by ground shadows and ground reflection.
      * @returns {RenderBatch[]}
      */
    this.getGeomScenes = function () {
        return _iterator.getGeomScenes();
    };
    /** Get progress of current rendering traversal.
      *  @returns {number} in [0,1]
      */
    this.getRenderProgress = function () {
        var progress = _renderCounter / _drawIterator.getSceneCount();
        // the renderCounter can become > scene count.
        return progress > 1.0 ? 1.0 : progress;
    };
    /** Page geometry out if memory is under pressure. This method is internally
     *  used by this.frameUpdatePaging() below.
     *   @param [bool] iterationDone - indicates whether the iteration is done or not.
     *   @param [bool] forcePageOut  - By default, fragments can only be paged out if already traversed.
     *                                 If forcePageOut is set, we also allow to page-out geometry
     *                                 of fragments that were not traversed yet.
     *   @returns {number} pageState - Possible values:
     *                                   PAGEOUT_SUCCESS: We paged out enough, so that the number
     *                                                        of geometries is within the limit.
     *                                   PAGEOUT_FAIL:    Still exceeding the limit.
     */
    this.pageOutIfNeeded = function (iterationDone, forcePageOut, pagingOptions) {
        return _frags.pagingProxy ? _frags.pagingProxy.pageOut(iterationDone, forcePageOut, pagingOptions) : PAGEOUT_NONE;
    };
    /**
     *  Triggers paging out of geometry if necessary.
     *
     *  In each frame update, some more batches of the overall scene are rendered until time runs out.
     *  This function is called at the end of each such frame update to page out stuff if needed.
     *  (see RenderScene.renderSome)
     *
     *   &param [bool] isBeginFrame - Indicates if the current frame update was the first one.
     *                                TODO: isbeginFrame can be removed.
     */
    this.frameUpdatePaging = function (isBeginFrame, pagingOptions) {
        // Check if we should use paging.
        var pagingEnabled = _frags && _frags.pageOutGeometryEnabled();
        if (!pagingEnabled) {
            return _pageOutStatus;
        }
        _pageOutStatus = this.pageOutIfNeeded(false, false, pagingOptions);
        // When scene rendering traversal is finished and we did not page out enough
        // in the previous frame updates yet, do some final paging-out and make sure that it succeeds.
        if (_drawIterator.done()) {
            // We will give a last try of paging out,
            // if still fail and traversed geometry is not empty, then will need another render.
            // otherwise, need a hard page out no matter geometry get traversed or not.
            _pageOutStatus = this.pageOutIfNeeded(true, false, pagingOptions);
            if (_pageOutStatus == PAGEOUT_FAIL) {
                _pageOutStatus = this.pageOutIfNeeded(true, true, pagingOptions);
            }
        }
        return _pageOutStatus;
    };
    /** Used by SvfLoader to decide which fragments to load next.
     *  @returns {number[]} pack ids of all fragments that were missing in last frame.
     */
    this.geomPacksMissingLastFrame = function () {
        return _frags && _frags.pagingProxy ? _frags.pagingProxy.geomPacksMissingLastFrame() : [];
    };
    /** Explicitly add the pack as missing from last frame.
     *  Used by SvfLoader to delay-load fragments for which on-demand-load failed because all workers
     *  were busy.
     *   &param {number} packId
     */
    this.addGeomPackMissingLastFrame = function (packId) {
        return _frags && _frags.pagingProxy ? _frags.pagingProxy.addGeomPackMissingLastFrame(packId) : true;
    };
    this.needResumeNextFrame = function () {
        return _frags && _frags.pagingProxy ? _frags.pagingProxy.needResumeNextFrame() : false;
    };
    /**
     *  @params  {number} timeStamp
     *  @returns {bool}   true if the model needs a redraw
     */
    this.update = function (timeStamp) {
        // if there is an iterator that implements update method...
        if (_iterator && _iterator.update) {
            return _iterator.update(timeStamp);
        }
        // assume constant scene otherwise
        return false;
    };
    /** Highlight an object with a theming color that is blended with the original object's material.
     *   @param {number}        dbId
     *   @param {THREE.Vector4} themingColor (r, g, b, intensity), all in [0,1]
     */
    this.setThemingColor = function (dbId, color) {
        if (_frags) {
            _frags.setThemingColor(dbId, color);
        } else {
            THREE$1.warn("Theming colors are not supported by this model type.");
        }
    };
    /** Revert all theming colors.
     *   @param {number}        dbId
     *   @param {THREE.Vector4} themingColor (r, g, b, intensity), all in [0,1]
     */
    this.clearThemingColors = function () {
        if (_frags) {
            _frags.clearThemingColors();
        }
    };
    /** Access to leaflet-specific functionality. Returns null if RenderModel is no leaflet. */
    this.getLeaflet = function () {
        if (_iterator instanceof ModelIteratorTexQuad) {
            return _iterator;
        }
        return null;
    };
    /**
     * This function creates an internal copy of the FragmentList that is consolidated to reduce the
     * shape count as far as possible. This takes more memory, but may strongly accelerate rendering
     * for models with many small shapes.
     *
     * NOTE: For making consolidation effective, it should ideally be activated via the load options already.
     *       This will automatically adjust the depth of the spatial hierarchy. Without that, the scene traversal
     *       may still be slow and the performance gain much smaller.
     *
     * @param {MaterialManager} materials
     * @param {number}          [byteLimit = 100 << 20] - Merging geometries is the most efficient technique in terms
     *                                                    of rendering performance. But, it can strongly increase
     *                                                    the memory consumption, particularly because merged
     *                                                    geometry cannot be shared, i.e. multiple instances of
     *                                                    a single geometry must be replicated per instance for merging.
     *                                                    Therefore, the memory spent for merging is restricted.
     *                                                    A higher value may make rendering faster, but increases (also GPU) memory
     *                                                    workload.
     * @param {boolean}         [multithreaded]         - Optional: If true, a part of the work is delegated to a worker thread.
     *                                                    This function will return faster, but the consolidation is marked as not usable
     *                                                    (see Consolidation.inProgress) until all worker results are returned.
     *
     * @param {FireFlyWebGLRenderer} glRenderer
     */
    this.consolidate = function (materials, byteLimit, glRenderer) {
        // consolidate fragment list
        var consolidation = consolidateFragmentList(_frags, materials, byteLimit, glRenderer, _consolidationMap);
        // make BVHIterator use the consolidation when possible
        _consolidationIterator = new ConsolidationIterator(_frags, consolidation);
        // cache some intermediate results. Consolidations are memory-intensive, so it can be necessary to temporarily
        // remove them to free memory. By caching intermediate results, we can rebuild them faster.
        _consolidationMap = consolidation.consolidationMap;
    };
    /**
     * Removes consolidation to free memory. Just some compact intermediate results are cached, so that the
     * consolidation can be rebuilt quickly.
     */
    this.unconsolidate = function () {
        if (!_consolidationIterator) {
            return;
        }
        _consolidationIterator.dispose();
        _consolidationIterator = null;
    };
    this.isConsolidated = function () {
        return !!_consolidationIterator;
    };
    this.getConsolidation = function () {
        return _consolidationIterator ? _consolidationIterator.getConsolidation() : null;
    };
    this.getInstanceTree = function () {
        return _svf ? _svf.instanceTree : null;
    };
    this.getFragmentMap = function () {
        return _svf ? _svf.instanceTree || _svf.fragmentMap : null;
    };
    this.getBoundingBox = function () {
        return _svf ? _svf.bbox : null;
    };
    this.is2d = function () {
        return !!(_svf && _svf.is2d);
    };
    /** Returns true if the model is an OTG file - which supports sharing of materials and geometry. */
    this.isOTG = function () {
        return _svf && !!_svf.isOTG;
    };
    /**
     * This function is only needed if...
     *
     *   1. You want to draw a fragment to an overlay scene that overdraws the original fragment, and
     *   2. Consolidation is used for this model.
     *
     *  To avoid flickering artifacts, the geometry used for the overlay scene must exactly match with the
     *  one used for the main scene rendering. However, when consolidation is used, this geometry may vary
     *  and (slightly) differ from the original fragment geometry.
     *
     *  This function updates the given render proxy to make it exactly match with the geometry used for the
     *  the last main scene rendering. This involves to replace geometry, material, and matrix when necessary.
     *
     *  NOTE: An updated proxy can exclusively be used for rendering. Do not use this function if you want to
     *        access any vertex data directly.
     *
     *   @param {THREE.Mesh} proxy  - currently used proxy mesh to represent the fragment
     *   @param {Number}     fragId - fragment represented by this proxy */
    this.updateRenderProxy = function (proxy, fragId) {
        if (!_consolidationIterator) {
            // nothing to do - rendering will always use the original geometry anyway.
            return;
        }
        // fragment might be consolidated.
        _consolidationIterator.updateRenderProxy(proxy, fragId);
    };
    this.skipOpaqueShapes = function () {
        if (_iterator && _iterator.skipOpaqueShapes) {
            _iterator.skipOpaqueShapes();
        }
    };
    /**
     * Get the memory stats when using on demand loading.
     * @returns {object|null} Object containing the limit and loaded memory usage for the model.
     *                        Return null if the model isn't being loaded on demand.
     */
    this.getMemoryInfo = function () {
        return _frags && _frags.getMemoryInfo();
    };
}

'use strict';
function CreateCubeMapFromColors(ctop, cbot) {
    var r1 = ctop.x * 255,
        g1 = ctop.y * 255,
        b1 = ctop.z * 255,
        r2 = cbot.x * 255,
        g2 = cbot.y * 255,
        b2 = cbot.z * 255;
    var pixelsTop = new Uint8Array(16);
    var pixelsBot = new Uint8Array(16);
    var pixelsSide = new Uint8Array(16);
    for (var i = 0; i < 4; i++) {
        pixelsTop[i * 4] = r1;
        pixelsTop[i * 4 + 1] = g1;
        pixelsTop[i * 4 + 2] = b1;
        pixelsTop[i * 4 + 3] = 255;
        pixelsBot[i * 4] = r2;
        pixelsBot[i * 4 + 1] = g2;
        pixelsBot[i * 4 + 2] = b2;
        pixelsBot[i * 4 + 3] = 255;
        // was this, which is wild: if (0 | (i / 2)) {
        if (i > 1) {
            // color sides 2 and 3 with the first color
            pixelsSide[i * 4] = r1;
            pixelsSide[i * 4 + 1] = g1;
            pixelsSide[i * 4 + 2] = b1;
            pixelsSide[i * 4 + 3] = 255;
        } else {
            // color sides 0 and 1 with the second color
            pixelsSide[i * 4] = r2;
            pixelsSide[i * 4 + 1] = g2;
            pixelsSide[i * 4 + 2] = b2;
            pixelsSide[i * 4 + 3] = 255;
        }
    }
    var x_neg = new THREE$1.DataTexture(pixelsSide, 2, 2, THREE$1.RGBAFormat);
    var x_pos = new THREE$1.DataTexture(pixelsSide, 2, 2, THREE$1.RGBAFormat);
    var y_neg = new THREE$1.DataTexture(pixelsBot, 2, 2, THREE$1.RGBAFormat);
    var y_pos = new THREE$1.DataTexture(pixelsTop, 2, 2, THREE$1.RGBAFormat);
    var z_neg = new THREE$1.DataTexture(pixelsSide, 2, 2, THREE$1.RGBAFormat);
    var z_pos = new THREE$1.DataTexture(pixelsSide, 2, 2, THREE$1.RGBAFormat);
    var texture = new THREE$1.Texture(null, THREE$1.CubeReflectionMapping, THREE$1.RepeatWrapping, THREE$1.RepeatWrapping, THREE$1.LinearFilter, THREE$1.LinearFilter,
    //NearestFilter, NearestFilter,
    THREE$1.RGBAFormat);
    texture.image = [x_pos, x_neg, y_pos, y_neg, z_pos, z_neg];
    texture.needsUpdate = true;
    return texture;
}

var screen_quad_vert = "\nvoid main() {\n    gl_Position = projectionMatrix * modelViewMatrix * vec4( position, 1.0 );\n}\n";

var sao_minfirst_frag = "uniform sampler2D tDiffuse;\nuniform vec2 resolution;\nuniform float cameraNear;\nuniform float cameraInvNearFar;\n#include <pack_depth>\nvoid main() {\n    vec2 ssP = vec2(gl_FragCoord.xy);\n    ssP = ssP * 2.0 + mod(ssP, 2.0);\n    ssP = (ssP + 0.5) * resolution * 0.5;\n    float depth = texture2D(tDiffuse, ssP).z;\n    if (depth != 0.0)\n        depth = (depth + cameraNear) * cameraInvNearFar;\n    gl_FragColor = packDepth(depth);\n}\n";

var sao_min_frag = "uniform sampler2D tDiffuse;\nuniform vec2 resolution;\nvoid main() {\n    vec2 ssP = vec2(gl_FragCoord.xy);\n    ssP = ssP * 2.0 + mod(ssP, 2.0);\n    ssP = (ssP + 0.5) * resolution * 0.5;\n    gl_FragColor = texture2D(tDiffuse, ssP);\n}\n";

// Shader used to convert the normals+depth texture into a smaller texture containing only depth
// Since it packs depth into RGBA8 target it also maps it to the range 0-1 then packs that float
// into an RGBA using magic.
var SAOMinifyFirstShader = {
    uniforms: {
        tDiffuse: { type: "t", value: null },
        cameraNear: { type: "f", value: 1 },
        cameraInvNearFar: { type: "f", value: 100 },
        resolution: { type: "v2", value: new THREE$1.Vector2(1.0 / 512, 1.0 / 512) }
    },
    vertexShader: screen_quad_vert,
    fragmentShader: sao_minfirst_frag
};
// Shader used to generate mip levels for the depth texture (used by the SAO shader)
var SAOMinifyShader = {
    uniforms: {
        tDiffuse: { type: "t", value: null },
        resolution: { type: "v2", value: new THREE$1.Vector2(1.0 / 512, 1.0 / 512) }
    },
    vertexShader: screen_quad_vert,
    fragmentShader: sao_min_frag
};

var fbuf = new Float32Array(1);
var ibuf = new Uint32Array(fbuf.buffer);
var tmp = new Uint16Array(1);
var hp = new Uint16Array(1);
var FloatToHalf = function FloatToHalf(f) {
    fbuf[0] = f;
    var x = ibuf[0];
    var i = 0;
    if ((x & 0x7FFFFFFF) === 0) {
        hp[i++] = x >> 16; // Return the signed zero
    } else {
        var xs = x & 0x80000000; // Pick off sign bit
        var xe = x & 0x7F800000; // Pick off exponent bits
        var xm = x & 0x007FFFFF; // Pick off mantissa bits
        if (xe === 0) {
            hp[i++] = xs >> 16;
        } else if (xe == 0x7F800000) {
            if (xm === 0) {
                hp[i++] = xs >> 16 | 0x7C00; // Signed Inf
            } else {
                hp[i++] = 0xFE00; // NaN, only 1st mantissa bit set
            }
        } else {
            var hm, he;
            var hs = xs >> 16; // Sign bit
            var hes = (0 | xe >> 23) - 127 + 15; // Exponent unbias the single, then bias the halfp
            if (hes >= 0x1F) {
                hp[i++] = xs >> 16 | 0x7C00; // Signed Inf
            } else if (hes <= 0) {
                if (14 - hes > 24) {
                    hm = 0; // Set mantissa to zero
                } else {
                    xm |= 0x00800000; // Add the hidden leading bit
                    hm = xm >> 14 - hes; // Mantissa
                    tmp[0] = hm;
                    hm = tmp[0];
                    if (xm >> 13 - hes & 0x00000001) hm += 1; // Round, might overflow into exp bit, but this is OK
                }
                hp[i++] = hs | hm; // Combine sign bit and mantissa bits, biased exponent is zero
            } else {
                he = hes << 10; // Exponent
                tmp[0] = he;
                he = tmp[0];
                hm = xm >> 13; // Mantissa
                tmp[0] = hm;
                hm = tmp[0];
                if (xm & 0x00001000) hp[i++] = (hs | he | hm) + 1; // Round, might overflow to inf, this is OK
                else hp[i++] = hs | he | hm; // No rounding
            }
        }
    }
    return hp[0];
};
var HalfToFloat = function HalfToFloat(source) {
    var target;
    var h = source & 0xFFFF;
    if ((h & 0x7FFF) === 0) {
        target = h << 16; // Return the signed zero
    } else {
        var hs = h & 0x8000; // Pick off sign bit
        var he = h & 0x7C00; // Pick off exponent bits
        var hm = h & 0x03FF; // Pick off mantissa bits
        if (he === 0) {
            var e = -1; // The following loop figures out how much extra to adjust the exponent
            do {
                e++;
                hm <<= 1;
            } while ((hm & 0x0400) === 0); // Shift until leading bit overflows into exponent bit
            var xs = hs << 16; // Sign bit
            var xes = (he << 16 >> 26) - 15 + 127 - e; // Exponent unbias the halfp, then bias the single
            var xe = xes << 23; // Exponent
            var xm = (hm & 0x03FF) << 13; // Mantissa
            target = xs | xe | xm; // Combine sign bit, exponent bits, and mantissa bits
        } else if (he == 0x7C00) {
            if (hm === 0) {
                target = hs << 16 | 0x7F800000; // Signed Inf
            } else {
                target = 0xFFC00000; // NaN, only 1st mantissa bit set
            }
        } else {
            xs = hs << 16; // Sign bit
            xes = (he << 16 >> 26) - 15 + 127; // Exponent unbias the halfp, then bias the single
            xe = xes << 23; // Exponent
            xm = hm << 13; // Mantissa
            target = xs | xe | xm; // Combine sign bit, exponent bits, and mantissa bits
        }
    }
    ibuf[0] = target;
    return fbuf[0];
};
var HALF_INT_MAX = 58 * 1024 - 2;
var IntToHalf = function IntToHalf(i) {
    if (i > HALF_INT_MAX - 1 || i < 0) {
        THREE$1.log("out of range");
        return FloatToHalf(NaN);
    }
    if (i === 0) return 0;
    var negate = false;
    if (i > HALF_INT_MAX / 2 - 1) {
        negate = true;
        i -= HALF_INT_MAX / 2 - 1;
    }
    var bucket = Math.abs(i / 1024) | 0;
    var base = Math.pow(2, bucket - 13);
    var mapped = base + (i - bucket * 1024) * base / 1024;
    if (negate) mapped = -mapped;
    return FloatToHalf(mapped);
};
var HalfToInt = function HalfToInt(half) {
    if (half === 0) return 0;
    var f = HalfToFloat(half);
    var negate = false;
    if (f < 0) {
        negate = true;
        f = -f;
    }
    var bucket = 0 | Math.floor(Math.log(f) / Math.log(2));
    var base = Math.pow(2, bucket);
    var decoded = (f - base) / base * 1024 + (bucket + 13) * 1024;
    if (negate) decoded += HALF_INT_MAX / 2 - 1;
    return decoded;
};
var HalfTest = function HalfTest() {
    var tests = [-1 / 255, -0.17, -75, -1789, -0.005];
    for (var i = 0; i < tests.length; i++) {
        THREE$1.log("input", tests[i], "encoded", FloatToHalf(tests[i]), "decoded", HalfToFloat(FloatToHalf(tests[i])));
    }
    for (var i = 0; i < HALF_INT_MAX; i++) {
        var roundtrip = HalfToInt(IntToHalf(i));
        if (roundtrip !== i) {
            THREE$1.log("Roundtrip failed for", i, roundtrip);
        }
    }
};
var HalfFloat = {
    FloatToHalf: FloatToHalf,
    HalfToFloat: HalfToFloat,
    HALF_INT_MAX: HALF_INT_MAX,
    IntToHalf: IntToHalf,
    HalfToInt: HalfToInt,
    HalfTest: HalfTest
};

var leafletdiff_frag = "#define HIGHLIGHT_NONE 0\n#define HIGHLIGHT_A 1\n#define HIGHLIGHT_B 2\n#define MIN_DIFF_VAL 0.5\n#define DIFF_THRESHOLD 0.1\nuniform sampler2D texture1;\nuniform sampler2D texture2;\nuniform float splitPosition;\nuniform int model;\nuniform int highlight;\nuniform vec2 resolution1;\nuniform vec2 resolution2;\nvarying vec2 vUvA;\nvarying vec2 vUvB;\nconst int BIT_COUNT = 2;\nint modi(int x, int y) {\n    return x - y * (x / y);\n}\nint and(int a, int b) {\n    int result = 0;\n    int n = 1;\n    for(int i = 0; i < BIT_COUNT; i++) {\n        if ((modi(a, 2) == 1) && (modi(b, 2) == 1)) {\n            result += n;\n        }\n        a = a / 2;\n        b = b / 2;\n        n = n * 2;\n        if(!(a > 0 && b > 0)) {\n            break;\n        }\n    }\n    return result;\n}\nfloat toGrayscale(vec4 v) {\n    return dot(v.rgb, vec3(0.299, 0.587, 0.114));\n}\nvoid main() {\n#ifdef SINGLE_MODEL\n    vec4 tex = texture2D(texture1, vUvA);\n    #ifdef SPLIT_VIEW\n    if (model == 1 && gl_FragCoord.x < splitPosition ||\n        model == 2 && gl_FragCoord.x >= splitPosition) {\n        gl_FragColor = tex;\n    } else {\n        discard;\n    }\n    #else\n    float gray = toGrayscale(tex);\n    gl_FragColor.rgb = vec3(gray);\n    #endif\n#else\n    vec4 tex1 = texture2D(texture1, vUvA);\n    vec4 tex2 = texture2D(texture2, vUvB);\n    #ifdef SPLIT_VIEW\n    gl_FragColor = gl_FragCoord.x < splitPosition ? tex1 : tex2;\n    #else\n    float gray1 = toGrayscale(tex1);\n    float gray2 = toGrayscale(tex2);\n    float maxGray = min(gray1, gray2);\n    float delta = gray1 - gray2;\n    gl_FragColor.rgb = vec3(maxGray);\n    if (abs(delta) > DIFF_THRESHOLD) {\n        if (delta > 0.0 && and(highlight, HIGHLIGHT_A) == HIGHLIGHT_A) {\n            gl_FragColor = vec4(max(gray1, MIN_DIFF_VAL), 0.0, 0.0, 1.0);\n        } else if (delta < 0.0 && and(highlight, HIGHLIGHT_B) == HIGHLIGHT_B) {\n            gl_FragColor = vec4(0.0, 0.0, max(gray2, MIN_DIFF_VAL), 1.0);\n        }\n    }\n        #ifdef ADD_THICKENING\n    else {\n        bool found = false;\n        for (int i = 0; i < 3; i++) {\n            for (int j = 0; j < 3; j++) {\n                if (i != 1 && j != 1) {\n                    vec4 nTex1 = texture2D(texture1, vUvA + resolution1*vec2(i - 1, j - 1));\n                    vec4 nTex2 = texture2D(texture2, vUvB + resolution2*vec2(i - 1, j - 1));\n                    float nGray1 = toGrayscale(nTex1);\n                    float nGray2 = toGrayscale(nTex2);\n                    delta = nGray1 - nGray2;\n                    if (abs(delta) > DIFF_THRESHOLD) {\n                        if (delta > 0.0 && and(highlight, HIGHLIGHT_A) == HIGHLIGHT_A) {\n                            gl_FragColor = vec4(1.25*max(nGray1, MIN_DIFF_VAL), 0.25, 0.25, 1.0);\n                        } else if (delta < 0.0 && and(highlight, HIGHLIGHT_B) == HIGHLIGHT_B) {\n                            gl_FragColor = vec4(0.25, 0.25, 1.25*max(nGray2, MIN_DIFF_VAL), 1.0);\n                        }\n                        found = true;\n                        break;\n                    }\n                }\n            }\n            if (found) break;\n        }\n    }\n        #endif\n    #endif\n#endif\n}";

var leafletdiff_vert = "varying vec2 vUvA;\nvarying vec2 vUvB;\nuniform vec4 uvTFa;\nuniform vec4 uvTFb;\nvoid main() {\n    vUvA = uv;\n#ifndef SINGLE_MODEL\n    float x = (uv.x - uvTFa.x) / uvTFa.z;\n    float y = (uv.y - uvTFa.y) / uvTFa.w;\n    vUvB.x = uvTFb.x + x*uvTFb.z;\n    vUvB.y = uvTFb.y + y*uvTFb.w;\n#endif\n    gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);\n}";

var LeafletDiffModes = {
    NORMAL_DIFF: 0,
    MODEL_A_ONLY: 1,
    MODEL_B_ONLY: 2,
    SPLIT_VIEW: 3,
    HIGHLIGHT_A: 4,
    HIGHLIGHT_B: 5
};
function Rect() {
    var l = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : Infinity;
    var b = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : Infinity;
    var r = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : -Infinity;
    var t = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : -Infinity;

    this.l = l;
    this.b = b;
    this.r = r;
    this.t = t;
}
Rect.prototype.width = function () {
    return this.r - this.l;
};
Rect.prototype.height = function () {
    return this.t - this.b;
};
Rect.prototype.getIntersection = function (otherRect) {
    var l = Math.max(this.l, otherRect.l);
    var r = Math.min(this.r, otherRect.r);
    var b = Math.max(this.b, otherRect.b);
    var t = Math.min(this.t, otherRect.t);
    if (r > l && t > b) return new Rect(l, b, r, t);else return null;
};
Rect.prototype.equals = function (otherRect) {
    return this.l == otherRect.l && this.r == otherRect.r && this.t == otherRect.t && this.b == otherRect.b;
};
Rect.prototype.union = function (otherRect) {
    this.l = Math.min(this.l, otherRect.l);
    this.r = Math.max(this.r, otherRect.r);
    this.b = Math.min(this.b, otherRect.b);
    this.t = Math.max(this.t, otherRect.t);
    return this;
};
/**
 Manages lists of materials for reuse, avoiding the creation of too many materials
 Each material is grouped by a type identifier (a string), since mixing shader materials
 is not possible without recompiling the shader material.
*/
function ShaderMaterialManager() {
    var _reusedMaterials = {};
    var _nextFreeMaterial = {};
    function initReusedContainer(type) {
        _reusedMaterials[type] = [];
        _nextFreeMaterial[type] = 0;
    }
    function disposeMaterial(material) {
        if (!material) {
            return;
        }
        // dispose shader program etc.
        material.dispose();
        material.needsUpdate = true;
    }
    this.acquireShaderMaterial = function (uniforms, type) {
        if (!_reusedMaterials[type]) {
            initReusedContainer(type);
        }
        // get next reusable material and increase counter
        var material = _reusedMaterials[type][_nextFreeMaterial[type]];
        if (!material) {
            material = new THREE$1.ShaderMaterial({
                uniforms: uniforms,
                vertexShader: leafletdiff_vert,
                fragmentShader: leafletdiff_frag
            });
            _reusedMaterials[type][_nextFreeMaterial[type]] = material;
        } else {
            material.defines = {}; // Clean defines
            for (var uniform in uniforms) {
                material.uniforms[uniform].value = uniforms[uniform].value;
            }
        }
        _nextFreeMaterial[type]++;
        return material;
    };
    this.reset = function () {
        for (var nextFree in _nextFreeMaterial) {
            _nextFreeMaterial[nextFree] = 0;
        }
    };
    this.dispose = function () {
        for (var type in _reusedMaterials) {
            for (var j = 0; j < _reusedMaterials[type].length; j++) {
                disposeMaterial(_reusedMaterials[type][j]);
            }
        }
    };
}
/** @classDesc Wraps two iterators of type {ModelIteratorTexQuad} and produces a new scene which blends their textures
 *             according to the desired compare mode:
 *                 NORMAL_DIFF: Show differences in red (pixels only in model A) and blue (pixels only in model B), gray otherwise.
 *                 MODEL_A_ONLY, MODEL_B_ONLY: Show only one model (A or B)
 *                 SPLIT_VIEW: Show model A on the left, model B on the right of a split line
 *                 HIGHLIGHT_A: Show in red pixels only in model A, gray otherwise
 *                 HIGHLIGHT_B: Show in red pixels only in model B, gray otherwise
 *
 *             The documents may not always overlap, in which case there's an offset that can be added to the second document.
 *
 *             The tiles themselves may not always completely overlap, so the common area between 2 tiles is found, and a new
 *             shader material is created which contains the textures that correspond to both documents at that position. The
 *             offset and sizes of the textures relevant for that portion are also sent to the shader, where the actual comparison
 *             is done (see leafletdiff_frag.glsl). The leftover parts that don't intersect are in the end added as well.
 *
 *   @class
 *   @param {ModelIteratorTexQuad}  iterA
 *   @param {ModelIteratorTexQuad}  iterB
 */
function LeafletDiffIterator(iterA, iterB) {
    var _iterA = iterA;
    var _iterB = iterB;
    // reused scene that we reconfigure on each iterator reset.
    var _scene = new THREE$1.Scene();
    // This iterator returns only a single scene. Therefore, _done is set to false when on iteration start (this.reset())
    // and set to true again after first call of nextBatch.
    var _done = true;
    var _needsRedraw = false; // Used to trigger redraw
    var _isFirstScene = true; // Used to know if this is the first scene being created
    var geometryManager = new GeometryManager();
    var materialManager = new ShaderMaterialManager();
    var _offset = new THREE$1.Vector3(); // The offset for aligning the second document
    var _splitPosition = 0.5; // Percentage of the width where the split line is positioned
    var addThickening = false; // Adds an extra pixel adjacent to diff pixels, to thicken the lines
    var HIGHLIGHT_NONE = 0;
    var HIGHLIGHT_A = 1;
    var HIGHLIGHT_B = 2;
    var HIGHLIGHT_BOTH = 3; // A + B
    var _highlightMode = HIGHLIGHT_BOTH; // Used when highlighting only the differences in one document
    var pixelRatio = window.devicePixelRatio || 1;
    var _deltaZ = 0.0; // For the non-intersecting tiles, since they might overlap a bit with other tiles
    var _diffMode = LeafletDiffModes.NORMAL_DIFF;
    var NO_INTERSECTION = 0;
    var PARTIAL_INTERSECTION = 1;
    var FULL_INTERSECTION = 2;
    /**
     * Changes the comparison mode
     * @param {LeafletDiffModes} mode
     */
    this.setDiffMode = function (mode) {
        _diffMode = mode;
        _needsRedraw = true;
    };
    /**
     * Returns the current comparison mode
     * @return {LeafletDiffModes}
     */
    this.getDiffMode = function () {
        return _diffMode;
    };
    /**
     * Returns the current offset for the second document
     * @return {THREE.Vector3}
     */
    this.getOffset = function () {
        return _offset;
    };
    /**
     * Sets the offset for the second document, for alignment
     * @param {THREE.Vector3} offset
     */
    this.setOffset = function (offset) {
        _offset = offset;
    };
    /**
     * Sets the position of the split line, for split view mode
     * @param {Number} splitPos - a percentage of the document width (between 0 and 1)
     */
    this.setSplitPosition = function (splitPos) {
        _splitPosition = splitPos;
    };
    /** Perform raycast
     * @param {THREE.RayCaster} raycaster
     * @param {Object[]}        intersects - An object array that contains intersection result objects.
     *                                       Each result r stores properties like r.point, r.fragId, r.dbId. (see VBIntersector.js for details)
     */
    this.rayCast = function (raycaster, intersects) {
        // not implemented yet
        return null;
    };
    /** Copies visible bbox into the given output params. Since per-fragment visibility is not supported
     *  by this iterator, both bboxes are always identical.
     *
     *   @param {THREE.Box3} [visibleBounds]
     *   @param {THREE.Box3} [visibleBoundsWithHidden]
     */
    this.getVisibleBounds = function (visibleBounds, visibleBoundsWithHidden) {
        var tmpBox = new THREE$1.Box3();
        var tmpBoxWithHidden = new THREE$1.Box3();
        _iterA.getVisibleBounds(tmpBox, tmpBoxWithHidden);
        _iterB.getVisibleBounds(visibleBounds, visibleBoundsWithHidden);
        visibleBounds.union(tmpBox);
        visibleBoundsWithHidden.union(tmpBoxWithHidden);
    };
    /**
     * @returns {boolean} true if an offset has been set
     */
    function isOffsetNotEmpty() {
        return _offset.x !== 0 || _offset.y !== 0;
    }
    /**
     * Changes the current camera position when there's an offset, so that when resetting the second document it will
     * retrieve the correct tiles for the actual view.
     * @param {String} action - either 'sub' or 'add', to add or remove the offset
     * @param: {FrustumIntersector} frustum
     * @param: {UnifiedCamera}      camera
     */
    function setCameraOffset(action, frustum, camera) {
        camera.position[action](_offset);
        camera.target[action](_offset);
        camera.updateMatrixWorld(true);
        camera.matrixWorldInverse.getInverse(camera.matrixWorld);
        frustum.reset(camera);
    }
    /**
     * Adds a non-intersecting tile to the scene
     * @param {THREE.Mesh} shape - the source mesh
     * @param {Number} posZ - the z-coordinate for the new mesh. Needed to avoid z-fighting with the adjacent intersecting tiles
     * @param {Number} model - 1 or 2, for first or second document, to be passed to the shader
     * @returns {THREE.Mesh} the newly created mesh
     */
    function addNonIntersectingTiles(shape, posZ, model) {
        var mesh = shape.clone();
        mesh.position.z = posZ;
        var uniforms = {
            texture1: { type: 't', value: shape.material.map },
            model: { type: 'i', value: model },
            splitPosition: { type: 'f', value: _splitPosition * window.innerWidth * pixelRatio }
        };
        var isSplit = _diffMode === LeafletDiffModes.SPLIT_VIEW;
        var material = materialManager.acquireShaderMaterial(uniforms, 'nonintersect' + (isSplit ? 'split' : ''));
        material.defines.SINGLE_MODEL = 1;
        if (isSplit) {
            material.defines.SPLIT_VIEW = 1;
        }
        mesh.material = material;
        _scene.add(mesh);
        return mesh;
    }
    /**
     * Calculates the transform for the textures when there's an intersection. Compares the relative change from the intersecting
     * rectangle to the original rectangle, in order to find the same change in the texture offsets and scale.
     * @param {UVTransform} uvTF - the transform to update
     * @param {UVTransform} origUvTF - the original transform
     * @param {Rect} rect - the original tile rectangle
     * @param {Rect} intersec - the intersection of rect with another rectangle
     */
    function calcTransformation(uvTF, origUvTF, rect, intersec) {
        uvTF.offsetX = origUvTF.offsetX + (intersec.l - rect.l) / rect.width() * origUvTF.scaleX;
        uvTF.offsetY = origUvTF.offsetY + (intersec.b - rect.b) / rect.height() * origUvTF.scaleY;
        uvTF.scaleX = origUvTF.scaleX * intersec.width() / rect.width();
        uvTF.scaleY = origUvTF.scaleY * intersec.height() / rect.height();
    }
    /**
     * Adds an intersecting tile to the scene
     * @param {THREE.Mesh} shapeB - Mesh from second document
     * @param {THREE.Mesh} shapeA - Mesh from first document
     * @param {Rect} rectA - the first document's tile rectangle
     * @param {THREE.Texture} textureA - the first document's texture corresponding to shapeA
     * @param {boolean} isPartial - true if the current miplevel hasn't fully loaded yet.
     *                              To avoid flickering of the materials we don't show a level until it's ready.
     * @returns {Rect} the intersection found
     */
    function addMeshFromIntersection(shapeB, shapeA, rectA, textureA, isPartial) {
        var rectB = shapeB.rect;
        var intersec = rectA.getIntersection(rectB);
        if (intersec) {
            shapeB.intersecStatus = PARTIAL_INTERSECTION; // Some intersection found
            shapeB.intersec.union(intersec); // Keep track of total intersection for shapeB
            var textureB = shapeB.material.map;
            var mesh = shapeA.clone();
            var uvTFa = new UVTransform();
            var origUvTFa = mesh.geometry.uvTransform;
            if (!intersec.equals(rectA)) {
                // Since intersect is different from rectA, the relative uv transform must be found
                // and a new geometry is needed, since a single geometry can't share different uv tranforms.
                calcTransformation(uvTFa, origUvTFa, rectA, intersec);
                mesh.geometry = geometryManager.acquireQuadGeom(uvTFa);
            } else {
                // rectA == intersect, so the same transform will do
                origUvTFa.copyTo(uvTFa);
                if (intersec.equals(rectB)) {
                    // Full equality -> rectA == intersect == rectB
                    // shapeB could not intersect with any other tile
                    shapeB.intersecStatus = FULL_INTERSECTION;
                }
            }
            var uvTFb = new UVTransform();
            var origUvTFb = shapeB.geometry.uvTransform;
            // Get the relative uv transform for the second doc's texture as well. Passed to the shader for calculations.
            calcTransformation(uvTFb, origUvTFb, rectB, intersec);
            // The mesh will have the dimensions of the intersection
            mesh.position.set(intersec.l, intersec.b, 0.0);
            mesh.scale.set(intersec.width(), intersec.height(), 1.0);
            var resolutionA = new THREE$1.Vector2();
            var resolutionB = new THREE$1.Vector2();
            if (addThickening) {
                resolutionA.x = 1.0 / (1 | textureA.image.width * pixelRatio);
                resolutionA.y = 1.0 / (1 | textureA.image.height * pixelRatio);
                resolutionB.x = 1.0 / (1 | textureB.image.width * pixelRatio);
                resolutionB.y = 1.0 / (1 | textureB.image.height * pixelRatio);
            }
            var uniforms = {
                texture1: { type: 't', value: textureA },
                texture2: { type: 't', value: textureB },
                uvTFa: { type: 'v4', value: uvTFa.toVec4() },
                uvTFb: { type: 'v4', value: uvTFb.toVec4() },
                highlight: { type: 'i', value: isPartial ? HIGHLIGHT_NONE : _highlightMode },
                splitPosition: { type: 'f', value: _splitPosition * window.innerWidth * pixelRatio },
                resolution1: { type: 'v2', value: resolutionA },
                resolution2: { type: 'v2', value: resolutionB }
            };
            var isSplit = _diffMode === LeafletDiffModes.SPLIT_VIEW;
            var material = materialManager.acquireShaderMaterial(uniforms, 'intersection' + (isSplit ? 'split' : ''));
            if (isSplit) {
                material.defines.SPLIT_VIEW = 1;
            }
            if (addThickening) {
                material.defines.ADD_THICKENING = 1;
            }
            mesh.material = material;
            _scene.add(mesh);
            return intersec;
        }
        return null;
    }
    /**
     * Initialize and calculate some parameters for the second document
     * @param {THREE.Scene} sceneB
     */
    function preprocessModelB(sceneB) {
        for (var j = 0; j < sceneB.children.length; j++) {
            var shapeB = sceneB.children[j];
            shapeB.intersecStatus = NO_INTERSECTION; // Status of this shape's intersection
            shapeB.intersec = new Rect(); // Current intersection
            var posB = new THREE$1.Vector3();
            posB.addVectors(shapeB.position, _offset); // Store the position with the alignment offset
            var scaleB = shapeB.scale;
            shapeB.rect = new Rect(posB.x, posB.y, posB.x + scaleB.x, posB.y + scaleB.y);
        }
    }
    /**
     * Main function for the standard compare (red for model A, blue for model, gray otherwise), as well as the highlight A or B modes.
     * Resets the internal iterators, applying offset if needed, and calls the performDiff function
     * @param: {FrustumIntersector} frustum
     * @param: {UnifiedCamera}      camera
     * @returns {boolean} true if both scenes are stable (all tiles for current view loaded)
     */
    function normalDiff(frustum, camera) {
        var hasOffset = isOffsetNotEmpty();
        _deltaZ = 0.5 * (camera.far - camera.near);
        // Reset the wrapped iterators
        var sceneAcomplete = _iterA.reset(frustum, camera);
        // Move the camera in case the second model is offsetted for alignment
        if (hasOffset) {
            setCameraOffset('sub', frustum, camera);
        }
        var sceneBcomplete = _iterB.reset(frustum, camera);
        if (hasOffset) {
            setCameraOffset('add', frustum, camera);
        }
        performDiff(!sceneAcomplete || !sceneBcomplete);
        return sceneAcomplete && sceneBcomplete;
    }
    /**
     * Iterates through the scene and finds the intersecting rectangles.
     * @param {boolean} isIncomplete - true if one of the iterators hasn't finished loading all the tiles for the current level
     */
    function performDiff() {
        var isIncomplete = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : false;

        var sceneA = _iterA.getScene();
        var sceneB = _iterB.getScene();
        preprocessModelB(sceneB);
        for (var i = 0; i < sceneA.children.length; i++) {
            var status = NO_INTERSECTION;
            var shapeA = sceneA.children[i];
            var tileA = shapeA.tile;
            var textureA = shapeA.material.map;
            var matTileA = shapeA.material.tile;
            var posA = shapeA.position;
            var scaleA = shapeA.scale;
            var rectA = new Rect(posA.x, posA.y, posA.x + scaleA.x, posA.y + scaleA.y);
            var totalIntersec = new Rect();
            // Assuming most cases will be of matching documents (in size). That means if sceneA and sceneB have
            // the same children number we can start checking from the same index
            var first = i < sceneB.children.length ? i : 0;
            var last = sceneB.children.length;
            for (var j = first; j < last; j++) {
                var shapeB = sceneB.children[j];
                var tileB = shapeB.tile;
                var matTileB = shapeB.material.tile;
                // For partial intersections we show everything in grayscale, otherwise we get situations where it looks like the materials are flickering red and blue
                // until it stabilizes.
                var isPartial = isIncomplete && (matTileB.level !== matTileA.level || tileA.level !== tileB.level || matTileA.level < tileA.level || matTileB.level < tileB.level);
                var intersec = addMeshFromIntersection(shapeB, shapeA, rectA, textureA, isPartial);
                if (intersec) {
                    status = shapeB.intersecStatus;
                    totalIntersec.union(intersec);
                    if (status === FULL_INTERSECTION) {
                        break;
                    }
                }
                if (first > 0 && j === last - 1) {
                    last = first;
                    first = 0;
                    j = -1;
                }
            }
            // No intersection or partial intersection for shapeA
            // Improvement for partial intersection: find actual intersection (should be at most 2 rectangles), instead of drawing
            // the whole thing (might not be so much advantage from this - in most cases it might be 1 rectangle)
            if (status === NO_INTERSECTION || status === PARTIAL_INTERSECTION && !rectA.equals(totalIntersec)) {
                addNonIntersectingTiles(shapeA, -0.2 * _deltaZ, 1);
            }
        }
        // Finally add the shapes from second document that had none or partial intersection
        for (var k = 0; k < sceneB.children.length; k++) {
            var shapeB = sceneB.children[k];
            if (shapeB.intersecStatus === NO_INTERSECTION || shapeB.intersecStatus === PARTIAL_INTERSECTION && !shapeB.rect.equals(shapeB.intersec)) {
                var mesh = addNonIntersectingTiles(shapeB, -0.1 * _deltaZ, 2);
                mesh.position.add(_offset);
            }
        }
    }
    /**
     * Show only the first document
     * @param: {FrustumIntersector} frustum
     * @param: {UnifiedCamera}      camera
     */
    function showModelA(frustum, camera) {
        _iterA.reset(frustum, camera);
        _scene = _iterA.getScene().clone();
    }
    /**
     * Show only the second document
     * @param: {FrustumIntersector} frustum
     * @param: {UnifiedCamera}      camera
     */
    function showModelB(frustum, camera) {
        var hasOffset = isOffsetNotEmpty();
        if (hasOffset) {
            setCameraOffset('sub', frustum, camera);
        }
        _iterB.reset(frustum, camera);
        _scene = _iterB.getScene().clone();
        _scene.position.copy(_offset);
        if (hasOffset) {
            setCameraOffset('add', frustum, camera);
        }
    }
    /**
     * Show split view mode.
     * This just calls normalDiff for now, since all the changes are done in the shader
     * @param: {FrustumIntersector} frustum
     * @param: {UnifiedCamera}      camera
     */
    function splitView(frustum, camera) {
        normalDiff(frustum, camera);
    }
    var _progress = 0;
    var _lastTime = 0;
    var _isFirstProgress = true;
    /**
     * Gives a sense of progress while the scene is stabilizing (when all iterators' scenes are complete)
     * The progress here is very much a heuristic, since it's hard to know actually how much time it will take.
     * @param sceneComplete
     */
    this.updateProgress = function (sceneComplete) {
        if (sceneComplete) {
            this.onProgress(100); // User provided callback
            _progress = 0;
            _isFirstProgress = true;
        } else {
            if (_isFirstProgress) {
                _lastTime = Date.now();
                _progress = 10;
                _isFirstProgress = false;
            } else {
                // Update with some progress
                var curTime = Date.now();
                var factor = _progress > 60 ? 10 : 5;
                _progress += factor * (curTime - _lastTime) / 250;
                _progress = Math.min(95, _progress);
                _lastTime = curTime;
            }
            this.onProgress(_progress); // User provided callback
        }
    };
    /** Start iterator
     *   @param: {FrustumIntersector} frustum
     *   @param: {UnifiedCamera}      camera
     */
    this.reset = function (frustum, camera) {
        _done = false;
        for (var i = 0; i < _scene.children.length; i++) {
            var obj = _scene.children[i];
            obj.dispatchEvent({ type: 'removed' });
        }
        // clear scene
        _scene.children.length = 0;
        _scene.position.set(0, 0, 0);
        // reset counter for reused temp geometry and materials
        geometryManager.reset();
        materialManager.reset();
        var sceneComplete = true;
        switch (_diffMode) {
            case LeafletDiffModes.NORMAL_DIFF:
                _highlightMode = HIGHLIGHT_BOTH;
                sceneComplete = normalDiff(frustum, camera);
                break;
            case LeafletDiffModes.MODEL_A_ONLY:
                showModelA(frustum, camera);
                break;
            case LeafletDiffModes.MODEL_B_ONLY:
                showModelB(frustum, camera);
                break;
            case LeafletDiffModes.SPLIT_VIEW:
                splitView(frustum, camera);
                break;
            case LeafletDiffModes.HIGHLIGHT_A:
                _highlightMode = HIGHLIGHT_A;
                sceneComplete = normalDiff(frustum, camera);
                break;
            case LeafletDiffModes.HIGHLIGHT_B:
                _highlightMode = HIGHLIGHT_B;
                sceneComplete = normalDiff(frustum, camera);
                break;
        }
        if (_isFirstScene) {
            if (sceneComplete) {
                if (this.onFirstSceneComplete) {
                    this.onFirstSceneComplete();
                }
                _isFirstScene = false;
            }
        } else if (this.onProgress) {
            this.updateProgress(sceneComplete);
        }
    };
    /** @returns {THREE.Scene|null} */
    this.nextBatch = function () {
        // first call since reset => return _scene
        if (!_done) {
            _done = true;
            return _scene;
        }
        return null;
    };
    this.getScene = function () {
        return _scene;
    };
    this.getSceneCount = function () {
        return 1; // TexQuadIterators are always rendered as a single batch
    };
    /** @returns {bool} */
    this.done = function () {
        return _done;
    };
    /** @returns {bool} Indicates that a full redraw is required to see the latest state. */
    this.update = function () {
        if (_needsRedraw) {
            _needsRedraw = false;
            return true;
        }
        return _iterA.update() || _iterB.update();
    };
    this.dispose = function () {
        // Dispose all material and geometries created for this iterator
        materialManager.dispose();
        geometryManager.dispose();
    };
    this.dtor = function () {
        this.dispose();
    };
}

var NODE_TYPE_LAYER = 0x2;
var NODE_TYPE_COLLECTION = 0x3;
var NODE_TYPE_COMPOSITE = 0x4;
var NODE_TYPE_MODEL = 0x5;
var NODE_TYPE_BITS = 0x7;
var NODE_FLAG_NOSELECT = 0x20000000;
var NODE_FLAG_OFF = 0x40000000;
var NODE_FLAG_HIDE = 0x80000000;
var SelectionMode = {
    LEAF_OBJECT: 0,
    FIRST_OBJECT: 1,
    LAST_OBJECT: 2
};
function InstanceTree(nodeAccess, objectCount, maxDepth) {
    this.nodeAccess = nodeAccess;
    this.maxDepth = maxDepth;
    this.objectCount = objectCount;
    this.numHidden = 0;
    this.numOff = 0;
}
InstanceTree.prototype.setFlagNode = function (dbId, flag, value) {
    var old = this.nodeAccess.getNodeFlags(dbId);
    // "!!" converts to bool
    if (!!(old & flag) == value) return false;
    if (value) this.nodeAccess.setNodeFlags(dbId, old | flag);else this.nodeAccess.setNodeFlags(dbId, old & ~flag);
    return true;
};
InstanceTree.prototype.setFlagGlobal = function (flag, value) {
    var na = this.nodeAccess;
    var i = 0,
        iEnd = na.numNodes;
    if (value) {
        for (; i < iEnd; i++) {
            na.setNodeFlags(i, na.getNodeFlags(i) | flag);
        }
    } else {
        var notflag = ~flag;
        for (; i < iEnd; i++) {
            na.setNodeFlags(i, na.getNodeFlags(i) & notflag);
        }
    }
};
/**
 * When a node is OFF, it is completely skipped for display purposes
 */
InstanceTree.prototype.setNodeOff = function (dbId, value) {
    var res = this.setFlagNode(dbId, NODE_FLAG_OFF, value);
    if (res) {
        if (value) this.numOff++;else this.numOff--;
    }
    return res;
};
InstanceTree.prototype.isNodeOff = function (dbId) {
    return !!(this.nodeAccess.getNodeFlags(dbId) & NODE_FLAG_OFF);
};
/**
 * When a node is HIDDEN it will display in ghosted style
 * if display of hidden objects is on
 */
InstanceTree.prototype.setNodeHidden = function (dbId, value) {
    var res = this.setFlagNode(dbId, NODE_FLAG_HIDE, value);
    if (res) {
        if (value) this.numHidden++;else this.numHidden--;
    }
    return res;
};
InstanceTree.prototype.isNodeHidden = function (dbId) {
    return !!(this.nodeAccess.getNodeFlags(dbId) & NODE_FLAG_HIDE);
};
InstanceTree.prototype.getNodeType = function (dbId) {
    return this.nodeAccess.getNodeFlags(dbId) & NODE_TYPE_BITS;
};
InstanceTree.prototype.isNodeSelectable = function (dbId) {
    return !(this.nodeAccess.getNodeFlags(dbId) & NODE_FLAG_NOSELECT);
};
InstanceTree.prototype.getNodeParentId = function (dbId) {
    return this.nodeAccess.getParentId(dbId);
};
InstanceTree.prototype.getRootId = function () {
    return this.nodeAccess.rootId;
};
InstanceTree.prototype.getNodeName = function (dbId) {
    return this.nodeAccess.name(dbId);
};
InstanceTree.prototype.getChildCount = function (dbId) {
    return this.nodeAccess.getNumChildren(dbId);
};
InstanceTree.prototype.getNodeBox = function (dbId, dst) {
    this.nodeAccess.getNodeBox(dbId, dst);
};
InstanceTree.prototype.getNodeIndex = function (dbId) {
    return this.nodeAccess.getIndex(dbId);
};
InstanceTree.prototype.enumNodeFragments = function (node, callback, recursive) {
    function predicate() {
        callback.apply(null, arguments);
        return false;
    }
    
    this.findNodeFragment(node, predicate, recursive);
};
InstanceTree.prototype.enumNodeChildren = function (node, callback, recursive) {
    function predicate() {
        callback.apply(null, arguments);
        return false;
    }
    
    this.findNodeChild(node, predicate, recursive);
};
InstanceTree.prototype.findNodeFragment = function (node, predicate, recursive) {
    //TODO: Temporary until we are consistently using dbId
    var dbId;
    if (typeof node == "number") dbId = node;else if (node) dbId = node.dbId;
    var self = this;
    function traverse(dbId) {
        if (self.nodeAccess.findNodeFragment(dbId, predicate)) {
            return dbId;
        }
        if (recursive) {
            return self.findNodeChild(dbId, function (child_dbId) {
                return traverse(child_dbId);
            });
        }
    }
    return traverse(dbId);
};
InstanceTree.prototype.findNodeChild = function (node, predicate, recursive) {
    //TODO: Temporary until we are consistently using dbId
    var dbId;
    if (typeof node == "number") dbId = node;else if (node) dbId = node.dbId;
    var self = this;
    if (recursive) {
        if (predicate(dbId)) {
            return dbId;
        }
    }
    function traverse(dbId) {
        return self.nodeAccess.findNodeChild(dbId, function (childId) {
            if (predicate(childId)) {
                return childId;
            }
            if (recursive) return traverse(childId);
        });
    }
    return traverse(dbId);
};
//Given a leaf node, find the correct parent
//node to select according to the given selection mode
InstanceTree.prototype.findNodeForSelection = function (dbId, selectionMode) {
    //Default legacy mode -- select exactly the node we got asked for.
    if (selectionMode === SelectionMode.LEAF_OBJECT) return dbId;
    var res = dbId;
    var node, nt;
    if (selectionMode === SelectionMode.FIRST_OBJECT) {
        //1. Find the leaf node of the selection tree containing it and then follow the chain of parents all the way up to the root to get the complete path from root to leaf node.
        //2. Start at the root and walk down the path until the first node that is not a Model, Layer or Collection. Select it.
        var idpath = [];
        node = dbId;
        while (node) {
            idpath.push(node);
            node = this.getNodeParentId(node);
        }
        for (var i = idpath.length - 1; i >= 0; i--) {
            nt = this.getNodeType(idpath[i]);
            if (nt !== NODE_TYPE_MODEL && nt !== NODE_TYPE_LAYER && nt !== NODE_TYPE_COLLECTION) {
                res = idpath[i];
                break;
            }
        }
    } else if (selectionMode === SelectionMode.LAST_OBJECT) {
        // Start at the leaf and walk up the path until the first node that is Composite. Select it. If theres no Composite node in the path select the leaf.
        node = dbId;
        while (node) {
            nt = this.getNodeType(node);
            if (nt === NODE_TYPE_COMPOSITE) {
                res = node;
                break;
            }
            node = this.getNodeParentId(node);
        }
    }
    return res;
};

var NODE_FLAG_OFF$1 = 0x1000000;
var NODE_FLAG_HIDE$1 = 0x2000000;
var FRAG_COUNT_MASK = 0x0ffffff;
var ROOT_NODE_ID = -1 << 30;
/**
 * Map dbids to fragment dbids
 *
 * When there isn't an instance tree this object can be used to get the fragment ids for
 * database ids.
 *
 * @param {ArrayLike} fragToDbId - fragToDbId[i] is the dbid or an array of dbids for fragment with id i
 */
function DbidFragmentMap(fragToDbId) {
    this.numOffs = 0;
    this.numHidden = 0;
    // Build the map from dbid to fragids.
    // _dbidToIndex maps dbids to an index in _dbidFrags.
    var _dbidToIndex = {};
    // _dbidFrags contains the fragment ids for the all of the dbids. The index from _dbidToIndex
    // points to an integer that contains flags and a fragment id count for the dbid. The fragment
    // ids follow that.
    var _dbidFrags;
    function buildMap(fragToDbId) {
        var fragArrayCount = 0; // Count of elements in _dbidFrags;
        var fragCounts = []; // Fragment id count for dbids
        var dbidArray = [0]; // Array to use for single fragment dbids
        function forEach(callback) {
            for (var i = 0, iEnd = fragToDbId.length; i < iEnd; i++) {
                var dbIds = fragToDbId[i];
                //In 2D drawings, a single fragment (consolidation mesh)
                //can contain multiple objects with different dbIds.
                if (!Array.isArray(dbIds)) {
                    dbidArray[0] = dbIds;
                    dbIds = dbidArray;
                }
                for (var j = 0; j < dbIds.length; j++) {
                    var dbId = dbIds[j];
                    callback(i, dbId);
                }
            }
        }
        // First pass, count the fragment ids per dbid.
        forEach(function (fragId, dbId) {
            var index = _dbidToIndex[dbId];
            if (index === undefined) {
                //If it's the first fragments for this dbid,
                //store the index directly -- most common case.
                _dbidToIndex[dbId] = index = fragCounts.length;
                fragCounts.push(0); // Push count
                fragCounts.push(0); // Push index
            }
            // Count fragments for dbid
            ++fragCounts[index];
            ++fragArrayCount; // Total count of fragments
        });
        // Allocate the array for the fragment ids
        _dbidFrags = new Uint32Array(fragArrayCount + fragCounts.length / 2);
        _dbidFrags.fill(0);
        // Now calculate the index for each dbid
        var dbId,
            index,
            curIndex = 0;
        for (dbId in _dbidToIndex) {
            index = _dbidToIndex[dbId];
            var count = fragCounts[index];
            var nextIndex = curIndex + count + 1;
            _dbidFrags[curIndex] = count;
            fragCounts[index] = fragCounts[index + 1] = curIndex;
            curIndex = nextIndex;
        }
        // Put the fragment ids in the fragment id array
        var logged = false;
        forEach(function (fragId, dbId) {
            var index = _dbidToIndex[dbId];
            var fragIndex = fragCounts[index + 1] + 1;
            if (fragIndex > _dbidFrags.length || _dbidFrags[fragIndex]) {
                if (!logged) {
                    console.error("DbidFragmentMap.buildMap: Internal error fragment overlap");
                    logged = true;
                }
            } else {
                _dbidFrags[fragIndex] = fragId;
                fragCounts[index + 1] = fragIndex;
            }
        });
        // Make sure we filled each dbids fragments
        logged = false;
        for (dbId in _dbidToIndex) {
            index = _dbidToIndex[dbId];
            var fragIndex = fragCounts[index + 1] + 1;
            if (fragIndex < _dbidFrags.length && !_dbidFrags[fragIndex]) {
                if (!logged) {
                    console.error("DbidFragmentMap.buildMap: Internal error fragment underfilled");
                    logged = true;
                }
            }
        }
        // Finally put the indices into _dbidToIndex
        for (dbId in _dbidToIndex) {
            index = _dbidToIndex[dbId];
            _dbidToIndex[dbId] = fragCounts[index];
        }
    }
    buildMap(fragToDbId);
    this.setFlagNode = function (dbId, flag, value) {
        if (!_dbidToIndex.hasOwnProperty(dbId)) return false;
        var index = _dbidToIndex[dbId];
        var old = _dbidFrags[index];
        // "!!" converts to bool
        if (!!(old & flag) == value) return false;
        if (value) _dbidFrags[index] |= flag;else _dbidFrags[index] &= ~flag;
        return true;
    };
    /**
     * When a node is OFF, it is completely skipped for display purposes
     */
    this.setNodeOff = function (dbId, value) {
        var res = this.setFlagNode(dbId, NODE_FLAG_OFF$1, value);
        if (res) {
            if (value) this.numOff++;else this.numOff--;
        }
        return res;
    };
    this.isNodeOff = function (dbId) {
        var index = _dbidToIndex[dbId];
        return !!(_dbidFrags[index] & NODE_FLAG_OFF$1);
    };
    /**
     * When a node is HIDDEN it will display in ghosted style
     * if display of hidden objects is on
     */
    this.setNodeHidden = function (dbId, value) {
        var res = this.setFlagNode(dbId, NODE_FLAG_HIDE$1, value);
        if (res) {
            if (value) this.numHidden++;else this.numHidden--;
        }
        return res;
    };
    this.isNodeHidden = function (dbId) {
        var index = _dbidToIndex[dbId];
        return !!(_dbidFrags[index] & NODE_FLAG_HIDE$1);
    };
    /**
     * Provide an id to standin for the root node. This id is used
     * in enumNodeChildren to enumerate all nodes in the scene.
     */
    this.getRootId = function () {
        return ROOT_NODE_ID;
    };
    /**
     * Enumerate the fragment ids for a database id
     */
    this.enumNodeFragments = function (node, callback /*, recursive*/) {
        //TODO: Temporary until we are consistently using dbId
        var dbId;
        if (typeof node == "number") dbId = node;else if (node) dbId = node.dbId;
        var index = _dbidToIndex[dbId];
        var end = (_dbidFrags[index] & FRAG_COUNT_MASK) + index + 1;
        while (++index < end) {
            callback(_dbidFrags[index], dbId);
        }
    };
    /**
     * Convenience function for code that uses the recursive
     * flag to convert database ids to fragment ids.
     */
    this.enumNodeChildren = function (node, callback, recursive) {
        if (recursive) callback(node);
        if (node == ROOT_NODE_ID) {
            for (var dbId in _dbidToIndex) {
                callback(Number(dbId));
            }
        }
    };
}

//
// struct Node {
//     int dbId;
//     int parentDbId;
//     int firstChild; //if negative it's a fragment list
//     int numChildren;
//     int flags;   
// };
// sizeof(Node) == 20
var SIZEOF_NODE = 5;
var OFFSET_DBID = 0;
var OFFSET_PARENT = 1;
var OFFSET_FIRST_CHILD = 2;
var OFFSET_NUM_CHILD = 3;
var OFFSET_FLAGS = 4;
// note: objectCount and fragmentCount are not used; was called NodeArray, but it is not used
// with that name externally - BVHBuilder defines the public NodeArray class. Changed here to avoid confusion.
function InstanceTreeStorage(objectCount, fragmentCount) {
    this.nodes = [];
    this.nextNode = 0;
    this.children = [];
    this.nextChild = 0;
    this.dbIdToIndex = {};
    this.names = [];
    this.s2i = {}; //duplicate string pool
    this.strings = [];
    this.nameSuffixes = []; //integers
    //Occupy index zero so that we can use index 0 as undefined
    this.getIndex(0);
}
InstanceTreeStorage.prototype.getIndex = function (dbId) {
    var index = this.dbIdToIndex[dbId];
    if (index) return index;
    index = this.nextNode++;
    //Allocate space for new node
    this.nodes.push(dbId); //store the dbId as first integer in the Node structure
    //Add four blank integers to be filled by setNode
    for (var i = 1; i < SIZEOF_NODE; i++) {
        this.nodes.push(0);
    }this.dbIdToIndex[dbId] = index;
    return index;
};
InstanceTreeStorage.prototype.setNode = function (dbId, parentDbId, name, flags, childrenIds, fragIds) {
    var index = this.getIndex(dbId);
    var baseOffset = index * SIZEOF_NODE;
    var numChildren = childrenIds.length;
    var hasFragments = fragIds && fragIds.length;
    if (hasFragments) {
        numChildren += fragIds.length;
    }
    this.nodes[baseOffset + OFFSET_PARENT] = parentDbId;
    this.nodes[baseOffset + OFFSET_FIRST_CHILD] = this.nextChild;
    this.nodes[baseOffset + OFFSET_NUM_CHILD] = hasFragments ? -numChildren : numChildren;
    this.nodes[baseOffset + OFFSET_FLAGS] = flags;
    var i;
    for (i = 0; i < childrenIds.length; i++) {
        this.children[this.nextChild++] = this.getIndex(childrenIds[i]);
    } //Store fragIds as negative numbers so we can differentiate them when looking through
    //the array later.
    if (hasFragments) {
        for (i = 0; i < fragIds.length; i++) {
            this.children[this.nextChild++] = -fragIds[i] - 1;
        } //index 0 stored as -1, etc., since 0 is not negative
    }
    if (this.nextChild > this.children.length) {
        // TODO: this code may run in a worker, replace console with something else
        console.error("Child index out of bounds -- should not happen");
    }
    this.processName(index, name);
};
InstanceTreeStorage.prototype.processName = function (index, name) {
    //Attempt to decompose the name into a base string + integer,
    //like for example "Base Wall [12345678]" or "Crank Shaft:1"
    //We will try to reduce memory usage by storing "Base Wall" just once.
    var base;
    var suffix;
    //Try Revit style [1234] first
    var iStart = -1;
    var iEnd = -1;
    if (name) {
        iEnd = name.lastIndexOf("]");
        iStart = name.lastIndexOf("[");
        //Try Inventor style :1234
        if (iStart === -1 || iEnd === -1) {
            iStart = name.lastIndexOf(":");
            iEnd = name.length;
        }
    }
    //TODO: Any other separators? What does AutoCAD use?
    if (iStart >= 0 && iEnd > iStart) {
        base = name.slice(0, iStart + 1);
        var ssuffix = name.slice(iStart + 1, iEnd);
        suffix = parseInt(ssuffix, 10);
        //make sure we get the same thing back when
        //converting back to string, otherwise don't 
        //decompose it.
        if (!suffix || suffix + "" !== ssuffix) {
            base = name;
            suffix = 0;
        }
    } else {
        base = name;
        suffix = 0;
    }
    var idx = this.s2i[base];
    if (idx === undefined) {
        this.strings.push(base);
        idx = this.strings.length - 1;
        this.s2i[base] = idx;
    }
    this.names[index] = idx;
    this.nameSuffixes[index] = suffix;
};
function arrayToBuffer(a) {
    var b = new Int32Array(a.length);
    b.set(a);
    return b;
}
// note none of these arguments are used
InstanceTreeStorage.prototype.flatten = function (dbId, parentDbId, name, flags, childrenIds, isLeaf) {
    this.nodes = arrayToBuffer(this.nodes);
    this.children = arrayToBuffer(this.children);
    this.names = arrayToBuffer(this.names);
    this.nameSuffixes = arrayToBuffer(this.nameSuffixes);
    this.s2i = null; //we don't need this temporary map once we've built the strings list
};
function InstanceTreeAccess(nodeArray, rootId, nodeBoxes) {
    this.nodes = nodeArray.nodes;
    this.children = nodeArray.children;
    this.dbIdToIndex = nodeArray.dbIdToIndex;
    this.names = nodeArray.names;
    this.nameSuffixes = nodeArray.nameSuffixes;
    this.strings = nodeArray.strings;
    this.rootId = rootId;
    this.numNodes = this.nodes.length / SIZEOF_NODE;
    this.visibleIds = null;
    this.nodeBoxes = nodeBoxes || new Float32Array(6 * this.numNodes);
}
// note dbId is not used
InstanceTreeAccess.prototype.getNumNodes = function (dbId) {
    return this.numNodes;
};
InstanceTreeAccess.prototype.getIndex = function (dbId) {
    return this.dbIdToIndex[dbId];
};
InstanceTreeAccess.prototype.name = function (dbId) {
    var idx = this.dbIdToIndex[dbId];
    if (typeof idx !== "number") {
        return undefined;
    }
    var base = this.strings[this.names[idx]];
    var suffix = this.nameSuffixes[idx];
    if (suffix) {
        //NOTE: update this logic if more separators are supported in processName above
        var lastChar = base.charAt(base.length - 1);
        if (lastChar === "[") return base + suffix + "]";else return base + suffix;
    } else {
        return base;
    }
};
InstanceTreeAccess.prototype.getParentId = function (dbId) {
    var idx = this.dbIdToIndex[dbId];
    if (typeof idx !== "number") {
        return undefined;
    }
    return this.nodes[idx * SIZEOF_NODE + OFFSET_PARENT];
};
InstanceTreeAccess.prototype.getNodeFlags = function (dbId) {
    var idx = this.dbIdToIndex[dbId];
    if (typeof idx !== "number") {
        return undefined;
    }
    return this.nodes[idx * SIZEOF_NODE + OFFSET_FLAGS];
};
InstanceTreeAccess.prototype.setNodeFlags = function (dbId, flags) {
    var idx = this.dbIdToIndex[dbId];
    if (typeof idx === "number") {
        this.nodes[idx * SIZEOF_NODE + OFFSET_FLAGS] = flags;
    }
};
InstanceTreeAccess.prototype.getNumChildren = function (dbId) {
    var idx = this.dbIdToIndex[dbId];
    if (typeof idx !== "number") {
        return 0;
    }
    var numChildren = this.nodes[idx * SIZEOF_NODE + OFFSET_NUM_CHILD];
    //If numChildren is non-negative, then all children are nodes (not fragments)
    if (numChildren >= 0) return numChildren;
    //Node has mixed fragments and child nodes, so we have to loop and collect just the node children
    var firstChild = this.nodes[idx * SIZEOF_NODE + OFFSET_FIRST_CHILD];
    numChildren = Math.abs(numChildren);
    var numNodeChildren = 0;
    for (var i = 0; i < numChildren; i++) {
        var childIdx = this.children[firstChild + i];
        //did we reach the fragment ids sub-list?
        if (childIdx < 0) break;
        numNodeChildren++;
    }
    return numNodeChildren;
};
InstanceTreeAccess.prototype.getNumFragments = function (dbId) {
    var idx = this.dbIdToIndex[dbId];
    if (typeof idx !== "number") {
        return 0;
    }
    var numChildren = this.nodes[idx * SIZEOF_NODE + OFFSET_NUM_CHILD];
    //If numChildren is non-negative, there aren't any fragments belonging to this node
    if (numChildren >= 0) return 0;
    //Node has mixed fragments and child nodes, so we have to loop and collect just the node children
    var firstChild = this.nodes[idx * SIZEOF_NODE + OFFSET_FIRST_CHILD];
    numChildren = Math.abs(numChildren);
    var numFragChildren = 0;
    //Iterate backwards, because fragment children are at the back of the children list
    for (var i = numChildren - 1; i >= 0; i--) {
        var childIdx = this.children[firstChild + i];
        //did we reach the inner node children ids sub-list?
        if (childIdx >= 0) break;
        numFragChildren++;
    }
    return numFragChildren;
};
InstanceTreeAccess.prototype.getNodeBox = function (dbId, dst) {
    var idx = this.getIndex(dbId);
    if (typeof idx !== "number") {
        dst.makeEmpty();
        return;
    }
    var off = idx * 6;
    for (var i = 0; i < 6; i++) {
        dst[i] = this.nodeBoxes[off + i];
    }
};
//Returns an array containing the dbIds of all objects
//that are physically represented in the scene. Not all
//objects in the property database occur physically in each graphics viewable.
InstanceTreeAccess.prototype.getVisibleIds = function () {
    if (!this.visibleIds) {
        this.visibleIds = Object.keys(this.dbIdToIndex).map(function (k) {
            return parseInt(k);
        });
    }
    return this.visibleIds;
};
InstanceTreeAccess.prototype.enumNodeChildren = function (dbId, callback) {
    function predicate() {
        callback.apply(null, arguments);
        return false;
    }
    
    this.findNodeChild(dbId, predicate);
};
InstanceTreeAccess.prototype.enumNodeFragments = function (dbId, callback) {
    function predicate() {
        callback.apply(null, arguments);
        return false;
    }
    
    this.findNodeFragment(dbId, predicate);
};
InstanceTreeAccess.prototype.findNodeChild = function (dbId, predicate) {
    var idx = this.dbIdToIndex[dbId];
    if (typeof idx !== "number") {
        return;
    }
    var firstChild = this.nodes[idx * SIZEOF_NODE + OFFSET_FIRST_CHILD];
    var numChildren = this.nodes[idx * SIZEOF_NODE + OFFSET_NUM_CHILD];
    numChildren = Math.abs(numChildren);
    for (var i = 0; i < numChildren; i++) {
        var childIdx = this.children[firstChild + i];
        //did we reach the fragment ids sub-list?
        if (childIdx < 0) break;
        var childDbId = this.nodes[childIdx * SIZEOF_NODE + OFFSET_DBID];
        if (predicate(childDbId, dbId, idx)) {
            return dbId;
        }
    }
};
InstanceTreeAccess.prototype.findNodeFragment = function (dbId, predicate) {
    var idx = this.dbIdToIndex[dbId];
    if (typeof idx !== "number") {
        return;
    }
    var firstChild = this.nodes[idx * SIZEOF_NODE + OFFSET_FIRST_CHILD];
    var numChildren = this.nodes[idx * SIZEOF_NODE + OFFSET_NUM_CHILD];
    //If numChildren is negative, it means there are fragments in the node
    if (numChildren < 0) {
        numChildren = -numChildren;
        for (var i = 0; i < numChildren; i++) {
            var childIdx = this.children[firstChild + i];
            //skip past children that are inner nodes (not fragments)
            if (childIdx > 0) continue;
            //Convert fragId from -1 based negative back to the actual fragId
            if (predicate(-childIdx - 1, dbId, idx)) {
                return dbId;
            }
        }
    }
};
InstanceTreeAccess.prototype.computeBoxes = function (fragBoxes) {
    var nodeAccess = this;
    var idx = nodeAccess.getIndex(nodeAccess.rootId);
    var nodeBoxes = nodeAccess.nodeBoxes;
    function traverseChildren(child_dbId, parentDbID, parentIdx) {
        var childIdx = nodeAccess.getIndex(child_dbId);
        //Recurse, then add all child boxes to make this node's box
        computeTreeBBoxesRec(child_dbId, childIdx);
        var box_offset = parentIdx * 6;
        var child_box_offset = childIdx * 6;
        for (var k = 0; k < 3; k++) {
            if (nodeBoxes[box_offset + k] > nodeBoxes[child_box_offset + k]) nodeBoxes[box_offset + k] = nodeBoxes[child_box_offset + k];
            if (nodeBoxes[box_offset + k + 3] < nodeBoxes[child_box_offset + k + 3]) nodeBoxes[box_offset + k + 3] = nodeBoxes[child_box_offset + k + 3];
        }
    }
    function traverseFragments(fragId, dbId, idx) {
        var frag_box_offset = fragId * 6;
        var box_offset = idx * 6;
        for (var k = 0; k < 3; k++) {
            if (nodeBoxes[box_offset + k] > fragBoxes[frag_box_offset + k]) nodeBoxes[box_offset + k] = fragBoxes[frag_box_offset + k];
            if (nodeBoxes[box_offset + k + 3] < fragBoxes[frag_box_offset + k + 3]) nodeBoxes[box_offset + k + 3] = fragBoxes[frag_box_offset + k + 3];
        }
    }
    function computeTreeBBoxesRec(dbId, idx) {
        var box_offset = idx * 6;
        nodeBoxes[box_offset] = nodeBoxes[box_offset + 1] = nodeBoxes[box_offset + 2] = Infinity;
        nodeBoxes[box_offset + 3] = nodeBoxes[box_offset + 4] = nodeBoxes[box_offset + 5] = -Infinity;
        if (nodeAccess.getNumChildren(dbId)) {
            nodeAccess.enumNodeChildren(dbId, traverseChildren, true);
        }
        //Leaf node -- don't think it's possible for a node to have
        //both children and leaf fragments, but we do handle that here.
        if (nodeAccess.getNumFragments(dbId)) {
            nodeAccess.enumNodeFragments(dbId, traverseFragments);
        }
    }
    computeTreeBBoxesRec(nodeAccess.rootId, idx);
};

/**
 * BVH definitions:
 *
 * BVH Node: if this was C (the only real programming language), it would go something like this,
 * but with better alignment.
 *
 * This is definition for "fat" nodes (for rasterization),
 * i.e. when inner nodes also contain primitives.
 * struct Node {                                                            byte/short/int offset
 *      float worldBox[6]; //world box of the node node                         0/0/0
 *      int leftChildIndex; //pointer to left child node (right is left+1)     24/12/6
 *      ushort primCount; //how many fragments are at this node                28/14/7
 *      ushort flags; //bitfield of good stuff                                 30/15/7.5
 *
 *      int primStart; //start of node's own primitives (fragments) list       32/16/8
 * };
 * => sizeof(Node) = 36 bytes

 * Definition for lean nodes (for ray casting): when a node is either inner node (just children, no primitives)
 * or leaf (just primitives, no children).
 * struct Node {
 *      float worldBox[6]; //world box of the node
 *      union {
 *          int leftChildIndex; //pointer to left child node (right is left+1)
 *          int primStart; //start of node's own primitives (fragments) list
 *      };
 *      ushort primCount; //how many fragments are at this node
 *      ushort flags; //bitfield of good stuff
 * };
 * => sizeof(Node) = 32 bytes
 *
 * The class below encapsulates an array of such nodes using ArrayBuffer as backing store.
 *
 * @param {ArrayBuffer|number} initialData  Initial content of the NodeArray, or initial allocation of empty nodes
 * @param {boolean} useLeanNode Use minimal node structure size. Currently this parameter must be set to false.
 * @constructor
 */
/**
 * BVH definitions:
 *
 * BVH Node: if this was C (the only real programming language), it would go something like this,
 * but with better alignment.
 *
 * This is definition for "fat" nodes (for rasterization),
 * i.e. when inner nodes also contain primitives.
 * struct Node {                                                            byte/short/int offset
 *      float worldBox[6]; //world box of the node node                         0/0/0
 *      int leftChildIndex; //pointer to left child node (right is left+1)     24/12/6
 *      ushort primCount; //how many fragments are at this node                28/14/7
 *      ushort flags; //bitfield of good stuff                                 30/15/7.5
 *
 *      int primStart; //start of node's own primitives (fragments) list       32/16/8
 * };
 * => sizeof(Node) = 36 bytes

 * Definition for lean nodes (for ray casting): when a node is either inner node (just children, no primitives)
 * or leaf (just primitives, no children).
 * struct Node {
 *      float worldBox[6]; //world box of the node
 *      union {
 *          int leftChildIndex; //pointer to left child node (right is left+1)
 *          int primStart; //start of node's own primitives (fragments) list
 *      };
 *      ushort primCount; //how many fragments are at this node
 *      ushort flags; //bitfield of good stuff
 * };
 * => sizeof(Node) = 32 bytes
 *
 * The class below encapsulates an array of such nodes using ArrayBuffer as backing store.
 *
 * @param {ArrayBuffer|number} initialData  Initial content of the NodeArray, or initial allocation of empty nodes
 * @param {boolean} useLeanNode Use minimal node structure size. Currently this parameter must be set to false.
 * @constructor
 */function NodeArray(initialData, useLeanNode) {
    'use strict';

    if (useLeanNode) {
        this.bytes_per_node = 32;
    } else {
        this.bytes_per_node = 36;
    }
    var initialCount;
    var initialBuffer;
    if (initialData instanceof ArrayBuffer) {
        initialCount = initialData.byteLength / this.bytes_per_node;
        initialBuffer = initialData;
        this.nodeCount = initialCount;
    } else {
        initialCount = initialData | 0;
        initialBuffer = new ArrayBuffer(this.bytes_per_node * initialCount);
        this.nodeCount = 0;
    }
    this.nodeCapacity = initialCount;
    this.nodesRaw = initialBuffer;
    this.is_lean_node = useLeanNode;
    this.node_stride = this.bytes_per_node / 4;
    this.node_stride_short = this.bytes_per_node / 2;
    //Allocate memory buffer for all tree nodes
    this.nodesF = new Float32Array(this.nodesRaw);
    this.nodesI = new Int32Array(this.nodesRaw);
    this.nodesS = new Uint16Array(this.nodesRaw);
}
NodeArray.prototype.setLeftChild = function (nodeidx, childidx) {
    this.nodesI[nodeidx * this.node_stride + 6] = childidx;
};
NodeArray.prototype.getLeftChild = function (nodeidx) {
    return this.nodesI[nodeidx * this.node_stride + 6];
};
NodeArray.prototype.setPrimStart = function (nodeidx, start) {
    if (this.is_lean_node) this.nodesI[nodeidx * this.node_stride + 6] = start;else this.nodesI[nodeidx * this.node_stride + 8] = start;
};
NodeArray.prototype.getPrimStart = function (nodeidx) {
    if (this.is_lean_node) return this.nodesI[nodeidx * this.node_stride + 6];else return this.nodesI[nodeidx * this.node_stride + 8];
};
NodeArray.prototype.setPrimCount = function (nodeidx, count) {
    this.nodesS[nodeidx * this.node_stride_short + 14] = count;
};
NodeArray.prototype.getPrimCount = function (nodeidx) {
    return this.nodesS[nodeidx * this.node_stride_short + 14];
};
NodeArray.prototype.setFlags = function (nodeidx, axis, isFirst, isTransparent) {
    this.nodesS[nodeidx * this.node_stride_short + 15] = isTransparent << 3 | isFirst << 2 | axis & 0x3;
};
NodeArray.prototype.getFlags = function (nodeidx) {
    return this.nodesS[nodeidx * this.node_stride_short + 15];
};
NodeArray.prototype.setBox0 = function (nodeidx, src) {
    var off = nodeidx * this.node_stride;
    var dst = this.nodesF;
    dst[off] = src[0];
    dst[off + 1] = src[1];
    dst[off + 2] = src[2];
    dst[off + 3] = src[3];
    dst[off + 4] = src[4];
    dst[off + 5] = src[5];
};
NodeArray.prototype.getBoxThree = function (nodeidx, dst) {
    var off = nodeidx * this.node_stride;
    var src = this.nodesF;
    dst.min.x = src[off];
    dst.min.y = src[off + 1];
    dst.min.z = src[off + 2];
    dst.max.x = src[off + 3];
    dst.max.y = src[off + 4];
    dst.max.z = src[off + 5];
};
NodeArray.prototype.setBoxThree = function (nodeidx, src) {
    var off = nodeidx * this.node_stride;
    var dst = this.nodesF;
    dst[off] = src.min.x;
    dst[off + 1] = src.min.y;
    dst[off + 2] = src.min.z;
    dst[off + 3] = src.max.x;
    dst[off + 4] = src.max.y;
    dst[off + 5] = src.max.z;
};
NodeArray.prototype.makeEmpty = function (nodeidx) {
    var off = nodeidx * this.node_stride;
    var dst = this.nodesI;
    //No point to makeEmpty here, because the box gets set
    //directly when the node is initialized in bvh_subdivide.
    //box_make_empty(this.nodesF, off);
    //_this.setLeftChild(nodeidx,-1);
    dst[off + 6] = -1;
    //both prim count and flags to 0
    dst[off + 7] = 0;
    //_this.setPrimStart(nodeidx, -1);
    if (!this.is_lean_node) dst[off + 8] = -1;
};
NodeArray.prototype.realloc = function (extraSize) {
    if (this.nodeCount + extraSize > this.nodeCapacity) {
        var nsz = 0 | this.nodeCapacity * 3 / 2;
        if (nsz < this.nodeCount + extraSize) nsz = this.nodeCount + extraSize;
        var nnodes = new ArrayBuffer(nsz * this.bytes_per_node);
        var nnodesI = new Int32Array(nnodes);
        nnodesI.set(this.nodesI);
        this.nodeCapacity = nsz;
        this.nodesRaw = nnodes;
        this.nodesF = new Float32Array(nnodes);
        this.nodesI = nnodesI;
        this.nodesS = new Uint16Array(nnodes);
    }
};
NodeArray.prototype.nextNodes = function (howMany) {
    this.realloc(howMany);
    var res = this.nodeCount;
    this.nodeCount += howMany;
    for (var i = 0; i < howMany; i++) {
        this.makeEmpty(res + i);
    }
    return res;
};
NodeArray.prototype.getRawData = function () {
    return this.nodesRaw.slice(0, this.nodeCount * this.bytes_per_node);
};
var POINT_STRIDE = 3;
var BOX_EPSILON = 1e-5;
var BOX_SCALE_EPSILON = 1e-5;
var MAX_DEPTH = 15; /* max tree depth */
var MAX_BINS = 16;
/**
* Bounding Volume Hierarchy build algorithm.
* Uses top down binning -- see "On fast Construction of SAH-based Bounding Volume Hierarchies" by I.Wald
* Ported from the C version here: https://git.autodesk.com/stanevt/t-ray/blob/master/render3d/t-ray/t-core/t-bvh.c
* Optimized for JavaScript.
*/
var BVHModule = function () {
    //There be dragons in this closure.
    "use strict";
    /**
     * Utilities for manipulating bounding boxes stored
     * in external array (as sextuplets of float32)
     */

    function box_get_centroid(dst, dst_off, src, src_off) {
        dst[dst_off] = 0.5 * (src[src_off] + src[src_off + 3]);
        dst[dst_off + 1] = 0.5 * (src[src_off + 1] + src[src_off + 4]);
        dst[dst_off + 2] = 0.5 * (src[src_off + 2] + src[src_off + 5]);
    }
    function box_add_point_0(dst, src, src_off) {
        if (dst[0] > src[src_off]) dst[0] = src[src_off];
        if (dst[3] < src[src_off]) dst[3] = src[src_off];
        if (dst[1] > src[src_off + 1]) dst[1] = src[src_off + 1];
        if (dst[4] < src[src_off + 1]) dst[4] = src[src_off + 1];
        if (dst[2] > src[src_off + 2]) dst[2] = src[src_off + 2];
        if (dst[5] < src[src_off + 2]) dst[5] = src[src_off + 2];
    }
    function box_add_box_0(dst, src, src_off) {
        if (dst[0] > src[src_off]) dst[0] = src[src_off];
        if (dst[1] > src[src_off + 1]) dst[1] = src[src_off + 1];
        if (dst[2] > src[src_off + 2]) dst[2] = src[src_off + 2];
        if (dst[3] < src[src_off + 3]) dst[3] = src[src_off + 3];
        if (dst[4] < src[src_off + 4]) dst[4] = src[src_off + 4];
        if (dst[5] < src[src_off + 5]) dst[5] = src[src_off + 5];
    }
    function box_add_box_00(dst, src) {
        if (dst[0] > src[0]) dst[0] = src[0];
        if (dst[1] > src[1]) dst[1] = src[1];
        if (dst[2] > src[2]) dst[2] = src[2];
        if (dst[3] < src[3]) dst[3] = src[3];
        if (dst[4] < src[4]) dst[4] = src[4];
        if (dst[5] < src[5]) dst[5] = src[5];
    }
    function box_get_size(dst, dst_off, src, src_off) {
        for (var i = 0; i < 3; i++) {
            dst[dst_off + i] = src[src_off + 3 + i] - src[src_off + i];
        }
    }
    //function box_copy(dst, dst_off, src, src_off) {
    //    for (var i=0; i<6; i++) {
    //        dst[dst_off+i] = src[src_off+i];
    //    }
    //}
    // unwound version of box_copy
    function box_copy_00(dst, src) {
        dst[0] = src[0];
        dst[1] = src[1];
        dst[2] = src[2];
        dst[3] = src[3];
        dst[4] = src[4];
        dst[5] = src[5];
    }
    var dbl_max = Infinity;
    //function box_make_empty(dst, dst_off) {
    //        dst[dst_off]   =  dbl_max;
    //        dst[dst_off+1] =  dbl_max;
    //        dst[dst_off+2] =  dbl_max;
    //        dst[dst_off+3] = -dbl_max;
    //        dst[dst_off+4] = -dbl_max;
    //        dst[dst_off+5] = -dbl_max;
    //}
    function box_make_empty_0(dst) {
        dst[0] = dbl_max;
        dst[1] = dbl_max;
        dst[2] = dbl_max;
        dst[3] = -dbl_max;
        dst[4] = -dbl_max;
        dst[5] = -dbl_max;
    }
    function box_area(src, src_off) {
        var dx = src[src_off + 3] - src[src_off];
        var dy = src[src_off + 4] - src[src_off + 1];
        var dz = src[src_off + 5] - src[src_off + 2];
        if (dx < 0 || dy < 0 || dz < 0) return 0;
        return 2.0 * (dx * dy + dy * dz + dz * dx);
    }
    function box_area_0(src) {
        var dx = src[3] - src[0];
        var dy = src[4] - src[1];
        var dz = src[5] - src[2];
        if (dx < 0 || dy < 0 || dz < 0) return 0;
        return 2.0 * (dx * dy + dy * dz + dz * dx);
    }
    function bvh_split_info() {
        this.vb_left = new Float32Array(6);
        this.vb_right = new Float32Array(6);
        this.cb_left = new Float32Array(6);
        this.cb_right = new Float32Array(6);
        this.num_left = 0;
        this.best_split = -1;
        this.best_cost = -1;
        this.num_bins = -1;
    }
    bvh_split_info.prototype.reset = function () {
        this.num_left = 0;
        this.best_split = -1;
        this.best_cost = -1;
        this.num_bins = -1;
    };
    function bvh_bin() {
        this.box_bbox = new Float32Array(6); // bbox of all primitive bboxes
        this.box_centroid = new Float32Array(6); // bbox of all primitive centroids
        this.num_prims = 0; // number of primitives in the bin
    }
    bvh_bin.prototype.reset = function () {
        this.num_prims = 0; // number of primitives in the bin
        box_make_empty_0(this.box_bbox);
        box_make_empty_0(this.box_centroid);
    };
    function accum_bin_info() {
        this.BL = new Float32Array(6);
        this.CL = new Float32Array(6);
        this.NL = 0;
        this.AL = 0;
    }
    accum_bin_info.prototype.reset = function () {
        this.NL = 0;
        this.AL = 0;
        box_make_empty_0(this.BL);
        box_make_empty_0(this.CL);
    };
    //Scratch variables used by bvh_bin_axis
    //TODO: can be replaced by a flat ArrayBuffer
    var bins = [];
    var i;
    for (i = 0; i < MAX_BINS; i++) {
        bins.push(new bvh_bin());
    }
    //TODO: can be replaced by a flat ArrayBuffer
    var ai = [];
    for (i = 0; i < MAX_BINS - 1; i++) {
        ai.push(new accum_bin_info());
    }var BR = new Float32Array(6);
    var CR = new Float32Array(6);
    function assign_bins(bvh, start, end, axis, cb, cbdiag, num_bins) {
        var centroids = bvh.centroids;
        var primitives = bvh.primitives;
        var boxes = bvh.finfo.boxes;
        var boxStride = bvh.finfo.boxStride;
        /* bin assignment */
        var k1 = num_bins * (1.0 - BOX_SCALE_EPSILON) / cbdiag[axis];
        var cbaxis = cb[axis];
        var sp = bvh.sort_prims;
        for (var j = start; j <= end; j++) {
            /* map array index to primitive index -- since primitive index array gets reordered by the BVH build*/
            /* while the primitive info array is not reordered */
            var iprim = primitives[j] | 0;
            var fpbin = k1 * (centroids[iprim * 3 /*POINT_STRIDE*/ + axis] - cbaxis);
            var binid = fpbin | 0; //Truncate to int is algorithmic -> not an optimization thing!
            /* possible floating point problems */
            if (binid < 0) {
                binid = 0;
                //debug("Bin index out of range " + fpbin);
            } else if (binid >= num_bins) {
                binid = num_bins - 1;
                //debug("Bin index out of range. " + fpbin);
            }
            /* Store the bin index for the partitioning step, so we don't recompute it there */
            sp[j] = binid;
            /* update other bin data with the new primitive */
            //var bin = bins[binid];
            bins[binid].num_prims++;
            box_add_box_0(bins[binid].box_bbox, boxes, iprim * boxStride);
            box_add_point_0(bins[binid].box_centroid, centroids, iprim * 3 /*POINT_STRIDE*/);
        }
        /* at this point all primitves are assigned to a bin */
    }
    function bvh_bin_axis(bvh, start, end, axis, cb, cbdiag, split_info) {
        /* if size is near 0 on this axis, cost of split is infinite */
        if (cbdiag[axis] < bvh.scene_epsilon) {
            split_info.best_cost = Infinity;
            return;
        }
        var num_bins = MAX_BINS;
        if (num_bins > end - start + 1) num_bins = end - start + 1;
        var i;
        for (i = 0; i < num_bins; i++) {
            bins[i].reset();
        }for (i = 0; i < num_bins - 1; i++) {
            ai[i].reset();
        }split_info.num_bins = num_bins;
        assign_bins(bvh, start, end, axis, cb, cbdiag, num_bins);
        /* now do the accumulation sweep from left to right */
        box_copy_00(ai[0].BL, bins[0].box_bbox);
        box_copy_00(ai[0].CL, bins[0].box_centroid);
        ai[0].AL = box_area_0(ai[0].BL);
        ai[0].NL = bins[0].num_prims;
        var bin;
        for (i = 1; i < num_bins - 1; i++) {
            bin = bins[i];
            var aii = ai[i];
            box_copy_00(aii.BL, ai[i - 1].BL);
            box_add_box_00(aii.BL, bin.box_bbox);
            aii.AL = box_area_0(aii.BL);
            box_copy_00(aii.CL, ai[i - 1].CL);
            box_add_box_00(aii.CL, bin.box_centroid);
            aii.NL = ai[i - 1].NL + bin.num_prims;
        }
        /* sweep from right to left, keeping track of lowest cost and split */
        i = num_bins - 1;
        box_copy_00(BR, bins[i].box_bbox);
        box_copy_00(CR, bins[i].box_centroid);
        var AR = box_area_0(BR);
        var NR = bins[i].num_prims;
        var best_split = i;
        var best_cost = AR * NR + ai[i - 1].AL * ai[i - 1].NL;
        box_copy_00(split_info.vb_right, BR);
        box_copy_00(split_info.cb_right, bins[i].box_centroid);
        box_copy_00(split_info.vb_left, ai[i - 1].BL);
        box_copy_00(split_info.cb_left, ai[i - 1].CL);
        split_info.num_left = ai[i - 1].NL;
        for (i = i - 1; i >= 1; i--) {
            bin = bins[i];
            box_add_box_00(BR, bin.box_bbox);
            box_add_box_00(CR, bin.box_centroid);
            AR = box_area_0(BR);
            NR += bin.num_prims;
            var cur_cost = AR * NR + ai[i - 1].AL * ai[i - 1].NL;
            if (cur_cost <= best_cost) {
                best_cost = cur_cost;
                best_split = i;
                box_copy_00(split_info.vb_right, BR);
                box_copy_00(split_info.cb_right, CR);
                box_copy_00(split_info.vb_left, ai[i - 1].BL);
                box_copy_00(split_info.cb_left, ai[i - 1].CL);
                split_info.num_left = ai[i - 1].NL;
            }
        }
        split_info.best_split = best_split;
        split_info.best_cost = best_cost;
    }
    function bvh_partition(bvh, start, end, axis, cb, cbdiag, split_info) {
        //At this point, the original algorithm does an in-place NON-STABLE partition
        //to move primitives to the left and right sides of the split plane
        //into contiguous location of the primitives list for use by
        //the child nodes. But, we want to preserve the ordering by size
        //without having to do another sort, so we have to use
        //a temporary storage location to copy into. We place right-side primitives
        //in temporary storage, then copy back into the original storage in the right order.
        //Left-side primitives are still put directly into the destination location.
        var primitives = bvh.primitives;
        //var centroids = bvh.centroids;
        var i, j;
        //sort_prims contains bin indices computed during the split step.
        //Here we read those and also use sort_prims as temporary holding
        //of primitive indices. Hopefully the read happens before the write. :)
        //In C it was cheap enough to compute this again...
        //var k1 = split_info.num_bins * (1.0 - BOX_SCALE_EPSILON) / cbdiag[axis];
        //var cbaxis = cb[axis];
        var sp = bvh.sort_prims;
        var right = 0;
        var left = start | 0;
        var best_split = split_info.best_split | 0;
        for (i = start; i <= end; i++) {
            var iprim = primitives[i] | 0;
            //var fpbin = (k1 * (centroids[3/*POINT_STRIDE*/ * iprim + axis] - cbaxis));
            var binid = sp[i]; /* fpbin|0; */
            if (binid < best_split) {
                primitives[left++] = iprim;
            } else {
                sp[right++] = iprim;
            }
        }
        //if ((left-start) != split_info.num_left)
        //    debug("Mismatch between binning and partitioning.");
        //Copy back the right-side primitives into main primitives array, while
        //maintaining order
        for (j = 0; j < right; j++) {
            primitives[left + j] = sp[j];
        }
        /* at this point the binning is complete and we have computed a split */
    }
    function bvh_fatten_inner_node(bvh, nodes, nodeidx, start, end, cb, cbdiag, poly_cut_off) {
        var primitives = bvh.primitives;
        var centroids = bvh.centroids;
        //Take the first few items to place into the inner node,
        //but do not go over the max item or polygon count.
        var prim_count = end - start + 1;
        if (prim_count > bvh.frags_per_inner_node) prim_count = bvh.frags_per_inner_node;
        if (prim_count > poly_cut_off) prim_count = poly_cut_off;
        nodes.setPrimStart(nodeidx, start);
        nodes.setPrimCount(nodeidx, prim_count);
        start += prim_count;
        //Because we take some primitives off the input, we have to recompute
        //the bounding box used for computing the node split.
        box_make_empty_0(cb);
        for (var i = start; i <= end; i++) {
            box_add_point_0(cb, centroids, 3 /*POINT_STRIDE*/ * primitives[i]);
        }
        //Also update the split axis -- it could possibly change too.
        box_get_size(cbdiag, 0, cb, 0);
        //Decide which axis to split on. Done purely by longest.
        var axis = 0;
        if (cbdiag[1] > cbdiag[0]) axis = 1;
        if (cbdiag[2] > cbdiag[axis]) axis = 2;
        return axis;
    }
    var cbdiag = new Float32Array(3); //scratch variable used in bvh_subdivide
    function bvh_subdivide(bvh, nodeidx, /* current parent node to consider splitting */start, end, /* primitive sub-range to be considered at this recursion step */vb, /* bounding volume of the primitives' bounds in the sub-range */cb, /* bounding box of primitive centroids in this range */transparent, /* does the node contain opaque or transparent objects */depth /* recursion depth */) {
        box_get_size(cbdiag, 0, cb, 0);
        var nodes = bvh.nodes;
        var frags_per_leaf = transparent ? bvh.frags_per_leaf_node_transparent : bvh.frags_per_leaf_node;
        var frags_per_inner = transparent ? bvh.frags_per_inner_node_transparent : bvh.frags_per_inner_node;
        var polys_per_node = bvh.max_polys_per_node;
        //Decide which axis to split on.
        var axis = 0;
        if (cbdiag[1] > cbdiag[0]) axis = 1;
        if (cbdiag[2] > cbdiag[axis]) axis = 2;
        //Whether the node gets split or not, it gets
        //the same overall bounding box.
        nodes.setBox0(nodeidx, vb);
        //Check the expected polygon count of the node. This figures out the maximum number of fragments
        // we can put at the node as determined by polys_per_node
        var poly_count = 0;
        var poly_cut_off = 0;
        var prim_count = end - start + 1;
        // If we have the number of triangles in each mesh, limit the number of primitives in an inner node.
        if (bvh.finfo.hasPolygonCounts && bvh.frags_per_inner_node) {
            // Walk through primitives, add up the counts until we reach polys_per_node (10000), or run through
            // frags_per_inner_node (usually 32).
            // We know that later on we'll limit the number to frags_per_inner_node, so also do it here.
            var shorten_end = prim_count <= bvh.frags_per_inner_node ? end : start + bvh.frags_per_inner_node - 1;
            for (var i = start; i <= shorten_end; i++) {
                poly_count += bvh.finfo.getPolygonCount(bvh.primitives[i]);
                poly_cut_off++;
                if (poly_count > polys_per_node) break;
            }
        }
        var isSmall = prim_count <= frags_per_leaf && poly_count < polys_per_node || prim_count === 1;
        //Decide whether to terminate recursion
        if (isSmall || depth > MAX_DEPTH || cbdiag[axis] < bvh.scene_epsilon) {
            nodes.setLeftChild(nodeidx, -1);
            nodes.setPrimStart(nodeidx, start);
            nodes.setPrimCount(nodeidx, end - start + 1);
            nodes.setFlags(nodeidx, 0, 0, transparent ? 1 : 0);
            return;
        }
        //Pick the largest (first) primitives to live in this node
        //NOTE: this assumes primitives are sorted by size.
        //NOTE: This step is an optional departure from the original, and we also do a check for it above
        // to compute poly_cut_off.
        if (frags_per_inner) {
            axis = bvh_fatten_inner_node(bvh, nodes, nodeidx, start, end, cb, cbdiag, poly_cut_off);
            start = start + nodes.getPrimCount(nodeidx);
        }
        var split_info = new bvh_split_info();
        //Do the binning of the remaining primitives to go into child nodes
        bvh_bin_axis(bvh, start, end, axis, cb, cbdiag, split_info);
        if (split_info.num_bins < 0) {
            //Split was too costly, so add all objects to the current node and bail
            nodes.setPrimCount(nodeidx, nodes.getPrimCount(nodeidx) + end - start + 1);
            return;
        }
        bvh_partition(bvh, start, end, axis, cb, cbdiag, split_info);
        var child_idx = nodes.nextNodes(2);
        /* set info about split into the node */
        var cleft = (split_info.vb_left[3 + axis] + split_info.vb_left[axis]) * 0.5;
        var cright = (split_info.vb_right[3 + axis] + split_info.vb_right[axis]) * 0.5;
        nodes.setFlags(nodeidx, axis, cleft < cright ? 0 : 1, transparent ? 1 : 0);
        nodes.setLeftChild(nodeidx, child_idx);
        /* validate split */
        /*
        if (true) {
            for (var i=start; i< start+num_left; i++)
            {
                //int binid = (int)(k1 * (info->prim_info[info->bvh->iprims[i]].centroid.v[axis] - cb->min.v[axis]));
                var cen = primitives[i] * POINT_STRIDE;
                if (   centroids[cen] < split_info.cb_left[0]
                    || centroids[cen] > split_info.cb_left[3]
                    || centroids[cen+1] < split_info.cb_left[1]
                    || centroids[cen+1] > split_info.cb_left[4]
                    || centroids[cen+2] < split_info.cb_left[2]
                    || centroids[cen+2] > split_info.cb_left[5])
                {
                    debug ("wrong centroid box");
                }
            }
                 for (i=start+num_left; i<=end; i++)
            {
                //int binid = (int)(k1 * (info->prim_info[info->bvh->iprims[i]].centroid.v[axis] - cb->min.v[axis]));
                var cen = primitives[i] * POINT_STRIDE;
                if (   centroids[cen] < split_info.cb_right[0]
                    || centroids[cen] > split_info.cb_right[3]
                    || centroids[cen+1] < split_info.cb_right[1]
                    || centroids[cen+1] > split_info.cb_right[4]
                    || centroids[cen+2] < split_info.cb_right[2]
                    || centroids[cen+2] > split_info.cb_right[5])
                {
                    debug ("wrong centroid box");
                }
            }
        }
        */
        /* recurse */
        //bvh_subdivide(bvh, child_idx, start, start + split_info.num_left - 1, split_info.vb_left, split_info.cb_left, transparent, depth+1);
        //bvh_subdivide(bvh, child_idx + 1, start + split_info.num_left, end, split_info.vb_right, split_info.cb_right, transparent, depth+1);
        //Iterative stack-based recursion for easier profiling
        bvh.recursion_stack.push([bvh, child_idx + 1, start + split_info.num_left, end, split_info.vb_right, split_info.cb_right, transparent, depth + 1]);
        bvh.recursion_stack.push([bvh, child_idx, start, start + split_info.num_left - 1, split_info.vb_left, split_info.cb_left, transparent, depth + 1]);
    }
    function compute_boxes(bvh) {
        var boxv_o = bvh.boxv_o;
        var boxc_o = bvh.boxc_o;
        var boxv_t = bvh.boxv_t;
        var boxc_t = bvh.boxc_t;
        box_make_empty_0(boxv_o);
        box_make_empty_0(boxc_o);
        box_make_empty_0(boxv_t);
        box_make_empty_0(boxc_t);
        var c = bvh.centroids;
        var b = bvh.finfo.boxes;
        var boxStride = bvh.finfo.boxStride;
        for (var i = 0, iEnd = bvh.prim_count; i < iEnd; i++) {
            // find which primitive in the sorted list to use next
            var p = bvh.primitives[i];
            box_get_centroid(c, 3 /*POINT_STRIDE*/ * p, b, boxStride * p);
            if (i >= bvh.first_transparent) {
                box_add_point_0(boxc_t, c, 3 /*POINT_STRIDE*/ * p);
                box_add_box_0(boxv_t, b, boxStride * p);
            } else {
                box_add_point_0(boxc_o, c, 3 /*POINT_STRIDE*/ * p);
                box_add_box_0(boxv_o, b, boxStride * p);
            }
        }
        box_get_size(cbdiag, 0, bvh.boxv_o, 0);
        var maxsz = Math.max(cbdiag[0], cbdiag[1], cbdiag[2]);
        bvh.scene_epsilon = BOX_EPSILON * maxsz;
    }
    //Module exports
    return {
        bvh_subdivide: bvh_subdivide,
        compute_boxes: compute_boxes,
        box_area: box_area
    };
}();
function FragInfo(fragments, materialDefs) {
    //Invariants
    this.boxes = fragments.boxes; //Array of Float32, each bbox is a sextuplet
    this.polygonCounts = fragments.polygonCounts;
    this.hasPolygonCounts = !!this.polygonCounts;
    this.materials = fragments.materials; //material indices (we need to know which fragments are transparent)
    this.materialDefs = materialDefs;
    this.count = fragments.length;
    this.boxStride = 6;
}
FragInfo.prototype.getCount = function () {
    return this.count;
};
FragInfo.prototype.isTransparent = function (i) {
    return this.materialDefs && this.materialDefs[this.materials[i]] ? this.materialDefs[this.materials[i]].transparent : false;
};
FragInfo.prototype.getPolygonCount = function (i) {
    return this.polygonCounts[i];
};
/**
 * Given a list of LMV fragments, builds a spatial index for view-dependent traversal and hit testing.
 * @constructor
 */
function BVHBuilder(fragments, materialDefs, finfo) {
    //Initialize the inputs (bboxes, transparent flags, polygon counts)
    this.finfo = finfo || new FragInfo(fragments, materialDefs);
    this.prim_count = this.finfo.getCount();
    //To be initialized by build() function based on build options
    this.frags_per_leaf_node = -1;
    this.frags_per_inner_node = -1;
    this.nodes = null;
    this.work_buf = new ArrayBuffer(this.prim_count * 4);
    this.sort_prims = new Int32Array(this.work_buf);
    //Allocate memory buffer for re-ordered fragment primitive indices,
    //which will be sorted by node ownership and point to the index
    //of the fragment data.
    this.primitives = new Int32Array(this.prim_count);
    //The BVH split algorithm works based on centroids of the bboxes.
    this.centroids = new Float32Array(POINT_STRIDE * this.prim_count);
    //BBoxes and centroid bboxes for opaque and transparent primitive sets
    this.boxv_o = new Float32Array(6);
    this.boxc_o = new Float32Array(6);
    this.boxv_t = new Float32Array(6);
    this.boxc_t = new Float32Array(6);
    this.recursion_stack = [];
}
BVHBuilder.prototype.sortPrimitives = function () {
    var prim_sizes = new Float32Array(this.work_buf);
    var primitives = this.primitives;
    var numTransparent = 0;
    //Sort the input objects by size
    //We assume all LMV SVF files come
    //sorted by draw priority already, so in theory we can skip this step.
    //This turns out to not be the case - some fragments are badly sorted.
    //Part of the reason may be that the surface area of the geometry itself,
    //not its bounding box, is used to sort by physical size in LMVTK.
    //In any case, the transparent objects do not always come last (bug in LMVTK?),
    //so we still have to pull them out to the end of the list, so some sorting
    //takes place no matter how this value is set.
    // Turning this option on will mean that the BVH building process as a whole
    // will be 45% to 75% longer, for large models - full sorting takes awhile.
    // In absolute terms this is an increase of a maximum of 1.15 seconds for a
    // very large model (one with over 1 million fragments, i.e., mesh instances).
    // This cost may be acceptable. For smaller models - "only" 70K instances -
    // the cost is 0.05 seconds. For 130k instances, 0.1 seconds. The rise is
    // slightly more than linear, but not excessively slow. I think it's acceptable,
    // given that the cost is still much less than loading even a small part of the
    // model.
    var WANT_SORT = true;
    // console.log("BVH sort is " + WANT_SORT);
    var i, iEnd;
    for (i = 0, iEnd = this.prim_count; i < iEnd; i++) {
        //Start with trivial 1:1 order of the indices array
        primitives[i] = i;
        var transparent = this.finfo.isTransparent(i);
        if (transparent) numTransparent++;
        if (WANT_SORT) {
            prim_sizes[i] = BVHModule.box_area(this.finfo.boxes, this.finfo.boxStride * i);
            //In order to make transparent objects appear last,
            //we give them a negative size, so that they are naturally
            //sorted last in the sort by size.
            if (transparent) prim_sizes[i] = -prim_sizes[i];
        } else {
            //We still need the transparency flag for the loop below
            //where we find the last opaque item, but we can
            //short-cut the size computation.
            prim_sizes[i] = transparent ? -1 : 1;
        }
    }
    if (WANT_SORT) {
        Array.prototype.sort.call(this.primitives, function (a, b) {
            return prim_sizes[b] - prim_sizes[a];
        });
    } else {
        if (numTransparent && numTransparent < this.prim_count) {
            var tmpTransparent = new Int32Array(numTransparent);
            var oidx = 0,
                tidx = 0;
            for (i = 0, iEnd = this.prim_count; i < iEnd; i++) {
                if (prim_sizes[i] >= 0) primitives[oidx++] = primitives[i];else tmpTransparent[tidx++] = primitives[i];
            }
            primitives.set(tmpTransparent, this.prim_count - numTransparent);
        }
    }
    this.first_transparent = this.prim_count - numTransparent;
};
BVHBuilder.prototype.build = function (options) {
    //Kick off the BVH build.
    var useSlimNodes = options && !!options.useSlimNodes;
    var self = this;
    function assign_option(name, defaultVal) {
        if (options.hasOwnProperty(name)) self[name] = options[name];else self[name] = defaultVal;
    }
    // note: frags_per_leaf_node does *not* make an upper limit for the number of frags per node.
    //options for build optimized for rasterization renderer scenes
    if (useSlimNodes) {
        assign_option("frags_per_leaf_node", 1);
        assign_option("frags_per_inner_node", 0);
        assign_option("frags_per_leaf_node_transparent", 1);
        assign_option("frags_per_inner_node_transparent", 0);
        assign_option("max_polys_per_node", Infinity);
    } else {
        var multiplier = options.isWeakDevice ? 0.5 : 1.0;
        //TODO: tune these constants
        assign_option("frags_per_leaf_node", 0 | 32 * multiplier);
        //Placing fragments at inner nodes places more emphasis on bigger objects during tree traversal
        //but it can only be done for opaque objects. Transparent objects have to be strictly back to front
        //traversal regardless of size, unless a unified traversal
        assign_option("frags_per_inner_node", 0 | this.frags_per_leaf_node);
        assign_option("frags_per_leaf_node_transparent", this.frags_per_leaf_node);
        assign_option("frags_per_inner_node_transparent", 0);
        assign_option("max_polys_per_node", 0 | 10000 * multiplier);
    }
    //Reuse existing node array if there
    if (this.nodes && this.nodes.is_lean_node == useSlimNodes) this.nodes.nodeCount = 0;else {
        var est_nodes = this.prim_count / this.frags_per_leaf_node;
        var num_nodes = 1;
        while (num_nodes < est_nodes) {
            num_nodes *= 2;
        }this.nodes = new NodeArray(num_nodes, options ? options.useSlimNodes : false);
    }
    this.sortPrimitives();
    BVHModule.compute_boxes(this);
    //Init the root nodes at 0 for opaque
    //and 1 for transparent objects
    var root = this.nodes.nextNodes(2);
    //Now kick off the recursive tree build
    //Opaque
    BVHModule.bvh_subdivide(this, root, 0, this.first_transparent - 1, this.boxv_o, this.boxc_o, false, 0);
    var a;
    while (this.recursion_stack.length) {
        a = this.recursion_stack.pop();
        BVHModule.bvh_subdivide(a[0], a[1], a[2], a[3], a[4], a[5], a[6], a[7]);
    }
    //Transparent
    BVHModule.bvh_subdivide(this, root + 1, this.first_transparent, this.prim_count - 1, this.boxv_t, this.boxc_t, true, 0);
    while (this.recursion_stack.length) {
        a = this.recursion_stack.pop();
        BVHModule.bvh_subdivide(a[0], a[1], a[2], a[3], a[4], a[5], a[6], a[7]);
    }
};

/**
 * The object that holds the worker methods
 */
var workerScript = {};
/**
 * Load workers
 * @param webWorker     True to prefer loading the web worker, false to prefer using main thread workers
 * @param url           The url of the worker script
 * @param enableInline  True to load the workers directly from the URL. False to cache the workers and load from a data URL.
 * @returns A WorkerCreator to create the workers. If the desired preference is available, then it
 * will be used. If it isn't the other method will be used. Null is returned if no worker method was set.
 */
function loadWorker(webWorker, url, enableInline) {
  var creator = webWorker && workerScript.webWorkerClass || !workerScript.mainThreadClass ? workerScript.webWorkerClass : workerScript.mainThreadClass;
  return creator ? new creator(url, !!enableInline) : null;
}

/**
 * Error code constants
 *
 * These constants will be used in `onErrorCallback` functions.
 *
 * @enum {number}
 * @readonly
 * @category Core
 */

(function (ErrorCodes) {
    /** An unknown failure has occurred. */
    ErrorCodes[ErrorCodes["UNKNOWN_FAILURE"] = 1] = "UNKNOWN_FAILURE";
    /** Bad data (corrupted or malformed) was encountered. */
    ErrorCodes[ErrorCodes["BAD_DATA"] = 2] = "BAD_DATA";
    /** A network failure was encountered. */
    ErrorCodes[ErrorCodes["NETWORK_FAILURE"] = 3] = "NETWORK_FAILURE";
    /** Access was denied to a network resource (HTTP 403) */
    ErrorCodes[ErrorCodes["NETWORK_ACCESS_DENIED"] = 4] = "NETWORK_ACCESS_DENIED";
    /** A network resource could not be found (HTTP 404) */
    ErrorCodes[ErrorCodes["NETWORK_FILE_NOT_FOUND"] = 5] = "NETWORK_FILE_NOT_FOUND";
    /** A server error was returned when accessing a network resource (HTTP 5xx) */
    ErrorCodes[ErrorCodes["NETWORK_SERVER_ERROR"] = 6] = "NETWORK_SERVER_ERROR";
    /** An unhandled response code was returned when accessing a network resource (HTTP 'everything else') */
    ErrorCodes[ErrorCodes["NETWORK_UNHANDLED_RESPONSE_CODE"] = 7] = "NETWORK_UNHANDLED_RESPONSE_CODE";
    /** Browser error = webGL is not supported by the current browser */
    ErrorCodes[ErrorCodes["BROWSER_WEBGL_NOT_SUPPORTED"] = 8] = "BROWSER_WEBGL_NOT_SUPPORTED";
    /** There is nothing viewable in the fetched document */
    ErrorCodes[ErrorCodes["BAD_DATA_NO_VIEWABLE_CONTENT"] = 9] = "BAD_DATA_NO_VIEWABLE_CONTENT";
    /** Browser error = webGL is supported, but not enabled */
    ErrorCodes[ErrorCodes["BROWSER_WEBGL_DISABLED"] = 10] = "BROWSER_WEBGL_DISABLED";
    /** There is no geometry in loaded model */
    ErrorCodes[ErrorCodes["BAD_DATA_MODEL_IS_EMPTY"] = 11] = "BAD_DATA_MODEL_IS_EMPTY";
    /** Collaboration server error */
    ErrorCodes[ErrorCodes["RTC_ERROR"] = 12] = "RTC_ERROR";
    /** The extension of the loaded file is not supported */
    ErrorCodes[ErrorCodes["UNSUPORTED_FILE_EXTENSION"] = 13] = "UNSUPORTED_FILE_EXTENSION";
    /** Viewer error: wrong or forbidden usage of the viewer */
    ErrorCodes[ErrorCodes["VIEWER_INTERNAL_ERROR"] = 14] = "VIEWER_INTERNAL_ERROR";
})(exports.ErrorCodes || (exports.ErrorCodes = {}));
function errorCodeString(errorCode) {
    return "ErrorCode:" + errorCode + ".";
}
function getErrorCode(networkStatus) {
    if (networkStatus === 403 || networkStatus === 401) {
        return exports.ErrorCodes.NETWORK_ACCESS_DENIED;
    } else if (networkStatus === 404) {
        return exports.ErrorCodes.NETWORK_FILE_NOT_FOUND;
    } else if (networkStatus >= 500) {
        return exports.ErrorCodes.NETWORK_SERVER_ERROR;
    }
    return exports.ErrorCodes.NETWORK_UNHANDLED_RESPONSE_CODE;
}

var SimpleLogger = function () {
    function SimpleLogger() {
        classCallCheck(this, SimpleLogger);

        this.callback = function (entry, val) {};
        this.level = -1;
        this.setLevel(exports.LogLevels.ERROR);
    }

    createClass(SimpleLogger, [{
        key: 'initialize',
        value: function initialize(options) {
            if (options && options.eventCallback) this.callback = options.callback;
        }
    }, {
        key: 'shutdown',
        value: function shutdown() {}
    }, {
        key: 'track',
        value: function track(entry) {}
    }, {
        key: 'logToADP',
        value: function logToADP(entry) {
            return false;
        }
    }, {
        key: 'updateRuntimeStats',
        value: function updateRuntimeStats(entry) {}
    }, {
        key: 'reportRuntimeStats',
        value: function reportRuntimeStats() {}
    }, {
        key: 'setLevel',
        value: function setLevel(level) {
            if (this.level === level) return;
            this.level = level;
            var self = this;
            function nullFn() {}
            
            function reportError() {
                var msg = Array.prototype.slice.call(arguments).join(' ');
                self.callback({ category: 'error', message: msg }, { adp: false });
                console.error.apply(console, arguments);
            }
            // Bind to console
            this.debug = level >= exports.LogLevels.DEBUG ? console.log.bind(console) : nullFn;
            this.log = level >= exports.LogLevels.LOG ? console.log.bind(console) : nullFn;
            this.info = level >= exports.LogLevels.INFO ? console.info.bind(console) : nullFn;
            this.warn = level >= exports.LogLevels.WARNING ? console.warn.bind(console) : nullFn;
            this.error = level >= exports.LogLevels.ERROR ? reportError : nullFn;
        }
    }]);
    return SimpleLogger;
}();

"use strict";
// http://www.onicos.com/staff/iz/amuse/javascript/expert/utf.txt
/* utf.js - UTF-8 <=> UTF-16 convertion
 *
 * Copyright (C) 1999 Masanao Izumo <iz@onicos.co.jp>
 * Version: 1.0
 * LastModified: Dec 25 1999
 * This library is free.  You can redistribute it and/or modify it.
 */

function utf8BlobToStr(array, start, length) {
    var out, i, len, c, outArray, count;
    var char2, char3;
    var STR_CVT_LIMIT = 32 * 1024;
    out = "";
    outArray = [];
    len = length;
    count = 0;
    i = 0;
    while (i < len) {
        c = array[start + i++];
        switch (c >> 4) {
            case 0:
            case 1:
            case 2:
            case 3:
            case 4:
            case 5:
            case 6:
            case 7:
                // 0xxxxxxx
                outArray.push(String.fromCharCode(c));
                break;
            case 12:
            case 13:
                // 110x xxxx   10xx xxxx
                char2 = array[start + i++];
                outArray.push(String.fromCharCode((c & 0x1F) << 6 | char2 & 0x3F));
                break;
            case 14:
                // 1110 xxxx  10xx xxxx  10xx xxxx
                char2 = array[start + i++];
                char3 = array[start + i++];
                outArray.push(String.fromCharCode((c & 0x0F) << 12 | (char2 & 0x3F) << 6 | (char3 & 0x3F) << 0));
                break;
        }
        if (++count >= STR_CVT_LIMIT || i >= len) {
            out += outArray.join("");
            outArray.length = 0;
            count = 0;
        }
    }
    return out;
}
var USE_MANUAL_UTF8 = true;
function utf8ArrayToString(array, start, length) {
    if (start === undefined) start = 0;
    if (length === undefined) length = array.length;
    if (USE_MANUAL_UTF8) {
        return utf8BlobToStr(array, start, length);
    } else {
        var encodedString = "";
        for (var i = start, iEnd = start + length; i < iEnd; i++) {
            encodedString += String.fromCharCode(array[i]);
        }return decodeURIComponent(escape(encodedString));
    }
}

function blobToJson(blob) {
    var decodedString = utf8ArrayToString(blob, 0, blob.length);
    return JSON.parse(decodedString);
}

//parses a piece of json from a given blob (representing an array of json values)
//up to the next comma+newline combo (i.e. array delimiter).




//Simple integer array parse -- expects the array in property database
//format, where the array is packed with possibly newline separator,
//but no other white space. Does not do extensive error checking


//Scans an array of json values (strings, integers, doubles) and finds the
//offset of each value in the array, so that we can later pick off that
//specific value, without parsing the whole (potentially huge) json array up front.
//This expects the input blob to be in the form serialized by the property database
//C++ component -- one value per line. A more sophisticated parser would be needed
//in case the format changes and this assumption is not true anymore.

var scope = {};

/** @license zlib.js 2012 - imaya [ https://github.com/imaya/zlib.js ] The MIT License */(function() {'use strict';function n(e){throw e;}var p=void 0,aa=this;function r(e,c){var d=e.split("."),b=aa;!(d[0]in b)&&b.execScript&&b.execScript("var "+d[0]);for(var a;d.length&&(a=d.shift());)!d.length&&c!==p?b[a]=c:b=b[a]?b[a]:b[a]={};}var u="undefined"!==typeof Uint8Array&&"undefined"!==typeof Uint16Array&&"undefined"!==typeof Uint32Array;new (u?Uint8Array:Array)(256);function x(e,c,d){var b,a="number"===typeof c?c:c=0,f="number"===typeof d?d:e.length;b=-1;for(a=f&7;a--;++c)b=b>>>8^y[(b^e[c])&255];for(a=f>>3;a--;c+=8)b=b>>>8^y[(b^e[c])&255],b=b>>>8^y[(b^e[c+1])&255],b=b>>>8^y[(b^e[c+2])&255],b=b>>>8^y[(b^e[c+3])&255],b=b>>>8^y[(b^e[c+4])&255],b=b>>>8^y[(b^e[c+5])&255],b=b>>>8^y[(b^e[c+6])&255],b=b>>>8^y[(b^e[c+7])&255];return(b^4294967295)>>>0}
var z=[0,1996959894,3993919788,2567524794,124634137,1886057615,3915621685,2657392035,249268274,2044508324,3772115230,2547177864,162941995,2125561021,3887607047,2428444049,498536548,1789927666,4089016648,2227061214,450548861,1843258603,4107580753,2211677639,325883990,1684777152,4251122042,2321926636,335633487,1661365465,4195302755,2366115317,997073096,1281953886,3579855332,2724688242,1006888145,1258607687,3524101629,2768942443,901097722,1119000684,3686517206,2898065728,853044451,1172266101,3705015759,
2882616665,651767980,1373503546,3369554304,3218104598,565507253,1454621731,3485111705,3099436303,671266974,1594198024,3322730930,2970347812,795835527,1483230225,3244367275,3060149565,1994146192,31158534,2563907772,4023717930,1907459465,112637215,2680153253,3904427059,2013776290,251722036,2517215374,3775830040,2137656763,141376813,2439277719,3865271297,1802195444,476864866,2238001368,4066508878,1812370925,453092731,2181625025,4111451223,1706088902,314042704,2344532202,4240017532,1658658271,366619977,
2362670323,4224994405,1303535960,984961486,2747007092,3569037538,1256170817,1037604311,2765210733,3554079995,1131014506,879679996,2909243462,3663771856,1141124467,855842277,2852801631,3708648649,1342533948,654459306,3188396048,3373015174,1466479909,544179635,3110523913,3462522015,1591671054,702138776,2966460450,3352799412,1504918807,783551873,3082640443,3233442989,3988292384,2596254646,62317068,1957810842,3939845945,2647816111,81470997,1943803523,3814918930,2489596804,225274430,2053790376,3826175755,
2466906013,167816743,2097651377,4027552580,2265490386,503444072,1762050814,4150417245,2154129355,426522225,1852507879,4275313526,2312317920,282753626,1742555852,4189708143,2394877945,397917763,1622183637,3604390888,2714866558,953729732,1340076626,3518719985,2797360999,1068828381,1219638859,3624741850,2936675148,906185462,1090812512,3747672003,2825379669,829329135,1181335161,3412177804,3160834842,628085408,1382605366,3423369109,3138078467,570562233,1426400815,3317316542,2998733608,733239954,1555261956,
3268935591,3050360625,752459403,1541320221,2607071920,3965973030,1969922972,40735498,2617837225,3943577151,1913087877,83908371,2512341634,3803740692,2075208622,213261112,2463272603,3855990285,2094854071,198958881,2262029012,4057260610,1759359992,534414190,2176718541,4139329115,1873836001,414664567,2282248934,4279200368,1711684554,285281116,2405801727,4167216745,1634467795,376229701,2685067896,3608007406,1308918612,956543938,2808555105,3495958263,1231636301,1047427035,2932959818,3654703836,1088359270,
936918E3,2847714899,3736837829,1202900863,817233897,3183342108,3401237130,1404277552,615818150,3134207493,3453421203,1423857449,601450431,3009837614,3294710456,1567103746,711928724,3020668471,3272380065,1510334235,755167117],y=u?new Uint32Array(z):z;function A(){}A.prototype.getName=function(){return this.name};A.prototype.getData=function(){return this.data};A.prototype.G=function(){return this.H};r("Zlib.GunzipMember",A);r("Zlib.GunzipMember.prototype.getName",A.prototype.getName);r("Zlib.GunzipMember.prototype.getData",A.prototype.getData);r("Zlib.GunzipMember.prototype.getMtime",A.prototype.G);function C(e){var c=e.length,d=0,b=Number.POSITIVE_INFINITY,a,f,g,k,m,q,t,h,l;for(h=0;h<c;++h)e[h]>d&&(d=e[h]),e[h]<b&&(b=e[h]);a=1<<d;f=new (u?Uint32Array:Array)(a);g=1;k=0;for(m=2;g<=d;){for(h=0;h<c;++h)if(e[h]===g){q=0;t=k;for(l=0;l<g;++l)q=q<<1|t&1,t>>=1;for(l=q;l<a;l+=m)f[l]=g<<16|h;++k;}++g;k<<=1;m<<=1;}return[f,d,b]}var D=[],E;for(E=0;288>E;E++)switch(!0){case 143>=E:D.push([E+48,8]);break;case 255>=E:D.push([E-144+400,9]);break;case 279>=E:D.push([E-256+0,7]);break;case 287>=E:D.push([E-280+192,8]);break;default:n("invalid literal: "+E);}
var ca=function(){function e(a){switch(!0){case 3===a:return[257,a-3,0];case 4===a:return[258,a-4,0];case 5===a:return[259,a-5,0];case 6===a:return[260,a-6,0];case 7===a:return[261,a-7,0];case 8===a:return[262,a-8,0];case 9===a:return[263,a-9,0];case 10===a:return[264,a-10,0];case 12>=a:return[265,a-11,1];case 14>=a:return[266,a-13,1];case 16>=a:return[267,a-15,1];case 18>=a:return[268,a-17,1];case 22>=a:return[269,a-19,2];case 26>=a:return[270,a-23,2];case 30>=a:return[271,a-27,2];case 34>=a:return[272,
a-31,2];case 42>=a:return[273,a-35,3];case 50>=a:return[274,a-43,3];case 58>=a:return[275,a-51,3];case 66>=a:return[276,a-59,3];case 82>=a:return[277,a-67,4];case 98>=a:return[278,a-83,4];case 114>=a:return[279,a-99,4];case 130>=a:return[280,a-115,4];case 162>=a:return[281,a-131,5];case 194>=a:return[282,a-163,5];case 226>=a:return[283,a-195,5];case 257>=a:return[284,a-227,5];case 258===a:return[285,a-258,0];default:n("invalid length: "+a);}}var c=[],d,b;for(d=3;258>=d;d++)b=e(d),c[d]=b[2]<<24|b[1]<<
16|b[0];return c}();u&&new Uint32Array(ca);function G(e,c){this.i=[];this.j=32768;this.d=this.f=this.c=this.n=0;this.input=u?new Uint8Array(e):e;this.o=!1;this.k=H;this.w=!1;if(c||!(c={}))c.index&&(this.c=c.index),c.bufferSize&&(this.j=c.bufferSize),c.bufferType&&(this.k=c.bufferType),c.resize&&(this.w=c.resize);switch(this.k){case I:this.a=32768;this.b=new (u?Uint8Array:Array)(32768+this.j+258);break;case H:this.a=0;this.b=new (u?Uint8Array:Array)(this.j);this.e=this.D;this.q=this.A;this.l=this.C;break;default:n(Error("invalid inflate mode"));}}
var I=0,H=1;
G.prototype.g=function(){for(;!this.o;){var e=J(this,3);e&1&&(this.o=!0);e>>>=1;switch(e){case 0:var c=this.input,d=this.c,b=this.b,a=this.a,f=p,g=p,k=p,m=b.length,q=p;this.d=this.f=0;f=c[d++];f===p&&n(Error("invalid uncompressed block header: LEN (first byte)"));g=f;f=c[d++];f===p&&n(Error("invalid uncompressed block header: LEN (second byte)"));g|=f<<8;f=c[d++];f===p&&n(Error("invalid uncompressed block header: NLEN (first byte)"));k=f;f=c[d++];f===p&&n(Error("invalid uncompressed block header: NLEN (second byte)"));k|=
f<<8;g===~k&&n(Error("invalid uncompressed block header: length verify"));d+g>c.length&&n(Error("input buffer is broken"));switch(this.k){case I:for(;a+g>b.length;){q=m-a;g-=q;if(u)b.set(c.subarray(d,d+q),a),a+=q,d+=q;else for(;q--;)b[a++]=c[d++];this.a=a;b=this.e();a=this.a;}break;case H:for(;a+g>b.length;)b=this.e({t:2});break;default:n(Error("invalid inflate mode"));}if(u)b.set(c.subarray(d,d+g),a),a+=g,d+=g;else for(;g--;)b[a++]=c[d++];this.c=d;this.a=a;this.b=b;break;case 1:this.l(da,ea);break;
case 2:fa(this);break;default:n(Error("unknown BTYPE: "+e));}}return this.q()};
var K=[16,17,18,0,8,7,9,6,10,5,11,4,12,3,13,2,14,1,15],L=u?new Uint16Array(K):K,N=[3,4,5,6,7,8,9,10,11,13,15,17,19,23,27,31,35,43,51,59,67,83,99,115,131,163,195,227,258,258,258],O=u?new Uint16Array(N):N,P=[0,0,0,0,0,0,0,0,1,1,1,1,2,2,2,2,3,3,3,3,4,4,4,4,5,5,5,5,0,0,0],Q=u?new Uint8Array(P):P,T=[1,2,3,4,5,7,9,13,17,25,33,49,65,97,129,193,257,385,513,769,1025,1537,2049,3073,4097,6145,8193,12289,16385,24577],ga=u?new Uint16Array(T):T,ha=[0,0,0,0,1,1,2,2,3,3,4,4,5,5,6,6,7,7,8,8,9,9,10,10,11,11,12,12,
13,13],U=u?new Uint8Array(ha):ha,V=new (u?Uint8Array:Array)(288),W,ia;W=0;for(ia=V.length;W<ia;++W)V[W]=143>=W?8:255>=W?9:279>=W?7:8;var da=C(V),X=new (u?Uint8Array:Array)(30),Y,ja;Y=0;for(ja=X.length;Y<ja;++Y)X[Y]=5;var ea=C(X);function J(e,c){for(var d=e.f,b=e.d,a=e.input,f=e.c,g;b<c;)g=a[f++],g===p&&n(Error("input buffer is broken")),d|=g<<b,b+=8;g=d&(1<<c)-1;e.f=d>>>c;e.d=b-c;e.c=f;return g}
function Z(e,c){for(var d=e.f,b=e.d,a=e.input,f=e.c,g=c[0],k=c[1],m,q,t;b<k;){m=a[f++];if(m===p)break;d|=m<<b;b+=8;}q=g[d&(1<<k)-1];t=q>>>16;e.f=d>>t;e.d=b-t;e.c=f;return q&65535}
function fa(e){function c(a,c,b){var d,e,f,g;for(g=0;g<a;)switch(d=Z(this,c),d){case 16:for(f=3+J(this,2);f--;)b[g++]=e;break;case 17:for(f=3+J(this,3);f--;)b[g++]=0;e=0;break;case 18:for(f=11+J(this,7);f--;)b[g++]=0;e=0;break;default:e=b[g++]=d;}return b}var d=J(e,5)+257,b=J(e,5)+1,a=J(e,4)+4,f=new (u?Uint8Array:Array)(L.length),g,k,m,q;for(q=0;q<a;++q)f[L[q]]=J(e,3);g=C(f);k=new (u?Uint8Array:Array)(d);m=new (u?Uint8Array:Array)(b);e.l(C(c.call(e,d,g,k)),C(c.call(e,b,g,m)));}
G.prototype.l=function(e,c){var d=this.b,b=this.a;this.r=e;for(var a=d.length-258,f,g,k,m;256!==(f=Z(this,e));)if(256>f)b>=a&&(this.a=b,d=this.e(),b=this.a),d[b++]=f;else{g=f-257;m=O[g];0<Q[g]&&(m+=J(this,Q[g]));f=Z(this,c);k=ga[f];0<U[f]&&(k+=J(this,U[f]));b>=a&&(this.a=b,d=this.e(),b=this.a);for(;m--;)d[b]=d[b++-k];}for(;8<=this.d;)this.d-=8,this.c--;this.a=b;};
G.prototype.C=function(e,c){var d=this.b,b=this.a;this.r=e;for(var a=d.length,f,g,k,m;256!==(f=Z(this,e));)if(256>f)b>=a&&(d=this.e(),a=d.length),d[b++]=f;else{g=f-257;m=O[g];0<Q[g]&&(m+=J(this,Q[g]));f=Z(this,c);k=ga[f];0<U[f]&&(k+=J(this,U[f]));b+m>a&&(d=this.e(),a=d.length);for(;m--;)d[b]=d[b++-k];}for(;8<=this.d;)this.d-=8,this.c--;this.a=b;};
G.prototype.e=function(){var e=new (u?Uint8Array:Array)(this.a-32768),c=this.a-32768,d,b,a=this.b;if(u)e.set(a.subarray(32768,e.length));else{d=0;for(b=e.length;d<b;++d)e[d]=a[d+32768];}this.i.push(e);this.n+=e.length;if(u)a.set(a.subarray(c,c+32768));else for(d=0;32768>d;++d)a[d]=a[c+d];this.a=32768;return a};
G.prototype.D=function(e){var c,d=this.input.length/this.c+1|0,b,a,f,g=this.input,k=this.b;e&&("number"===typeof e.t&&(d=e.t),"number"===typeof e.z&&(d+=e.z));2>d?(b=(g.length-this.c)/this.r[2],f=258*(b/2)|0,a=f<k.length?k.length+f:k.length<<1):a=k.length*d;u?(c=new Uint8Array(a),c.set(k)):c=k;return this.b=c};
G.prototype.q=function(){var e=0,c=this.b,d=this.i,b,a=new (u?Uint8Array:Array)(this.n+(this.a-32768)),f,g,k,m;if(0===d.length)return u?this.b.subarray(32768,this.a):this.b.slice(32768,this.a);f=0;for(g=d.length;f<g;++f){b=d[f];k=0;for(m=b.length;k<m;++k)a[e++]=b[k];}f=32768;for(g=this.a;f<g;++f)a[e++]=c[f];this.i=[];return this.buffer=a};
G.prototype.A=function(){var e,c=this.a;u?this.w?(e=new Uint8Array(c),e.set(this.b.subarray(0,c))):e=this.b.subarray(0,c):(this.b.length>c&&(this.b.length=c),e=this.b);return this.buffer=e};function $(e){this.input=e;this.c=0;this.m=[];this.s=!1;}$.prototype.F=function(){this.s||this.g();return this.m.slice()};
$.prototype.g=function(){for(var e=this.input.length;this.c<e;){var c=new A,d=p,b=p,a=p,f=p,g=p,k=p,m=p,q=p,t=p,h=this.input,l=this.c;c.u=h[l++];c.v=h[l++];(31!==c.u||139!==c.v)&&n(Error("invalid file signature:"+c.u+","+c.v));c.p=h[l++];switch(c.p){case 8:break;default:n(Error("unknown compression method: "+c.p));}c.h=h[l++];q=h[l++]|h[l++]<<8|h[l++]<<16|h[l++]<<24;c.H=new Date(1E3*q);c.N=h[l++];c.M=h[l++];0<(c.h&4)&&(c.I=h[l++]|h[l++]<<8,l+=c.I);if(0<(c.h&8)){m=[];for(k=0;0<(g=h[l++]);)m[k++]=String.fromCharCode(g);
c.name=m.join("");}if(0<(c.h&16)){m=[];for(k=0;0<(g=h[l++]);)m[k++]=String.fromCharCode(g);c.J=m.join("");}0<(c.h&2)&&(c.B=x(h,0,l)&65535,c.B!==(h[l++]|h[l++]<<8)&&n(Error("invalid header crc16")));d=h[h.length-4]|h[h.length-3]<<8|h[h.length-2]<<16|h[h.length-1]<<24;h.length-l-4-4<512*d&&(f=d);b=new G(h,{index:l,bufferSize:f});c.data=a=b.g();l=b.c;c.K=t=(h[l++]|h[l++]<<8|h[l++]<<16|h[l++]<<24)>>>0;x(a,p,p)!==t&&n(Error("invalid CRC-32 checksum: 0x"+x(a,p,p).toString(16)+" / 0x"+t.toString(16)));c.L=
d=(h[l++]|h[l++]<<8|h[l++]<<16|h[l++]<<24)>>>0;(a.length&4294967295)!==d&&n(Error("invalid input size: "+(a.length&4294967295)+" / "+d));this.m.push(c);this.c=l;}this.s=!0;var F=this.m,s,M,R=0,S=0,B;s=0;for(M=F.length;s<M;++s)S+=F[s].data.length;if(u){B=new Uint8Array(S);for(s=0;s<M;++s)B.set(F[s].data,R),R+=F[s].data.length;}else{B=[];for(s=0;s<M;++s)B[s]=F[s].data;B=Array.prototype.concat.apply([],B);}return B};r("Zlib.Gunzip",$);r("Zlib.Gunzip.prototype.decompress",$.prototype.g);r("Zlib.Gunzip.prototype.getMembers",$.prototype.F);}).call(scope);

var Zlib = scope.Zlib;

"use strict";
var inWorkerThread = typeof self !== 'undefined' && typeof window === 'undefined';
var ViewingService = {
    endpoint: {
        HTTP_REQUEST_HEADERS: {},
        getApiEndpoint: function getApiEndpoint() {
            return null;
        },
        getManifestApi: function getManifestApi(endpoint, urn, api) {
            return null;
        },
        getItemApi: function getItemApi(endpoint, urn, api) {
            return null;
        },
        getThumbnailApi: function getThumbnailApi(endpoint, urn, api) {
            return null;
        },
        makeOssPath: function makeOssPath(root, bucket, object) {
            return null;
        },
        getUseCredentials: function getUseCredentials() {
            return false;
        },
        pathRequiresCredentials: function pathRequiresCredentials(path) {
            return false;
        },
        getDomainParam: function getDomainParam() {
            return '';
        },
        setUseCredentials: function setUseCredentials(useCredentials) {}
    }
};
ViewingService.setEndpoint = function (endpoint) {
    this.endpoint = endpoint;
};
var warnedGzip = false;
// Simplify Unix style file path. For example, turn '/a/./b/../../c/' into "/c".
// Required to deal with OSS crappy URNs where there are embedded '..'.
function simplifyPath(path) {
    var elements = path.split('/');
    if (elements.length == 0) return path;
    var stack = [];
    for (var index = 0; index < elements.length; ++index) {
        var c = elements[index];
        if (c === '.') {
            continue;
        }
        if (c === '..' && stack.length) {
            stack.pop();
        } else {
            stack.push(c);
        }
    }
    // Great, the path commits suicide.
    if (stack.length == 0) return '';
    return stack.join("/");
}
ViewingService.simplifyPath = simplifyPath;
function textToArrayBuffer(textBuffer, startOffset) {
    var len = textBuffer.length - startOffset;
    var arrayBuffer = new ArrayBuffer(len);
    var ui8a = new Uint8Array(arrayBuffer, 0);
    for (var i = 0, j = startOffset; i < len; i++, j++) {
        ui8a[i] = textBuffer.charCodeAt(j) & 0xff;
    }return ui8a;
}
ViewingService.OSS_PREFIX = "urn:adsk.objects:os.object:";
ViewingService.getDirectOSSUrl = function (baseEndpoint, path) {
    // When we see a resource is hosted on OSS (by checking the urn prefix where it contain a specific signature),
    // we'll construct the full OSS url that can be used to call the OSS GET object API.
    // The construction process will extract the OSS bucket name (which is the payload between the signature and the first forward slash first enoutered afterwards),
    // and then the object name (which is the payload left). The object name has to be URL encoded because OSS will choke on forward slash.
    var ossIndex = path.indexOf(ViewingService.OSS_PREFIX);
    if (ossIndex !== -1) {
        var ossPath = path.substr(ossIndex + ViewingService.OSS_PREFIX.length);
        var bucket = ossPath.substr(0, ossPath.indexOf("/"));
        var object = ossPath.substr(ossPath.indexOf("/") + 1);
        object = simplifyPath(object);
        return this.endpoint.makeOssPath(baseEndpoint, bucket, object);
    }
};
/**
 * Construct full URL given a potentially partial viewing service "urn:" prefixed resource
 * @returns {string}
 */
ViewingService.generateUrl = function (baseUrl, api, path) {
    path = path || "";
    //NODE
    if (isNodeJS() && !isRemotePath(baseUrl, path)) {
        return path;
    }
    path = simplifyPath(path);
    //V2 only accepts URL encoded paths
    var urnidx = path.indexOf("urn:");
    var qidx = path.indexOf("?");
    if (urnidx != -1) {
        if (qidx !== -1) {
            //TODO: not sure this will happen, queryParams are normally
            //passed in separately in the options object
            path = path.slice(0, urnidx) + encodeURIComponent(path.slice(urnidx, qidx)) + path.slice(qidx);
        } else {
            path = path.slice(0, urnidx) + encodeURIComponent(path.slice(urnidx));
        }
    } else {
        path = encodeURI(path);
    }
    //Check if it's a viewing service item path
    //Public/static content will not have the urn: prefix.
    //So URL construction is a no-op
    if (!api || decodeURIComponent(path).indexOf('urn:') !== 0) {
        if (isRemotePath(null, path)) return path;else return baseUrl + path;
    }
    //Remove "urn:" prefix when getting URN-based stuff (manifests and thumbnails)
    if (api !== 'items') {
        path = path.substr(6);
    }
    switch (api) {
        case "items":
            return this.endpoint.getItemApi(baseUrl, path);
        case "bubbles":
            return this.endpoint.getManifestApi(baseUrl, path);
        case "thumbnails":
            return this.endpoint.getThumbnailApi(baseUrl, path);
    }
};
function isRemotePath(baseUrl, path) {
    if (path.indexOf("file://") !== -1) return false;
    if (path.indexOf("://") !== -1) return true;
    if (baseUrl) return true;
}
//Conditional GET request implementation for node vs. browser
if (isNodeJS()) {
    (function () {
        var fs = require('fs');
        var zlib = require('zlib');
        var https = require('https');
        var http = require('http');
        var urllib = require('url');
        var forgeAgent = new https.Agent({ maxSockets: 10 });
        function loadLocalFile(url, onSuccess, onFailure, options) {
            if (url.indexOf("file://") === 0) url = url.substr(7);
            function postProcess(data) {
                if (options.responseType === "json") {
                    try {
                        return JSON.parse(data.toString("utf8"));
                    } catch (e) {
                        onFailure(e);
                    }
                }
                return data;
            }
            //Always use async on Node
            fs.readFile(url, function (error$$1, data) {
                if (error$$1) {
                    onFailure(0, 0, { httpStatusText: error$$1, url: url });
                } else {
                    if (data[0] === 31 && data[1] === 139) {
                        zlib.gunzip(data, null, function (error$$1, data) {
                            if (error$$1) onFailure(0, 0, { httpStatusText: error$$1, url: url });else {
                                data = postProcess(data);
                                if (options.ondata) options.ondata(data);
                                onSuccess(data);
                            }
                        });
                    } else {
                        data = postProcess(data);
                        if (options.ondata) options.ondata(data);
                        onSuccess(data);
                    }
                }
            });
        }
        function needsGunzip(res, pathname) {
            if (res.headers['content-encoding'] === 'gzip') return true;
            //These SVF related files come pre-gzipped
            //regardless of content-encoding header
            if (pathname.endsWith(".json.gz")) return true;
            if (pathname.endsWith("FragmentList.pack")) return true;
            if (pathname.endsWith("LightList.bin")) return true;
            if (pathname.endsWith("CameraList.bin")) return true;
            if (pathname.endsWith("CameraDefinitions.bin")) return true;
            if (pathname.endsWith("LightDefinitions.bin")) return true;
            return false;
        }
        /**
         *  Performs a GET/HEAD request to Viewing Service. (Node.js specific implementation)
         *
         * @param {string} viewingServiceBaseUrl - The base url for the viewing service.
         * @param {string} api - The api to call in the viewing service.
         *  @param {string} url - The url for the request.
         *  @param {function} onSuccess - A function that takes a single parameter that represents the response
         *                                returned if the request is successful.
         *  @param {function} onFailure - A function that takes an integer status code, and a string status, which together represent
         *                                the response returned if the request is unsuccessful, and a third data argument, which
         *                                has more information about the failure.  The data is a dictionary that minimally includes
         *                                the url, and an exception if one was raised.
         *  @param {Object=} [options] - A dictionary of options that can include:
         *                               headers - A dictionary representing the additional headers to add.
         *                               queryParams - A string representing the query parameters
         *                               responseType - A string representing the response type for this request.
         *                               {boolean} [encodeUrn] - when true, encodes the document urn if found.
         *                               {boolean} [noBody] - when true, will perform a HEAD request
         */
        ViewingService.rawGet = function (viewingServiceBaseUrl, api, url, onSuccess, onFailure, options) {
            options = options || {};
            url = ViewingService.generateUrl(viewingServiceBaseUrl, api, url);
            if (!isRemotePath(viewingServiceBaseUrl, url)) {
                loadLocalFile(url, onSuccess, onFailure, options);
                return;
            }
            if (options.queryParams) {
                var concatSymbol = url.indexOf('?') === -1 ? '?' : '&';
                url = url + concatSymbol + options.queryParams;
            }
            var parsed = urllib.parse(url);
            var req = {
                host: parsed.hostname,
                port: parsed.port,
                method: options.method || "GET",
                path: parsed.path,
                headers: {},
                retryCount: 0
            };
            //Don't overload derivative service with requests
            if (req.host.endsWith(".api.autodesk.com") && (req.path.startsWith("/derivativeservice") || req.path.startsWith("/modelderivative"))) {
                req.agent = forgeAgent;
            }
            if (options.headers) {
                for (var p in options.headers) {
                    req.headers[p] = options.headers[p];
                }
            }
            if (!req.headers['accept-encoding']) {
                req.headers['accept-encoding'] = 'gzip, deflate';
            }
            if (options.range) {
                req.headers["Range"] = "bytes=" + options.range.min + "-" + options.range.max;
            }
            //Undo hack used to make streaming receive work on browser XHR -- the hack
            //involves processing the response as text, so responseType is set to "".
            if (options.ondata || options.onprogress) {
                options.responseType = "arraybuffer";
            }
            var request = (parsed.protocol === "https:" ? https : http).request(req, function (res) {
                var hasError = !(res.statusCode >= 200 && res.statusCode < 400);
                //Pipe through gunzip if needed
                var stream = res;
                if (!hasError && needsGunzip(res, parsed.pathname) && !options.skipDecompress) {
                    stream = res.pipe(zlib.createGunzip());
                }
                //Decode as UTF8 string if needed
                if (options.responseType === "json" || options.responseType === "text" || !options.responseType) stream.setEncoding('utf8');
                var chunks = [];
                var receiveBuffer;
                stream.on('data', function (chunk) {
                    //The onprogress callback is special in that it
                    //want us to accumulate the data as we receive it, and it only looks at it.
                    if (options.onprogress) {
                        if (!receiveBuffer) receiveBuffer = chunk;else receiveBuffer = Buffer.concat([receiveBuffer, chunk]);
                        options.onprogress(receiveBuffer);
                        return;
                    } else {
                        chunks.push(chunk);
                    }
                    if (options.ondata) {
                        options.ondata(chunk);
                    }
                });
                stream.on('end', function () {
                    if (res.statusCode >= 200 && res.statusCode < 400) {
                        if (options.responseType === "json") {
                            var jsobj = JSON.parse(chunks.join(''));
                            onSuccess(jsobj);
                            return;
                        }
                        if (options.responseType === "text" || options.responseType === "") {
                            var str = chunks.join('');
                            onSuccess(str);
                            return;
                        }
                        var buf = options.onprogress ? receiveBuffer : Buffer.concat(chunks);
                        if (!options.skipDecompress && buf[0] === 31 && buf[1] === 139) {
                            exports.logger.warn("An LMV resource (" + url + ") was double compressed, or Content-Encoding header missing");
                            try {
                                buf = zlib.gunzipSync(buf);
                            } catch (err) {
                                onFailure(exports.ErrorCodes.BAD_DATA, "Malformed data received when requesting file", { "url": url, "exception": err.toString(), "stack": err.stack });
                            }
                        }
                        onSuccess(buf);
                    } else {
                        if (onFailure) onFailure(res.statusCode, res.statusMessage, { url: url });
                    }
                });
            });
            request.on("error", function (error$$1) {
                if (onFailure) onFailure(error$$1.code, error$$1.message, { url: url });
            });
            if (options.postData) {
                request.write(options.postData);
            }
            request.end();
        };
    })();
} else {
    /**
     *  Performs a GET/HEAD request to Viewing Service.
     *
     * @param {string} viewingServiceBaseUrl - The base url for the viewing service.
     * @param {string} api - The api to call in the viewing service.
     *  @param {string} url - The url for the request.
     *  @param {function} onSuccess - A function that takes a single parameter that represents the response
     *                                returned if the request is successful.
     *  @param {function} onFailure - A function that takes an integer status code, and a string status, which together represent
     *                                the response returned if the request is unsuccessful, and a third data argument, which
     *                                has more information about the failure.  The data is a dictionary that minimally includes
     *                                the url, and an exception if one was raised.
     *  @param {Object=} [options] - A dictionary of options that can include:
     *                               headers - A dictionary representing the additional headers to add.
     *                               queryParams - A string representing the query parameters
     *                               responseType - A string representing the response type for this request.
     *                               {boolean} [encodeUrn] - when true, encodes the document urn if found.
     *                               {boolean} [noBody] - when true, will perform a HEAD request
     */
    ViewingService.rawGet = function (viewingServiceBaseUrl, api, url, onSuccess, onFailure, options) {
        options = options || {};
        url = ViewingService.generateUrl(viewingServiceBaseUrl, api, url);
        if (options.queryParams) {
            var concatSymbol = url.indexOf('?') === -1 ? '?' : '&';
            url = url + concatSymbol + options.queryParams;
        }
        var request = new XMLHttpRequest();
        function onError(e) {
            if (onFailure) onFailure(request.status, request.statusText, { url: url });
        }
        function fixJsonResponse(response) {
            if (options.responseType === "json") {
                try {
                    if (response instanceof Uint8Array) {
                        //This should only happen in the node.js case so we can do toString
                        //instead of using the LMV utf8 converter.
                        return blobToJson(response);
                    } else if (typeof response === "string") {
                        return JSON.parse(response);
                    }
                } catch (e) {}
            }
            return response;
        }
        function onLoad(e) {
            if (request.status === 200 || request.status === 206) {
                if (request.response && request.response instanceof ArrayBuffer) {
                    var rawbuf = new Uint8Array(request.response);
                    // It's possible that if the Content-Encoding header is set,
                    // the browser unzips the file by itself, so let's check if it did.
                    // Return raw buffer if skip decompress is true
                    if (!options.skipDecompress && rawbuf[0] === 31 && rawbuf[1] === 139) {
                        if (!warnedGzip) {
                            warnedGzip = true;
                            exports.logger.warn("An LMV resource (" + url + ") was not uncompressed by the browser. This hurts performance. Check the Content-Encoding header returned by the server and check whether you're getting double-compressed streams. The warning prints only once but it's likely the problem affects multiple resources.");
                        }
                        try {
                            rawbuf = new Zlib.Gunzip(rawbuf).decompress();
                        } catch (err) {
                            onFailure(exports.ErrorCodes.BAD_DATA, "Malformed data received when requesting file", { "url": url, "exception": err.toString(), "stack": err.stack });
                        }
                    }
                    onSuccess && onSuccess(fixJsonResponse(rawbuf));
                } else {
                    var res = request.response;
                    if (!res && (!options.responseType || options.responseType === "text")) res = request.responseText;
                    onSuccess && onSuccess(fixJsonResponse(res));
                }
            } else {
                onError(e);
            }
        }
        try {
            var isAsync = options.hasOwnProperty('asynchronous') ? options.asynchronous : true;
            request.open(options.method || (options.noBody ? 'HEAD' : 'GET'), url, isAsync);
            if (options.hasOwnProperty('responseType')) {
                request.responseType = options.responseType;
            }
            request.withCredentials = true;
            if (options.hasOwnProperty("withCredentials")) request.withCredentials = options.withCredentials;
            if (options.range) {
                request.setRequestHeader("Range", "bytes=" + options.range.min + "-" + options.range.max);
            }
            if (options.headers) {
                for (var header in options.headers) {
                    request.setRequestHeader(header, options.headers[header]);
                    // Disable withCredentials if header is Authorization type
                    // NOTE: using withCredentials attaches cookie data to request
                    if (header.toLocaleLowerCase() === "authorization") {
                        request.withCredentials = false;
                    }
                }
            }
            if (isAsync) {
                request.onload = onLoad;
                request.onerror = onError;
                request.ontimeout = onError;
                if (options.ondata || options.onprogress) {
                    //Set up incremental progress notification
                    //if needed. We have to do some magic in order
                    //to get the received data progressively.
                    //https://developer.mozilla.org/en-US/docs/Web/API/XMLHttpRequest/Using_XMLHttpRequest
                    request.overrideMimeType('text/plain; charset=x-user-defined');
                    options._dlProgress = {
                        streamOffset: 0
                    };
                    request.onreadystatechange = function () {
                        if (request.readyState > 2 && request.status === 200) {
                            if (options.ondata) {
                                var textBuffer = request.responseText;
                                // No new data coming in.
                                if (options._dlProgress.streamOffset >= textBuffer.length) return;
                                var arrayBuffer = textToArrayBuffer(textBuffer, options._dlProgress.streamOffset);
                                options._dlProgress.streamOffset = textBuffer.length;
                                options.ondata(arrayBuffer);
                            } else if (options.onprogress) {
                                options.onprogress(request.responseText);
                            }
                        }
                    };
                }
            }
            request.send(options.postData);
            if (options.skipAssetCallback) {} else {
                if (inWorkerThread) {
                    self.postMessage({ assetRequest: [url, options.headers, null /* ACM session id, null in this case. */] });
                } else if (exports.assets) {
                    exports.assets.push([url, options.headers, null /* ACM session id, null in this case. */]);
                }
            }
            if (!isAsync) {
                onLoad();
            }
        } catch (e) {
            onFailure(request.status, request.statusText, { url: url, exception: e });
        }
    };
} //rawGet conditionsl implementation
// Create the default failure callback.
//
ViewingService.defaultFailureCallback = function (httpStatus, httpStatusText, data) {
    if (httpStatus == 403) {
        this.raiseError(exports.ErrorCodes.NETWORK_ACCESS_DENIED, "Access denied to remote resource", { "url": data.url, "httpStatus": httpStatus, "httpStatusText": httpStatusText });
    } else if (httpStatus == 404) {
        this.raiseError(exports.ErrorCodes.NETWORK_FILE_NOT_FOUND, "Remote resource not found", { "url": data.url, "httpStatus": httpStatus, "httpStatusText": httpStatusText });
    } else if (httpStatus >= 500 && httpStatus < 600) {
        this.raiseError(exports.ErrorCodes.NETWORK_SERVER_ERROR, "Server error when accessing resource", { "url": data.url, "httpStatus": httpStatus, "httpStatusText": httpStatusText });
    } else if (data.exception) {
        this.raiseError(exports.ErrorCodes.NETWORK_FAILURE, "Network failure", { "url": data.url, "exception": data.exception.toString(), "stack": data.exception.stack });
    } else {
        this.raiseError(exports.ErrorCodes.NETWORK_UNHANDLED_RESPONSE_CODE, "Unhandled response code from server", { "url": data.url, "httpStatus": httpStatus, "httpStatusText": httpStatusText, data: data });
    }
};
function copyOptions(loadContext, options) {
    //Those are the usual defaults when called from the LMV worker
    if (!options.hasOwnProperty("asynchronous")) options.asynchronous = true;else if (!options.asynchronous) exports.logger.warn("LMV: Sync XHR used. Performance warning.");
    if (!options.hasOwnProperty("responseType")) options.responseType = "arraybuffer";
    //Add options junk we got from the main thread context
    if (!options.hasOwnProperty("withCredentials")) options.withCredentials = !!loadContext.auth;
    options.headers = loadContext.headers;
    options.queryParams = loadContext.queryParams;
    options.endpoint = loadContext.endpoint;
}
//Utility function called from the web worker to set up the options for a get request,
//then calling ViewingService.get internally
ViewingService.getItem = function (loadContext, url, onSuccess, onFailure, options) {
    options = options || {};
    copyOptions(loadContext, options);
    ViewingService.rawGet(loadContext.endpoint, 'items', url, onSuccess, onFailure, options);
};
//Utility function called from the web worker to set up the options for a get request,
//then calling ViewingService.get internally
ViewingService.getManifest = function (loadContext, url, onSuccess, onFailure, options) {
    options = options || {};
    if (!options.hasOwnProperty("responseType")) options.responseType = "json";
    copyOptions(loadContext, options);
    ViewingService.rawGet(loadContext.endpoint, 'bubbles', url, onSuccess, onFailure, options);
};
//Utility function called from the web worker to set up the options for a get request,
//then calling ViewingService.get internally
ViewingService.getThumbnail = function (loadContext, url, onSuccess, onFailure, options) {
    options = options || {};
    copyOptions(loadContext, options);
    var queryParams = options.queryParams || '';
    var missingElements = [];
    if (queryParams.indexOf('guid=') === -1) {
        missingElements.push("guid=" + encodeURIComponent(options.guid));
    }
    if (queryParams.indexOf('role=') === -1) {
        var role = options.role || "rendered";
        missingElements.push("role=" + role);
    }
    if (queryParams.indexOf('width=') === -1) {
        var sz = options.size || 400;
        missingElements.push("width=" + sz);
    }
    if (queryParams.indexOf('height=') === -1) {
        var sz = options.size || 400;
        missingElements.push("height=" + sz);
    }
    if (queryParams.indexOf('acmsession=') === -1 && options.acmsession) {
        missingElements.push("acmsession=" + options.acmsession);
    }
    var thumbQueryParams = missingElements.join('&');
    if (options.queryParams) {
        options.queryParams = options.queryParams + '&' + thumbQueryParams;
    } else {
        options.queryParams = thumbQueryParams;
    }
    ViewingService.rawGet(loadContext.endpoint, 'thumbnails', url, onSuccess, onFailure, options);
};
ViewingService.getACMSession = function (endpoint, acmProperties, onSuccess, onFailure) {
    var acmHeaders = {};
    var token;
    for (var key in acmProperties) {
        if (key === "oauth2AccessToken") token = acmProperties[key];else if (key.indexOf("x-ads-acm") !== -1) acmHeaders[key] = acmProperties[key];
    }
    // The value of this can be anything. Required for some arcane reasons.
    acmHeaders.application = "autodesk";
    var xhr = new XMLHttpRequest();
    xhr.open("POST", endpoint + '/oss-ext/v2/acmsessions', true);
    xhr.setRequestHeader("Content-Type", "application/json");
    xhr.setRequestHeader("Authorization", "Bearer " + token);
    xhr.responseType = "json";
    xhr.onload = function () {
        if (xhr.status === 200 && xhr.response) {
            // If the response is a string (e.g. from IE), need to parse it to an object first
            var response = typeof xhr.response === 'string' ? JSON.parse(xhr.response) : xhr.response;
            if (response && response.acmsession) {
                onSuccess(response.acmsession);
            } else {
                onFailure(xhr.status, "Can't get acm session from response.");
            }
        } else {
            onFailure(xhr.status);
        }
    };
    xhr.onerror = onFailure;
    xhr.ontimeout = onFailure;
    xhr.send(JSON.stringify(acmHeaders));
    // "application" header is only required for OSS end point, and should not be passed
    // with normal requests because this header is not in allowed header sets of APIGEE.
    delete acmHeaders.application;
};

/**
 * Base class for file loaders
 */

var FileLoader = function () {
    /**
     * Constructor
     * @param delegate  The delegate from the application
     * @param config    Configuration parameters
     */
    function FileLoader(delegate, config) {
        classCallCheck(this, FileLoader);

        this.delegate = FileLoader.copyDelegate(this, delegate);
    }
    /**
     * Destructor called when the loader is no longer needed.
     * Allows the loader to clean up workers or other assets.
     */


    createClass(FileLoader, [{
        key: "dtor",
        value: function dtor() {
            this.delegate = null;
        }
        /**
         * Check for whether dtor has been called
         */

    }, {
        key: "isValid",
        value: function isValid() {
            return this.delegate != null;
        }
    }, {
        key: "transferToDelegate",
        value: function transferToDelegate(delegate) {
            // If loader dtor has been called, return
            if (this.delegate == null) {
                console.warn("Cannot transfer destroyed loader to new delegate");
                return false;
            }
            this.delegate = FileLoader.copyDelegate(this, delegate);
            // Also transfer the property Db loader if we have one.
            if (this.model && this.model.getData() && this.model.getData().propDbLoader) {
                this.model.getData().propDbLoader.transferToDelegate(this.delegate);
            }
            return true;
        }
    }], [{
        key: "simpleInitLoadContext",

        /**
         * Simple load context that can be used for files or without credentials
         * or special headers.
         * @param context load context
         */
        value: function simpleInitLoadContext(context) {
            context = context || {};
            context.headers = context.headers || {};
            return context;
        }
    }, {
        key: "nullFunction",
        value: function nullFunction() {}
        /**
         * Create a new delegate and supply null functions for missing
         * optional properties.
         * @param input delegate from application
         */

    }, {
        key: "copyDelegate",
        value: function copyDelegate(loader, input) {
            var obj = {};
            if (input) {
                Object.assign(obj, input);
            }
            if (!obj.workerScript) {
                if (workerScript.mainThreadClass) {
                    obj.workerScript = new workerScript.mainThreadClass();
                }
            }
            if (!obj.matman) {
                obj.matman = new MaterialManager();
            }
            if (!obj.model) {
                obj.model = RenderModel;
            }
            if (!obj.getGeomCache) {
                obj.getGeomCache = FileLoader.nullFunction;
            }
            if (!obj.eventTarget) {
                THREE$1.EventDispatcher.prototype.apply(loader);
                obj.eventTarget = loader;
            }
            if (!obj.initLoadContext) {
                obj.initLoadContext = FileLoader.simpleInitLoadContext;
            }
            if (!obj.requestRedraw) {
                obj.requestRedraw = FileLoader.nullFunction;
            }
            if (!obj.reportError) {
                obj.reportError = FileLoader.nullFunction;
            }
            if (!obj.signalProgress) {
                obj.signalProgress = FileLoader.nullFunction;
            }
            if (!obj.toggleTwoSided) {
                obj.toggleTwoSided = FileLoader.nullFunction;
            }
            return obj;
        }
    }]);
    return FileLoader;
}();

"use strict";
var LOAD_ORDER_TIMEOUT = 100; // 100 msec delay to ask for sorted load order
var PAST_LAST_PACK = 1.0e10; // Large number past last pack id
// occlusion testing state.
var NO_OCCLUSION_TESTING = 0;
var QUEUE_OCCLUSION_TESTING = 1;
var PERFORM_OCCLUSION_TESTING = 2;
var MEGA$1 = 1024 * 1024;
// This three constants are used to asjust the memory limit if
// the overhead is too large to allow any geometry to be loaded.
// We start with MIN_OVERHEAD_FACTOR * total geometry + overhead size
// and clip it to the range [MIN_OVERHEAD_LIMIT, MAX_OVERHEAD_LIMIT]
var MIN_OVERHEAD_FACTOR = 0.1; // Factor of total size
var MIN_OVERHEAD_LIMIT = 10;
var MAX_OVERHEAD_LIMIT = 50;
// Paging proxy object to manage on demand loading and paging logic, 
// that is specific to the model loaded by svf loader.
var SvfPagingProxy = function SvfPagingProxy(loader, options) {
    var _extendObject = function _extendObject(target, source) {
        for (var prop in source) {
            if (source.hasOwnProperty(prop)) {
                target[prop] = source[prop];
            }
        }
    };
    var _loader = loader;
    // Options of control memory management.
    this.options = {
        onDemandLoading: false,
        pageOutGeometryEnabled: false
    };
    _extendObject(this.options, options);
    this.options.debug = {
        // Increase the max page out size. On slow (mobile) devices the scene
        // traversal is a bottle neck and making this larger helps load more
        // pack files earlier in the load.
        maxPageOutSize: 195,
        pixelCullingEnable: this.options.onDemandLoading,
        pixelCullingThreshold: PIXEL_CULLING_THRESHOLD,
        occlusionThreshold: 1,
        occlusionTestThreshold: 1,
        startOcclusionTestingPackCount: 8,
        testPackfileCount: 4,
        useOcclusionInstancing: true,
        automaticRefresh: true,
        boxProxyMaxCount: 0,
        boxProxyMinScreen: 0.4 // if entire render batch is >= 1/10 of the screen in area
    };
    _extendObject(this.options.debug, options.debug);
    // If reach limit, then stop loading any further pack files.
    this.reachLimit = false;
    // the geom ids map, is a dictionary that key is the geometry id,
    // and value is an index to an array that record the traversed count
    // for that geometry.
    // ??? The reason that doesn't use the object to record the count but
    // ??? use the indirect arry is due to PERFORMANCE. 
    // ??? Because, if the JS object properties' value are changed frequently,
    // ??? the performance will hurt a whole lot.
    this.geomidsmap = {};
    this.geomTravCount = [];
    // Variables for recording loaded or loading or queued pack files.
    this.loadedPacks = {}; // Staticly bound to functions, replace this object
    this.loadedPackfileCount = 0;
    this.memoryOverhead = 0;
    this.loadingPacks = {};
    this.loadingPacksSize = 0;
    this.queuedPacks = [];
    this.packQueuedMap = {};
    this.queuedPacksSize = 0;
    this.occludedPacks = [];
    this.occlusionCulledCount = 0;
    this.packsPagedOut = 0;
    this.traversedCounter = 0;
    this.transparentCounter = 0;
    this.resetCount = 0;
    this.invalidateCount = -1;
    // read from options, and passed by the loader.
    this.geompacks = _loader.svf.geompacks;
    this.geommap = _loader.geommap;
    this.totalGeomSize = this.options.totalGeomSize;
    this.overheadSize = this.options.overheadSize;
    // Adjust the limit if the overhead is too large.
    this.minMemoryLimit = Math.min(Math.max(this.totalGeomSize * MIN_OVERHEAD_FACTOR, MIN_OVERHEAD_LIMIT), MAX_OVERHEAD_LIMIT) + this.overheadSize;
    this.lastPageOut = -1;
    this.pageOutResetCounter = -1;
    var _resumeNextFrame = false;
    // Variables used to handle the load order from the worker
    var _nextOrderToLoad = 0; // Next list of fragments to load
    var _nextFragToLoad = 0; // Next fragment in load order
    var _loadOrderId = 0; // Last load order request
    var _fragOrder = []; // Fragment order - allow multiple ordered lists
    var _packOrder; // Pack file order
    var _pfVisible = -1; // Number of visible pack files.
    var _packOrderMap = []; // Order of pack files in pack order
    var _firstReset = true; // Track first time we ask for the load order
    var _lastResult = null; // Last load order result
    var _loadOrderTimer = 0; // Timer used to keep down traffic to load order worker
    var _pageOutStillPossible = true; // More possible to page out
    var _loadDoneSent = false; // Load done has been sent
    var loadMissingGeometryHandler = function (e) {
        // e.unloadPackFiles is for debugging only
        this.resetCanPageOut(!!e.debug.unloadPackFiles, e.delay != false, false);
    }.bind(this);
    _loader.delegate.eventTarget && _loader.delegate.eventTarget.addEventListener(LOAD_MISSING_GEOMETRY, loadMissingGeometryHandler);
    this.dtor = function () {
        _loader.delegate.eventTarget && _loader.delegate.eventTarget.removeEventListener(LOAD_MISSING_GEOMETRY, loadMissingGeometryHandler);
    };
    // Return true of false, whether on demand loading enabled.
    // This mainly controls how the geometries referenced by the fagments
    // are going to load. 
    //
    // If false, then geometry pack files will load in sequence all at once.
    // if true, then only those geometry pack files that are request to render,
    //          can they start to load *on demand*
    this.onDemandLoadingEnabled = function () {
        return this.options.onDemandLoading;
    };
    this.pageOutGeometryEnabled = function () {
        return this.options.pageOutGeometryEnabled && this.onDemandLoadingEnabled();
    };
    this.pixelCullingEnable = function () {
        return this.options.debug.pixelCullingEnable;
    };
    this.pixelCullingThreshold = function () {
        return this.options.debug.pixelCullingThreshold;
    };
    this.getMemoryLimit = function () {
        return Math.max(this.minMemoryLimit, this.options.limit);
    };
    /**
     * Get the memory stats when using on demand loading.
     * @returns {object|null} Object containing the limit and loaded memory usage for the model.
     *                        Return null if the model isn't being loaded on demand.
     */
    this.getMemoryInfo = function () {
        return this.onDemandLoadingEnabled() ? {
            limit: this.options.limit,
            effectiveLimit: this.getMemoryLimit(),
            loaded: this.preparedPackFilesSize()
        } : null;
    };
    this.getLoadedMeshes = function (packId) {
        var pack = this.loadedPacks[packId];
        return pack && pack.inMemory;
    };
    this.loadPackFile = function () {
        return true;
    };
    this.doLoadPackFile = function (packId) {
        // If on demand loading is disabled, disallow load pack file arbitrarily.
        if (!this.onDemandLoadingEnabled()) return false;
        if (this.loadingPacks[packId]) return true;
        // Skip occluded packs
        if (this.occludedPacks[packId] === true) return false;
        if (this.queuedPacks.length > 0 || this.occlusionTesting >= QUEUE_OCCLUSION_TESTING) {
            if (!this.addGeomPackMissingLastFrame(packId)) return false;
            this.loadGeometryMissingLastFrame();
            return true;
        }
        return _loader.loadGeometryPackOnDemand(packId, this.getLoadedMeshes(packId));
    };
    // Take the geometry we will keep in a pack file and create a new set
    // of buffers for them.
    function removeAndCompactGeometry(packId, frags, unloadAll, traversed, transparent, pack) {
        var bufferSize = 0;
        var unloadedSize = 0,
            size;
        var retainedGeoms = [];
        var inMemory = pack.inMemory;
        var needCompaction = false;
        var count = 0;
        var geomsList = frags.geoms;
        // If all of the current geometry has been traversed, then there
        // is nothing for us to do.
        if (!unloadAll && pack.travsed >= pack.currentCount) return 0;
        function processMesh(meshIdx) {
            // If mesh isn't in memory, return
            if (!(inMemory[meshIdx >> 5] & 1 << (meshIdx & 31))) return;
            var fragId = frags.fragments.mesh2frag[packId + ":" + meshIdx];
            if (Array.isArray(fragId)) fragId = fragId[0];
            var geom = geomsList.geoms[frags.getGeometryId(fragId)];
            if (geom && geom.packId == packId) {
                // We handle meshes that occupy an entire buffer differently from
                // meshes that are sharing a buffer. If we unload a mesh that is
                // part of a shared buffer, we need to compact the buffer. Similarly
                // we only need to include meshes that are part of a shared buffer
                // in the meshes we want to compact.
                var partialBuffer = geom.vb.buffer === geom.ib.buffer ? geom.vb.buffer.byteLength > geom.vb.byteLength + geom.ib.byteLength : geom.vb.buffer.byteLength > geom.vb.byteLength || geom.ib.buffer.byteLength > geom.ib.byteLength;
                // remove geometry we don't want to keep and keep track of the size
                if ((unloadAll || geom.traversed != traversed && geom.transparent != transparent) && (size = geomsList.removeGeometry(geom.svfid, _loader.delegate.webGLRenderer)) > 0) {
                    unloadedSize += size;
                    inMemory[geom.meshIndex >> 5] &= ~(1 << (geom.meshIndex & 31));
                    needCompaction = needCompaction || partialBuffer;
                } else {
                    ++count;
                    // Either don't want to remove the geometry, or we can't remove it
                    // We only compact geometry that is stored in a shared array buffer
                    if (partialBuffer) {
                        bufferSize += geom.vb.byteLength;
                        bufferSize += geom.ib.byteLength + 3 & ~3;
                        retainedGeoms.push(geom);
                    }
                }
            } else console.error("Mismapped or missing geometry %d:%d", packId, meshIdx);
        }
        // Remove geometry that we can. Make a list of the geometry that
        // we want to keep.
        var i;
        for (i = 0; i < pack.totalCount; ++i) {
            processMesh(i);
        }pack.currentCount = count;
        pack.culled = 0;
        // Nothing more to do, if nothing was unloaded or everything was unloaded
        if (unloadedSize == 0) return 0;
        unloadedSize /= MEGA$1;
        // If we don't need to compact, then don't
        if (retainedGeoms.length == 0 || !needCompaction) return unloadedSize;
        var newBuffer = new ArrayBuffer(bufferSize);
        var offset = 0;
        // Copy a single buffer to the destination
        function copy(type, src, size) {
            var b = null;
            if (src) {
                var round = size - 1;
                offset = offset + round & ~round; // size must be a power of 2
                var length = src.length;
                b = new type(newBuffer, offset, length);
                b.set(src);
                offset += length * size;
            }
            return b;
        }
        // Copy data to new buffer
        retainedGeoms.forEach(function (geom) {
            geom.vb = copy(Float32Array, geom.vb, 4);
            geom.ib = copy(Uint16Array, geom.ib, 2);
        });
        return unloadedSize;
    }
    this.unloadPackFile = function (packId, unloadAll, pageOut) {
        // If on demand loading is disabled, can't unload on runtime.
        if (!this.onDemandLoadingEnabled()) {
            return false;
        }
        var frags = _loader.model.getFragmentList();
        var pack = this.loadedPacks[packId];
        if (!frags || !pack || !frags.geoms) {
            return false;
        }
        // Remove all geometries comming from this pack file
        removeAndCompactGeometry(packId, frags, unloadAll, this.traversedCounter, this.transparentCounter, pack);
        if (pack.currentCount == 0) {
            // Then, remove the record and decrease the count.
            delete this.loadedPacks[packId];
            --this.loadedPackfileCount;
            if (pageOut) ++this.packsPagedOut;
        }
        return true;
    };
    var redrawIfIdle = function () {
        // Schedule a redraw if we think we are idle. We detect idle
        // by tracking when the iterator is reset and when the traversal
        // is done.
        if (this.resetCount != this.pageOutResetCounter) return false; // Draw is active
        _loader.delegate.requestRedraw(false);
    }.bind(this);
    this.onPackFileLoaded = function (packId, data, geomSize) {
        // Record the pack file loaded.
        var pf = this.geommap[packId];
        _loadDoneSent = false; // Once we load a pack file, we need to send load done again
        // This packId is no longer being loaded, reduce the loading packs size        
        if (this.loadingPacks.hasOwnProperty(packId)) {
            delete this.loadingPacks[packId];
            this.loadingPacksSize -= pf.geomSize + pf.usize;
        }
        // If data is null, then there was an error
        if (data) {
            var pack = this.loadedPacks[packId];
            if (!pack) {
                var count = data.meshes.length;
                pack = this.loadedPacks[packId] = {
                    totalCount: count,
                    travsed: 0,
                    culled: 0,
                    resetCounter: this.resetCount,
                    geomSize: 0,
                    inMemory: new Array((count + 31) / 32 | 0)
                };
                ++this.loadedPackfileCount;
                if (this.options.debug.occlusionTestThreshold > 0 && this.occlusionTesting == NO_OCCLUSION_TESTING && this.loadedPackfileCount >= this.options.debug.startOcclusionTestingPackCount) {
                    this.occlusionTesting = QUEUE_OCCLUSION_TESTING;
                }
            }
            // Once we load a pack file, everything is in memory again
            pack.geomSize += geomSize;
            pack.currentCount = pack.totalCount;
            pack.inMemory.fill(~0);
            // The geometry loaded now replaces all the geometry loaded before
            this.totalGeomSize += pack.geomSize - pf.geomSize;
            // Adjust queuedPacksSize if this packId has been queued again.
            if (this.packQueuedMap[packId]) this.queuedPacksSize += pack.geomSize - pf.geomSize;
            pf.geomSize = pack.geomSize;
            // Need to make sure we render something, to continue the loading process
            redrawIfIdle();
        }
        if (this.loadedGeometrySize() > this.getMemoryLimit()) {
            exports.logger.warn("More pack files being loaded than the max count: " + this.loadedGeometrySize());
        }
    };
    this.checkLoadFinished = function () {
        if (_loadDoneSent) return;
        // Are all workers done?
        var pack_workers = _loader.pack_workers;
        if (pack_workers) {
            for (var j = 0; j < pack_workers.length; j++) {
                if (pack_workers[j].queued != 0) return;
            }
        }
        // All workers are done. Is there anything more to do.
        if (this.geomPacksMissingLastFrame().length != 0 || _nextOrderToLoad < _fragOrder.length) {
            // More items on the list, so there might be more to do
            if (this.loadedGeometrySize() < this.getMemoryLimit() || _pageOutStillPossible) {
                // There may be more memory, so we aren't done yet
                return;
            }
        }
        // Done
        _loadDoneSent = true;
        _loader.onDemandGeomLoadDone();
    };
    this.doOnDemandLoadFinished = function () {
        // Any more to do?
        this.loadGeometryMissingLastFrame();
        this.checkLoadFinished();
    };
    this.onPackFileLoading = function (packId) {
        if (this.loadingPacks.hasOwnProperty(packId)) return;
        this.loadingPacks[packId] = true;
        var pf = this.geommap[packId];
        this.loadingPacksSize += pf.geomSize + pf.usize;
    };
    this.onProcessReceivedMesh = function (geometry, numInstances) {
        var geomId = geometry.svfid;
        if (this.onDemandLoadingEnabled() && numInstances > 1 && this.geomidsmap[geomId] == null) {
            this.geomidsmap[geomId] = this.geomTravCount.length;
            this.geomTravCount.push(0);
        }
    };
    this.loadedGeometrySize = function () {
        return _loader.model.getGeometryList().geomMemory / MEGA$1 + this.overheadSize;
    };
    this.preparedPackFilesSize = function () {
        return this.loadingPacksSize + this.loadedGeometrySize();
    };
    this.cancelPending = function () {
        if (this.loadingPacksSize > 1.0 / MEGA$1) {
            // Cancel any on going geometry loading, as it is probably no longer
            // immediately used by the following rendering as scene or camera 
            // changed.
            _loader.cancelGeometryPackLoading();
            this.loadingPacks = {};
            this.loadingPacksSize = 0;
        }
        this.queuedPacks.length = 0;
        this.queuedPacksSize = 0;
        this.packQueuedMap = {};
        this.occlusionTesting = this.onDemandLoadingEnabled() && this.options.debug.occlusionTestThreshold > 0 && this.loadedPackfileCount >= this.options.debug.startOcclusionTestingPackCount ? QUEUE_OCCLUSION_TESTING : NO_OCCLUSION_TESTING;
        this.occludedPacks.length = 0;
    };
    this.resetIterator = function (camera /*, resetType*/) {
        this.lastCamera = camera;
        ++this.resetCount;
    };
    this.reset = function () {
        // Reset the record of geometry travsed or culled count.
        var loadedPacks = this.loadedPacks;
        for (var p in loadedPacks) {
            loadedPacks[p].travsed = 0;
            loadedPacks[p].culled = 0;
        }
        this.geomTravCount.fill(0);
        // I don't like this but I don't see any way around it. The goal is to keep all
        // visible geometry in memory. So when we reset the geometry in memory we need
        // to clear the display, which calls this method again. invalidateCount is used
        // to keep us from starting over in that case.
        if (this.resetCount > this.invalidateCount) {
            this.cancelPending();
            this.resetCanPageOut(false, true, true);
        }
    };
    this.geomPacksMissingLastFrame = function () {
        return this.queuedPacks;
    };
    this.addGeomPackMissingLastFrame = function (packId) {
        if (!this.onDemandLoadingEnabled()) return true;
        if (this.pageOutGeometryEnabled()) {
            // Not too many loaded + loading + queued.
            if (this.loadedGeometrySize() >= this.getMemoryLimit()) {
                this.reachLimit = true;
            }
        }
        // Otherwise, schedule a futher loading
        if (!this.packQueuedMap[packId]) {
            var pf = this.geommap[packId];
            if (pf) {
                this.queuedPacks.push(packId);
                this.queuedPacksSize += pf.geomSize;
                this.packQueuedMap[packId] = true;
            }
        }
        return true;
    };
    this.loadGeometryMissingLastFrame = function () {
        // This load is done, then can start as many as possible.
        var missingPacks = this.queuedPacks;
        var i;
        for (i = 0; i < missingPacks.length; ++i) {
            var packId = missingPacks[i];
            if (this.occlusionTesting >= QUEUE_OCCLUSION_TESTING && this.occludedPacks[packId] === undefined) break;
            if (!this.geommap[packId].loading && !this.occludedPacks[packId]) {
                // Find one that hasn't been loaded.
                if (!_loader.loadGeometryPackOnDemand(packId, this.getLoadedMeshes(packId))) break; // can't load any more - stop
            }
        }
        // If we weren't able to load anything, redraw to start things up again.
        if (i == 0 && !_loadDoneSent) redrawIfIdle();
        // Remove pack files that are loading and the one we will load
        var _this = this;
        missingPacks.splice(0, i).forEach(function (packId) {
            _this.queuedPacksSize -= _this.geommap[packId].geomSize;
            delete _this.packQueuedMap[packId];
        });
    };
    this.needResumeNextFrame = function () {
        return _resumeNextFrame;
    };
    var _packSort = function (a, b) {
        var wa = a >= _packOrderMap.length ? PAST_LAST_PACK : _packOrderMap[a];
        var wb = b >= _packOrderMap.length ? PAST_LAST_PACK : _packOrderMap[b];
        return wb - wa;
    }.bind(this.loadedPacks);
    this.markVisibleGeoms = function (pagingOptions) {
        var map = _loader.model.getData().instanceTree || _loader.model.getData().fragmentMap;
        var ids;
        // Return if we can't get the data to mark visible geometry
        if (!map || !pagingOptions.visibleIdCB || !(ids = pagingOptions.visibleIdCB())) return;
        var visible = ++this.traversedCounter;
        var found = {};
        var end = ids.length;
        var id, key;
        var loadedPacks = this.loadedPacks;
        // Clear traversed count
        for (key in loadedPacks) {
            loadedPacks[key].travsed = 0;
        }
        // Count pixels covered by each id
        for (var i = 0; i < end; i += 4) {
            id = ids[i] | ids[i + 1] << 8 | ids[i + 2] << 16;
            id = id << 8 >> 8; // recover sign
            if (id > 0) found[id] = (found[id] | 0) + 1;
        }
        var frags = _loader.model.getFragmentList();
        var threshold = this.options.debug.occlusionThreshold | 0;
        for (key in found) {
            id = Number(key);
            if (found[id] >= threshold) {
                map.enumNodeFragments(id, function (fragId) {
                    var geom = frags.getGeometry(fragId);
                    if (geom) {
                        var pack = loadedPacks[geom.packId];
                        if (pack && geom.traversed != visible) ++pack.travsed;
                        geom.traversed = visible;
                    }
                });
            }
        }
    };
    this.pageOut = function (iterationDone, forcePageOut, pagingOptions) {
        _resumeNextFrame = false;
        var pageStatus = PAGEOUT_SUCCESS;
        if (iterationDone && this.options.debug.occlusionTestThreshold > 0 && this.loadedPackfileCount >= this.options.debug.startOcclusionTestingPackCount) {
            this.occlusionTesting = PERFORM_OCCLUSION_TESTING;
        }
        this.occlusionTest(pagingOptions);
        // Only try to page out at the end of iteration of scene travseral,
        // which is to guarantee the geometries loaded from pack files get 
        // all used (either traversed or culled.)
        if (!iterationDone) {
            return pageStatus;
        }
        // This page out will page geometries on a pack file basis
        this.pageOutResetCounter = this.resetCount;
        var size = this.loadedGeometrySize();
        _pageOutStillPossible = true;
        if (size && (this.reachLimit || size > this.getMemoryLimit())) {
            this.markVisibleGeoms(pagingOptions);
            var loadedPacks = this.loadedPacks;
            var loadedPackIds = Object.keys(loadedPacks);
            var packsSkipped = false;
            // Sorting functions for different paging strategies
            // Sort so pack files that can be paged come first
            // and are sorted in reverse culled count order.
            // Pack files that can't be paged are not sorted further
            loadedPackIds.sort(_packSort);
            // If we aren't paging normally, then the best performance is to
            // page out as much as possible.
            var unloaded = size - Math.min(size, this.options.debug.maxPageOutSize);
            // Then, unload pack files 
            loadedPackIds.every(function (id) {
                if (loadedPacks[id].resetCounter < this.resetCount) {
                    this.unloadPackFile(id, false, true);
                } else packsSkipped = true;
                return this.loadedGeometrySize() > unloaded;
            }.bind(this));
            if (forcePageOut && this.loadedGeometrySize() == size && loadedPacks[loadedPackIds[0]].resetCounter < this.resetCount) {
                this.unloadPackFile(loadedPackIds[0], false, true);
                exports.logger.log("A force page out occur.");
            }
            if (this.loadedGeometrySize() == size) {
                pageStatus = PAGEOUT_SUCCESS;
                this.reachLimit = true;
            } else {
                this.reachLimit = false;
                this.loadGeometryMissingLastFrame();
                _resumeNextFrame = true;
            }
            this.lastPageOut = size - this.loadedGeometrySize();
            exports.logger.log("[On Demand Loading] Unload pack files size: " + this.lastPageOut);
            if (window && window.gc) {
                window.gc();
            }
            // If we weren't able to pageout anything, see if we are done
            if (this.lastPageOut == 0) {
                // If we didn't skip any pack files and nothing was paged out
                // then we won't be able to page out more later.
                _pageOutStillPossible = packsSkipped;
                this.checkLoadFinished();
            }
            return pageStatus;
        }
        // resume on missing geom for next frame.
        _resumeNextFrame = _resumeNextFrame || this.queuedPacks.length > 0;
        this.loadFragsFromLoadOrder();
        return pageStatus;
    };
    this.occlusionTest = function (pagingProxy) {
        var occlusionTestCB = null;
        var fragmentList = null;
        var moving = false;
        var promise = null;
        var packIds = null;
        var occlusionTestTimer = 0;
        var waitingCount = 0;
        var delayPerWaiting = 3;
        function findFragsForPackfile(packIds) {
            var packids = fragmentList.fragments.packIds;
            if (!packids) return null;
            var packList = [];
            packIds.forEach(function (packId) {
                var fragIds = [];
                var i = packids.lastIndexOf(packId);
                while (i >= 0) {
                    if (packids[i] == packId) fragIds.push(i--);else i = packids.lastIndexOf(packId, i - 1);
                }
                packList.push(fragIds);
            });
            return packList;
        }
        function nextPackIds(count) {
            var packIds = null;
            waitingCount = 0;
            var queue = pagingProxy.queuedPacks;
            var occluded = pagingProxy.occludedPacks;
            count = Math.min(4, count || 4);
            var length = queue.length;
            for (var i = 0; i < length && count > 0; ++i) {
                var id = queue[i];
                if (occluded[id] === undefined) {
                    packIds = packIds || [];
                    packIds.push(id);
                    --count;
                } else if (!occluded[id]) ++waitingCount;
            }
            return packIds;
        }
        function handleOcclusion(visible) {
            promise = null;
            for (var i = 0; i < packIds.length; ++i) {
                pagingProxy.occludedPacks[packIds[i]] = !visible[i];
                if (!visible[i]) {
                    exports.logger.debug("[On Demand Loading] Occluded Geometry Pack file: " + packIds[i]);
                    ++pagingProxy.occlusionCulledCount;
                }
            }
            pagingProxy.doOnDemandLoadFinished(); // Remove packId from queue
            doOcclusionTest();
        }
        function doOcclusionTest() {
            if (occlusionTestTimer || promise || _loadDoneSent) return;
            // Clear previous promise
            promise = null;
            // Can we do occlusion testing now?
            if (occlusionTestCB && !moving && (packIds = nextPackIds(pagingProxy.options.debug.testPackfileCount))) {
                occlusionTestTimer = setTimeout(function () {
                    occlusionTestTimer = 0;
                    // Yes get the fragment ids for the pack files
                    var fragIds = findFragsForPackfile(packIds);
                    promise = occlusionTestCB(fragmentList.boxes, pagingProxy.options.debug.occlusionTestThreshold, fragIds, pagingProxy.options.debug.useOcclusionInstancing, packIds);
                    promise.then(handleOcclusion, function () {
                        // Assume visible if there is an error
                        handleOcclusion([true, true, true, true]);
                    });
                }, waitingCount * delayPerWaiting);
            }
        }
        function occlusionTest(pagingOptions) {
            // If we already have a test scheduled, or occlusion testing hasn't started yet.
            if (promise || this.occlusionTesting < PERFORM_OCCLUSION_TESTING) return;
            // collect data
            if (pagingOptions) {
                occlusionTestCB = pagingOptions.occlusionTestCB;
                moving = pagingOptions.moved;
            }
            fragmentList = _loader.model.getFragmentList();
            // Kick off the test
            if (fragmentList && occlusionTestCB && !moving) doOcclusionTest();
        }
        return occlusionTest;
    }(this);
    this.loadFragsFromLoadOrder = function () {
        var frags = _loader.model.getFragmentList();
        while (_nextOrderToLoad < _fragOrder.length) {
            var fragOrder = _fragOrder[_nextOrderToLoad];
            var len = fragOrder.length;
            while (_nextFragToLoad < len) {
                var fragId = fragOrder[_nextFragToLoad];
                if (!frags.getGeometry(fragId)) {
                    var packId = frags.fragments.packIds ? frags.fragments.packIds[fragId] : fragId;
                    var queuedLen = this.queuedPacks.length;
                    if (!this.doLoadPackFile(packId) && queuedLen == this.queuedPacks.length) return;
                }
                ++_nextFragToLoad;
            }
            ++_nextOrderToLoad;
            _nextFragToLoad = 0;
        }
    };
    this.pfOrder = function () {
        return _packOrder;
    };
    this.getNumVisiblePFs = function () {
        return _packOrder ? _pfVisible : -1;
    };
    this.onLoadOrderCalculated = function (loadOrder) {
        if (loadOrder.error) {
            _lastResult = null;
            return;
        }
        if (loadOrder.fragOrder && loadOrder.packOrder) _lastResult = loadOrder;
        if (loadOrder.id != _loadOrderId || !_lastResult) {
            return; // Superseded or error or frustum didn't change
        }
        this.lastPageOut = -1;
        _pageOutStillPossible = true;
        _loadDoneSent = false;
        _fragOrder.length = 0;
        if (_loader.model) {
            var fastFragsList = _loader.model.getFastLoadList();
            if (fastFragsList) {
                exports.logger.log("Using PF fast-load-list for homeView, size:", fastFragsList.length);
                _fragOrder.push(fastFragsList);
            }
        }
        _fragOrder.push(_lastResult.fragOrder);
        // create a map that maps a packId to its position in the load order
        // this is used during pageout to prioritize the packs paged out.
        _packOrder = _lastResult.packOrder;
        _pfVisible = _lastResult.pfVisible;
        var i,
            len = _packOrder.length;
        _packOrderMap.length = this.geompacks.length;
        // Put all packs at the end of the list
        _packOrderMap.fill(PAST_LAST_PACK);
        // Set the load order for pack Ids in the load order list
        for (i = 0; i < len; ++i) {
            _packOrderMap[_packOrder[i]] = i;
        } // Figure out which pack files need to be unloaded
        // We loop through the fragments and add up the pack file sizes
        // until we reach the memory limit. Those pack files are the
        // ones we keep. If the fragment geometry is in memory, we
        // use the size of geometry currently loaded in memory, if it
        // isn't we use the total size of the pack file.
        var frags = _loader.model.getFragmentList();
        var size = this.overheadSize;
        var limit = this.getMemoryLimit();
        var j;
        for (j = 0; j < _fragOrder.length && size < limit; ++j) {
            var fragOrder = _fragOrder[j];
            len = fragOrder.length;
            var keepPacks = [];
            keepPacks.length = _packOrderMap.length;
            keepPacks.fill(0);
            var geompacks = this.geompacks;
            for (i = 0; i < len && size < limit; ++i) {
                var fragId = fragOrder[i];
                var packId = frags.fragments.packIds ? frags.fragments.packIds[fragId] : fragId;
                var pack = geompacks[packId];
                if (pack) {
                    var geomSize = frags.getGeometry(fragId) ? pack.geomSize : pack.totalGeomSize;
                    if (geomSize > keepPacks[packId]) {
                        size += geomSize - keepPacks[packId];
                        keepPacks[packId] = geomSize;
                    }
                }
            }
        }
        // Clear can page out for all loaded pack files
        var loadedPacks = this.loadedPacks;
        for (var a in loadedPacks) {
            if (loadedPacks.hasOwnProperty(a)) {
                if (!keepPacks[a]) this.unloadPackFile(a, true);
            }
        }
        ++this.traversedCounter;
        ++this.transparentCounter;
        this.reachLimit = this.loadedGeometrySize() >= this.getMemoryLimit();
        this.cancelPending();
        _nextOrderToLoad = 0;
        _nextFragToLoad = 0;
        this.loadFragsFromLoadOrder();
        _loader.delegate.requestRedraw(true);
        this.invalidateCount = this.resetCount + 1;
    };
    this.resetCanPageOut = function (unloadPackFiles, delay, automatic) {
        if (_loadOrderTimer) {
            clearTimeout(_loadOrderTimer);
            _loadOrderTimer = 0;
        }
        var proxy = this;
        function doReset() {
            _loadOrderTimer = 0;
            // The first time we get here, from this.reset() then calculate the load order
            // This is so the scene will display, without manually calculating the load order.
            if (_firstReset || !automatic || proxy.options.debug.automaticRefresh) {
                proxy.occlusionCulledCount = 0;
                proxy.packsPagedOut = 0;
                var camera = proxy.lastCamera;
                var loadedPacks = proxy.loadedPacks;
                var a;
                // Unload all the pack files if needed;
                if (unloadPackFiles) {
                    for (a in loadedPacks) {
                        if (loadedPacks.hasOwnProperty(a)) {
                            proxy.unloadPackFile(a, true);
                        }
                    }
                }
                _loader.calculateLoadOrder(++_loadOrderId, camera, proxy.options.debug.pixelCullingEnable ? proxy.options.debug.pixelCullingThreshold : -1);
                _firstReset = false;
            }
        }
        if (delay) _loadOrderTimer = setTimeout(doReset, LOAD_ORDER_TIMEOUT);else doReset();
    };
    this.onGeomTraversed = function (geometry, transparent) {
        var packId = geometry.packId;
        var geomId = geometry.svfid;
        geometry.traversed = this.traversedCounter;
        if (transparent) geometry.transparent = this.transparentCounter;
        // Only record it for paging if the pack file is allowed to be paged out.
        //if (packId >= this.options.minPackFiles) {
        var geomTraversed = true;
        var mapIdx = this.geomidsmap[geomId];
        if (mapIdx != null) {
            // increase counter of traversed geometry instances
            this.geomTravCount[mapIdx] += 2;
            this.geomTravCount[mapIdx] |= 1;
            geomTraversed = geometry.instanceCount == this.geomTravCount[mapIdx] >> 1;
        }
        var loaded = this.loadedPacks[packId];
        if (loaded) {
            if (geomTraversed) {
                loaded.travsed++;
            }
        }
        //}
    };
    this.onGeomCulled = function (geometry) {
        if (!geometry) {
            return;
        }
        var packId = geometry.packId;
        var geomId = geometry.svfid;
        // Only record it for paging if the pack file is allowed to be paged out.
        //if (packId >= this.options.minPackFiles) {
        var mapIdx = this.geomidsmap[geomId];
        var geomCulled = !mapIdx;
        if (mapIdx != null) {
            // The low order bit of geomeTravCount indicates whether the
            // geometry has ever been traversed. If it has, then treat this
            // cull as a traverse.
            if (this.geomTravCount[mapIdx] & 1) this.onGeomTraversed(geometry);else {
                // ??? multiple geometry instance, may have some traversed
                // ??? and some culled. The culled one is also marked as traversed count,
                // ??? so this geometry may be counted as either culled or traversed,
                // ??? that is ok so far.
                this.geomTravCount[mapIdx] += 2;
                geomCulled = geometry.instanceCount == this.geomTravCount[mapIdx] >> 1;
            }
        }
        var loaded = this.loadedPacks[packId];
        if (loaded && geomCulled) loaded.culled++;
        //}
    };
};

"use strict";
var WORKER_GET_PROPERTIES = "GET_PROPERTIES";
var WORKER_SEARCH_PROPERTIES = "SEARCH_PROPERTIES";
var WORKER_FIND_PROPERTY = "FIND_PROPERTY";
var WORKER_FIND_LAYERS = "FIND_LAYERS";
var WORKER_BUILD_EXTERNAL_ID_MAPPING = "BUILD_EXTERNAL_ID_MAPPING";
var WORKER_BUILD_LAYER_TO_NODE_ID_MAPPING = "BUILD_LAYER_TO_NODE_ID_MAPPING";
var WORKER_LOAD_PROPERTYDB = "LOAD_PROPERTYDB";
var WORKER_UNLOAD_PROPERTYDB = "UNLOAD_PROPERTYDB";
//Use a global property worker thread, which does caching of
//shared property databases (and database files).
var propWorker;
//Keep track of all pending operations/callbacks going into the property worker
var PROPDB_CB_COUNTER = 1;
var PROPDB_CALLBACKS = {};
function propertyWorkerCallback(e) {
    var data = e.data;
    if (data && data.debug) {
        exports.logger.debug(data.message);
        return;
    }
    if (data.cbId) {
        var cbs = PROPDB_CALLBACKS[data.cbId];
        if (data && data.error) {
            if (cbs[1]) cbs[1](data.error);
        } else {
            if (cbs[0]) cbs[0](data.result);
        }
        delete PROPDB_CALLBACKS[data.cbId];
    }
}
function registerWorkerCallback(onSuccess, onError) {
    var cbId = PROPDB_CB_COUNTER++;
    PROPDB_CALLBACKS[cbId] = [onSuccess, onError];
    return cbId;
}
function clearPropertyWorkerCache() {
    if (!propWorker) return;
    propWorker.doOperation({
        "operation": WORKER_UNLOAD_PROPERTYDB,
        "clearCaches": true
    });
}
//Per model property database interface, talks to the worker thread behind the scenes
var PropDbLoader = function PropDbLoader(sharedDbPath, model, delegate) {
    this.delegate = FileLoader.copyDelegate(this, delegate);
    this.eventTarget = this.delegate.eventTarget;
    this.model = model;
    this.svf = model && model.getData();
    //Will be initialized by the complex logic below.
    this.dbPath = "";
    this.sharedDbPath = false;
    //If there is a shared db path and there is no
    //per-SVF specific property database, use the shared one
    if (this.svf && this.svf.propertydb && this.svf.propertydb.avs.length) {
        //If the SVF specified its own property db files, assume they are not shared
        this.dbFiles = this.svf.propertydb;
        for (var f in this.dbFiles) {
            if (this.dbFiles[f][0]) {
                //Revit outputs backslashes in the
                //relative path in the SVF manifest. WTF?
                this.dbFiles[f][0] = this.dbFiles[f][0].replace(/\\/g, "/");
            }
        }
        //Now check if the SVF propertydb definition actually refers to the same property database
        //as the shared database path. This is made harder by various "../../.." relative things
        //in the svf property db files list, hence the nasty path normalization stuff.
        var svfPath = pathToURL(this.svf.basePath);
        if (sharedDbPath) {
            var avsPath = ViewingService.simplifyPath(svfPath + this.svf.propertydb.avs[0]);
            avsPath = avsPath.slice(0, avsPath.lastIndexOf("/") + 1);
            //Does the property db path specified in the SVF match the
            //one specified as shared db path in the manifest?
            if (avsPath === sharedDbPath) {
                //Convert the property db file list to be relative
                //to the shared property db location, instead of
                //relative to the SVF location
                var dbFilesNew = {};
                for (var f in this.dbFiles) {
                    var fpath = this.dbFiles[f][0];
                    fpath = ViewingService.simplifyPath(svfPath + fpath);
                    dbFilesNew[f] = [fpath];
                }
                //Replace the loader parameters by the recomputed ones
                this.dbFiles = dbFilesNew;
                //Use the less specific out of the SVF and shared bubble
                //paths, and convert all file paths to be relative from that.
                this.dbPath = sharedDbPath;
                this.sharedDbPath = true;
            } else {
                this.dbPath = svfPath;
                this.sharedDbPath = false;
            }
        } else {
            this.dbPath = svfPath;
            this.sharedDbPath = false;
        }
    } else {
        this.sharedDbPath = true;
        this.dbPath = sharedDbPath;
        //This lets the worker initialize the file list with defaults.
        //TODO: The file list in the worker uses v1 defaults and so this
        //code needs to be revisited for v2 defaults in cases where the
        //v2 files are not defined in the manifest (code path in the other branch above).
        this.dbFiles = { attrs: [], avs: [], ids: [], values: [], offsets: [] };
        exports.logger.log("Using shared db path " + sharedDbPath);
    }
    this.queryParams = "";
    if (this.svf && this.svf.acmSessionId) {
        this.queryParams = "acmsession=" + this.svf.acmSessionId;
    }
};
PropDbLoader.prototype.transferToDelegate = function (delegate) {
    this.delegate = FileLoader.copyDelegate(this, delegate);
    return true;
};
PropDbLoader.prototype.dtor = function () {
    this.asyncPropertyOperation({
        "operation": WORKER_UNLOAD_PROPERTYDB
    }, function () {}, function () {});
};
PropDbLoader.prototype.processLoadResult = function (result) {
    var scope = this;
    if (result.instanceTreeStorage) {
        var nodeAccess = new InstanceTreeAccess(result.instanceTreeStorage, result.rootId, result.instanceBoxes);
        scope.instanceTree = new InstanceTree(nodeAccess, result.objectCount, result.maxTreeDepth);
        //For backwards compatibility, svf.instanceTree has to be set also
        if (scope.svf) {
            scope.svf.instanceTree = scope.instanceTree;
        }
    } else if (result.instanceTree) {
        //Case of fake glTF instance tree
        //TODO: the glTF instance tree would have to be converted or warpped inside an InstanceTree
        //in order to be usable by the UI.
        exports.logger.warn("glTF instance tree not supported");
        scope.hasObjectProperties = result.objectCount;
    } else if (result.objectCount) {
        //Case where there is no object tree, but objects
        //do still have properties. This is the case for F2D drawings.
        scope.hasObjectProperties = result.objectCount;
        if (scope.svf) {
            scope.svf.hasObjectProperties = result.objectCount;
        }
    }
    scope.eventTarget.dispatchEvent({
        type: OBJECT_TREE_CREATED_EVENT,
        svf: scope.svf,
        model: scope.model,
        target: scope
    });
};
PropDbLoader.prototype.processLoadError = function (error$$1) {
    var scope = this;
    scope.propertyDbError = error$$1;
    scope.eventTarget.dispatchEvent({
        type: OBJECT_TREE_UNAVAILABLE_EVENT,
        svf: scope.svf,
        model: scope.model,
        target: scope
    });
};
PropDbLoader.prototype.load = function () {
    var scope = this;
    //In the case of glTF, the instance tree is immediately available, loaded
    //together with the geometry payload ("the svf")
    if (this.svf && this.svf.instanceTree && this.svf.instanceBoxes) {
        //Need this call to be async, because some state required
        //by object tree load event handlers is not yet initialized
        //when the PropDbLoader.load() is called (in particular, viewer.model is not assigned at that point)
        setTimeout(function () {
            scope.processLoadResult(scope.svf);
        }, 0);
        return;
    }
    //Create the shared property worker if not already done
    if (!propWorker) {
        propWorker = this.delegate.workerScript.createWorkerWithIntercept();
        propWorker.addEventListenerWithIntercept(propertyWorkerCallback);
    }
    this.propWorker = propWorker; //Used by node.js code to get direct access to the worker (which runs on the same thread in node.js)
    var onObjectTreeRead = function onObjectTreeRead(result) {
        scope.processLoadResult(result);
    };
    var onObjectTreeError = function onObjectTreeError(error$$1) {
        scope.processLoadError(error$$1);
    };
    var cbId = registerWorkerCallback(onObjectTreeRead, onObjectTreeError);
    var xfer = { "operation": WORKER_LOAD_PROPERTYDB,
        "dbPath": this.dbPath,
        "sharedDbPath": this.sharedDbPath,
        "propertydb": this.dbFiles,
        "fragToDbId": this.svf && this.svf.fragments.fragId2dbId,
        "fragBoxes": this.svf && this.svf.fragments.boxes,
        cbId: cbId,
        queryParams: this.queryParams
    };
    propWorker.doOperation(this.delegate.initLoadContext(xfer)); // Send data to our worker.
};
PropDbLoader.prototype.asyncPropertyOperation = function (opArgs, success, fail) {
    var scope = this;
    //Identify which property database we want to work on (the worker can hold multiple property databases)
    opArgs.dbPath = this.dbPath;
    if (scope.instanceTree || scope.hasObjectProperties) {
        opArgs.cbId = registerWorkerCallback(success, fail);
        propWorker.doOperation(opArgs); // Send data to our worker.
    } else if (scope.propertyDbError) {
        if (fail) fail(scope.propertyDbError);
    } else {
        var onEvent = function onEvent(e) {
            scope.eventTarget.removeEventListener(OBJECT_TREE_CREATED_EVENT, onEvent);
            scope.eventTarget.removeEventListener(OBJECT_TREE_UNAVAILABLE_EVENT, onEvent);
            if (scope.instanceTree || scope.hasObjectProperties || scope.propertyDbError) scope.asyncPropertyOperation(opArgs, success, fail);else if (fail) fail({ code: exports.ErrorCodes.UNKNOWN_FAILURE, msg: "Failed to load properties" }); //avoid infinite recursion.
        };
        scope.eventTarget.addEventListener(OBJECT_TREE_CREATED_EVENT, onEvent);
        scope.eventTarget.addEventListener(OBJECT_TREE_UNAVAILABLE_EVENT, onEvent);
    }
};
PropDbLoader.prototype.getProperties = function (dbId, onSuccess, onError) {
    this.asyncPropertyOperation({
        "operation": WORKER_GET_PROPERTIES,
        "dbId": dbId
    }, onSuccess, onError);
};
/**
 * Bulk property retrieval with property name filter.
 * dbIds -- array of object dbIds to return properties for.
 * propFilter -- array of property names to retrieve values for. If empty, all properties are returned.
 * ignoreHidden -- ignore hidden properties
 */
PropDbLoader.prototype.getBulkProperties = function (dbIds, propFilter, onSuccess, onError, ignoreHidden) {
    this.asyncPropertyOperation({
        "operation": WORKER_GET_PROPERTIES,
        "dbIds": dbIds,
        "propFilter": propFilter,
        "ignoreHidden": ignoreHidden
    }, onSuccess, onError);
};
PropDbLoader.prototype.searchProperties = function (searchText, attributeNames, onSuccess, onError, completeInfo) {
    this.asyncPropertyOperation({
        "operation": WORKER_SEARCH_PROPERTIES,
        "searchText": searchText,
        "attributeNames": attributeNames,
        "completeInfo": completeInfo
    }, onSuccess, onError);
};
PropDbLoader.prototype.findProperty = function (propertyName) {
    var that = this;
    return new Promise(function (resolve, reject) {
        that.asyncPropertyOperation({
            "operation": WORKER_FIND_PROPERTY,
            "propertyName": propertyName
        }, resolve, reject);
    });
};
PropDbLoader.prototype.findLayers = function () {
    var that = this;
    return new Promise(function (resolve, reject) {
        that.asyncPropertyOperation({
            "operation": WORKER_FIND_LAYERS
        }, resolve, reject);
    });
};
PropDbLoader.prototype.getExternalIdMapping = function (onSuccess, onError) {
    this.asyncPropertyOperation({
        "operation": WORKER_BUILD_EXTERNAL_ID_MAPPING
    }, onSuccess, onError);
};
PropDbLoader.prototype.getLayerToNodeIdMapping = function (onSuccess, onError) {
    this.asyncPropertyOperation({
        "operation": WORKER_BUILD_LAYER_TO_NODE_ID_MAPPING
    }, onSuccess, onError);
};
PropDbLoader.prototype.isObjectTreeLoaded = function () {
    return !!this.instanceTree;
};
PropDbLoader.prototype.getObjectTree = function (onSuccess, onError) {
    var scope = this;
    if (scope.instanceTree) {
        onSuccess(scope.instanceTree);
    } else if (scope.propertyDbError) {
        if (onError) onError(scope.propertyDbError);
    } else if ('hasObjectProperties' in scope) {
        if (onError) onError('F2D files do not have an InstanceTree.');
    } else {
        // Property Db has been requested; waiting for worker to complete //
        var listener = function listener() {
            scope.eventTarget.removeEventListener(OBJECT_TREE_CREATED_EVENT, listener);
            scope.eventTarget.removeEventListener(OBJECT_TREE_UNAVAILABLE_EVENT, listener);
            scope.getObjectTree(onSuccess, onError);
        };
        scope.eventTarget.addEventListener(OBJECT_TREE_CREATED_EVENT, listener);
        scope.eventTarget.addEventListener(OBJECT_TREE_UNAVAILABLE_EVENT, listener);
    }
};

'use strict';
var M = [6.0014, -2.7008, -1.7996, -1.3320, 3.1029, -5.7721, 0.3008, -1.0882, 5.6268];
function LogLuvDecode(dst, src) {
    var Le = src[2] * 255.0 + src[3];
    var Xp_Y_XYZp_y = Math.pow(2.0, (Le - 127.0) / 2.0);
    var Xp_Y_XYZp_z = Xp_Y_XYZp_y / src[1];
    var Xp_Y_XYZp_x = src[0] * Xp_Y_XYZp_z;
    var r = M[0] * Xp_Y_XYZp_x + M[3] * Xp_Y_XYZp_y + M[6] * Xp_Y_XYZp_z;
    var g = M[1] * Xp_Y_XYZp_x + M[4] * Xp_Y_XYZp_y + M[7] * Xp_Y_XYZp_z;
    var b = M[2] * Xp_Y_XYZp_x + M[5] * Xp_Y_XYZp_y + M[8] * Xp_Y_XYZp_z;
    if (r < 0) r = 0;
    if (g < 0) g = 0;
    if (b < 0) b = 0;
    dst[0] = r;
    dst[1] = g;
    dst[2] = b;
}
function RGBMEncode(dst, src, expScale) {
    var r = Math.sqrt(src[0] * expScale) * 0.0625; // 1/16 = 0.0625
    var g = Math.sqrt(src[1] * expScale) * 0.0625;
    var b = Math.sqrt(src[2] * expScale) * 0.0625;
    var maxL = Math.max(Math.max(r, g), Math.max(b, 1e-6));
    if (maxL > 1.0) maxL = 1.0;
    var w = Math.ceil(maxL * 255.0) / 255.0;
    if (r > 1.0) r = 1.0;
    if (g > 1.0) g = 1.0;
    if (b > 1.0) b = 1.0;
    dst[3] = w;
    var a = 1.0 / w;
    dst[0] = r * a;
    dst[1] = g * a;
    dst[2] = b * a;
}
function RGB16Encode(dst, src, expScale) {
    var r = Math.sqrt(src[0] * expScale);
    var g = Math.sqrt(src[1] * expScale);
    var b = Math.sqrt(src[2] * expScale);
    //That's pretty unlikely to happen...
    var MAX_HALF = 65504;
    if (r > MAX_HALF) r = MAX_HALF;
    if (g > MAX_HALF) g = MAX_HALF;
    if (b > MAX_HALF) b = MAX_HALF;
    dst[0] = r;
    dst[1] = g;
    dst[2] = b;
}
var tmpSrc = new Float32Array(4);
var tmpDst = new Float32Array(4);
//Converts incoming environment cube maps to image format suitable for use by the shader.
var DecodeEnvMap = function DecodeEnvMap(map, exposure, useHalfFloat, callback) {
    if (!map.LogLuv) {
        exports.logger.warn("Environment map expected to be in LogLuv format.");
        return;
    }
    var scale = Math.pow(2.0, exposure);
    // if `map.image` is an array, use it as it is, otherwise create an array with single item (`map.image`) in it
    var images = Array.isArray(map.image) ? map.image : [map.image];
    for (var i = 0; i < images.length; i++) {
        var image = images[i];
        for (var j = 0; j < image.mipmaps.length; j++) {
            var mipmap = image.mipmaps[j];
            var src = mipmap.data;
            var dst;
            if (useHalfFloat) {
                //var dst = new Float32Array(src.length / 4 * 3);
                dst = new Uint16Array(src.length / 4 * 3);
                mipmap.data = dst;
            } else dst = src.buffer;
            var m = 0;
            for (var k = 0; k < src.length; k += 4) {
                tmpSrc[0] = src[k] / 255.0;
                tmpSrc[1] = src[k + 1] / 255.0;
                tmpSrc[2] = src[k + 2] / 255.0;
                tmpSrc[3] = src[k + 3] / 255.0;
                LogLuvDecode(tmpDst, tmpSrc);
                if (useHalfFloat) {
                    //Use sqrt to gamma-compress the data to help the texture filtering
                    //hardware.
                    RGB16Encode(tmpSrc, tmpDst, scale);
                    dst[m++] = FloatToHalf(tmpSrc[0]);
                    dst[m++] = FloatToHalf(tmpSrc[1]);
                    dst[m++] = FloatToHalf(tmpSrc[2]);
                } else {
                    //Temporary: decode incoming LogLUV environments and convert them
                    //to RGBM format for use by the shader. Eventually we will use half-float format
                    //instead, but that has to be better tested.
                    RGBMEncode(tmpSrc, tmpDst, scale);
                    src[k] = Math.round(tmpSrc[0] * 255.0);
                    src[k + 1] = Math.round(tmpSrc[1] * 255.0);
                    src[k + 2] = Math.round(tmpSrc[2] * 255.0);
                    src[k + 3] = Math.round(tmpSrc[3] * 255.0);
                }
            }
        }
    }
    map.LogLuv = false;
    if (useHalfFloat) {
        map.type = THREE$1.HalfFloatType;
        map.format = THREE$1.RGBFormat;
        map.RGBM = false;
        map.GammaEncoded = true;
    } else map.RGBM = true;
    if (callback) callback(map);
};
//web worker used for image processing, etc.
var imageWorker = null;
var messageId = 1;
function getTransferables(map) {
    var res = [];
    // if `map.image` is an array, use it as it is, otherwise create an array with single item (`map.image`) in it
    var images = Array.isArray(map.image) ? map.image : [map.image];
    for (var i = 0; i < images.length; i++) {
        var image = images[i];
        for (var j = 0; j < image.mipmaps.length; j++) {
            var mipmap = image.mipmaps[j];
            res.push(mipmap.data.buffer);
        }
    }
    return res;
}
var DecodeEnvMapAsync = function DecodeEnvMapAsync(workerScript, map, exposure, useHalfFloat, callback) {
    if (!map.LogLuv) {
        exports.logger.warn("Environment map expected to be in LogLuv format.");
        return;
    }
    if (!imageWorker) imageWorker = workerScript.createWorker();
    var id = messageId++;
    var onMessage = function onMessage(msg) {
        if (msg.data.id !== id) return;
        imageWorker.removeEventListener("message", onMessage);
        var mapWorker = msg.data.map;
        map.image = mapWorker.image;
        map.LogLuv = false;
        if (useHalfFloat) {
            map.type = THREE$1.HalfFloatType;
            map.format = THREE$1.RGBFormat;
            map.RGBM = false;
            map.GammaEncoded = true;
        } else map.RGBM = true;
        callback(map);
    };
    imageWorker.addEventListener("message", onMessage);
    imageWorker.doOperation({
        operation: "DECODE_ENVMAP",
        map: map,
        exposure: exposure,
        useHalfFloat: useHalfFloat,
        id: id
    }, getTransferables(map));
};

/*
 * @author mrdoob / http://mrdoob.com/
 */
THREE.DDSLoader = function () {
	this._parser = THREE.DDSLoader.parse;
};

THREE.DDSLoader.prototype = Object.create( THREE.CompressedTextureLoader.prototype );
THREE.DDSLoader.prototype.constructor = THREE.DDSLoader;

THREE.DDSLoader.parse = function ( buffer, loadMipmaps ) {

	var dds = { mipmaps: [], width: 0, height: 0, format: null, mipmapCount: 1 };

	// Adapted from @toji's DDS utils
	//	https://github.com/toji/webgl-texture-utils/blob/master/texture-util/dds.js

	// All values and structures referenced from:
	// http://msdn.microsoft.com/en-us/library/bb943991.aspx/

	var DDS_MAGIC = 0x20534444;

	var DDSCAPS2_CUBEMAP = 0x200;

	var DDPF_ALPHAPIXELS = 0x1,
		DDPF_ALPHA = 0x2,
		DDPF_FOURCC = 0x4;

	function fourCCToInt32( value ) {

		return value.charCodeAt(0) +
			(value.charCodeAt(1) << 8) +
			(value.charCodeAt(2) << 16) +
			(value.charCodeAt(3) << 24);

	}

	function int32ToFourCC( value ) {

		return String.fromCharCode(
			value & 0xff,
			(value >> 8) & 0xff,
			(value >> 16) & 0xff,
			(value >> 24) & 0xff
		);
	}

	function loadARGBMip( buffer, dataOffset, width, height ) {
		var dataLength = width * height * 4;
		var srcBuffer = new Uint8Array( buffer, dataOffset, dataLength );
		var byteArray = new Uint8Array( dataLength );
		var dst = 0;
		var src = 0;
		for ( var y = 0; y < height; y ++ ) {
			for ( var x = 0; x < width; x ++ ) {
				var b = srcBuffer[src]; src ++;
				var g = srcBuffer[src]; src ++;
				var r = srcBuffer[src]; src ++;
				var a = srcBuffer[src]; src ++;
				byteArray[dst] = r; dst ++;	//r
				byteArray[dst] = g; dst ++;	//g
				byteArray[dst] = b; dst ++;	//b
				byteArray[dst] = a; dst ++;	//a
			}
		}
		return byteArray;
	}

	var FOURCC_DXT1 = fourCCToInt32("DXT1");
	var FOURCC_DXT3 = fourCCToInt32("DXT3");
	var FOURCC_DXT5 = fourCCToInt32("DXT5");

	var headerLengthInt = 31; // The header length in 32 bit ints

	// Offsets into the header array

	var off_magic = 0;

	var off_size = 1;
	var off_height = 3;
	var off_width = 4;

	var off_mipmapCount = 7;

	var off_pfFlags = 20;
	var off_pfFourCC = 21;
	var off_RGBBitCount = 22;
	var off_RBitMask = 23;
	var off_GBitMask = 24;
	var off_BBitMask = 25;
	var off_ABitMask = 26;

	var off_caps2 = 28;
	var header = new Int32Array( buffer, 0, headerLengthInt );

	if ( header[ off_magic ] !== DDS_MAGIC ) {

		console.error( 'THREE.DDSLoader.parse: Invalid magic number in DDS header.' );
		return dds;

	}

	if ( ! header[ off_pfFlags ] & DDPF_FOURCC ) {

		console.error( 'THREE.DDSLoader.parse: Unsupported format, must contain a FourCC code.' );
		return dds;

	}

	var blockBytes;

	var fourCC = header[ off_pfFourCC ];

	var isRGBAUncompressed = false;

	switch ( fourCC ) {

		case FOURCC_DXT1:

			blockBytes = 8;
			dds.format = THREE.RGB_S3TC_DXT1_Format;
			break;

		case FOURCC_DXT3:

			blockBytes = 16;
			dds.format = THREE.RGBA_S3TC_DXT3_Format;
			break;

		case FOURCC_DXT5:

			blockBytes = 16;
			dds.format = THREE.RGBA_S3TC_DXT5_Format;
			break;

		default:

			if ( header[off_RGBBitCount] == 32
				&& header[off_RBitMask]&0xff0000
				&& header[off_GBitMask]&0xff00
				&& header[off_BBitMask]&0xff
				&& header[off_ABitMask]&0xff000000  ) {
				isRGBAUncompressed = true;
				blockBytes = 64;
				dds.format = THREE.RGBAFormat;
			} else {
				console.error( 'THREE.DDSLoader.parse: Unsupported FourCC code ', int32ToFourCC( fourCC ) );
				return dds;
			}
	}

	dds.mipmapCount = 1;

	if ( header[ off_mipmapCount ] > 0 && loadMipmaps !== false ) {

		dds.mipmapCount = Math.max( 1, header[ off_mipmapCount ] );

	}

	//TODO: Verify that all faces of the cubemap are present with DDSCAPS2_CUBEMAP_POSITIVEX, etc.

	dds.isCubemap = header[ off_caps2 ] & DDSCAPS2_CUBEMAP ? true : false;

	dds.width = header[ off_width ];
	dds.height = header[ off_height ];

	var dataOffset = header[ off_size ] + 4;

	// Extract mipmaps buffers

	var width = dds.width;
	var height = dds.height;

	var faces = dds.isCubemap ? 6 : 1;

	for ( var face = 0; face < faces; face ++ ) {

		for ( var i = 0; i < dds.mipmapCount; i ++ ) {

			if ( isRGBAUncompressed ) {
				var byteArray = loadARGBMip( buffer, dataOffset, width, height );
				var dataLength = byteArray.length;
			} else {
				var dataLength = Math.max( 4, width ) / 4 * Math.max( 4, height ) / 4 * blockBytes;
				var byteArray = new Uint8Array( buffer, dataOffset, dataLength );
			}

			var mipmap = { "data": byteArray, "width": width, "height": height };
			dds.mipmaps.push( mipmap );

			dataOffset += dataLength;

			width = Math.max( width * 0.5, 1 );
			height = Math.max( height * 0.5, 1 );

		}

		width = dds.width;
		height = dds.height;

	}

	return dds;

};

/*
 *	 PVRLoader
 *   Author: pierre lepers
 *   Date: 17/09/2014 11:09
 *
 *	 PVR v2 (legacy) parser
 *   TODO : Add Support for PVR v3 format
 *   TODO : implement loadMipmaps option
 */
THREE.PVRLoader = function ( manager ) {

	this.manager = ( manager !== undefined ) ? manager : THREE.DefaultLoadingManager;

	this._parser = THREE.PVRLoader.parse;

};

THREE.PVRLoader.prototype = Object.create( THREE.CompressedTextureLoader.prototype );
THREE.PVRLoader.prototype.constructor = THREE.PVRLoader;


THREE.PVRLoader.parse = function ( buffer, loadMipmaps ) {

	var headerLengthInt = 13;
	var header = new Uint32Array( buffer, 0, headerLengthInt );

	var pvrDatas = {
		buffer: buffer,
		header : header,
		loadMipmaps : loadMipmaps
	};

	// PVR v3
	if ( header[ 0 ] === 0x03525650 ) {

		return THREE.PVRLoader._parseV3( pvrDatas );

	}
	// PVR v2
	else if ( header[ 11 ] === 0x21525650 ) {

		return THREE.PVRLoader._parseV2( pvrDatas );

	} else {

		throw new Error( "[THREE.PVRLoader] Unknown PVR format" );

	}

};

THREE.PVRLoader._parseV3 = function ( pvrDatas ) {

	var header = pvrDatas.header;
	var bpp, format;


	var metaLen 	  = header[ 12 ],
		pixelFormat   =  header[ 2 ],
		height        =  header[ 6 ],
		width         =  header[ 7 ],
		numSurfs      =  header[ 9 ],
		numFaces      =  header[ 10 ],
		numMipmaps    =  header[ 11 ];

	switch ( pixelFormat ) {
		case 0 : // PVRTC 2bpp RGB
			bpp = 2;
			format = THREE.RGB_PVRTC_2BPPV1_Format;
			break;
		case 1 : // PVRTC 2bpp RGBA
			bpp = 2;
			format = THREE.RGBA_PVRTC_2BPPV1_Format;
			break;
		case 2 : // PVRTC 4bpp RGB
			bpp = 4;
			format = THREE.RGB_PVRTC_4BPPV1_Format;
			break;
		case 3 : // PVRTC 4bpp RGBA
			bpp = 4;
			format = THREE.RGBA_PVRTC_4BPPV1_Format;
			break;
		default :
			throw new Error( "pvrtc - unsupported PVR format " + pixelFormat );
	}

	pvrDatas.dataPtr 	 = 52 + metaLen;
	pvrDatas.bpp 		 = bpp;
	pvrDatas.format 	 = format;
	pvrDatas.width 		 = width;
	pvrDatas.height 	 = height;
	pvrDatas.numSurfaces = numFaces;
	pvrDatas.numMipmaps  = numMipmaps;

	pvrDatas.isCubemap 	= ( numFaces === 6 );

	return THREE.PVRLoader._extract( pvrDatas );

};

THREE.PVRLoader._parseV2 = function ( pvrDatas ) {

	var header = pvrDatas.header;

	var headerLength  =  header[ 0 ],
		height        =  header[ 1 ],
		width         =  header[ 2 ],
		numMipmaps    =  header[ 3 ],
		flags         =  header[ 4 ],
		dataLength    =  header[ 5 ],
		bpp           =  header[ 6 ],
		bitmaskRed    =  header[ 7 ],
		bitmaskGreen  =  header[ 8 ],
		bitmaskBlue   =  header[ 9 ],
		bitmaskAlpha  =  header[ 10 ],
		pvrTag        =  header[ 11 ],
		numSurfs      =  header[ 12 ];


	var TYPE_MASK = 0xff;
	var PVRTC_2 = 24,
		PVRTC_4 = 25;

	var formatFlags = flags & TYPE_MASK;



	var bpp, format;
	var _hasAlpha = bitmaskAlpha > 0;

	if ( formatFlags === PVRTC_4 ) {

		format = _hasAlpha ? THREE.RGBA_PVRTC_4BPPV1_Format : THREE.RGB_PVRTC_4BPPV1_Format;
		bpp = 4;

	} else if ( formatFlags === PVRTC_2 ) {

		format = _hasAlpha ? THREE.RGBA_PVRTC_2BPPV1_Format : THREE.RGB_PVRTC_2BPPV1_Format;
		bpp = 2;

	} else
		throw new Error( "pvrtc - unknown format " + formatFlags );



	pvrDatas.dataPtr 	 = headerLength;
	pvrDatas.bpp 		 = bpp;
	pvrDatas.format 	 = format;
	pvrDatas.width 		 = width;
	pvrDatas.height 	 = height;
	pvrDatas.numSurfaces = numSurfs;
	pvrDatas.numMipmaps  = numMipmaps + 1;

	// guess cubemap type seems tricky in v2
	// it juste a pvr containing 6 surface (no explicit cubemap type)
	pvrDatas.isCubemap 	= ( numSurfs === 6 );

	return THREE.PVRLoader._extract( pvrDatas );

};


THREE.PVRLoader._extract = function ( pvrDatas ) {

	var pvr = {
		mipmaps: [],
		width: pvrDatas.width,
		height: pvrDatas.height,
		format: pvrDatas.format,
		mipmapCount: pvrDatas.numMipmaps,
		isCubemap : pvrDatas.isCubemap
	};

	var buffer = pvrDatas.buffer;



	// console.log( "--------------------------" );

	// console.log( "headerLength ", headerLength);
	// console.log( "height       ", height      );
	// console.log( "width        ", width       );
	// console.log( "numMipmaps   ", numMipmaps  );
	// console.log( "flags        ", flags       );
	// console.log( "dataLength   ", dataLength  );
	// console.log( "bpp          ", bpp         );
	// console.log( "bitmaskRed   ", bitmaskRed  );
	// console.log( "bitmaskGreen ", bitmaskGreen);
	// console.log( "bitmaskBlue  ", bitmaskBlue );
	// console.log( "bitmaskAlpha ", bitmaskAlpha);
	// console.log( "pvrTag       ", pvrTag      );
	// console.log( "numSurfs     ", numSurfs    );




	var dataOffset = pvrDatas.dataPtr,
		bpp = pvrDatas.bpp,
		numSurfs = pvrDatas.numSurfaces,
		dataSize = 0,
		blockSize = 0,
		blockWidth = 0,
		blockHeight = 0,
		widthBlocks = 0,
		heightBlocks = 0;



	if ( bpp === 2 ) {

		blockWidth = 8;
		blockHeight = 4;

	} else {

		blockWidth = 4;
		blockHeight = 4;

	}

	blockSize = ( blockWidth * blockHeight ) * bpp / 8;

	pvr.mipmaps.length = pvrDatas.numMipmaps * numSurfs;

	var mipLevel = 0;

	while ( mipLevel < pvrDatas.numMipmaps ) {

		var sWidth = pvrDatas.width >> mipLevel,
		sHeight = pvrDatas.height >> mipLevel;

		widthBlocks = sWidth / blockWidth;
		heightBlocks = sHeight / blockHeight;

		// Clamp to minimum number of blocks
		if ( widthBlocks < 2 )
			widthBlocks = 2;
		if ( heightBlocks < 2 )
			heightBlocks = 2;

		dataSize = widthBlocks * heightBlocks * blockSize;


		for ( var surfIndex = 0; surfIndex < numSurfs; surfIndex ++ ) {

			var byteArray = new Uint8Array( buffer, dataOffset, dataSize );

			var mipmap = {
				data: byteArray,
				width: sWidth,
				height: sHeight
			};

			pvr.mipmaps[ surfIndex * pvrDatas.numMipmaps + mipLevel ] = mipmap;

			dataOffset += dataSize;


		}

		mipLevel ++;

	}


	return pvr;

};

"use strict";
var MAX_REQUESTS = isMobileDevice() ? 4 : Infinity;
var _requestQueue = [];
var _requestsInProgress = 0;
var TEXTURE_MEMORY = isMobileDevice() ? 32 : Infinity;
TEXTURE_MEMORY *= 1024 * 1024;
var _textureCount = 0;
var _textureSize = Infinity; // Max texture sizes in pixels
function resizeImage(img) {
    var ow = img.width;
    var oh = img.height;
    var w = void 0,
        h = void 0;
    //It's a power of two already and not too large
    if ((ow & ow - 1) === 0 && (oh & oh - 1) === 0) {
        if (ow * oh <= _textureSize) {
            return img;
        }
        w = ow;
        h = oh;
    } else {
        w = 1;
        while (w * 2 < ow) {
            w *= 2;
        }h = 1;
        while (h * 2 < oh) {
            h *= 2;
        }
    }
    while (w * h > _textureSize) {
        w = Math.max(w / 2, 1);
        h = Math.max(h / 2, 1);
    }
    var canvas = document.createElement("canvas");
    var ctx = canvas.getContext("2d");
    canvas.width = w;
    canvas.height = h;
    // if a resize happens, set this special flag to note it.
    canvas.wasNPOT = true;
    ctx.drawImage(img, 0, 0, w, h);
    return canvas;
}
function textureHasAlphaChannel(texture) {
    return texture.format === THREE$1.AlphaFormat || texture.format === THREE$1.RGBAFormat;
}
function textureUsesClamping(texture) {
    return texture.clampS || texture.clampT;
}
function textureUsesMipmapping(texture) {
    return texture.minFilter !== THREE$1.NearestFilter && texture.minFilter !== THREE$1.LinearFilter;
    // Full test, but the Chrome bug happens only on mipmapping, from what we can tell.
    // if wrapping is not clamp to edge, or minFilter is a mipmap mode, then we need power of two.
    //return ( texture.wrapS !== THREE.ClampToEdgeWrapping || texture.wrapT !== THREE.ClampToEdgeWrapping ) ||
    //  ( texture.minFilter !== THREE.NearestFilter && texture.minFilter !== THREE.LinearFilter );
}
function applyBrowserSpecificSizeHacks(tex) {
    // check: if the texture is not a power-of-two, then turn off mipmapping
    // At this point all textures are powers of two. However, Chrome cannot use mipmapping if
    // this image was a non-power-of-two with an alpha channel. This is a bug in Chrome.
    // If wasNPOT is true, then we need it off, but only if the filter is clamped, for some reason.
    // See https://jira.autodesk.com/browse/LMV-2556 and linked defects.
    // This entire test and corrective action can be removed once the version of Chrome is past
    // Version 60.0.3086.0, see https://jira.autodesk.com/browse/LMV-2426. If we remove this
    // patch, please also remove wasNPOT getting set in resizeImage().
    if (tex.image.wasNPOT === true && textureHasAlphaChannel(tex) && textureUsesClamping(tex) && textureUsesMipmapping(tex) &&
    // This fix can be removed as soon as Windows Chrome build is Version 60.0.3086.0 (Official Build) canary (64-bit)
    isChrome() && isWindows()) {
        // turn mipmapping off - TODO need to check for PNG alpha
        tex.minFilter = THREE$1.LinearFilter;
        tex.generateMipmaps = false;
        tex.needsUpdate = true;
    }
}
function arrayBufferToDataUri(buffer) {
    var binary = '';
    var bytes = new Uint8Array(buffer);
    var len = bytes.byteLength;
    for (var i = 0; i < len; i++) {
        binary += String.fromCharCode(bytes[i]);
    }
    return "data:image/jpeg;base64," + window.btoa(binary);
}
var nextRequest = function nextRequest() {
    while (_requestsInProgress < MAX_REQUESTS && _requestQueue.length > 0) {
        var request = _requestQueue.shift();
        ++_requestsInProgress;
        request.loadFunction(request.context, request.path, request.mapping, request.callback, request.options);
    }
};
// Request a texture. Either do it now or queue it for later.
var requestTexture = function requestTexture(loadFunction, context, path, mapping, callback, options) {
    if (_requestsInProgress < MAX_REQUESTS && _requestQueue.length <= 0) {
        ++_requestsInProgress;
        loadFunction(context, path, mapping, callback, options);
        return;
    }
    // Record the asset for the mobile application
    if (exports.assets && context) {
        // Ugly - this is taken from the ViewingSevice
        var url = ViewingService.generateUrl(context.endpoint, "items", path);
        if (context.queryParams) {
            var concatSymbol = url.indexOf('?') === -1 ? '?' : '&';
            url = url + concatSymbol + context.queryParams;
        }
        exports.assets.push([url, context.headers, null /* ACM session id, null in this case. */]);
    }
    // Queue the texture for loading later
    _requestQueue.push({
        loadFunction: loadFunction,
        context: context,
        path: path,
        mapping: mapping,
        callback: callback,
        options: options
    });
    nextRequest();
};
var _loadTexture = function _loadTexture(delegate, model, path, isShared, textureDef, acmSessionId, svf, convertTexture) {
    //Create the three.js texture object (with delay loaded image data)
    TextureLoader.loadTextureWithSecurity(path, isShared, THREE$1.UVMapping, function (tex) {
        //NOTE: tex could be null here in case of load error.
        if (tex) {
            var units = svf.materials.scene.SceneUnit;
            var anisotropy = delegate.webGLRenderer ? delegate.webGLRenderer.getMaxAnisotropy() : 0;
            convertTexture(textureDef, tex, units, anisotropy);
        }
        var matman = delegate.matman;
        //It's possible MaterialManager got destroyed before the texture loads
        if (!matman) return;
        matman.setTextureInCache(model, textureDef, tex, path);
        //Private API: Call a custom texture processing callback if one is supplied.
        //This is used for texture processing in node.js tools.
        //We are avoiding a more generic fireEvent mechanism in order to avoid publishing
        //yet another event type.
        if (svf.loadOptions.onTextureReceived) {
            svf.loadOptions.setTextureInCache(matman, textureDef, tex, !requestsInProgress());
        }
        //Unfortunately we have to check for texture load complete here also, not just
        //in the final call to loadTextures. This is because geometry load can complete
        //before or after texture load completes.
        if (!requestsInProgress() && svf.loadDone && !svf.texLoadDone) {
            svf.texLoadDone = true;
            // Fire the event so we know the textures for a model are done loading.
            delegate.eventTarget.dispatchEvent({
                type: TEXTURES_LOADED_EVENT,
                model: model
            });
        }
    }, acmSessionId, delegate.initLoadContext);
};
var loadTextures = function loadTextures(delegate, model, textures) {
    var length = textures.length;
    if (length > 0) {
        TextureLoader.setTextureCount(length);
        var svf = model.getData();
        for (var i = 0; i < length; ++i) {
            var texPathData = textures[i];
            _loadTexture(delegate, model, texPathData.path, texPathData.isShared, texPathData.map, texPathData.acmSessionId, svf, MaterialConverter.convertTexture);
        }
    }
};
// For texture loading, three.js expects loadable URL for the image.
// When we put the token in request header instead of cookie, we need AJAX the
// texture and base64 encode it to create a data URI and feed it to three.js.
function loadTextureWithToken(loadContext, path, mapping, callback, options) {
    var texture = new THREE$1.Texture(undefined, mapping);
    function onSuccess(data) {
        if (options && options.extractImage) {
            data = options.extractImage(data);
        }
        var image = new Image();
        texture.image = image;
        applyBrowserSpecificSizeHacks(texture);
        image.onload = function () {
            texture.needsUpdate = true;
            if (callback) callback(texture);
        };
        image.onerror = function (e) {
            exports.logger.error(e, errorCodeString(exports.ErrorCodes.UNKNOWN_FAILURE));
            if (callback) callback(null);
        };
        image.src = arrayBufferToDataUri(data);
    }
    function onTextureFailure(statusCode, statusText) {
        var errorMsg = "Error: " + statusCode + " (" + statusText + ")";
        exports.logger.error(errorMsg, errorCodeString(exports.ErrorCodes.NETWORK_SERVER_ERROR));
        //We need to call the callback because it decrements the pending texture counter
        callback && callback(null);
    }
    if (options && options.rawData) {
        onSuccess(options.rawData);
    } else {
        ViewingService.getItem(loadContext, path, onSuccess, onTextureFailure);
    }
    return texture;
}
// Load texture in node.js
function loadTextureWithTokenNode(loadContext, path, mapping, callback, options) {
    var texture = new THREE$1.DataTexture(undefined, mapping);
    function onSuccess(data) {
        if (options && options.extractImage) {
            data = options.extractImage(data);
        }
        texture.image = { data: data, width: undefined, height: undefined };
        texture.needsUpdate = true;
        if (callback) callback(texture);
    }
    function onTextureFailure(statusCode, statusText) {
        var errorMsg = "Error: " + statusCode + " (" + statusText + ")";
        exports.logger.error(errorMsg, errorCodeString(exports.ErrorCodes.NETWORK_SERVER_ERROR));
        //We need to call the callback because it decrements the pending texture counter
        callback && callback(null);
    }
    ViewingService.getItem(loadContext, path, onSuccess, onTextureFailure);
    return texture;
}
/**
 * Load all texture for a single material
 * @param material The material whose texture are loaded
 */
var findMaterialTextures = function findMaterialTextures(delegate, model, material, textureDefs) {
    // Get texture path and session info
    function determineSvfTexturePath(model, material, map, mapName) {
        var svf = model.getData();
        var texDef = TextureLoader.calculateTexturePath(model, map.uri, material, delegate.initLoadContext);
        texDef.map = map;
        texDef.acmSessionId = svf.acmSessionId;
        return texDef;
    }
    if (!material.textureMaps) return;
    if (material.texturesLoaded) return;
    material.texturesLoaded = true;
    // Iterate and parse textures from ugly JSON for each texture type in material.
    // If has URI and valid mapName load and initialize that texture.
    var textures = material.textureMaps;
    for (var mapName in textures) {
        var textureDef = textures[mapName];
        // The model editor will add incomplete textures that get completed
        // calling other methods. Errors using the model editor can leave
        // the texture definition in a state where it can't be loaded, so
        // make sure we skip those cases.
        if (textureDef.uri && textureDef.textureObj && textureDef.mapName && !delegate.matman.loadTextureFromCache(model, material, textureDef, mapName)) {
            textureDefs.push(determineSvfTexturePath(model, material, textureDef, mapName));
        }
    }
};
function removeTexture(model, matman, material, mapName) {
    var maps = material.textureMaps;
    if (!maps) {
        return false;
    }
    var map = maps[mapName];
    if (!map) {
        return false;
    }
    matman.clearTextureFromMaterial(model, material, map, mapName);
    if (map.tex) {
        var defines = material.defines;
        if (defines) delete defines[mapName];
        material.needsUpdate = true;
        material[mapName] = null;
        map.tex = null;
    }
    return true;
}
/**
 * Return the number of outstanding texture requests
 */
function requestsInProgress() {
    return _requestsInProgress + _requestQueue.length;
}

/**
 * Loader for textures
 */
var TextureLoader = function () {
    function TextureLoader() {
        classCallCheck(this, TextureLoader);
    }

    createClass(TextureLoader, null, [{
        key: "setMaxRequest",

        /**
         * Set the max request count
         * @param count The maximum number of outstanding request that can be started in parallel.
         */
        value: function setMaxRequest(count) {
            if (count > 0) MAX_REQUESTS = count;
        }
        /**
         * Get the max request count
         */

    }, {
        key: "getMaxRequest",
        value: function getMaxRequest() {
            return MAX_REQUESTS;
        }
        /**
         * Set the texture memory limit
         * @param size The memory allowed for textures.
         */

    }, {
        key: "setMemoryLimit",
        value: function setMemoryLimit(size) {
            if (size > 0) {
                TEXTURE_MEMORY = size;
                TextureLoader.setTextureCount(_textureCount);
            }
        }
        /**
         * Get the texture memory limit
         */

    }, {
        key: "getMemoryLimit",
        value: function getMemoryLimit() {
            return TEXTURE_MEMORY;
        }
        /**
         * Set the texture count. This is set by loadModelTextures
         * @param count The count of textures for model
         */

    }, {
        key: "setTextureCount",
        value: function setTextureCount(count) {
            if (count >= 0) {
                _textureCount = count;
                _textureSize = Math.max(16 * 1024, TEXTURE_MEMORY / (_textureCount * 4));
            }
        }
        /**
         * Get the texture count
         */

    }, {
        key: "getTextureCount",
        value: function getTextureCount() {
            return _textureCount;
        }
        // Get texture path and session info

    }, {
        key: "calculateTexturePath",
        value: function calculateTexturePath(model, uri, material, initLoadContext, return_asset) {
            var svf = model.getData();
            var calculateSvfTexturePath = function calculateSvfTexturePath() {
                var texPath = null;
                //Of course, Prism uses a different CDN endpoint from Protein, so
                //we have to distinguish between the two...
                var isProteinMat = material && material.proteinType;
                var isPrism = material && material.isPrismMaterial && material.prismType;
                var isSharedTexture = (isPrism && ViewingService.endpoint.PRISM_ROOT || isProteinMat && ViewingService.endpoint.PROTEIN_ROOT) && (uri.indexOf("1/Mats") === 0 || uri.indexOf("2/Mats") === 0 || uri.indexOf("3/Mats") === 0);
                if (return_asset) {
                    return_asset.asset = null;
                }
                if (isSharedTexture) {
                    if (isPrism) {
                        texPath = ViewingService.endpoint.PRISM_ROOT + uri;
                    } else {
                        texPath = ViewingService.endpoint.PROTEIN_ROOT + uri;
                    }
                } else {
                    for (var j = 0; j < svf.manifest.assets.length; ++j) {
                        var asset = svf.manifest.assets[j];
                        if (asset.id.toLowerCase() == uri.toLowerCase()) {
                            texPath = pathToURL(svf.basePath + asset.URI);
                            if (return_asset) {
                                return_asset.asset = asset;
                            }
                            break;
                        }
                    }
                    if (!texPath) {
                        texPath = pathToURL(svf.basePath + uri);
                    }
                }
                return { path: texPath, isShared: isSharedTexture };
            };
            function calculateOtgTexturePath() {
                var loadContext = initLoadContext({});
                // get request url
                var url = svf.makeSharedResourcePath(loadContext.otg_cdn, "textures", uri);
                return { path: url, isShared: !!loadContext.otg_cdn };
            }
            return model.isOTG() ? calculateOtgTexturePath() : calculateSvfTexturePath();
        }
        /**
         * Load a texture from a path
         * @param path URL of the texture
         * @param mapping Mapping type of the texture
         * @param callback Callback when texture is loaded
         * @param acmSessionId Session ID
         * @param skipResize True if the texture should not be resized.
         */

    }, {
        key: "loadTextureWithSecurity",
        value: function loadTextureWithSecurity(path, isShared, mapping, callback, acmSessionId, initLoadContext, skipResize, options) {
            var useCredentials = void 0;
            if (ViewingService.endpoint.getUseCredentials()) {
                // TODO: We should actually ALSO consider the case where texture is being loaded from
                // the same domain as the SVF being served. With such a change, we will be taking into
                // account developers exposing SVF's through their own proxy servers.
                useCredentials = !isShared && ViewingService.endpoint.pathRequiresCredentials(path);
                if (useCredentials) {
                    THREE$1.ImageUtils.crossOrigin = 'use-credentials';
                } else {
                    THREE$1.ImageUtils.crossOrigin = 'anonymous';
                }
            } else {
                THREE$1.ImageUtils.crossOrigin = '';
            }
            var index = path.indexOf('urn:');
            var queryParams = void 0;
            if (useCredentials && index !== -1) {
                queryParams = ViewingService.endpoint.getDomainParam();
                if (acmSessionId) {
                    queryParams = queryParams ? queryParams + "&" : "";
                    queryParams += "acmsession=" + acmSessionId;
                }
            }
            if (options && options.queryParams) {
                queryParams = queryParams ? queryParams + "&" : "";
                queryParams += options.queryParams;
            }
            if (queryParams) path += "?" + queryParams;
            /*  LMV-1955: use viewerAPI until the permissions on OSS endpoint are fixed.
                // If the textures are stored on OSS, directly stream it from OSS instead of going through items API.
                let ossPath = ViewingService.getDirectOSSUrl(ViewingService.endpoint, path);
                if (ossPath)
                    path = ossPath;
            */
            var callbackWithoutResize = function callbackWithoutResize(tex) {
                _requestsInProgress--;
                callback(tex);
                nextRequest();
            };
            //In the web browser (non-node) case, we always pass through
            //the power of two resizer if the image is not opaque DataTexture
            var callbackWithResize = skipResize ? callbackWithoutResize : function (tex) {
                _requestsInProgress--;
                if (tex) {
                    tex.image = resizeImage(tex.image);
                }
                callback(tex);
                nextRequest();
            };
            var simpleError = function simpleError(e) {
                _requestsInProgress--;
                exports.logger.error("Texture load error", e);
                callback(null);
            };
            //For node.js, always use the "manual" load code path
            if (isNodeJS()) {
                requestTexture(loadTextureWithTokenNode, initLoadContext(), path, mapping, callbackWithoutResize, options);
                return;
            }
            if (path.slice(path.length - 4).toLocaleLowerCase() === ".dds") {
                if (isIOSDevice()) {
                    var pvrPath = path.slice(0, path.length - 4) + ".pvr";
                    requestTexture(function (context, path, mapping, callback) {
                        new THREE$1.PVRLoader().load(pvrPath, callback, simpleError);
                    }, null, pvrPath, mapping, callbackWithoutResize);
                } else {
                    requestTexture(function (context, path, mapping, callback) {
                        new THREE$1.DDSLoader().load(path, callback, simpleError);
                    }, null, path, mapping, callbackWithoutResize);
                }
            } else if (useCredentials || options && (options.rawData || options.extractImage)) {
                requestTexture(loadTextureWithToken, initLoadContext(), path, mapping, callbackWithResize, options);
            } else {
                requestTexture(function (context, path, mapping, callback) {
                    THREE$1.ImageUtils.loadTexture(path, mapping, callback, simpleError);
                }, null, path, mapping, callbackWithResize, options);
            }
        }
    }, {
        key: "setTextureDefinition",
        value: function setTextureDefinition(delegate, model, material, mapName, textureDef) {
            if (!removeTexture(model, delegate.matman, material, mapName)) {
                return false;
            }
            var svf = model.getData();
            var sceneUnit = svf && svf.materials ? svf.materials.scene.SceneUnit : "inch";
            material.textureMaps[mapName].textureObj = textureDef;
            MaterialConverter.get2DMapTransform(textureDef, true, sceneUnit);
            return true;
        }
    }, {
        key: "loadTexture",
        value: function loadTexture(delegate, model, material, mapName, textureUrn, textureUrl, isShared, convertTexture, onDone) {
            var maps = material.textureMaps;
            if (!maps) {
                return false;
            }
            var map = maps[mapName];
            if (!map || !map.textureObj) {
                return false;
            }
            map.uri = textureUrn;
            function callBack(tex) {
                onDone && onDone(tex ? null : "Texture load failed", tex);
            }
            if (delegate.matman.loadTextureFromCache(model, material, map, mapName, textureUrl, callBack)) {
                onDone && onDone(null, material[mapName]);
            } else {
                _loadTexture(delegate, model, textureUrl, isShared, map, null, model.getData(), convertTexture);
            }
            return true;
        }
        /**
         * Load all texture for a single material
         * @param material The material whose texture are loaded
         */

    }, {
        key: "loadMaterialTextures",
        value: function loadMaterialTextures(delegate, model, material) {
            var textures = [];
            findMaterialTextures(delegate, model, material, textures);
            loadTextures(delegate, model, textures);
        }
        /**
         * Loads all textures for the model.
         * Textures delayed until all geometry is loaded, hence not done in convertMaterials.
         * TODO: Probably a better place for this would be Viewer3dImpl itself
         */

    }, {
        key: "loadModelTextures",
        value: function loadModelTextures(delegate, model) {
            var matman = delegate.matman;
            var hash = matman._getModelHash(model);
            var textures = [];
            for (var p in matman._materials) {
                //Prevent textures for already loaded models from being loaded
                //again. Not elegant, and we can somehow only process the materials
                //per model.
                if (p.indexOf(hash) == -1) continue;
                var material = matman._materials[p];
                findMaterialTextures(delegate, model, material, textures);
            }
            loadTextures(delegate, model, textures);
            //Model had no textures at all, call the completion callback immediately
            var svf = model.getData();
            if (!requestsInProgress() && svf.loadDone && !svf.texLoadDone) {
                svf.texLoadDone = true;
                // Fire the event so we know the textures for a model are done loading.
                delegate.eventTarget.dispatchEvent({
                    type: TEXTURES_LOADED_EVENT,
                    model: model
                });
            }
        }
        /**
         * Load a cube map
         * @param path Path to the cube map
         * @param exposure Exposure setting for high-dynamic-range cube maps
         * @param onReady Called when the texture is loaded
         */

    }, {
        key: "loadCubeMap",
        value: function loadCubeMap(path, exposure, onReady) {
            var texLoadDone = function texLoadDone(map) {
                if (map) {
                    map.mapping = THREE$1.CubeReflectionMapping;
                    map.LogLuv = path.indexOf("logluv") !== -1;
                    map.RGBM = path.indexOf("rgbm") !== -1;
                    // TODO: Turn on use of half-float textures for envmaps. Disable due to blackness on Safari.
                    DecodeEnvMap(map, exposure, false /*isMobileDevice() ? false : this.viewer.glrenderer().supportsHalfFloatTextures()*/, onReady);
                } else {
                    if (onReady) {
                        onReady(map);
                    }
                }
            };
            var cubeMap = void 0;
            THREE$1.ImageUtils.crossOrigin = '';
            if (Array.isArray(path)) {
                cubeMap = THREE$1.ImageUtils.loadTextureCube(path, THREE$1.CubeReflectionMapping, texLoadDone);
                cubeMap.format = THREE$1.RGBFormat;
            } else if (typeof path === "string") {
                if (path.toLowerCase().indexOf(".dds") !== -1) {
                    cubeMap = new THREE$1.DDSLoader().load(path, texLoadDone);
                } else {
                    cubeMap = THREE$1.ImageUtils.loadTexture(path, THREE$1.SphericalReflectionMapping, onReady);
                    cubeMap.format = THREE$1.RGBFormat;
                }
            } else if (path) {
                //here we assume path is already a texture object
                if (onReady) {
                    onReady(path);
                }
            } else {
                if (onReady) {
                    onReady(null);
                }
            }
            return cubeMap;
        }
    }]);
    return TextureLoader;
}();

"use strict";
var NUM_WORKER_THREADS = isNodeJS() ? 10 : isMobileDevice() ? 2 : 6;
var WORKER_LOAD_GEOMETRY = "LOAD_GEOMETRY";
var WORKER_LOAD_SVF = "LOAD_SVF";
var WORKER_LOAD_SVF_CONTD = "LOAD_SVF_CONTD";
var WORKER_FETCH_TOPOLOGY = "FETCH_TOPOLOGY";
var WORKER_CALCULATE_LOAD_ORDER = "CALCULATE_LOAD_ORDER";
// This limit in MB is how much memory needs to be available
// to load textures. The texture loader tries to squeeze
// all textures into 32MB, so this limit should be larger than that.
var MOBILE_TEXTURE_LIMIT = 50;
var GEOM_PACK_SIZE_FACTOR = 0.7; // Approximate ratio of geometry size to uncompressed pack file size
var MEGA = 1024 * 1024;
// Overhead constants. The total overhead is calculated as
// <#meshes> * MESH_OVERHEAD + <#fragments> * FRAG_OVERHEAD
var MESH_OVERHEAD = 224; // Fixed overhead per mesh
var FRAG_OVERHEAD = 134; // Fixed overhead per fragment
var _meshInfo = {};
var _fragLoadedEvent = {
    type: FRAGMENTS_LOADED_EVENT,
    model: null,
    data: null,
    getFragIds: function getFragIds() {
        if (this.fragIds) return this.fragIds;
        var rm = this.model;
        if (!rm || !this.data || !this.data.meshes) return null;
        var fragIds = this.fragIds = [];
        var packId = this.data.packId;
        var meshIndex = 0;
        var svf = rm.getData();
        var fragments = svf.fragments;
        var meshesLength = this.data.meshes.length;
        for (meshIndex = 0; meshIndex < meshesLength; ++meshIndex) {
            //Find all fragments that instance this mesh
            var meshid = packId + ":" + meshIndex++;
            var fragIndexes = fragments.mesh2frag[meshid];
            if (fragIndexes === undefined) return;
            if (Array.isArray(fragIndexes)) {
                fragIndexes.forEach(function (fragId) {
                    fragIds.push(fragId);
                });
            } else fragIds.push(fragIndexes);
        }
        return fragIds;
    }
};
var fireFragmentsLoadedEvent = function fireFragmentsLoadedEvent(loader, data) {
    _fragLoadedEvent.model = loader.model;
    _fragLoadedEvent.data = data;
    loader.delegate.eventTarget.dispatchEvent(_fragLoadedEvent);
};
// Calculate the memory used by a texture
var calculateTextureSize = function calculateTextureSize(tex) {
    var pixsize = 4; // assume 4 byte pixels.
    switch (tex.format) {
        case THREE$1.AlphaFormat:
            pixsize = 1;
            break;
        case THREE$1.RGBFormat:
            pixsize = 3;
            break;
        case THREE$1.LuminanceFormat:
            pixsize = 1;
            break;
        case THREE$1.LuminanceAlphaFormat:
            pixsize = 2;
            break;
    }
    switch (tex.type) {
        case THREE$1.ShortType:
        case THREE$1.UnsignedShortType:
        case THREE$1.HalfFloatType:
            pixsize *= 2;
            break;
        case THREE$1.IntType:
        case THREE$1.UnsignedIntType:
        case THREE$1.FloatType:
            pixsize *= 4;
            break;
        case THREE$1.UnsignedShort4444Type:
        case THREE$1.UnsignedShort5551Type:
        case THREE$1.UnsignedShort565Type:
            pixsize = 2;
            break;
    }
    var rowsize = pixsize * tex.image.width;
    rowsize += tex.unpackAlignment - 1;
    rowsize -= rowsize % tex.unpackAlignment;
    return tex.image.height * rowsize;
};
/** @constructor */
var SvfLoader = function (_FileLoader) {
    inherits(SvfLoader, _FileLoader);

    function SvfLoader(delegate, config) {
        classCallCheck(this, SvfLoader);

        var _this = possibleConstructorReturn(this, (SvfLoader.__proto__ || Object.getPrototypeOf(SvfLoader)).call(this, delegate, config));

        _this.next_pack = 0;
        _this.loading = false;
        _this.loadedPacksCount = 0;
        _this.tmpMatrix = new THREE$1.Matrix4();
        _this.tmpBox = new THREE$1.Box3();
        _this.fetchingTopology = false;
        _this.loadTime = 0;
        var scope = _this;
        // Supply defaults that load the property database and textures
        if (!_this.delegate.loadPropertyDb) {
            _this.delegate.loadPropertyDb = function (sharedDbPath, model) {
                // In this function "this" is the delegate object
                var svf = model.getData();
                svf.propDbLoader = new PropDbLoader(sharedDbPath, model, scope.delegate);
                svf.propDbLoader.load();
            };
        }
        if (!_this.delegate.loadModelTextures) {
            // In this function "this" is the delegate object
            _this.delegate.loadModelTextures = function (model) {
                TextureLoader.loadModelTextures(scope.delegate, model);
            };
        }
        var memoryOpts = config && config.memory;
        var options = _this.memoryOpts = {
            debug: {}
        };
        if (!isNodeJS()) {
            // Default on demand loading if not node.js
            options.limit = isAndroidDevice() ? 195 : isIOSDevice() ? 150 : 600;
            options.onDemandLoading = true;
            options.pageOutGeometryEnabled = true;
            // Turn on demand loading off if we get a memory configuration without a limit
            // or the limit is 0.
            if (memoryOpts) {
                options.debug = memoryOpts.debug || {};
                var newLimit = memoryOpts.hasOwnProperty("limit") ? memoryOpts.limit : 0;
                if ((newLimit | 0) > 0) {
                    options.limit = newLimit | 0;
                } else if (newLimit == 0) {
                    options.onDemandLoading = false;
                    options.pageOutGeometryEnabled = false;
                    options.debug.force = false;
                } else {
                    exports.logger.warn("Memory limit, " + newLimit + ", is invalid - ignored");
                }
            }
            if (options.onDemandLoading) setMemoryOptimizedLoading(true); // Required for on demand loading
        }
        return _this;
    }

    createClass(SvfLoader, [{
        key: 'dtor',
        value: function dtor() {
            // Cancel all potential process on loading a file.
            // 1. init worker script can be cancelled. 
            // 
            if (this.initWorkerScriptToken) {
                this.initWorkerScriptToken.cancel();
                this.initWorkerScriptToken = null;
                exports.logger.debug("SVF loader dtor: on init worker script.");
            }
            // 2. load model root (aka. svf) can be cancelled. 
            //
            if (this.svfWorker) {
                this.svfWorker.clearAllEventListenerWithIntercept();
                this.svfWorker.terminate();
                this.svfWorker = null;
                exports.logger.debug("SVF loader dtor: on svf worker.");
            }
            if (this.svfLoadOrderWorker) {
                this.svfLoadOrderWorker.terminate();
                this.svfLoadOrderWorker = null;
                exports.logger.debug("SVF loader dtor: on load order worker.");
            }
            // 3. load geometry pack files can be cancelled.
            // 
            if (this.pack_workers) {
                for (var i = 0; i < this.pack_workers.length; i++) {
                    this.pack_workers[i].clearAllEventListenerWithIntercept();
                    this.pack_workers[i].terminate();
                }
                this.pack_workers = null;
                exports.logger.debug("SVF loader dtor: on geom worker.");
            }
            // 4. load property can be cancelled.
            // 
            if (this.svf && this.svf.propDbLoader) {
                this.svf.propDbLoader.dtor();
                this.svf.propDbLoader = null;
            }
            if (this.pagingProxy) {
                this.pagingProxy.dtor();
                this.pagingProxy = null;
            }
            // and clear metadata.
            this.tmpMatrix = null;
            this.tmpBox = null;
            this.next_pack = 0;
            this.loading = false;
            this.loadedPacksCount = 0;
            this.loadTime = 0;
            get(SvfLoader.prototype.__proto__ || Object.getPrototypeOf(SvfLoader.prototype), 'dtor', this).call(this);
        }
    }, {
        key: 'loadFile',
        value: function loadFile(path, options, onDone, onWorkerStart) {
            if (!this.delegate) {
                exports.logger.log("SVF loader was already destructed. So no longer usable.");
                return false;
            }
            if (this.loading) {
                exports.logger.log("Loading of SVF already in progress. Ignoring new request.");
                return false;
            }
            // Mark it as loading now.
            this.loading = true;
            this.delegate.eventTarget.dispatchEvent({ type: FILE_LOAD_STARTED, loader: this });
            var index = path.indexOf('urn:');
            if (index != -1) {
                // Extract urn:adsk.viewing:foo.bar.whateverjunks out of the path URL and bind it to logger.
                // From now on, we can send logs to viewing service, and logs are grouped by urn to make Splunk work.
                path = decodeURIComponent(path);
                var urn = path.substr(index, path.substr(index).indexOf('/'));
                exports.logger.log("Extracted URN: " + urn);
                // Extract urn(just base64 code)
                var _index = urn.lastIndexOf(':');
                this.svfUrn = urn.substr(_index + 1);
            } else {
                this.svfUrn = path;
            }
            this.sharedDbPath = options.sharedPropertyDbPath;
            this.currentLoadPath = path;
            var lastSlash = this.currentLoadPath.lastIndexOf("/");
            if (lastSlash != -1) this.basePath = this.currentLoadPath.substr(0, lastSlash + 1);
            this.acmSessionId = options.acmSessionId;
            this.queryParams = "";
            if (this.acmSessionId) {
                this.queryParams = "acmsession=" + this.acmSessionId;
            }
            this.options = options;
            var scope = this;
            this.initWorkerScriptToken = this.delegate.workerScript.initWorkerScript(function () {
                scope.loadSvfCB(path, options, onDone, onWorkerStart);
            });
            return true;
        }
    }, {
        key: 'loadSvfCB',
        value: function loadSvfCB(path, options, onDone, onWorkerStart) {
            this.t0 = new Date().getTime();
            this.firstPixelTimestamp = null;
            this.failedToLoadSomeGeometryPacks = null;
            this.failedToLoadPacksCount = 0;
            var first = true;
            if (options.doneWhenDownloaded) {
                this.onDone = onDone;
            }
            var scope = this;
            var msg = {
                url: pathToURL(path),
                basePath: this.currentLoadPath,
                objectIds: options.ids,
                globalOffset: options.globalOffset,
                placementTransform: options.placementTransform,
                applyRefPoint: options.applyRefPoint,
                queryParams: this.queryParams,
                bvhOptions: options.bvhOptions || { isWeakDevice: isMobileDevice() },
                applyScaling: options.applyScaling,
                loadInstanceTree: options.loadInstanceTree,
                max_pf_files: 0
            };
            var optLoad = this.memoryOpts.onDemandLoading || !!this.memoryOpts.debug.memoryOptimizedSvfLoading;
            if (optLoad) {
                msg.perfOpt = {
                    memoryOptimizedSvfLoading: optLoad,
                    forceMemoryOptimizedMode: !!this.memoryOpts.debug.forceMemoryOptimizedModeOnSvfLoading
                };
            }
            var w = this.svfWorker = this.delegate.workerScript.createWorkerWithIntercept();
            var onSVFLoad = function onSVFLoad(ew) {
                var cleaner = function cleaner() {
                    if (w) {
                        w.clearAllEventListenerWithIntercept();
                        w.terminate();
                        scope.svfWorker = null;
                        w = null;
                    }
                };
                if (first && onWorkerStart) {
                    first = false;
                    onWorkerStart();
                }
                if (ew.data && ew.data.manifest) {
                    SvfLoader.interceptManifest.call(scope, ew.data.manifest);
                    msg.operation = WORKER_LOAD_SVF_CONTD;
                    msg.manifest = ew.data.manifest;
                    w.doOperation(msg);
                } else if (ew.data && ew.data.svf) {
                    //Decompression is done.
                    var svf = scope.svf = ew.data.svf;
                    if (scope.failedToLoadSomeGeometryPacks) {
                        // Report a warning. It is not a fatal error.
                        if (onDone) {
                            onDone(scope.failedToLoadSomeGeometryPacks, null);
                            delete scope.onDone;
                        }
                        scope.failedToLoadSomeGeometryPacks = null;
                    }
                    scope.onModelRootLoadDone(svf);
                    if (onDone && !options.doneWhenDownloaded) {
                        onDone(null, scope.model);
                    }
                    scope.delegate.eventTarget.dispatchEvent({ type: MODEL_ROOT_LOADED_EVENT, svf: svf, model: scope.model });
                    scope.svf.loadDone = false;
                    var isGltf = false;
                    if (scope.svf.metadata && scope.svf.metadata.gltf) {
                        isGltf = true;
                    }
                    if (!isGltf) {
                        var numGeomPacks = svf.geompacks.length;
                        if (numGeomPacks == 0) {
                            scope.onGeomLoadDone();
                        } else {
                            if (scope.model.getFragmentList().onDemandLoadingEnabled()) {
                                // On demand loading is enabled, then
                                // Defer to launch jobs for loading some geometry packs,
                                // until the viewer really need them.
                                exports.logger.debug("[On Demand Loading]: Enabled.");
                                scope.loadedPacksCount = 0;
                            } else {
                                // On demand loading is disabled, then
                                // Require loading immediately
                                if (numGeomPacks) {
                                    var count = Math.min(numGeomPacks, NUM_WORKER_THREADS);

                                    var _loop = function _loop(i) {
                                        var pf = svf.geompacks[scope.next_pack++];
                                        pf.loading = true;
                                        if (isNodeJS()) {
                                            scope.loadGeometryPack(pf.id, pf.uri);
                                        } else {
                                            (function (pf) {
                                                setTimeout(function () {
                                                    scope.loadGeometryPack(pf.id, pf.uri);
                                                }, i * 200);
                                            })(pf);
                                        }
                                    };

                                    for (var i = 0; i < count; i++) {
                                        _loop(i);
                                    }
                                }
                            }
                        }
                    }
                    if (ew.data.progress == 1) {
                        scope.loading = false;
                        cleaner();
                    }
                    if (!svf.fragments.polygonCounts) svf.fragments.polygonCounts = new Int32Array(svf.fragments.length);
                    // Set bvh to svf, if it is posted with svf together.
                    if (ew.data.bvh) {
                        scope.svf.bvh = ew.data.bvh;
                        scope.model.setBVH(new NodeArray(scope.svf.bvh.nodes, scope.svf.bvh.useLeanNodes), scope.svf.bvh.primitives, scope.options.bvhOptions);
                        scope.delegate.requestRedraw(false);
                    }
                } else if (ew.data && ew.data.bvh) {
                    //Spatial index was done by the worker:
                    if (scope.svf && !scope.svf.bvh) {
                        scope.svf.bvh = ew.data.bvh;
                        scope.model.setBVH(new NodeArray(scope.svf.bvh.nodes, scope.svf.bvh.useLeanNodes), scope.svf.bvh.primitives, scope.options.bvhOptions);
                        scope.delegate.requestRedraw(false);
                    }
                    scope.loading = false;
                    cleaner();
                } else if (ew.data && ew.data.mesh) {
                    //GLTF loader sends meshes from the main loader thread
                    scope.processReceivedMesh(ew.data);
                    if (ew.data.progress === 1) {
                        scope.onGeomLoadDone();
                        scope.loading = false;
                        cleaner();
                    }
                } else if (ew.data && ew.data.progress) {
                    if (ew.data.progress == 1) {
                        scope.loading = false;
                        cleaner();
                    }
                } else if (ew.data && ew.data.error) {
                    scope.loading = false;
                    cleaner();
                    exports.logger.error("Error while processing SVF: " + JSON.stringify(ew.data.error.args));
                    if (onDone) {
                        onDone(ew.data.error, null);
                        delete scope.onDone;
                    }
                } else if (ew.data && ew.data.debug) {
                    exports.logger.debug(ew.data.message);
                } else {
                    scope.delegate.reportError(exports.ErrorCodes.NETWORK_FAILURE, "SVF download failed.");
                    //Download failed.
                    scope.loading = false;
                    cleaner();
                }
            };
            w.addEventListenerWithIntercept(onSVFLoad);
            msg.operation = WORKER_LOAD_SVF;
            msg.interceptManifest = !!SvfLoader.interceptManifest;
            w.doOperation(this.delegate.initLoadContext(msg));
            return true;
        }
    }, {
        key: 'cancelGeometryPackLoading',
        value: function cancelGeometryPackLoading() {
            // Cancel any ongoing geometry pack file loading.
            if (!this.pack_workers || !this.isValid()) {
                return;
            }
            for (var i = 0; i < this.pack_workers.length; i++) {
                if (this.svf) {
                    var _pf = this.geommap[this.pack_workers[i].packId];
                    if (_pf) _pf.loading = false;
                }
                this.pack_workers[i].queued = 0;
                this.pack_workers[i].clearAllEventListenerWithIntercept();
                this.pack_workers[i].terminate();
            }
            this.pack_workers = null;
        }
    }, {
        key: 'loadGeometryPackOnDemand',
        value: function loadGeometryPackOnDemand(packId, inMemory) {
            // If loader is already destructed, do nothing.
            if (!this.svf || !this.isValid()) {
                return true;
            }
            // Do nothing if the geometry pack file is already in loading.
            var pf = this.geommap[packId];
            if (!pf || pf.loading) {
                return true;
            }
            // Record the time on first on demand geometry pack file loading request
            if (!this.t0) {
                this.t0 = new Date().getTime();
            }
            var pp = this.pagingProxy;
            var i = void 0;
            var scope = this;
            // Common handling when a worker is done with a pack file
            function packFileWorkerComplete(worker, packId) {
                worker.queued = 0;
                scope.geommap[packId].loading = false;
                pp.doOnDemandLoadFinished();
            }
            var onMeshLoad = function onMeshLoad(ew) {
                if (ew.data && ew.data.meshes) {
                    var meshes = ew.data.meshes;
                    var mdata = {
                        packId: ew.data.packId,
                        meshIndex: 0,
                        mesh: null
                    };
                    var geomSize = 0;
                    for (var _i = 0; _i < meshes.length; _i++) {
                        var mesh = meshes[_i];
                        if (!mesh) continue;
                        mdata.meshIndex = _i;
                        mdata.mesh = mesh;
                        scope.processReceivedMesh(mdata);
                        if (mdata.geometry) {
                            geomSize += mdata.geometry.byteSize + GEOMETRY_OVERHEAD;
                            mdata.geometry = null;
                        }
                    }
                    pp.onPackFileLoaded(ew.data.packId, ew.data, geomSize / MEGA);
                    fireFragmentsLoadedEvent(scope, ew.data);
                    if (ew.data.progress >= 1.0) {
                        scope.loadedPacksCount++;
                        packFileWorkerComplete(scope.pack_workers[ew.data.workerId], ew.data.packId);
                    }
                } else if (ew.data && ew.data.progress) {
                    scope.pack_workers[ew.data.workerId].queued -= 1;
                    scope.delegate.signalProgress(100 * scope.loadedPacksCount / scope.svf.geompacks.length);
                } else if (ew.data && ew.data.debug) {
                    exports.logger.debug(ew.data.message);
                } else if (ew.data && ew.data.error) {
                    pp.onPackFileLoaded(ew.target.packId, null, 0);
                    packFileWorkerComplete(ew.target, ew.target.packId);
                    ++scope.failedToLoadPacksCount;
                    scope.failedToLoadSomeGeometryPacks = { code: ew.data.error.code, msg: ew.data.error.msg };
                } else {
                    //Download failed.
                    pp.onPackFileLoaded(ew.target.packId, null, 0);
                    packFileWorkerComplete(ew.target, ew.target.packId);
                }
            };
            // Initialize pack workers if it is not ready yet.
            if (!this.pack_workers) {
                this.pack_workers = [];
                var numWorkers = NUM_WORKER_THREADS;
                for (i = 0; i < numWorkers; i++) {
                    var wr = this.delegate.workerScript.createWorkerWithIntercept();
                    wr.addEventListenerWithIntercept(onMeshLoad);
                    wr.queued = 0;
                    this.pack_workers.push(wr);
                }
            }
            //Find the least busy worker
            var which = 0;
            var queued = this.pack_workers[0].queued;
            for (i = 1; i < this.pack_workers.length; i++) {
                if (this.pack_workers[i].queued < queued) {
                    which = i;
                    queued = this.pack_workers[i].queued;
                }
            }
            // If worker is busy queue this reqest for next try.
            if (queued > 1 || pp.preparedPackFilesSize() >= pp.getMemoryLimit()) {
                // All workers are busy, then queue it for next try.
                if (!this.model.addGeomPackMissingLastFrame(packId)) {
                    // If failed to add, it means that it is too many queued.
                    // then restart render.
                    this.delegate.requestRedraw(false);
                    //logger.debug("[On Demand Loading] Re-render on too many geom pack file requests.");
                }
                return false;
            }
            var w = void 0,
                workerId = void 0;
            var path = pf.uri;
            w = this.pack_workers[which];
            w.queued += 2;
            w.packId = packId;
            workerId = which;
            pp.onPackFileLoading(packId);
            pf.loading = true;
            this.svf.partPacksLoadDone = false; // Still loading geometry pack files.
            exports.logger.debug("[On Demand Loading] Loading Geometry Pack file: " + packId);
            //Pass unzip job to the worker
            var reqPath = pathToURL(this.svf.basePath + path);
            var xfer = { "operation": WORKER_LOAD_GEOMETRY,
                "url": reqPath,
                "packId": packId,
                "workerId": workerId,
                "packNormals": this.options.packNormals,
                "createWireframe": this.options.createWireframe,
                "skipAssetCallback": true,
                "queryParams": this.queryParams,
                "inMemory": inMemory };
            w.doOperation(this.delegate.initLoadContext(xfer)); // Send data to our worker.
            return true;
        }
    }, {
        key: 'loadGeometryPack',
        value: function loadGeometryPack(packId, path) {
            var w = void 0;
            var workerId = void 0;
            var i = void 0,
                j = void 0;
            var scope = this;
            // If loader is already destructed, do nothing.
            if (!this.svf || !this.isValid()) {
                return;
            }
            var onMeshLoad = function onMeshLoad(ew) {
                if (ew.data && ew.data.meshes) {
                    var meshes = ew.data.meshes;
                    var mdata = {
                        packId: ew.data.packId,
                        meshIndex: 0,
                        mesh: null
                    };
                    for (var _i2 = 0; _i2 < meshes.length; _i2++) {
                        var mesh = meshes[_i2];
                        if (!mesh) continue;
                        mdata.meshIndex = _i2;
                        mdata.mesh = mesh;
                        scope.processReceivedMesh(mdata);
                    }
                    //Is the worker done loading the geom pack?
                    if (ew.data.progress >= 1.0) {
                        scope.pack_workers[ew.data.workerId].queued -= 1;
                        scope.loadedPacksCount++;
                        scope.delegate.signalProgress(100 * scope.loadedPacksCount / scope.svf.geompacks.length);
                        //Are all workers done?
                        var isdone = true;
                        for (j = 0; j < scope.pack_workers.length; j++) {
                            if (scope.pack_workers[j].queued != 0) {
                                isdone = false;
                                break;
                            }
                        }
                        if (isdone) {
                            for (j = 0; j < scope.pack_workers.length; j++) {
                                scope.pack_workers[j].clearAllEventListenerWithIntercept();
                                scope.pack_workers[j].terminate();
                            }
                            scope.pack_workers = null;
                        }
                        if (scope.loadedPacksCount + scope.failedToLoadPacksCount == scope.svf.geompacks.length) {
                            scope.onGeomLoadDone();
                        }
                    }
                } else if (ew.data && ew.data.progress) {
                    //download is done, queue the next download
                    scope.pack_workers[ew.data.workerId].queued -= 1;
                    if (scope.next_pack < scope.svf.geompacks.length) {
                        var _pf2 = null;
                        while (scope.next_pack < scope.svf.geompacks.length) {
                            _pf2 = scope.svf.geompacks[scope.next_pack++];
                            if (!_pf2.loading) {
                                break;
                            }
                        }
                        if (_pf2 && !_pf2.loading) {
                            _pf2.loading = true;
                            scope.loadGeometryPack(_pf2.id, _pf2.uri);
                        } else {
                            scope.svf.fragments.packIds = null; // not needed anymore
                        }
                    }
                } else if (ew.data && ew.data.debug) {
                    exports.logger.debug(ew.data.message);
                } else if (ew.data && ew.data.error) {
                    ++scope.failedToLoadPacksCount;
                    scope.failedToLoadSomeGeometryPacks = { code: ew.data.error.code, msg: ew.data.error.msg };
                } else {
                    //Download failed.
                    scope.pack_workers[ew.data.workerId].queued -= 2;
                }
            };
            var pw = this.pack_workers;
            if (!pw) {
                pw = this.pack_workers = [];
            }
            //If all workers are busy and we are allowed to create more, then create a new one
            if (pw.length < NUM_WORKER_THREADS) {
                var allBusy = true;
                for (i = 0; i < pw.length; i++) {
                    if (pw[i].queued === 0) {
                        allBusy = false;
                        break;
                    }
                }
                if (allBusy) {
                    var wr = this.delegate.workerScript.createWorkerWithIntercept();
                    wr.addEventListenerWithIntercept(onMeshLoad);
                    wr.queued = 0;
                    pw.push(wr);
                }
            }
            //Find the least busy worker
            var which = 0;
            var queued = pw[0].queued;
            for (i = 1; i < pw.length; i++) {
                if (pw[i].queued < queued) {
                    which = i;
                    queued = pw[i].queued;
                }
            }
            w = pw[which];
            w.queued += 2;
            workerId = which;
            //Pass unzip job to the worker
            var reqPath = pathToURL(this.svf.basePath + path);
            var xfer = { "operation": WORKER_LOAD_GEOMETRY,
                "url": reqPath,
                "packId": parseInt(packId),
                "workerId": workerId,
                "createWireframe": this.options.createWireframe,
                "packNormals": this.options.packNormals,
                "queryParams": this.queryParams };
            w.doOperation(this.delegate.initLoadContext(xfer)); // Send data to our worker.
        }
    }, {
        key: 'processReceivedMesh',
        value: function processReceivedMesh(mdata) {
            //Find all fragments that instance this mesh
            var meshid = mdata.packId + ":" + mdata.meshIndex;
            var svf = this.svf;
            var fragments = svf.fragments;
            var rm = this.model;
            var fragIndexes = fragments.mesh2frag[meshid];
            if (fragIndexes === undefined) {
                exports.logger.warn("Mesh " + meshid + " was not referenced by any fragments.");
                return;
            }
            if (!Array.isArray(fragIndexes)) fragIndexes = [fragIndexes];
            //Convert the received mesh to THREE buffer geometry
            BufferGeometryUtils.meshToGeometry(mdata);
            mdata.geometry.packId = mdata.packId;
            mdata.geometry.meshIndex = mdata.meshIndex;
            var numInstances = fragIndexes.length;
            //Reuse previous index of this geometry, if available
            var idx = rm.getFragmentList().getGeometryId(fragIndexes[0]);
            //let geomId = 
            rm.getGeometryList().addGeometry(mdata.geometry, numInstances, idx);
            // This is to record how many instances this geometry has,
            // and the number of instances have been rendered in one frame.
            this.pagingProxy && this.pagingProxy.onProcessReceivedMesh(mdata.geometry, numInstances);
            var ib = mdata.geometry.attributes['index'].array || mdata.geometry.ib;
            var polyCount = ib.length / 3;
            //For each fragment, add a mesh instance to the renderer
            for (var i = 0; i < fragIndexes.length; i++) {
                var fragId = 0 | fragIndexes[i];
                //We get the matrix from the fragments and we set it back there
                //with the activateFragment call, but this is to maintain the
                //ability to add a plain THREE.Mesh -- otherwise it could be simpler
                rm.getFragmentList().getOriginalWorldMatrix(fragId, this.tmpMatrix);
                var materialId = fragments.materials[fragId].toString();
                if (fragments.polygonCounts) fragments.polygonCounts[fragId] = polyCount;
                var geometry = mdata.geometry;
                _meshInfo.geometry = geometry;
                _meshInfo.material = this.delegate.matman.setupMaterial(this.model, geometry, materialId);
                _meshInfo.matrix = this.tmpMatrix;
                _meshInfo.isLine = geometry.isLines;
                _meshInfo.isWideLine = geometry.isWideLines;
                _meshInfo.isPoint = geometry.isPoints;
                _meshInfo.is2d = geometry.is2d;
                //If there is a placement transform, we tell activateFragment to also recompute the
                //world space bounding box of the fragment from the raw geometry model box, for a tighter
                //fit compared to what we get when loading the fragment list initially.
                rm.activateFragment(fragId, _meshInfo, !!svf.placementTransform);
            }
            if (!this.model.getFragmentList().onDemandLoadingEnabled()) {
                //don't need this mapping anymore.
                fragments.mesh2frag[meshid] = null;
            }
            //Repaint and progress reporting
            fragments.numLoaded += fragIndexes.length;
            //repaint every once in a while -- more initially, less as the load drags on.
            var geomList = rm.getGeometryList();
            if (geomList.geomPolyCount > svf.nextRepaintPolys) {
                //logger.log("num loaded " + numLoaded);
                this.firstPixelTimestamp = this.firstPixelTimestamp || Date.now();
                svf.numRepaints++;
                svf.nextRepaintPolys += 10000 * Math.pow(1.5, svf.numRepaints);
                this.delegate.requestRedraw(false);
            }
        }
        //Some insane files come without any material reuse
        //which means we end up with ten of thousands of material objects
        //that are all the same. Create a re-mapping that gives a single ID
        //for all material IDs whose materials are duplicates
        /* currently not used
        function deduplicateMaterials(svf, logger) {
             let mats = svf.materials.materials;
             let dedup = {};
            let remap = [];
            let count = 0;
            let ucount = 0;
             for (let p in mats) {
                 let matIdx = parseInt(p);
                let hash = JSON.stringify(mats[p]);
                 let idx = dedup[hash];
                 if (idx === undefined) {
                    remap[matIdx] = matIdx;
                    dedup[hash] = matIdx;
                    ucount++;
                } else {
                    remap[matIdx] = idx;
                    mats[p].duplicateOf = idx;
                }
                 count++;
            }
             logger.log("Total mats: " + count + " Unique mats:" + ucount);
             let fmats = svf.fragments.materials;
            for (let i=0; i<fmats.length; i++) {
                fmats[i] = remap[fmats[i]];
            }
             return remap;
        }
        */

    }, {
        key: 'onModelRootLoadDone',
        value: function onModelRootLoadDone(svf) {
            svf.geomMemory = 0;
            svf.fragments.numLoaded = 0;
            svf.gpuNumMeshes = 0;
            svf.gpuMeshMemory = 0;
            svf.nextRepaintPolys = 0;
            svf.numRepaints = 0;
            svf.urn = this.svfUrn;
            svf.acmSessionId = this.acmSessionId;
            svf.basePath = this.basePath;
            svf.loadOptions = this.options;
            //let tM = Date.now();
            //deduplicateMaterials(svf, logger);
            var t1 = Date.now();
            this.loadTime += t1 - this.t0;
            exports.logger.log("SVF load: " + (t1 - this.t0));
            //logger.log("Material dedup: " + (t1 - tM));
            // Create the API Model object and its render proxy
            var model = this.model = new this.delegate.model(svf);
            model.loader = this;
            // Let's set the options through for each model that control how memory saving mode start,
            // which decide how to load geometry pack files, and whether paging out if needed.
            // And assume the performance tuning options passed through viewer's config.
            var memoryOpts = this.memoryOpts;
            // So, for now do not support on paging for multiple models. 
            if (this.delegate.renderScene && this.delegate.renderScene.length > 0) {
                // If already a model loaded into viewer, then disable paging for the other ones.
                memoryOpts.pageOutGeometryEnabled = false;
            }
            var geommap = this.geommap = {}; // Map packids to geompacks objects
            // Calculate the size of pack files and the geometry in them
            var meshCount = Object.keys(svf.fragments.mesh2frag).length;
            var fragCount = svf.fragments.length;
            var overhead = (meshCount * MESH_OVERHEAD + fragCount * FRAG_OVERHEAD) / MEGA;
            var totalGeomSize = 0;
            svf.geompacks.forEach(function (pf) {
                // If the geometry worker doesn't give us a geom size, then supply an estimate
                if (!pf.hasOwnProperty("geomSize")) pf.geomSize = pf.usize * GEOM_PACK_SIZE_FACTOR;
                pf.usize /= MEGA;
                pf.geomSize /= MEGA;
                totalGeomSize += pf.geomSize;
                geommap[parseInt(pf.id)] = pf;
            });
            // On mobile devices the memory used by the GPU is take from system memory, so we need
            // to include that memory in our estimate of the size of the model. This is also true
            // for laptops and other systems that have an integrated GPU, but we only include it
            // for mobile devices.
            var gpuSize = isMobileDevice() ? Math.min(totalGeomSize, GPU_MEMORY_LIMIT / MEGA) : 0;
            totalGeomSize += overhead;
            // The estimated total geom size is the size of the geometry plus
            // the amount of memory needed to hold the uncompressed pack files in workers
            memoryOpts.totalGeomSize = totalGeomSize;
            memoryOpts.overheadSize = overhead;
            // On demand loading will be controlled by two factors.
            // 1. A global switch that enable/disable this behavior.
            // 2. The size of the model.
            if (memoryOpts.onDemandLoading) {
                if (totalGeomSize + gpuSize < memoryOpts.limit && !memoryOpts.debug.force) memoryOpts.onDemandLoading = false;else this.pagingProxy = new SvfPagingProxy(this, memoryOpts);
            }
            model.initialize(this.pagingProxy);
            var scope = this;
            function onLoaded(ew) {
                if (!scope.isValid() || !scope.pagingProxy) return;
                scope.pagingProxy.onLoadOrderCalculated(ew.data);
            }
            // If this is an svf file, then start the worker that calculates the load order
            if (this.model.getFragmentList().onDemandLoadingEnabled() && svf.fragments.boxes && svf.fragments.packIds) {
                // Create the worker and send the boxes and packids to it.
                this.svfLoadOrderWorker = this.delegate.workerScript.createWorker();
                this.svfLoadOrderWorker.addEventListener('message', onLoaded, false);
                this.svfLoadOrderWorker.doOperation({ operation: WORKER_CALCULATE_LOAD_ORDER,
                    fragments: { boxes: svf.fragments.boxes, packIds: svf.fragments.packIds }
                });
                this.model.setUUID(svf.urn);
            }
            //For 3D models, we can start loading the property database as soon
            //as we know the fragment list which contains the fragId->dbId map.
            //We would not load property db when we are on mobile device AND on demand loading is on (which
            //implies the model is not 'normal' in terms of its size.). This is only a temp solution that
            //allow big models loads on mobile without crash. Without property db loading selection could break.
            var shouldLoadPropertyDb = !(this.model.getFragmentList().onDemandLoadingEnabled() && isMobileDevice());
            if (shouldLoadPropertyDb && !this.options.skipPropertyDb) {
                this.delegate.loadPropertyDb(this.sharedDbPath, this.model);
            } else {
                // Not loading the property database, supply a flat dbid to fragment map
                this.svf.fragmentMap = new DbidFragmentMap(this.svf.fragments.fragId2dbId);
            }
            var numMaterials = this.convertMaterials(model);
            this.t0 = t1;
            //The BBox object loses knowledge of its
            //type when going across the worker thread boundary...
            svf.bbox = new THREE$1.Box3().copy(svf.bbox);
            if (svf.modelBox) svf.modelBox = new THREE$1.Box3().copy(svf.modelBox);
            if (svf.refPointTransform) {
                svf.refPointTransform = new LmvMatrix4(true).copy(svf.refPointTransform);
            }
            if (svf.placementTransform) {
                svf.placementTransform = new LmvMatrix4(true).copy(svf.placementTransform);
            }
            //Camera vectors also lose their prototypes when they
            //cross the thread boundary...
            if (svf.cameras) {
                for (var i = 0; i < svf.cameras.length; i++) {
                    var camera = svf.cameras[i];
                    camera.position = new THREE$1.Vector3().copy(camera.position);
                    camera.target = new THREE$1.Vector3().copy(camera.target);
                    camera.up = new THREE$1.Vector3().copy(camera.up);
                    // We have a case of a camera coming in with Nans for position and target. Not sure what to do in that case.
                    if (!isFinite(camera.position.x + camera.position.y + camera.position.z + camera.target.x + camera.target.y + camera.target.z + camera.up.x + camera.up.y + camera.up.z)) {
                        // Some coordinate in position, target or up is junk. Scrap them. Put the target at
                        // the center of the bounding box and the position outside of the bounding box.
                        camera.target = svf.bbox.center();
                        camera.position.copy(camera.target);
                        camera.position.z += svf.bbox.max.z - svf.bbox.min.z;
                        camera.up = { x: 0, y: 1, z: 0 };
                    }
                    if (!isFinite(camera.aspect)) {
                        camera.aspect = 1;
                    }
                    if (!isFinite(camera.fov)) {
                        camera.fov = 90;
                    }
                    if (!isFinite(camera.orthoScale)) {
                        camera.orthoScale = 1;
                    }
                }
            }
            //If the textures are likely to come from the Protein CDN
            //load them in parallel with the geometry packs. Don't load
            // Prism and Protein textures here, before we know how much
            // memory we have to hold them.
            if (svf.proteinMaterials && ViewingService.endpoint.PROTEIN_ROOT && ViewingService.endpoint.PRISM_ROOT && !(memoryOpts.onDemandLoading && isMobileDevice())) {
                this.delegate.loadModelTextures(this.model);
            }
            exports.logger.log("scene bounds: " + JSON.stringify(svf.bbox));
            var metadataStats = {
                category: "metadata_load_stats",
                urn: svf.urn,
                has_topology: !!svf.topologyPath,
                has_animations: !!svf.animations,
                cameras: svf.cameras ? svf.cameras.length : 0,
                lights: svf.lights ? svf.lights.length : 0,
                materials: numMaterials,
                is_mobile: isMobileDevice()
            };
            exports.logger.track(metadataStats);
            this.delegate.signalProgress(5);
            this.delegate.requestRedraw(false);
        }
    }, {
        key: 'calculateLoadOrder',
        value: function calculateLoadOrder(id, camera, pixelCullingThreshold) {
            if (!this.svfLoadOrderWorker) return false;
            var cvtcam = {
                projectionMatrix: { elements: camera.projectionMatrix.elements },
                matrixWorldInverse: { elements: camera.matrixWorldInverse.elements },
                aspect: camera.aspect,
                position: { x: camera.position.x, y: camera.position.y, z: camera.position.z },
                clientWidth: camera.clientWidth,
                clientHeight: camera.clientHeight
            };
            var msg = {
                operation: WORKER_CALCULATE_LOAD_ORDER,
                id: id,
                camera: cvtcam,
                pixelCullingThreshold: pixelCullingThreshold
            };
            this.svfLoadOrderWorker.doOperation(msg);
            return true;
        }
    }, {
        key: 'convertMaterials',

        /**
         * Converts from SVF materials json to THREE.js materials and adds them to the MaterialManager
         * @param {RenderModel} model
         */
        value: function convertMaterials(model) {
            var matman = this.delegate.matman;
            var svf = this.svf;
            var totalAdded = 0;
            var p = void 0;
            if (!svf.materials) {
                return totalAdded;
            }
            if (svf.gltfMaterials) {
                var gltfmats = svf.materials["materials"];
                for (p in gltfmats) {
                    var gltfMat = gltfmats[p];
                    var phongMat = MaterialConverter.convertMaterialGltf(gltfMat, svf);
                    var matName = matman._getMaterialHash(model, p);
                    matman.addMaterial(matName, phongMat, false);
                    totalAdded++;
                }
                return totalAdded;
            }
            // Get outer Protein materials block.
            // The way this works: there is always (supposed to be) a Materials.json file in SVF. This
            // is put into svf.materials["materials"]. There is also, optionally, a ProteinMaterials.json
            // file, read into svf.proteinMaterials["materials"]. We look through the Protein materials
            // (if present) and see which ones we can interpret (currently only PRISM materials). If we
            // can interpret it, great. Otherwise, we use the Materials.json file's version, which is
            // (always) a SimplePhong material.
            var mats = svf.materials["materials"];
            var prismmats = svf.proteinMaterials ? svf.proteinMaterials["materials"] : null;
            for (p in mats) {
                var isPrism = prismmats && prismmats[p] && MaterialConverter.isPrismMaterial(prismmats[p]);
                //If the definition is prism, use the prism object.
                var matObj = isPrism ? prismmats[p] : mats[p];
                matman.convertOneMaterial(model, matObj, p);
                totalAdded++;
            }
            return totalAdded;
        }
    }, {
        key: 'makeBVH',
        value: function makeBVH(svf) {
            var t0 = performance.now();
            var mats = svf.materials ? svf.materials["materials"] : null;
            svf.bvh = new BVHBuilder(svf.fragments, mats);
            svf.bvh.build(this.options.bvhOptions || { isWeakDevice: isMobileDevice() });
            var t1 = performance.now();
            exports.logger.log("BVH build time: " + (t1 - t0));
        }
    }, {
        key: 'onDemandGeomLoadDone',
        value: function onDemandGeomLoadDone() {
            // Only check to load textures once.
            if (!this.svf.loadDone) {
                // Launch the texture loads only on those materials that are required by current rendered geometries.
                if (!this.svf.proteinMaterials || !ViewingService.endpoint.PROTEIN_ROOT || !ViewingService.endpoint.PRISM_ROOT || isMobileDevice()) {
                    if (isMobileDevice()) {
                        // If we are on a mobile device, then we will check the memory used
                        // to see if we think there may be enough to load textures.
                        // Get the memory limit from the renderScene, which can hold multiple models. If
                        // we don't have a renderScene to use, just use the model to get the memory limit.
                        var info = this.delegate.renderScene ? this.delegate.renderScene.getMemoryInfo() : this.model.getMemoryInfo();
                        // If we can't get the info, then don't load the textures.
                        if (info != null) {
                            // If the effectiveLimit is larger than the limit, then the model has
                            // so many fragments, that we don't think we can restrict memory to
                            // the requested limit. This means memory should be really tight and
                            // we won't load the textures. If the loaded memory size if too close
                            // to the limit, then don't load the texture.
                            if (info.effectiveLimit <= info.limit && info.limit - info.loaded > MOBILE_TEXTURE_LIMIT) {
                                // Listen for the textures loaded event
                                var callback = function (e) {
                                    this.delegate.eventTarget.removeEventListener(TEXTURES_LOADED_EVENT, callback);
                                    // Calculate the size of textures used by this model
                                    var size = 0;
                                    this.delegate.matman.enumTextures(this.model, function (tex) {
                                        if (tex) {
                                            size += calculateTextureSize(tex);
                                        }
                                    });
                                    // Adjust the limit in the SvfPagingProxy.
                                    size /= MEGA;
                                    this.pagingProxy.options.limit -= size;
                                }.bind(this);
                                // When all of the textures are loaded, adjust the memory limit
                                this.delegate.eventTarget.addEventListener(TEXTURES_LOADED_EVENT, callback);
                                // Load the textures
                                this.delegate.loadModelTextures(this.model);
                            }
                        }
                    } else {
                        // If we aren't on a mobile device, then load the textures.
                        this.delegate.loadModelTextures(this.model);
                    }
                }
            }
            this.svf.loadDone = true;
            // Time for loading part of the on-demanded geometries.
            var t1 = Date.now();
            var msg = "[On Demand Loading] On demand requested geometries load time: " + (t1 - this.t0);
            exports.logger.log(msg);
            // Track the on demand geom load stats.
            var modelStats = {
                category: "on_demand_geom_load_stats",
                is_f2d: false,
                has_prism: this.delegate.matman.hasPrism,
                load_time: t1 - this.t0,
                geometry_size: this.model.getGeometryList().geomMemory,
                meshes_count: this.model.getGeometryList().geoms.length,
                fragments_count: this.model.getFragmentList().getCount(),
                load_pack_count: this.loadedPacksCount,
                urn: this.svfUrn
            };
            exports.logger.track(modelStats);
            // TODO: send recorded assets to ios. 
            // clear the start time, which can be set again if on demand loading geometry again.
            this.t0 = null;
            function sendMessage(data) {
                var aMessage = { 'command': 'assets', data: data };
                if (!isNodeJS() && window.webkit.messageHandlers.callbackHandler) window.webkit.messageHandlers.callbackHandler.postMessage(aMessage);
            }
            if (exports.assets) {
                // Callback to ios.
                if (!isNodeJS() && window.webkit) {
                    sendMessage(exports.assets);
                    clearAssets();
                }
            }
            this.loadedPacksCount = 0;
            this.svf.partPacksLoadDone = true;
            this.delegate.eventTarget.dispatchEvent({ type: GEOMETRY_DOWNLOAD_COMPLETE, model: this.model, memoryLimited: true });
            if (this.onDone) {
                this.onDone(null, this.model);
                delete this.onDone;
            }
        }
    }, {
        key: 'onGeomLoadDone',
        value: function onGeomLoadDone() {
            this.svf.loadDone = true;
            //launch the texture loads in case that was not done already
            if (!this.svf.proteinMaterials || !ViewingService.endpoint.PROTEIN_ROOT || !ViewingService.endpoint.PRISM_ROOT) {
                this.delegate.loadModelTextures(this.model);
            }
            // We need to keep a copy of the original fragments
            // transforms in order to restore them after explosions, etc.
            // the rotation/scale 3x3 part.
            // TODO: consider only keeping the position vector and throwing out
            //
            //delete this.svf.fragments.transforms;
            // Release that won't be used. the on demand loading won't call this anyway.
            this.svf.fragments.entityIndexes = null;
            this.svf.fragments.mesh2frag = null;
            var t1 = Date.now();
            var msg = "Fragments load time: " + (t1 - this.t0);
            this.loadTime += t1 - this.t0;
            var firstPixelTime = this.firstPixelTimestamp - this.t0;
            msg += ' (first pixel time: ' + firstPixelTime + ')';
            //If there is a post-transform, the BVH has to be computed after
            //all the world transforms/boxes are updated
            if (!this.svf.bvh || this.svf.placementTransform) {
                this.makeBVH(this.svf);
                this.model.setBVH(this.svf.bvh.nodes, this.svf.bvh.primitives, this.options.bvhOptions);
                this.delegate.requestRedraw(false);
            }
            exports.logger.log(msg);
            // Run optional consolidation step
            if (this.options.useConsolidation && this.delegate.webGLRenderer) this.model.consolidate(this.delegate.matman, this.options.consolidationMemoryLimit, this.delegate.webGLRenderer);
            var modelStats = {
                category: "model_load_stats",
                is_f2d: false,
                has_prism: this.delegate.matman.hasPrism,
                load_time: this.loadTime,
                geometry_size: this.model.getGeometryList().geomMemory,
                meshes_count: this.model.getGeometryList().geoms.length,
                fragments_count: this.model.getFragmentList().getCount(),
                urn: this.svfUrn
            };
            if (firstPixelTime > 0) {
                modelStats['first_pixel_time'] = firstPixelTime; // time [ms] from SVF load to first geometry rendered
            }
            exports.logger.track(modelStats);
            function sendMessage(data) {
                var aMessage = { 'command': 'assets', data: data };
                if (!isNodeJS() && window.webkit.messageHandlers.callbackHandler) window.webkit.messageHandlers.callbackHandler.postMessage(aMessage);
            }
            if (exports.assets) {
                // Callback to ios.
                if (!isNodeJS() && window.webkit) {
                    sendMessage(exports.assets);
                    clearAssets();
                }
            }
            this.currentLoadPath = null;
            this.delegate.eventTarget.dispatchEvent({ type: GEOMETRY_DOWNLOAD_COMPLETE, model: this.model, memoryLimited: false });
            if (this.onDone) {
                this.onDone(null, this.model);
                delete this.onDone;
            }
        }
    }, {
        key: 'fetchTopologyFile',
        value: function fetchTopologyFile(fullpath, onComplete) {
            if (this.fetchingTopology) return;
            this.fetchingTopology = true;
            var ww = this.delegate.workerScript.createWorkerWithIntercept();
            ww.addEventListenerWithIntercept(onTopology);
            var msg = {
                path: fullpath,
                queryParams: this.queryParams
            };
            var t0 = new Date().getTime();
            var t1 = void 0,
                t2 = void 0,
                timeSpan = void 0;
            exports.logger.log('Fetching topology file...');
            msg.operation = WORKER_FETCH_TOPOLOGY;
            ww.doOperation(this.delegate.initLoadContext(msg));
            var that = this;
            function onTopology(workerEvent) {
                // Status check
                if (workerEvent.data['status-topology']) {
                    t1 = new Date().getTime();
                    timeSpan = Math.round((t1 - t0) / 1000);
                    exports.logger.log('Topology file downloaded. (' + timeSpan + ' seconds). Processing...');
                    return;
                }
                // Done processing.
                var topoData = workerEvent.data['fetch-topology'];
                if (topoData) {
                    t2 = new Date().getTime();
                    timeSpan = Math.round((t2 - t1) / 1000);
                    if (topoData.topology) {
                        exports.logger.log('Topology file processed successfully! (' + timeSpan + ' seconds).');
                    } else {
                        exports.logger.log('Topology file processed, but an error ocurred. (' + timeSpan + ' seconds).');
                    }
                    onComplete(topoData);
                    that.fetchingTopology = false;
                    ww.clearAllEventListenerWithIntercept();
                    ww.terminate();
                    ww = null;
                }
            }
        }
    }, {
        key: 'is3d',
        value: function is3d() {
            return true;
        }
    }]);
    return SvfLoader;
}(FileLoader);
/**
 * Define this to manipulate the manifest before it is used.
 * Must be either undefined or a function that takes exactly one argument, the manifest.
 *
 * I.e.: SvfLoader.interceptManifest = function(manifest) { <your code> };
 *
 */
SvfLoader.interceptManifest = undefined;

var WorkerMain = function () {
    function WorkerMain() {
        classCallCheck(this, WorkerMain);

        this._workers = new Map();
    }

    createClass(WorkerMain, [{
        key: "dispatch",
        value: function dispatch(loadContext) {
            if (!loadContext.hasOwnProperty('operation')) {
                return;
            }
            var target = this._workers.get(loadContext.operation);
            if (!target) return;
            //Initialize the path that contains the requested
            //file. It's the root for other relative paths referenced
            //by the base file.
            loadContext.basePath = "";
            if (loadContext.url) {
                var lastSlash = loadContext.url.lastIndexOf("/");
                if (lastSlash != -1) loadContext.basePath = loadContext.url.substr(0, lastSlash + 1);
            }
            // Create the default failure callback.
            //
            loadContext.raiseError = function () {
                loadContext.worker.raiseError.apply(loadContext.worker, arguments);
            };
            loadContext.onFailureCallback = ViewingService.defaultFailureCallback.bind(loadContext);
            target.doOperation(loadContext);
        }
    }, {
        key: "register",
        value: function register(operation, worker) {
            this._workers.set(operation, worker);
        }
    }, {
        key: "unregister",
        value: function unregister(operation) {
            this._workers.delete(operation);
        }
    }]);
    return WorkerMain;
}();
var workerMain = new WorkerMain();

function loadAsyncResource(loadContext, resourcePath, responseType, callback) {
    ViewingService.getItem(loadContext, resourcePath, callback, loadContext.onFailureCallback, { asynchronous: true,
        responseType: responseType || "arraybuffer"
    });
}
/* eslint-disable no-invalid-this */
function setFromArray(array, offset) {
    this.min.x = array[offset];
    this.min.y = array[offset + 1];
    this.min.z = array[offset + 2];
    this.max.x = array[offset + 3];
    this.max.y = array[offset + 4];
    this.max.z = array[offset + 5];
}
function copyToArray(array, offset) {
    array[offset] = this.min.x;
    array[offset + 1] = this.min.y;
    array[offset + 2] = this.min.z;
    array[offset + 3] = this.max.x;
    array[offset + 4] = this.max.y;
    array[offset + 5] = this.max.z;
}
/* eslint-enable no-invalid-this */
function OtgFragInfo(data, placementWithOffset, placementTransform, globalOffset) {
    var byteStride = data[1] << 16 | data[0];
    //var version = data[3] << 16 | data[2];
    if (!byteStride) byteStride = 7 * 4;
    this.boxStride = byteStride / 4;
    this.count = data.byteLength / byteStride - 1;
    if (this.count) {
        //make views directly into the first data record (skipping the header record)
        this.boxes = new Float32Array(data.buffer, byteStride);
        this.flags = new Int32Array(data.buffer, byteStride);
        //apply placement transform if given
        var boxes = this.boxes;
        if (placementTransform) {
            var tmpBox = new LmvBox3();
            var offset = 0;
            for (var i = 0; i < this.count; i++, offset += this.boxStride) {
                setFromArray.call(tmpBox, boxes, offset);
                tmpBox.applyMatrix4(placementWithOffset); //this will apply both placement and global offset at once
                copyToArray.call(tmpBox, boxes, offset);
            }
        } else if (globalOffset && (globalOffset.x || globalOffset.y || globalOffset.z)) {
            //Faster code path when we only have global offset and no placement transform
            var offset = 0;
            for (var i = 0; i < this.count; i++, offset += this.boxStride) {
                boxes[offset] -= globalOffset.x;
                boxes[offset + 1] -= globalOffset.y;
                boxes[offset + 2] -= globalOffset.z;
                boxes[offset + 3] -= globalOffset.x;
                boxes[offset + 4] -= globalOffset.y;
                boxes[offset + 5] -= globalOffset.z;
            }
        }
    }
    this.hasPolygonCounts = true;
    this.wantSort = false;
}
OtgFragInfo.prototype.getCount = function () {
    return this.count;
};
OtgFragInfo.prototype.isTransparent = function (i) {
    var flags = this.flags[i * this.boxStride + 6];
    return !!(flags >> 24);
};
OtgFragInfo.prototype.getPolygonCount = function (i) {
    var flags = this.flags[i * this.boxStride + 6];
    return flags & 0xffffff;
};
function doLoadOtgBvh(loadContext) {
    //TODO: process bboxes progressively instead of doing it once the whole file is in.
    if (loadContext.fragments_extra) {
        loadAsyncResource(loadContext, loadContext.fragments_extra, "", function (data) {
            if (!data || !data.length) {
                return;
            }
            //Build the R-Tree
            //var t0 = performance.now();
            var finfo = new OtgFragInfo(data, loadContext.placementWithOffset, loadContext.placementTransform, loadContext.globalOffset);
            if (finfo.count) {
                var tmpbvh = new BVHBuilder(null, null, finfo);
                tmpbvh.build(loadContext.bvhOptions);
                var bvh = {
                    nodes: tmpbvh.nodes.getRawData(),
                    primitives: tmpbvh.primitives
                };
                //var t1 = performance.now();
                //console.log("BVH build time:" + (t1 - t0));
                loadContext.worker.postMessage({ bvh: bvh }, [bvh.nodes, bvh.primitives.buffer]);
            }
        });
    }
}
function doLoadOtgMats(loadContext) {}
workerMain.register("LOAD_OTG_BVH", { doOperation: doLoadOtgBvh });
workerMain.register("LOAD_OTG_MATS", { doOperation: doLoadOtgMats });

"use strict";

function getUnitScale(unit) {
    //Why are translators not using standard strings for those?!?!?!?
    switch (unit) {
        case 'meter':
        case 'meters':
        case 'm':
            return 1.0;
        case 'feet and inches':
        case 'foot':
        case 'feet':
        case 'ft':
            return 0.3048;
        case 'inch':
        case 'inches':
        case 'in':
            return 0.0254;
        case 'centimeter':
        case 'centimeters':
        case 'cm':
            return 0.01;
        case 'millimeter':
        case 'millimeters':
        case 'mm':
            return 0.001;
        default:
            return 1.0;
    }
}
function isIdentity(mtx) {
    var e = mtx.elements;
    for (var i = 0; i < 4; i++) {
        for (var j = 0; j < 4; j++) {
            if (i === j) {
                if (e[i * 4 + j] !== 1) return false;
            } else {
                if (e[i * 4 + j] !== 0) return false;
            }
        }
    }
    return true;
}
function derivePlacementTransform(svf, loadContext) {
    // We now will apply overall model transforms, following the following logic:
    //    1) placementTransform = options.placementTransform);
    //    2) placementTransform = placementTransform.multiply(scalingTransform);
    //    3) placementTransform = placementTransform.multiply(refPointTransform);
    // This is for aggregation scenarios, where multiple models are loaded into the scene
    // In such scenarios the client will most probably manually override the model units
    //First, take the input placement transform as is (could be null).
    svf.placementTransform = loadContext.placementTransform;
    // If requested in the load options, apply scaling from optional 'from' to 'to' units.
    // If unpecified, then units will be read from the models metadata.
    // * usage overloads
    //      options.appyScaling: { from: 'ft', to: 'm' }
    //      options.appyScaling: 'm'   ( equivalent to { to: 'm' })
    // * this is aimed at multiple 3D model situations where models potentialy have different units, but
    //   one  doesn't up-front know what these units are.It also allows overriding of such units.
    // * Model methods: getUnitString , getUnitScale &  getDisplayUnit will be automatically return corrected values
    //   as long as there are no additional options.placementTransform scalings applied.
    if (loadContext.applyScaling) {
        // default 'from' & 'to'  units are from metadata, or 'm' not present
        var scalingFromUnit = 'm';
        if (svf.metadata["distance unit"]) {
            scalingFromUnit = svf.metadata["distance unit"]["value"];
        }
        svf.scalingUnit = scalingFromUnit;
        if ('object' === _typeof(loadContext.applyScaling)) {
            if (loadContext.applyScaling.from) {
                scalingFromUnit = loadContext.applyScaling.from;
            }
            if (loadContext.applyScaling.to) {
                svf.scalingUnit = loadContext.applyScaling.to;
            }
        } else {
            svf.scalingUnit = loadContext.applyScaling;
        }
        // Work out overall desired scaling factor.
        var scalingFactor = getUnitScale(scalingFromUnit) / getUnitScale(svf.scalingUnit);
        if (1 != scalingFactor) {
            var placementS = new LmvMatrix4(true);
            var scalingTransform = new LmvMatrix4(true);
            scalingTransform.elements[0] = scalingFactor;
            scalingTransform.elements[5] = scalingFactor;
            scalingTransform.elements[10] = scalingFactor;
            if (loadContext.placementTransform) {
                // There may well already be a placementTransform from previous options/operations.
                placementS.copy(loadContext.placementTransform);
            }
            svf.placementTransform = loadContext.placementTransform = placementS.multiply(scalingTransform);
        }
    }
    //Is there extra transform information specified in the metadata?
    //This is important when aggregating Revit models from the same Revit
    //project into the same scene, because Revit SVFs use RVT internal coordinates, which
    //need extra transform to get into the world space.
    var refPointTransform = svf.metadata && svf.metadata['custom values'] && svf.metadata['custom values'].refPointTransform;
    if (refPointTransform) {
        // New style info: pre-calculated transform
        svf.refPointTransform = new LmvMatrix4(true);
        var m = svf.refPointTransform.elements;
        m[0] = refPointTransform[0];
        m[1] = refPointTransform[1];
        m[2] = refPointTransform[2];
        m[4] = refPointTransform[3];
        m[5] = refPointTransform[4];
        m[6] = refPointTransform[5];
        m[8] = refPointTransform[6];
        m[9] = refPointTransform[7];
        m[10] = refPointTransform[8];
        m[12] = refPointTransform[9];
        m[13] = refPointTransform[10];
        m[14] = refPointTransform[11];
    } else {
        // Legacy info: position and angle
        var refPointLMV = svf.metadata && svf.metadata.georeference && svf.metadata.georeference.refPointLMV;
        var angleToTrueNorth = svf.metadata && svf.metadata["custom values"] && svf.metadata["custom values"].angleToTrueNorth;
        var angle = angleToTrueNorth ? Math.PI / 180.0 * angleToTrueNorth : 0;
        if (refPointLMV || angle) {
            //Here we convert the reference point and rotation angles
            //to a simple 4x4 transform for easier use and application later.
            svf.refPointTransform = new LmvMatrix4(true);
            var m = svf.refPointTransform.elements;
            if (angle) {
                m[0] = m[5] = Math.cos(angle);
                m[1] = -Math.sin(angle);
                m[4] = Math.sin(angle);
            }
            if (refPointLMV) {
                m[12] = refPointLMV[0];
                m[13] = refPointLMV[1];
                m[14] = refPointLMV[2];
            }
        }
    }
    //If request in the load options, apply the reference point transform when loading the model
    if (loadContext.applyRefPoint && svf.refPointTransform) {
        var placement = new LmvMatrix4(true);
        //Normally we expect the input placement transform to come in as identity in case
        //we have it specified in the georef here, but, whatever, let's be thorough for once.
        if (loadContext.placementTransform) placement.copy(loadContext.placementTransform);
        placement.multiply(svf.refPointTransform);
        svf.placementTransform = loadContext.placementTransform = placement;
    }
    if (svf.placementTransform && isIdentity(svf.placementTransform)) svf.placementTransform = null;
    return svf.placementTransform;
}
function initPlacement(svf, loadContext) {
    if (!svf.metadata) return;
    //Retrieve world bounding box
    var bbox = svf.metadata["world bounding box"];
    var min = new LmvVector3$1(bbox.minXYZ[0], bbox.minXYZ[1], bbox.minXYZ[2]);
    var max = new LmvVector3$1(bbox.maxXYZ[0], bbox.maxXYZ[1], bbox.maxXYZ[2]);
    svf.bbox = new LmvBox3(min, max);
    //Global offset is used to avoid floating point precision issues for models
    //located enormous distances from the origin. The default is to move the model to the origin
    //but it can be overridden in case of model aggregation scenarios, where multiple
    //models are loaded into the scene and a common offset is needed for all.
    svf.globalOffset = loadContext.globalOffset || { x: 0.5 * (min.x + max.x), y: 0.5 * (min.y + max.y), z: 0.5 * (min.z + max.z) };
    var pt = derivePlacementTransform(svf, loadContext);
    var go = svf.globalOffset;
    if (go.x || go.y || go.z) {
        if (!pt) {
            pt = new LmvMatrix4(true);
            pt.makeTranslation(-go.x, -go.y, -go.z);
        } else {
            var pt2 = new LmvMatrix4(true);
            pt2.copy(pt);
            pt = pt2;
            pt.elements[12] -= go.x;
            pt.elements[13] -= go.y;
            pt.elements[14] -= go.z;
        }
        svf.placementWithOffset = pt;
    } else {
        svf.placementWithOffset = pt;
    }
    if (pt) {
        svf.bbox.applyMatrix4(pt);
    }
    if (svf.metadata.hasOwnProperty("double sided geometry") && svf.metadata["double sided geometry"]["value"]) {
        svf.doubleSided = true;
    }
}
function applyOffset(a, offset) {
    a[0] -= offset.x;
    a[1] -= offset.y;
    a[2] -= offset.z;
}
function transformAnimations(svf) {
    if (!svf.animations) return;
    // apply global offset to animations
    var animations = svf.animations["animations"];
    if (animations) {
        var globalOffset = svf.globalOffset;
        var t = new LmvMatrix4().makeTranslation(globalOffset.x, globalOffset.y, globalOffset.z);
        var tinv = new LmvMatrix4().makeTranslation(-globalOffset.x, -globalOffset.y, -globalOffset.z);
        var r = new LmvMatrix4();
        var m = new LmvMatrix4();
        for (var a = 0; a < animations.length; a++) {
            var anim = animations[a];
            if (anim.hierarchy) {
                for (var h = 0; h < anim.hierarchy.length; h++) {
                    var keys = anim.hierarchy[h].keys;
                    if (keys) {
                        for (var k = 0; k < keys.length; k++) {
                            var pos = keys[k].pos;
                            if (pos) {
                                var offset = globalOffset;
                                var rot = keys[k].rot;
                                if (rot) {
                                    r.makeRotationFromQuaternion({ x: rot[0], y: rot[1], z: rot[2], w: rot[3] });
                                    m.multiplyMatrices(t, r).multiply(tinv);
                                    offset = { x: m.elements[12], y: m.elements[13], z: m.elements[14] };
                                }
                                applyOffset(pos, offset);
                            }
                            var target = keys[k].target;
                            if (target) {
                                applyOffset(target, globalOffset);
                            }
                            var points = keys[k].points;
                            if (points) {
                                for (var p = 0; p < points.length; p++) {
                                    applyOffset(points[p], globalOffset);
                                }
                            }
                        }
                    }
                }
            }
        }
    }
}

var scope$1 = {};

/** @license zlib.js 2012 - imaya [ https://github.com/imaya/zlib.js ] The MIT License */(function() {'use strict';function m(b){throw b;}var n=void 0,r=this;function s(b,d){var a=b.split("."),c=r;!(a[0]in c)&&c.execScript&&c.execScript("var "+a[0]);for(var f;a.length&&(f=a.shift());)!a.length&&d!==n?c[f]=d:c=c[f]?c[f]:c[f]={};}var u="undefined"!==typeof Uint8Array&&"undefined"!==typeof Uint16Array&&"undefined"!==typeof Uint32Array;function v(b){var d=b.length,a=0,c=Number.POSITIVE_INFINITY,f,e,g,h,k,l,q,p,t;for(p=0;p<d;++p)b[p]>a&&(a=b[p]),b[p]<c&&(c=b[p]);f=1<<a;e=new (u?Uint32Array:Array)(f);g=1;h=0;for(k=2;g<=a;){for(p=0;p<d;++p)if(b[p]===g){l=0;q=h;for(t=0;t<g;++t)l=l<<1|q&1,q>>=1;for(t=l;t<f;t+=k)e[t]=g<<16|p;++h;}++g;h<<=1;k<<=1;}return[e,a,c]}function w(b,d){this.g=[];this.h=32768;this.d=this.f=this.a=this.l=0;this.input=u?new Uint8Array(b):b;this.m=!1;this.i=x;this.r=!1;if(d||!(d={}))d.index&&(this.a=d.index),d.bufferSize&&(this.h=d.bufferSize),d.bufferType&&(this.i=d.bufferType),d.resize&&(this.r=d.resize);switch(this.i){case y:this.b=32768;this.c=new (u?Uint8Array:Array)(32768+this.h+258);break;case x:this.b=0;this.c=new (u?Uint8Array:Array)(this.h);this.e=this.z;this.n=this.v;this.j=this.w;break;default:m(Error("invalid inflate mode"));}}
var y=0,x=1,z={t:y,s:x};
w.prototype.k=function(){for(;!this.m;){var b=A(this,3);b&1&&(this.m=!0);b>>>=1;switch(b){case 0:var d=this.input,a=this.a,c=this.c,f=this.b,e=n,g=n,h=n,k=c.length,l=n;this.d=this.f=0;e=d[a++];e===n&&m(Error("invalid uncompressed block header: LEN (first byte)"));g=e;e=d[a++];e===n&&m(Error("invalid uncompressed block header: LEN (second byte)"));g|=e<<8;e=d[a++];e===n&&m(Error("invalid uncompressed block header: NLEN (first byte)"));h=e;e=d[a++];e===n&&m(Error("invalid uncompressed block header: NLEN (second byte)"));h|=
e<<8;g===~h&&m(Error("invalid uncompressed block header: length verify"));a+g>d.length&&m(Error("input buffer is broken"));switch(this.i){case y:for(;f+g>c.length;){l=k-f;g-=l;if(u)c.set(d.subarray(a,a+l),f),f+=l,a+=l;else for(;l--;)c[f++]=d[a++];this.b=f;c=this.e();f=this.b;}break;case x:for(;f+g>c.length;)c=this.e({p:2});break;default:m(Error("invalid inflate mode"));}if(u)c.set(d.subarray(a,a+g),f),f+=g,a+=g;else for(;g--;)c[f++]=d[a++];this.a=a;this.b=f;this.c=c;break;case 1:this.j(B,C);break;case 2:aa(this);
break;default:m(Error("unknown BTYPE: "+b));}}return this.n()};
var D=[16,17,18,0,8,7,9,6,10,5,11,4,12,3,13,2,14,1,15],E=u?new Uint16Array(D):D,F=[3,4,5,6,7,8,9,10,11,13,15,17,19,23,27,31,35,43,51,59,67,83,99,115,131,163,195,227,258,258,258],G=u?new Uint16Array(F):F,H=[0,0,0,0,0,0,0,0,1,1,1,1,2,2,2,2,3,3,3,3,4,4,4,4,5,5,5,5,0,0,0],I=u?new Uint8Array(H):H,J=[1,2,3,4,5,7,9,13,17,25,33,49,65,97,129,193,257,385,513,769,1025,1537,2049,3073,4097,6145,8193,12289,16385,24577],K=u?new Uint16Array(J):J,L=[0,0,0,0,1,1,2,2,3,3,4,4,5,5,6,6,7,7,8,8,9,9,10,10,11,11,12,12,13,
13],M=u?new Uint8Array(L):L,N=new (u?Uint8Array:Array)(288),O,P;O=0;for(P=N.length;O<P;++O)N[O]=143>=O?8:255>=O?9:279>=O?7:8;var B=v(N),Q=new (u?Uint8Array:Array)(30),R,S;R=0;for(S=Q.length;R<S;++R)Q[R]=5;var C=v(Q);function A(b,d){for(var a=b.f,c=b.d,f=b.input,e=b.a,g;c<d;)g=f[e++],g===n&&m(Error("input buffer is broken")),a|=g<<c,c+=8;g=a&(1<<d)-1;b.f=a>>>d;b.d=c-d;b.a=e;return g}
function T(b,d){for(var a=b.f,c=b.d,f=b.input,e=b.a,g=d[0],h=d[1],k,l,q;c<h;){k=f[e++];if(k===n)break;a|=k<<c;c+=8;}l=g[a&(1<<h)-1];q=l>>>16;b.f=a>>q;b.d=c-q;b.a=e;return l&65535}
function aa(b){function d(a,b,c){var d,e,f,g;for(g=0;g<a;)switch(d=T(this,b),d){case 16:for(f=3+A(this,2);f--;)c[g++]=e;break;case 17:for(f=3+A(this,3);f--;)c[g++]=0;e=0;break;case 18:for(f=11+A(this,7);f--;)c[g++]=0;e=0;break;default:e=c[g++]=d;}return c}var a=A(b,5)+257,c=A(b,5)+1,f=A(b,4)+4,e=new (u?Uint8Array:Array)(E.length),g,h,k,l;for(l=0;l<f;++l)e[E[l]]=A(b,3);g=v(e);h=new (u?Uint8Array:Array)(a);k=new (u?Uint8Array:Array)(c);b.j(v(d.call(b,a,g,h)),v(d.call(b,c,g,k)));}
w.prototype.j=function(b,d){var a=this.c,c=this.b;this.o=b;for(var f=a.length-258,e,g,h,k;256!==(e=T(this,b));)if(256>e)c>=f&&(this.b=c,a=this.e(),c=this.b),a[c++]=e;else{g=e-257;k=G[g];0<I[g]&&(k+=A(this,I[g]));e=T(this,d);h=K[e];0<M[e]&&(h+=A(this,M[e]));c>=f&&(this.b=c,a=this.e(),c=this.b);for(;k--;)a[c]=a[c++-h];}for(;8<=this.d;)this.d-=8,this.a--;this.b=c;};
w.prototype.w=function(b,d){var a=this.c,c=this.b;this.o=b;for(var f=a.length,e,g,h,k;256!==(e=T(this,b));)if(256>e)c>=f&&(a=this.e(),f=a.length),a[c++]=e;else{g=e-257;k=G[g];0<I[g]&&(k+=A(this,I[g]));e=T(this,d);h=K[e];0<M[e]&&(h+=A(this,M[e]));c+k>f&&(a=this.e(),f=a.length);for(;k--;)a[c]=a[c++-h];}for(;8<=this.d;)this.d-=8,this.a--;this.b=c;};
w.prototype.e=function(){var b=new (u?Uint8Array:Array)(this.b-32768),d=this.b-32768,a,c,f=this.c;if(u)b.set(f.subarray(32768,b.length));else{a=0;for(c=b.length;a<c;++a)b[a]=f[a+32768];}this.g.push(b);this.l+=b.length;if(u)f.set(f.subarray(d,d+32768));else for(a=0;32768>a;++a)f[a]=f[d+a];this.b=32768;return f};
w.prototype.z=function(b){var d,a=this.input.length/this.a+1|0,c,f,e,g=this.input,h=this.c;b&&("number"===typeof b.p&&(a=b.p),"number"===typeof b.u&&(a+=b.u));2>a?(c=(g.length-this.a)/this.o[2],e=258*(c/2)|0,f=e<h.length?h.length+e:h.length<<1):f=h.length*a;u?(d=new Uint8Array(f),d.set(h)):d=h;return this.c=d};
w.prototype.n=function(){var b=0,d=this.c,a=this.g,c,f=new (u?Uint8Array:Array)(this.l+(this.b-32768)),e,g,h,k;if(0===a.length)return u?this.c.subarray(32768,this.b):this.c.slice(32768,this.b);e=0;for(g=a.length;e<g;++e){c=a[e];h=0;for(k=c.length;h<k;++h)f[b++]=c[h];}e=32768;for(g=this.b;e<g;++e)f[b++]=d[e];this.g=[];return this.buffer=f};
w.prototype.v=function(){var b,d=this.b;u?this.r?(b=new Uint8Array(d),b.set(this.c.subarray(0,d))):b=this.c.subarray(0,d):(this.c.length>d&&(this.c.length=d),b=this.c);return this.buffer=b};function U(b,d){var a,c;this.input=b;this.a=0;if(d||!(d={}))d.index&&(this.a=d.index),d.verify&&(this.A=d.verify);a=b[this.a++];c=b[this.a++];switch(a&15){case V:this.method=V;break;default:m(Error("unsupported compression method"));}0!==((a<<8)+c)%31&&m(Error("invalid fcheck flag:"+((a<<8)+c)%31));c&32&&m(Error("fdict flag is not supported"));this.q=new w(b,{index:this.a,bufferSize:d.bufferSize,bufferType:d.bufferType,resize:d.resize});}
U.prototype.k=function(){var b=this.input,d,a;d=this.q.k();this.a=this.q.a;if(this.A){a=(b[this.a++]<<24|b[this.a++]<<16|b[this.a++]<<8|b[this.a++])>>>0;var c=d;if("string"===typeof c){var f=c.split(""),e,g;e=0;for(g=f.length;e<g;e++)f[e]=(f[e].charCodeAt(0)&255)>>>0;c=f;}for(var h=1,k=0,l=c.length,q,p=0;0<l;){q=1024<l?1024:l;l-=q;do h+=c[p++],k+=h;while(--q);h%=65521;k%=65521;}a!==(k<<16|h)>>>0&&m(Error("invalid adler-32 checksum"));}return d};var V=8;s("Zlib.Inflate",U);s("Zlib.Inflate.prototype.decompress",U.prototype.k);var W={ADAPTIVE:z.s,BLOCK:z.t},X,Y,Z,$;if(Object.keys)X=Object.keys(W);else for(Y in X=[],Z=0,W)X[Z++]=Y;Z=0;for($=X.length;Z<$;++Z)Y=X[Z],s("Zlib.Inflate.BufferType."+Y,W[Y]);}).call(scope$1);

var Zlib$1 = scope$1.Zlib;

'use strict';

var FLUENT_CDN_URN = "urn:adsk.fluent:fs.file:fluent-cdn";
function ProgressiveReadContext(itemCB, defaultByteStride) {
    var currentRow = 0;
    var byteStride;
    var version;
    var bdata;
    var fdata;
    var idata;
    function readHeader(receiveBuffer) {
        var headerBytes = new Uint8Array(4);
        if (typeof receiveBuffer === "string") {
            for (var i = 0; i < 4; i++) {
                headerBytes[i] = receiveBuffer.charCodeAt(i);
            }
        } else {
            for (var i = 0; i < 4; i++) {
                headerBytes[i] = receiveBuffer[i];
            }
        }
        byteStride = headerBytes[1] << 8 | headerBytes[0];
        if (!byteStride) byteStride = defaultByteStride || 0;
        if (!byteStride) exports.logger.error("Unknwon byte stride.");
        if (byteStride % 4) exports.logger.error("Expected byte size to be multiple of 4, but got " + byteStride);
        version = headerBytes[3] << 8 | headerBytes[2];
        bdata = new Uint8Array(byteStride);
        fdata = new Float32Array(bdata.buffer);
        idata = new Uint32Array(bdata.buffer);
        
    }
    this.onData = function (receiveBuffer, finalCall) {
        var isString = typeof receiveBuffer === "string";
        while (true) {
            //On the first progress event, read the header
            if (!currentRow && receiveBuffer.length >= 4) {
                readHeader(receiveBuffer);
                currentRow++;
            } else if (receiveBuffer.length < 4) {
                return false;
            }
            var streamOffset = currentRow * byteStride;
            var endOffset = streamOffset + byteStride;
            if (receiveBuffer.length < endOffset) return finalCall;
            if (isString) {
                for (var j = 0; j < byteStride; j++) {
                    bdata[j] = receiveBuffer.charCodeAt(j + streamOffset) & 0xff;
                }
            } else {
                for (var j = 0; j < byteStride; j++) {
                    bdata[j] = receiveBuffer[j + streamOffset];
                }
            }
            //The callback will return true if it was able
            //to process the item at this time. If not, we will
            //call it later with the same item, until it accepts it.
            if (itemCB(currentRow - 1)) {
                currentRow++;
            } else {
                return false;
            }
        }
    };
    this.onEnd = function (receiveBuffer) {
        var isDoneProcessing = this.onData(receiveBuffer, true);
        //Remember the response data in case there is a dependency that hasn't loaded yet
        //and we need to delay processing
        if (!isDoneProcessing) this.rawData = receiveBuffer;
    };
    this.flush = function () {
        if (!this.rawData) return;
        var isDoneProcessing = this.onData(this.rawData, true);
        if (!isDoneProcessing) exports.logger.warn("Unexpected data stream termination.");
        this.rawData = null;
    };
    this.idata = function () {
        return idata;
    };
    this.fdata = function () {
        return fdata;
    };
    this.bdata = function () {
        return bdata;
    };
    this.version = function () {
        return version;
    };
    this.byteStride = function () {
        return byteStride;
    };
}
function OtgPackage(manifestFileData) {
    this.materials = null; //The materials json as it came from the SVF
    this.fragments = null; //will be wrapped in a FragmentList
    this.geompacks = [];
    this.propertydb = {
        attrs: [],
        avs: [],
        ids: [],
        values: [],
        offsets: []
    };
    this.bbox = null; //Overall scene bounds
    this.animations = null; // animations json
    this.pendingRequests = 0;
    this.globalOffset = { x: 0, y: 0, z: 0 };
    this.pendingRequests = 0;
    this.initialLoadProgress = 0;
    this.materialIdToHash = [];
    this.geomIdToHash = [];
    this.aborted = false;
}
var TO_HEX = new Array(256);
for (var i$1 = 0; i$1 < 256; i$1++) {
    var s = i$1.toString(16);
    if (s.length === 1) s = "0" + s;
    TO_HEX[i$1] = s;
}
function getHexString(buffer, offset, length) {
    var res = [];
    for (var i = 0; i < length; i++) {
        var b = buffer[offset + i];
        var s = TO_HEX[b];
        res.push(s);
    }
    return res.join("");
}
OtgPackage.prototype.getMaterialHash = function (materialIndex) {
    var cached = this.materialIdToHash[materialIndex];
    if (cached) return cached;
    // bytes per SHA1 hash
    var stride = this.materialHashes.byteStride;
    //get the hash string that points to the material
    var matHash = getHexString(this.materialHashes.hashes, materialIndex * stride, stride);
    this.materialIdToHash[materialIndex] = matHash;
    return matHash;
};
OtgPackage.prototype.getGeometryHash = function (geomIndex) {
    var cached = this.geomIdToHash[geomIndex];
    if (cached) return cached;
    // bytes per SHA1 hash
    var stride = this.geomMetadata.byteStride;
    //get the hash string that points to the geometry
    var gHash = getHexString(this.geomMetadata.hashes, geomIndex * stride, stride);
    this.geomIdToHash[geomIndex] = gHash;
    return gHash;
};
//Set up the fragments, materials, and meshes lists
//which get filled progressively as we receive their data
OtgPackage.prototype.initEmptyLists = function () {
    var svf = this;
    var frags = svf.fragments = {};
    frags.length = svf.metadata.stats.num_fragments;
    frags.numLoaded = 0;
    frags.boxes = new Float32Array(frags.length * 6);
    frags.transforms = new Float32Array(frags.length * 12);
    frags.materials = new Int32Array(frags.length);
    frags.geomDataIndexes = new Int32Array(frags.length);
    frags.fragId2dbId = new Int32Array(frags.length);
    frags.mesh2frag = {};
    frags.topoIndexes = null;
    svf.geomMetadata = {
        hashes: null,
        byteStride: 0,
        version: 0,
        numLoaded: 0,
        hashToIndex: {}
    };
    svf.materialHashes = {
        hashes: null,
        byteStride: 0,
        version: 0,
        numLoaded: 0
    };
    //Shell object to make it compatible with SVF.
    //Not sure which parts of this are really needed,
    //SceneUnit is one.
    svf.materials = {
        "name": "LMVTK Simple Materials",
        "version": "1.0",
        "scene": {
            "SceneUnit": 8215,
            "YIsUp": 0
        },
        materials: {}
    };
};
//TODO: this may be better done in ViewingServiceXhr, so that property database files
//which are done by the PropDbLoader can reuse the logic
function generateUrl(loadContext, path) {
    //Two cases here, plus the case for local debugging using absolute URL.
    //1. We get a path which has the fluent URN prefix, we lat that through unchanged.
    //   This happens for the root otg_manifest json file.
    //2. A path relative to the otg manifest file. This gets the path of the manifest as base path
    //   and then we have to map the constructed full fluent urn to a fluent path, as done for the manifest file.
    //3. Absolute URLs are pass through.
    if (path.indexOf("urn:adsk.fluent:fs.file:") === 0) {
        return path;
    } else {
        //If the path is relative, the basePath will most likely
        //add the urn:adsk.fluent:fs.file: prefix as in the case above
        if (path.indexOf("https://") !== 0 && path.indexOf("http://") !== 0) return loadContext.basePath + path;
    }
    return path;
}
OtgPackage.prototype.loadAsyncResource = function (loadContext, resourcePath, responseType, callback, onprogress) {
    //Launch an XHR to load the data from external file
    var svf = this;
    this.pendingRequests++;
    function xhrCB(responseData) {
        svf.pendingRequests--;
        callback(responseData);
    }
    resourcePath = generateUrl(loadContext, resourcePath);
    ViewingService.getItem(loadContext, resourcePath, xhrCB, loadContext.onFailureCallback, { asynchronous: true,
        responseType: responseType || "arraybuffer",
        onprogress: onprogress
    });
};
OtgPackage.prototype.loadAsyncProgressive = function (loadContext, resourcePath, ctx, resourceName) {
    var svf = this;
    resourcePath = generateUrl(loadContext, resourcePath);
    ViewingService.getItem(loadContext, resourcePath, function onDone(data) {
        ctx.onEnd(data);
        svf.postLoad(loadContext, resourceName, ctx, data);
    }, loadContext.onFailureCallback, { asynchronous: true,
        responseType: "text",
        ondata: function onProgress(receiveBuffer, request) {
            //TODO: abort the xhr without waiting for progress
            //To do that we need to remember the XHR when calling getItem above.
            if (svf.aborted && request) {
                request.abort();
                return;
            }
            //Read as many fragments as we can at this time
            ctx.onData(receiveBuffer);
        }
    });
};
OtgPackage.prototype.loadMetadata = function (loadContext, path) {
    var svf = this;
    this.loadAsyncResource(loadContext, path, "json", function (data) {
        //For OTG, there is a single JSON for metadata and manifest,
        //and it's the root
        svf.metadata = data;
        svf.manifest = svf.metadata.manifest;
        svf.processMetadata(loadContext);
        svf.initEmptyLists();
        var manifest = svf.metadata.manifest;
        //Add the shared property db files to the property db manifest
        //TODO: this is a bit hacky and hardcoded
        var spdb = manifest.shared_assets.pdb;
        for (var p in spdb) {
            if (svf.propertydb[p]) svf.propertydb[p].push(spdb[p]);else {
                //Skip this property db file from the list,
                //we don't know how to handle it.
                //This will always happen to the dbid.idx file, which is only used
                //server side during translation.
            }
        }
        var pdb = manifest.assets.pdb;
        for (var p in pdb) {
            if (svf.propertydb[p]) svf.propertydb[p].push(pdb[p]);else {
                //Skip this property db file from the list,
                //we don't know how to handle it.
                //This will always happen to the dbid.idx file, which is only used
                //server side during translation.
            }
        }
        //Optional resources
        //If there is a materials pack file, load that and use it instead of
        //individual material requests
        if (manifest.assets.materials_pack) {
            svf.pendingMaterialsPack = 2;
            svf.loadAsyncResource(loadContext, manifest.assets.materials_pack, null, function (data) {
                svf.hasMaterialsPack = true;
                svf.pendingMaterialsPack--;
                svf.materials_pack = data;
                loadContext.onLoaderEvent("materials_pack");
            });
            svf.loadAsyncResource(loadContext, manifest.assets.materials_idx, null, function (data) {
                svf.materials_offsets = new Uint32Array(data.buffer);
                svf.pendingMaterialsPack--;
                loadContext.onLoaderEvent("materials_offsets");
            });
        }
        if (manifest.assets.animations) {
            svf.loadAsyncResource(loadContext, manifest.assets.animations, "json", function (data) {
                svf.animations = data;
                transformAnimations(svf);
            });
        }
        if (manifest.assets.topology) {
            svf.loadAsyncResource(loadContext, path, "json", function (data) {
                svf.topology = data;
            });
        }
        loadContext.onLoaderEvent("otg_root");
        svf.postLoad(loadContext, "metadata");
    });
};
OtgPackage.prototype.loadFragmentList = function (loadContext, path) {
    var svf = this;
    var _t = new LmvVector3$1();
    var _s = new LmvVector3$1();
    var _q = { x: 0, y: 0, z: 0, w: 1 };
    var _m = new LmvMatrix4();
    var _b = new LmvBox3();
    var txOffset = 4;
    var ctx = new ProgressiveReadContext(readOneItem, 13 * 4);
    function readOneItem(i) {
        //Fragments have ot wait for the metadata (placement transform)
        //before they can be fully processed
        if (!svf.metadata) return;
        var idata = ctx.idata();
        var fdata = ctx.fdata();
        var offset = 0;
        var frags = svf.fragments;
        var meshid = frags.geomDataIndexes[i] = idata[offset];
        var materialId = frags.materials[i] = idata[offset + 1];
        //check if the fragment's material and geometry hashes are already known
        //If not, then pause fragment processing until they are
        //NOTE: mesh ID and material ID are 1-based indices.
        if (meshid > svf.geomMetadata.numLoaded || materialId > svf.materialHashes.numLoaded) {
            console.log("Delayed fragment", i);
            return false;
        }
        var dbId = frags.fragId2dbId[i] = idata[offset + 2];
        //Add the fragment's mesh to the reverse mapping of geom->fragment
        var meshRefs = frags.mesh2frag[meshid];
        if (meshRefs === undefined) {
            //If it's the first fragments for this mesh,
            //store the index directly -- most common case.
            frags.mesh2frag[meshid] = i;
        } else if (!Array.isArray(meshRefs)) {
            //otherwise put the fragments that
            //reference the mesh into an array
            frags.mesh2frag[meshid] = [meshRefs, i];
        } else {
            //already is an array
            meshRefs.push(i);
        }
        //Read the transform
        var to = offset + txOffset;
        _t.set(fdata[to + 0], fdata[to + 1], fdata[to + 2]);
        _q.x = fdata[to + 3];
        _q.y = fdata[to + 4];
        _q.z = fdata[to + 5];
        _q.w = fdata[to + 6];
        _s.set(fdata[to + 7], fdata[to + 8], fdata[to + 9]);
        _m.compose(_t, _q, _s);
        if (svf.placementWithOffset) {
            _m.multiplyMatrices(svf.placementWithOffset, _m);
        }
        var e = _m.elements;
        var dst = frags.transforms;
        var off = i * 12;
        dst[off + 0] = e[0];
        dst[off + 1] = e[1];
        dst[off + 2] = e[2];
        dst[off + 3] = e[4];
        dst[off + 4] = e[5];
        dst[off + 5] = e[6];
        dst[off + 6] = e[8];
        dst[off + 7] = e[9];
        dst[off + 8] = e[10];
        dst[off + 9] = e[12];
        dst[off + 10] = e[13];
        dst[off + 11] = e[14];
        //Estimated bounding box based on known unit box for the mesh, and the fragment's world transform
        //TODO: do we want to store the exact world space bbox?
        _b.min.x = -0.5;
        _b.min.y = -0.5;
        _b.min.z = -0.5;
        _b.max.x = 0.5;
        _b.max.y = 0.5;
        _b.max.z = 0.5;
        _b.applyMatrix4(_m);
        dst = frags.boxes;
        off = i * 6;
        dst[off + 0] = _b.min.x;
        dst[off + 1] = _b.min.y;
        dst[off + 2] = _b.min.z;
        dst[off + 3] = _b.max.x;
        dst[off + 4] = _b.max.y;
        dst[off + 5] = _b.max.z;
        frags.numLoaded = i + 1;
        loadContext.onLoaderEvent("fragment", i);
        return true;
    }
    this.loadAsyncProgressive(loadContext, path, ctx, "all_fragments");
    return ctx;
};
OtgPackage.prototype.loadGeometryHashList = function (loadContext, path) {
    var svf = this;
    var ctx = new ProgressiveReadContext(readOneHash, 20);
    function readOneHash(i) {
        //have ot wait for the metadata
        //before they can be fully processed
        if (!svf.metadata) return false;
        if (!svf.geomMetadata.hashes) {
            svf.numGeoms = svf.metadata.stats.num_geoms;
            svf.geomMetadata.hashes = new Uint8Array(ctx.byteStride() * (svf.numGeoms + 1));
            svf.geomMetadata.byteStride = ctx.byteStride();
            svf.geomMetadata.version = ctx.version();
        }
        //i is zero based, geoms ids are 1-based
        i += 1;
        svf.geomMetadata.hashes.set(ctx.bdata(), i * ctx.byteStride());
        //this is curretly set by the OtgLoader
        //		svf.geomMetadata.hashToIndex[] = i;
        svf.geomMetadata.numLoaded = i;
        return true;
    }
    this.loadAsyncProgressive(loadContext, path, ctx, "geometry_ptrs");
    return ctx;
};
OtgPackage.prototype.loadMaterialHashList = function (loadContext, path) {
    var svf = this;
    var ctx = new ProgressiveReadContext(readOneHash, 20);
    function readOneHash(i) {
        //have ot wait for the metadata
        //before they can be fully processed
        if (!svf.metadata) return false;
        if (!svf.materialHashes.hashes) {
            svf.numMaterials = svf.metadata.stats.num_materials;
            svf.materialHashes.hashes = new Uint8Array(ctx.byteStride() * (svf.numMaterials + 1));
            svf.materialHashes.byteStride = ctx.byteStride();
            svf.materialHashes.version = ctx.version();
        }
        //i is zero based, geoms ids are 1-based
        i += 1;
        svf.materialHashes.hashes.set(ctx.bdata(), i * ctx.byteStride());
        svf.materialHashes.numLoaded = i;
        return true;
    }
    this.loadAsyncProgressive(loadContext, path, ctx, "material_ptrs");
    return ctx;
};
OtgPackage.prototype.processMetadata = function (loadContext) {
    var svf = this;
    var metadata = svf.metadata;
    initPlacement(svf, loadContext);
    var pt = svf.placementWithOffset;
    if (metadata.cameras) {
        svf.cameras = metadata.cameras;
        if (pt) {
            for (var i = 0; i < svf.cameras.length; i++) {
                var cam = svf.cameras[i];
                cam.position = new LmvVector3$1(cam.position.x, cam.position.y, cam.position.z);
                cam.position.applyMatrix4(pt);
                cam.target = new LmvVector3$1(cam.target.x, cam.target.y, cam.target.z);
                cam.target.applyMatrix4(pt);
                cam.up = new LmvVector3$1(cam.up.x, cam.up.y, cam.up.z);
                cam.up.transformDirection(pt);
            }
        }
    }
};
OtgPackage.prototype.loadRemainingSvf = function (loadContext, otgPath) {
    this.loadMetadata(loadContext, otgPath);
    //These are fundamental and always there.
    //Because the file names are fixed, we can kick off those requests together with the root json.
    //TODO: This needs to be revised in case the filenames become variable (i.e. wait
    //until we can get them from metadata.manifest.assets.
    /*
    this.loadMaterialHashList(loadContext, manifest.assets.materials_ptrs);
    this.loadGeometryHashList(loadContext, manifest.assets.geometry_ptrs);
    this.loadFragmentList(loadContext, manifest.assets.fragments);
    */
    this.materialsCtx = this.loadMaterialHashList(loadContext, "materials_ptrs.hl");
    this.geometryCtx = this.loadGeometryHashList(loadContext, "geometry_ptrs.hl");
    this.fragmentsCtx = this.loadFragmentList(loadContext, "fragments.fl");
};
OtgPackage.prototype.extractMaterialFromPack = function (matId) {
    if (this.materials_pack && this.materials_offsets) {
        //If the materials pack is already received, extract the material JSON
        //from the pack
        //
        var baseOffset = this.materials_offsets[matId];
        var endOffset = matId < this.materials_offsets.length - 1 ? this.materials_offsets[matId + 1] : this.materials_pack.length;
        var matLengthBytes = endOffset - baseOffset;
        var buffer = new Uint8Array(this.materials_pack.buffer, baseOffset, matLengthBytes);
        buffer = new Zlib$1.Inflate(buffer).decompress();
        var decodedString = utf8ArrayToString(buffer, 0, buffer.length);
        var mat;
        try {
            mat = JSON.parse(decodedString);
        } catch (e) {
            console.error(e);
        }
        return mat;
    } else {
        return null;
    }
};
OtgPackage.prototype.makeSharedResourcePath = function (cdnUrl, whichType, hash) {
    //TODO: Make this logic preferentially use the CDN paths settings from the
    //viewable manifest instead of the .shared_assets in the per-model settings.
    //In general those will be equal though.
    if (cdnUrl) {
        var shardChars = this.manifest.shared_assets.global_sharding || 0;
        //The shard prefix is a number of character cut off from the hash
        //string and brought to the beginning of the S3 key to improve S3 read
        //preformance.
        var fname = hash;
        var shardPrefix = "";
        if (shardChars) {
            shardPrefix = "/" + hash.slice(0, shardChars);
            fname = hash.slice(shardChars);
        }
        //This prefix is an account ID hash, plus a relative path
        //that is one of /t /g or /m (texture, geometry, material)
        var prefix = this.manifest.shared_assets[whichType];
        if (prefix.indexOf(FLUENT_CDN_URN) !== 0) {
            //it can be a relative path in case of local testing data
            //TODO: not sure this branch will ever get hit
            var split = prefix.split("/");
            prefix = "/" + (split[split.length - 1] || split[split.length - 2]) + "/";
        } else {
            //The CDN prefix can have -dev or -prod piece, so skip that too,
            //by slicing up to the first slash
            prefix = prefix.slice(prefix.indexOf("/"));
        }
        return cdnUrl + shardPrefix + prefix + fname;
    } else {
        //Locally stored data (testing only) defaults to sharding size of 2 chars
        var shardChars = this.manifest.shared_assets.global_sharding || 2;
        var fname = hash;
        var shardPrefix = "";
        if (shardChars) {
            shardPrefix = "/" + hash.slice(0, shardChars) + "/";
            fname = hash.slice(shardChars);
        }
        var modelBasePath = pathToURL(this.basePath);
        return modelBasePath + this.manifest.shared_assets[whichType] + shardPrefix + fname;
    }
};
OtgPackage.prototype.loadMaterial = function (loadContext, matHash, matLoadCB) {
    // get request url
    var url;
    url = this.makeSharedResourcePath(loadContext.otg_cdn, "materials", matHash);
    // handle load failure
    var onFailure = function onFailure(error$$1) {
        exports.logger.error("Failed to load material " + matHash);
    };
    if (url.indexOf("https://") !== 0 && url.indexOf("http://") !== 0) url = loadContext.basePath + url;
    ViewingService.getItem(loadContext.otg_cdn ? {} : loadContext, url, matLoadCB, onFailure, { asynchronous: true,
        responseType: "json",
        withCredentials: false
    });
};
OtgPackage.prototype.postLoad = function (loadContext, what, ctx, data) {
    if (what) {
        //console.log("what", what);
        this.initialLoadProgress++;
    }
    //If required files are loaded, continue with the next
    //step of the load sequence
    if (this.initialLoadProgress === 4) {
        //Finish processing the data streams in order of dependcy
        this.materialsCtx.flush();
        this.geometryCtx.flush();
        this.fragmentsCtx.flush();
        this.materialsCtx = null;
        this.geometryCtx = null;
        this.fragmentsCtx = null;
        if (this.fragments.numLoaded < this.metadata.stats.num_fragments) exports.logger.warn("Fragments actually loaded fewer than expected.");
        loadContext.onLoaderEvent("all_fragments");
    }
};
OtgPackage.prototype.abort = function () {
    this.aborted = true;
};
OtgPackage.prototype.makeBVH = function (loadContext) {
    var svf = this;
    //TODO: we may want to do this in a worker, currently OTG does it on the main thread
    //TODO: process bboxes progressively instead of doing it once the whole file is in.
    if (this.manifest.assets.fragments_extra) {
        this.loadAsyncResource(loadContext, this.manifest.assets.fragments_extra, "", function (data) {
            if (!data || !data.length) {
                return;
            }
            //Build the R-Tree
            var t0 = performance.now();
            var finfo = new OtgFragInfo(data, svf.placementWithOffset);
            if (finfo.count) {
                var tmpbvh = new BVHBuilder(null, null, finfo);
                tmpbvh.build(loadContext.bvhOptions);
                svf.bvh = {
                    nodes: tmpbvh.nodes,
                    primitives: tmpbvh.primitives
                };
                var t1 = performance.now();
                exports.logger.debug("BVH build time:" + (t1 - t0));
                // In normal mode, just post back BVH as svf is already posted back earlier.
                loadContext.onLoaderEvent("bvh", svf.bvh);
            }
        });
    }
};

"use strict";

var MESH_RECEIVE_EVENT = "meshReceived";
var MESH_FAILED_EVENT = "meshFailed";
// Returns the surface area of a THREE.Box3.
function getBoxSurfaceArea(box) {
    var dx = box.max.x - box.min.x;
    var dy = box.max.y - box.min.y;
    var dz = box.max.z - box.min.z;
    return 2.0 * (dx * dy + dy * dz + dz * dx);
}
// @param {THREE.Vector3} p
// @param {THREE.Vector3} bboxMin
// @param {THREE.Vector3} bboxMax
// @returns {Number} Squared distance of the bbox to p    
var point2BoxDistance2$1 = function () {
    var _nearest = null;
    return function (p, boxMin, boxMax) {
        if (!_nearest) _nearest = new LmvVector3$1();
        // compute the point within bbox that is nearest to p by clamping against box
        _nearest.copy(p);
        _nearest.max(boxMin);
        _nearest.min(boxMax);
        // return squared length of the difference vector
        return _nearest.distanceToSquared(p);
    };
}();
// Helper function used for cache cleanup
function compareGeomsByImportance(geom1, geom2) {
    return geom1.importance - geom2.importance;
}
// Sort requests by decreasing importance
function compareRequests(req1, req2) {
    return req2.importance - req1.importance;
}
/** Read fragment from Float32-Array (storing each box as 6 floats)
 *  @param {Float32Array} boxes
 *  @param {number}       index
 *  @param {THREE.Box3}   outBox
 *  @returns {THREE.Box3} outBox
 */
function readFragmentBox(boxes, index, outBox) {
    var offset = 6 * index;
    outBox.min.y = boxes[offset + 1];
    outBox.min.z = boxes[offset + 2];
    outBox.min.x = boxes[offset + 0];
    outBox.max.x = boxes[offset + 3];
    outBox.max.y = boxes[offset + 4];
    outBox.max.z = boxes[offset + 5];
    return outBox;
}
/**
 * @param {number}            fragId
 * @param {Float32Array}      boxes
 * @param {FrustumInersector} frustum
 */
var computeFragImportance = function () {
    var _tmpBox = null;
    return function (fragId, boxes, frustum) {
        if (!_tmpBox) _tmpBox = new LmvBox3();
        // get fragment box
        var fragBox = readFragmentBox(boxes, fragId, _tmpBox);
        // frustum test
        var cullResult = frustum.intersectsBox(fragBox);
        // outside frustum => no importance
        if (cullResult === FrustumIntersector.OUTSIDE) {
            return 0.0;
        }
        // Estimate projected area. For shapes fully inside the frustum, we can
        // skip the clipping step. 
        var noClip = FrustumIntersector.INTERSECTS;
        var area = frustum.projectedBoxArea(fragBox, noClip);
        var dist = point2BoxDistance2$1(frustum.eye, fragBox.min, fragBox.max);
        dist = Math.max(dist, 0.01);
        return area / dist;
    };
}();
/** Shared cache of BufferGeometries used by different OtgLoaders.
 *   @param {GeomCacheDelegate} delegate - The delegate for application services
 *   @param {() => Camera} _cameraCallback - A callback to get the current camera
 */
function OtgGeomCache(delegate, _cameraCallback) {
    if (!delegate.eventTarget || !delegate.workerScript || !delegate.renderScene) {
        exports.logger.error("OtgGeomCache: Construction filed because of incomplete delegate");
    }
    var _delegate = {};
    Object.assign(_delegate, delegate);
    if (!_delegate.initLoadContext) {
        _delegate.initLoadContext = FileLoader.simpleInitLoadContext;
    }
    // all geometries, indexed by geom hashes
    var _geoms = {};
    // A single geometry may be requested by one or more model loaders.
    // This map keeps track of requests already in progress so that
    // we don't issue multiple simultaneously
    var _geomHash2Requests = {};
    // worker for geometry loading
    var NUM_WORKERS = 6;
    var _workers = [];
    var _ranges;
    for (var i = 0; i < NUM_WORKERS; i++) {
        _workers.push(_delegate.workerScript.createWorkerWithIntercept());
    }
    // track memory consumption
    this.byteSize = 0;
    // A request is called in-progress if we have sent it to the worker and didn't receive a result yet.
    // We restrict the number of _requestsInProgress. If the limit is reached, all additional requests
    // are enqueued in _waitingRequests.
    var _requestsInProgress = 0;
    var _maxRequestsPerWorker = 100;
    var _timeout = undefined;
    // If the number of requests in progress exceeds _maxRequests, all remaining ones are enqueued in this array.
    // Requests outside the worker can be rearranged based on priority changes (if model visibility changes).
    var _waitingTasks = []; // enqueued task messages to OTGGeomWorker, as defined in requestGeometry(...)
    var _prevNumTasks = 0;
    var _fullSortDone = false;
    var _this = this;
    // mem limits for cache cleanup
    var MB = 1024 * 1024;
    var _maxMemory = 100 * MB; // geometry limit at which cleanup is activated
    var _minCleanup = 50 * MB; // minimum amount of freed memory for a single cleanup run
    var _timeStamp = 0; // used for cache-cleanup to identify which geoms are in use
    // A cleanup will fail if there are no unused geometries anymore.
    // If this happens, we skip cleanup until the next model unload occurs.
    var _allGeomsInUse = false;
    // Whenever the camera or set of visible models change, we have to update request priorities.
    // These members are used to track relevant changes.
    var _lastCamPos = new LmvVector3$1();
    var _lastCamTarget = new LmvVector3$1();
    var _lastVisibleModelIds = []; // {number[]} ids of all visible RenderModels that we considered for last update
    function onModelUnloaded() {
        _allGeomsInUse = false;
    }
    _delegate.eventTarget.addEventListener(MODEL_UNLOADED_EVENT, onModelUnloaded);
    this.dtor = function () {
        _delegate.eventTarget.removeEventListener(MODEL_UNLOADED_EVENT, onModelUnloaded);
        _delegate = null;
    };
    // function to handle messages from OtgGeomWorker (posted in onGeometryLoaded)
    function handleMessage(msg) {
        if (!msg.data) {
            return;
        }
        if (msg.data.error) {
            var error$$1 = msg.data.error;
            // get hash for which request failed
            var hash = error$$1.args ? error$$1.args.hash : undefined;
            // inform affected clients.
            if (hash) {
                _geoms[hash] = error$$1; //create an error entry in the cache
                _this.dispatchEvent({ type: MESH_FAILED_EVENT, error: error$$1 });
            }
            delete _geomHash2Requests[error$$1.hash];
            // track number of requests in progress
            _requestsInProgress--;
        } else {
            var meshlist = msg.data;
            for (var i = 0; i < meshlist.length; i++) {
                var mdata = meshlist[i];
                if (mdata.hash && mdata.mesh) {
                    // convert goemetry data to GeometryBuffer (result is mdata.geometry)
                    meshToGeometry(mdata);
                    // add geom to cache
                    var hash = mdata.hash;
                    var geom = mdata.geometry;
                    _geoms[hash] = geom;
                    // track summed cache size in bytes
                    _this.byteSize += geom.byteSize;
                    // free old unused geoms if necessary
                    _this.cleanup();
                    // pass geometry to all receiver callbacks
                    _this.dispatchEvent({ type: MESH_RECEIVE_EVENT, geom: geom });
                    delete _geomHash2Requests[mdata.hash];
                }
                // track number of requests in progress
                _requestsInProgress--;
            }
        }
        if (_waitingTasks.length && !_timeout) {
            _timeout = setTimeout(processQueuedItems, 0);
        }
    }
    for (var i = 0; i < NUM_WORKERS; i++) {
        _workers[i].addEventListenerWithIntercept(handleMessage);
    }
    function assignWorkerForGeomId(geomId) {
        if (!_ranges || !geomId) return 0 | Math.random() * NUM_WORKERS;
        var lo = 0;
        var hi = _ranges.length - 1;
        var range;
        do {
            var mid = 0 | (lo + hi) / 2;
            range = _ranges[mid];
            if (range.geomStart > geomId) hi = mid - 1;else if (range.geomEnd <= geomId) lo = mid + 1;else break;
        } while (lo <= hi);
        if (range.geomStart <= geomId && range.geomEnd > geomId) return range.workerId;else {
            console.error("Range not found", geomId);
            return -1; //should not happen
        }
    }
    this.initWorker = function (urlPack, urlOffsets, geomFanout, queryParams) {
        //Create ranges of the geometry pack file based on first level fanout table
        //We will use those to distribute the work across worker threads
        _ranges = [];
        var fanout = geomFanout;
        for (var i = 0; i < fanout.length - 2; i += 2) {
            var range = {
                geomStart: fanout[i],
                geomEnd: fanout[i + 2],
                min: fanout[i + 1],
                max: fanout[i + 3],
                data: null,
                workerId: i / 2 % NUM_WORKERS //round robin the worker assignments to ensure even distribution in mesh sizes to each worker
            };
            _ranges.push(range);
        }
        //Tell each worker which ranges of the geometry pack it's responsible for.
        for (var i = 0; i < NUM_WORKERS; i++) {
            var rangesPerWorker = _ranges.filter(function (r) {
                return r.workerId === i;
            });
            var msg = {
                operation: "INIT_GEOMPACK_OTG",
                url: urlPack,
                urlOffsets: urlOffsets,
                queryParams: queryParams,
                ranges: rangesPerWorker,
                workerId: i
            };
            _workers[i].doOperation(_delegate.initLoadContext(msg));
        }
    };
    /**  Get a geometry from cache or load it.
     *    @param {string}   url         - full request url of the geometry/ies resource
     *    @param {boolean}  isCDN       - whether the URL is pointing to a public edge cache endpoint
     *    @param {string}   geomHash    - hash key to identify requested geometry/ies
     *    @param {int} geomIdx          - the geometry ID/index in the model's geometry hash list (optional, pass 0 to skip use of geometry packs)
     *    @param {string}   queryParams - additional param passed to file query
     *    @param {THREE.Matrix4} sampleWorldMatrix - an example world matrix used by a fragment referencing this mesh,
     *                                               used to get correct aspect ratios for angle measurement when computing
     *                                               the mesh topology
     */
    this.requestGeometry = function (url, isCDN, geomHash, geomIdx, queryParams, sampleWorldMatrix) {
        // if this geometry is in memory, just return it directly
        var geom = _geoms[geomHash];
        if (geom && geom.args) {
            //it failed to load previously
            this.dispatchEvent({ type: MESH_FAILED_EVENT, error: geom });
            return;
        } else if (geom) {
            //it was already cached
            this.dispatchEvent({ type: MESH_RECEIVE_EVENT, geom: geom });
            return;
        }
        // if geometry is already loading, just increment
        // the request counter.
        var task = _geomHash2Requests[geomHash];
        if (task && task.refcount) {
            task.importanceNeedsUpdate = true;
            task.refcount++;
            return;
        }
        var matrixElements = null;
        if (sampleWorldMatrix) {
            matrixElements = Array.from(sampleWorldMatrix.elements);
        }
        // geom is neither in memory nor loading.
        // we have to request it.
        var msg = {
            operation: "LOAD_GEOMETRY_OTG",
            url: url,
            isCDN: isCDN,
            hash: geomHash,
            geomIdx: geomIdx,
            queryParams: queryParams,
            importance: 0.0,
            sampleWorldMatrix: matrixElements,
            importanceNeedsUpdate: true,
            refcount: 1
        };
        _waitingTasks.push(msg);
        _geomHash2Requests[geomHash] = msg;
        if (!_timeout) {
            _timeout = setTimeout(processQueuedItems, 0);
        }
    };
    function processQueuedItems() {
        var howManyCanWeDo = _maxRequestsPerWorker * NUM_WORKERS - _requestsInProgress;
        if (howManyCanWeDo === 0) {
            _timeout = setTimeout(processQueuedItems, 30);
            return;
        }
        // recompute importance for each geometry and sort queue by decreasing priority
        var priorityUpdateFinished = _this.updateRequestPriorities();
        // Restrict number of simultaneous requests until our priorities are fully updated
        if (!priorityUpdateFinished) {
            howManyCanWeDo = Math.min(howManyCanWeDo, 10 * NUM_WORKERS);
        }
        var msgPerWorker = [];
        var tasksAdded = 0;
        var idx = 0;
        while (idx < _waitingTasks.length && tasksAdded < howManyCanWeDo) {
            var task = _waitingTasks[idx++];
            //Find which worker thread is preferred for the task
            //If we are using a geometry pack to accelerate loading for small meshes,
            //each worker has a specific piece of the overall geometry pack
            var whichWorker = assignWorkerForGeomId(task.geomIdx);
            var msg = msgPerWorker[whichWorker];
            if (!msg) {
                msg = {
                    operation: "LOAD_GEOMETRY_OTG",
                    urls: [task.url],
                    isCDN: task.isCDN,
                    hashes: [task.hash],
                    geomIds: [task.geomIdx],
                    sampleWorldMatrices: [task.sampleWorldMatrix],
                    queryParams: task.queryParams
                };
                msgPerWorker[whichWorker] = msg;
            } else {
                msg.urls.push(task.url);
                msg.hashes.push(task.hash);
                msg.geomIds.push(task.geomIdx);
                msg.sampleWorldMatrices.push(task.sampleWorldMatrix);
            }
            tasksAdded++;
        }
        _waitingTasks.splice(0, idx);
        for (var i = 0; i < msgPerWorker.length; i++) {
            var msg = msgPerWorker[i];
            if (msg) {
                // send request to worker
                _workers[i].doOperation(_delegate.initLoadContext(msg));
                _requestsInProgress += msg.urls.length;
            }
        }
        _timeout = undefined;
    }
    // remove all open requests of this client
    // input is a map whose keys are geometry hashes
    this.cancelRequests = function (geomHashMap) {
        for (var hash in geomHashMap) {
            var task = _geomHash2Requests[hash];
            if (task) task.refcount--;
            /*
            if (task.refcount === 1) {
                delete _geomHash2Requests[hash];
            }*/
        }
        var hiPrioList = [];
        for (var i = 0; i < _waitingTasks.length; i++) {
            var t = _waitingTasks[i];
            if (_geomHash2Requests[t.hash].refcount) hiPrioList.push(t);else delete _geomHash2Requests[t.hash];
        }
        //TODO: perhaps we can leave requests with refcount = 0 in the queue
        //but sort the queue based on refcount so that those get deprioritized
        _waitingTasks = hiPrioList;
        // TODO: To make switches faster, we should also inform the worker thread,
        //       so that it doesn't spend too much time with loading geometries that noone is waiting for.
    };
    // To prioritize a geometry, we track the bbox surface area of all fragments using it.
    //
    // For this, this function must be called for each new loaded fragment.
    //  @param {RenderModel} model
    //  @param {number}      fragId
    this.updateGeomImportance = function () {
        var tmpBox = new LmvBox3();
        return function (model, fragId) {
            // get geom and bbox of this fragment
            var frags = model.getFragmentList();
            var geom = frags.getGeometry(fragId);
            frags.getWorldBounds(fragId, tmpBox);
            // Geoms may be null by design, if the original geometry was degenerated before OTG translation
            if (!geom) {
                return;
            }
            var oldImportance = geom.importance || 0;
            var fragImportance = getBoxSurfaceArea(tmpBox);
            geom.importance = Math.max(oldImportance, fragImportance);
        };
    }();
    this.cleanup = function () {
        // {BufferGeometry[]} - reused tmp-array. Must always be cleared at function end to avoid geom leaking.
        var unusedGeoms = [];
        return function () {
            if (this.byteSize < _maxMemory) {
                return;
            }
            // get array of models in memory
            var loadedModels = _delegate.renderScene.getModels().concat(_delegate.renderScene.getHiddenModels());
            if (_allGeomsInUse) {
                // On last run, we discovered that we have no unused geometries anymore. As long as no model
                // is unloaded, we should not retry. Otherwise, we would waste a lot of time for each single new geometry.
                // Note that this has huge performance impact, because rerunning for each geometry is extremely slow.
                return;
            }
            // mark all geometries in-use with latest time-stamp
            // We consider a geometry as in-use if it is currently loaded by the viewer
            _timeStamp++;
            for (var i = 0; i < loadedModels.length; i++) {
                // get geom hashes for this model
                var model = loadedModels[i];
                var data = model.getData();
                if (!model.isOTG()) {
                    // if this is not an OTG model, it cannot contain shared geoms.
                    // We can skip it.
                    continue;
                }
                // For OTG models, we can assume that data is an OtgPackage and contains hashes
                // update timestamp for all geoms that are referenced by the hash list
                var hashCount = data.geomMetadata.hashes.length / data.geomMetadata.byteStride;
                for (var j = 1; j < hashCount; j++) {
                    // If the geom for this hash is in cache, update its tiemstamp
                    var hash = data.getGeometryHash(j);
                    var geom = _geoms[hash];
                    if (geom) {
                        geom.timeStamp = _timeStamp;
                    }
                }
            }
            // verify that no geom is leaked in the reused tmp array
            if (unusedGeoms.length > 0) {
                console.warn("OtgGeomCache.cleanup(): array must be empty");
            }
            // Collect all unused geoms, i.e., all geoms that do not have the latest timeStamp
            for (var hash in _geoms) {
                var geom = _geoms[hash];
                if (geom.timeStamp !== _timeStamp) {
                    unusedGeoms.push(geom);
                }
            }
            // Sort unused geoms by ascending importance
            unusedGeoms.sort(compareGeomsByImportance);
            // Since cleanup is too expensive to run per geometry,
            // we always remove a bit more than strictly necessary,
            // so that we can load some more new geometries before we have to
            // run cleanup again.
            var targetMem = _maxMemory - _minCleanup;
            // Remove geoms until we reach mem target
            var i = 0;
            for (; i < unusedGeoms.length && this.byteSize >= targetMem; i++) {
                var geom = unusedGeoms[i];
                // remove it from cache
                delete _geoms[geom.hash];
                // update mem consumption. Note that we run this only for geoms that
                // are not referenced by any RenderModel in memory, so that removing them
                // should actually free memory.
                this.byteSize -= geom.byteSize;
                // Dispose GPU mem.
                // NOTE: In case we get performance issues in Chrome, try commenting this out
                // (see hack in GeometryList.dispose)
                geom.dispose();
            }
            if (i === unusedGeoms.length) {
                // No more unused geometries. Any subsequent attempt to cleanup will fail until
                // the next model unload.
                _allGeomsInUse = true;
            }
            // clear reused temp array. Note that it's essential to do this immediately. Otherwise,
            // the geoms would be leaked until next cleanup.
            unusedGeoms.length = 0;
        };
    }();
    // Helper function to compare two THREE.Vector3
    function fuzzyEquals(a, b, eps) {
        return Math.abs(a.x - b.x) < eps && Math.abs(a.y - b.y) < eps && Math.abs(a.z - b.z) < eps;
    }
    // Checks if the camera has significantly changed 
    function checkCameraChanged(newPos, newTarget) {
        var Tolerance = 0.01;
        if (fuzzyEquals(_lastCamPos, newPos, Tolerance) && fuzzyEquals(_lastCamTarget, newTarget, Tolerance)) {
            // no change
            return false;
        }
        _lastCamPos.copy(newPos);
        _lastCamTarget.copy(newTarget);
        return true;
    }
    // Checks if the set of visible models has changed
    function checkModelsChanged() {
        // get currently visible models
        var models = _delegate.renderScene.getModels();
        var changed = false;
        // Check if number of visible models changed
        if (models.length != _lastVisibleModelIds.length) {
            _lastVisibleModelIds.length = models.length;
            changed = true;
        }
        // Check if any element of visible models have changed
        for (var i = 0; i < models.length; i++) {
            var idOld = _lastVisibleModelIds[i];
            var idNew = models[i].id;
            if (idOld !== idNew) {
                _lastVisibleModelIds[i] = idNew;
                changed = true;
            }
        }
        return changed;
    }
    // Checks for any relevant changes that require to recompute request priorities.
    // If found, all requests are marked by the importanceNeedsUpdate flag.
    function validateRequestPriorities() {
        // get current camera pos/target
        var cam = _cameraCallback();
        var pos = cam.position;
        var target = cam.target;
        // check if camera or set of visible model have changed
        var cameraChanged = checkCameraChanged(pos, target);
        var modelsChanged = checkModelsChanged();
        if (cameraChanged || modelsChanged) {
            // invalidate all task priorities
            for (var i = 0; i < _waitingTasks.length; i++) {
                _waitingTasks[i].importanceNeedsUpdate = true;
            }
        }
    }
    this.updateRequestPriorities = function () {
        // We track the time consumed for priority updates. If it exceeds the limit,
        // we stop the updates and continue next cycle.
        var updateStartTime = performance.now();
        var TimeLimit = 10; // in ms
        // Mark requests as outdated if any relevant changes occurred
        validateRequestPriorities();
        var frustum = _delegate.renderScene.frustum();
        var models = _delegate.renderScene.getModels(); // all models (excluding the hidden ones - which will not considered for importance)
        // Make sure that FrustumIntersector is up-to-date.
        frustum.reset(_cameraCallback());
        // indicates if we stopped due to timeout
        var timeOut = false;
        var useFullSort = _prevNumTasks === 0 || _waitingTasks.length - _prevNumTasks > 3000 || !_fullSortDone;
        _fullSortDone = !useFullSort;
        _prevNumTasks = _waitingTasks.length;
        // Update importance for each waiting request
        for (var i = 0; i < _waitingTasks.length; i++) {
            var task = _waitingTasks[i];
            // only do work for tasks that need it
            if (!task.importanceNeedsUpdate) {
                continue;
            }
            //Don't check the timer on every spin through the loop
            //as it takes some time.
            if (i % 10 === 0) {
                var elapsed = performance.now() - updateStartTime;
                if (elapsed > TimeLimit) {
                    timeOut = true;
                    break;
                }
            }
            task.importanceNeedsUpdate = false;
            // reset importance to 0.0, because we accumulate frag importances below
            task.importance = 0.0;
            var sumImportances = 0.0;
            // find fragments of all visible models that use geomHash
            var geomHash = task.hash;
            for (var j = 0; j < models.length; j++) {
                var model = models[j];
                // we only deal with otg geometries
                if (!model.isOTG()) {
                    continue;
                }
                // Note that we cannot use FragmentLists at this point, because FragmentLists only know about
                // fragments for which geometry is already loaded.
                // => We must use Otg package instead.
                var otg = model.getData();
                var frags = otg.fragments;
                var boxes = frags.boxes;
                // If the geomHash is used in this model, get its geom index
                var geomIndex = otg.geomMetadata.hashToIndex[geomHash];
                if (!geomIndex) {
                    // geom is not used by this model
                    continue;
                }
                // Get list of fragments in 'model' that are using 'geomIndex' 
                var fragIds = frags.mesh2frag[geomIndex];
                if (typeof fragIds === 'number') {
                    // single fragId
                    var value = computeFragImportance(fragIds, boxes, frustum);
                    sumImportances += value;
                } else if (Array.isArray(fragIds)) {
                    // multiple fragIds
                    for (var k = 0; k < fragIds.length; k++) {
                        var fragId = fragIds[k];
                        var value = computeFragImportance(fragId, boxes, frustum);
                        sumImportances += value;
                    }
                }
            }
            task.importance = sumImportances;
            if (!useFullSort) {
                //Move the task to the correct spot in the list based on its
                //new importance. This is basically insertion sort, but assuming
                //the task list is nearly sorted already it should be quick
                var j = i;
                while (j > 0 && sumImportances > _waitingTasks[j - 1].importance) {
                    _waitingTasks[j] = _waitingTasks[j - 1];
                    j--;
                }
                _waitingTasks[j] = task;
            }
        }
        if (useFullSort && !timeOut) {
            // sort task queue by descending request priority
            _waitingTasks.sort(compareRequests);
            _fullSortDone = true;
        }
        // return true if all request priorities are up-to-date and sorted
        return !timeOut;
    };
}
THREE$1.EventDispatcher.prototype.apply(OtgGeomCache.prototype);

"use strict";

var WORKER_LOAD_OTG_BVH = "LOAD_OTG_BVH";
/** @constructor */
var OtgLoader = function OtgLoader(delegate) {
    this.delegate = FileLoader.copyDelegate(this, delegate);
    var scope = this;
    // Supply defaults that load the property database and textures
    if (!this.delegate.loadPropertyDb) {
        this.delegate.loadPropertyDb = function (sharedDbPath, model) {
            // In this function "this" is the delegate object
            scope.svf.propDbLoader = new PropDbLoader(sharedDbPath, model, scope.delegate);
            scope.svf.propDbLoader.load();
        };
    }
    if (!this.delegate.loadModelTextures) {
        // In this function "this" is the delegate object
        this.delegate.loadModelTextures = function (model) {
            TextureLoader.loadModelTextures(scope.delegate, model);
        };
    }
    if (!this.delegate.loadMaterialTextures) {
        // In this function "this" is the delegate object
        this.delegate.loadMaterialTextures = function (model, material) {
            TextureLoader.loadMaterialTextures(scope.delegate, model, material);
        };
    }
    this.loading = false;
    this.tmpMatrix = new LmvMatrix4();
    this.tmpBox = new LmvBox3();
    this.logger = exports.logger;
    this.loadTime = 0;
    this.pendingMaterials = {};
    this.pendingMaterialIds = [];
    this.pendingMaterialsCount = 0;
    this.operationsDone = 0;
};
OtgLoader.prototype.dtor = function () {
    // Cancel all potential process on loading a file.
    // 1. init worker script can be cancelled.
    //
    if (this.initWorkerScriptToken) {
        this.initWorkerScriptToken.cancel();
        this.initWorkerScriptToken = null;
        exports.logger.debug("SVF loader dtor: on init worker script.");
    }
    // 2. load model root (aka. svf) can be cancelled.
    //
    if (this.bvhWorker) {
        this.bvhWorker.clearAllEventListenerWithIntercept();
        this.bvhWorker.terminate();
        this.bvhWorker = null;
        exports.logger.debug("SVF loader dtor: on svf worker.");
    }
    if (this.svf) {
        if (!this.svf.loadDone) console.log("stopping load before it was complete");
        this.svf.abort();
        if (this.svf.propWorker) {
            this.svf.propWorker.dtor();
            this.svf.propWorker = null;
        }
    }
    // 5. Cancel all running requests in shared geometry worker
    //
    if (this.geomCache && this.model) {
        if (this.loading) this.geomCache.cancelRequests(this.svf.geomMetadata.hashToIndex);
        this.removeMeshReceiveListener();
    }
    // and clear metadata.
    this.delegate = null;
    this.model = null;
    this.svf = null;
    this.logger = null;
    this.tmpMatrix = null;
    this.loading = false;
    this.loadTime = 0;
};
OtgLoader.prototype.isValid = function () {
    return this.delegate != null;
};
// Stop listening to mesh receive events
OtgLoader.prototype.removeMeshReceiveListener = function () {
    if (this.meshReceiveListener) {
        this.geomCache.removeEventListener(MESH_RECEIVE_EVENT, this.meshReceiveListener);
        this.geomCache.removeEventListener(MESH_FAILED_EVENT, this.meshReceiveListener);
        this.meshReceiveListener = null;
    }
};
OtgLoader.prototype.loadFile = function (path, options, onDone, onWorkerStart) {
    if (!this.delegate) {
        exports.logger.log("OTG loader was already destructed. So no longer usable.");
        return false;
    }
    if (this.loading) {
        exports.logger.log("Loading of OTG already in progress. Ignoring new request.");
        return false;
    }
    this.geomCache = this.delegate.getGeomCache();
    if (!this.geomCache) {
        // The OTG loader requires a geom cache. Leave loader uninitialized if we don't have one.
        exports.logger.log("GeomCache not provided so OTG loader cannot load the model");
        return false;
    }
    // Mark it as loading now.
    this.loading = true;
    this.delegate.eventTarget.dispatchEvent({ type: FILE_LOAD_STARTED, loader: this });
    var index = path.indexOf('urn:');
    if (index != -1) {
        // Extract urn:adsk.viewing:foo.bar.whateverjunks out of the path URL and bind it to logger.
        // From now on, we can send logs to viewing service, and logs are grouped by urn to make Splunk work.
        path = decodeURIComponent(path);
        var urn = path.substr(index, path.substr(index).indexOf('/'));
        exports.logger.log("Extracted URN: " + urn);
        // Extract urn(just base64 code)
        var _index = urn.lastIndexOf(':');
        this.svfUrn = urn.substr(_index + 1);
    } else {
        this.svfUrn = path;
    }
    this.sharedDbPath = options.sharedPropertyDbPath;
    this.currentLoadPath = path;
    var basePath = "";
    var lastSlash = this.currentLoadPath.lastIndexOf("/");
    if (lastSlash != -1) basePath = this.currentLoadPath.substr(0, lastSlash + 1);
    this.basePath = basePath;
    this.acmSessionId = options.acmSessionId;
    this.options = options;
    var loadContext = {
        basePath: basePath,
        objectIds: options.ids,
        globalOffset: options.globalOffset,
        placementTransform: options.placementTransform,
        applyRefPoint: options.applyRefPoint,
        queryParams: options.acmSessionId ? "acmsession=" + options.acmSessionId : "",
        bvhOptions: options.bvhOptions || { isWeakDevice: isMobileDevice() },
        applyScaling: options.applyScaling,
        loadInstanceTree: options.loadInstanceTree
    };
    this.loadContext = this.delegate.initLoadContext(loadContext);
    loadContext.onFailureCallback = function (code, message, data) {
        onDone && onDone({ code: code, message: message, data: data });
    };
    this.loadModelRoot(loadContext, onDone);
    //We don't use a worker for OTG root load, so we call this back immediately
    //We will use the worker for heavy tasks like BVH compute after we get the model root file.
    onWorkerStart && onWorkerStart();
    return true;
};
OtgLoader.prototype.loadModelRoot = function (loadContext, onDone) {
    this.t0 = new Date().getTime();
    this.firstPixelTimestamp = null;
    var scope = this;
    var svf = this.svf = new OtgPackage();
    svf.basePath = loadContext.basePath;
    //Those events happen on the main thread, unlike SVF loading where
    //everything happens in the svfWorker
    loadContext.onLoaderEvent = function (whatIsDone, data) {
        if (!scope.svf) {
            console.error("load callback called after load was aborted");
            return;
        }
        if (whatIsDone === "otg_root") {
            scope.onModelRootLoadDone(svf);
            if (onDone) onDone(null, scope.model);
            scope.makeBVHInWorker();
            // init shared cache on first use
            var geomCache = scope.geomCache;
            if (!geomCache) {
                // If this loader would create an own cache, it could be a hidden memory waste.
                // So it's better to complain.
                exports.logger.error("geomCache is required for loading OTG models.");
            }
            var urlPack = scope.svf.manifest.assets.geometry_pack;
            if (urlPack) {
                if (urlPack.indexOf("https://") !== 0 && urlPack.indexOf("http://") !== 0) urlPack = pathToURL(scope.basePath) + urlPack;
                var urlOffsets = scope.svf.manifest.assets.geometry_idx;
                if (urlOffsets.indexOf("https://") !== 0 && urlOffsets.indexOf("http://") !== 0) urlOffsets = pathToURL(scope.basePath) + urlOffsets;
                //TODO: Enable here to use geom packs
                geomCache.initWorker(urlPack, urlOffsets, scope.svf.metadata.stats.geometry_pack_fanout);
            }
            scope.meshReceiveListener = function (data) {
                if (data.error && data.error.args) {
                    scope.onMeshError(data);
                } else {
                    scope.onMeshReceived(data.geom);
                }
            };
            geomCache.addEventListener(MESH_RECEIVE_EVENT, scope.meshReceiveListener);
            geomCache.addEventListener(MESH_FAILED_EVENT, scope.meshReceiveListener);
            scope.svf.loadDone = false;
        } else if (whatIsDone === "fragment") {
            if (!scope.options.skipMeshLoad) scope.tryToActivateFragment(data, "fragment");
        } else if (whatIsDone === "all_fragments") {
            //For 3D models, we can start loading the property database as soon
            //as we know the fragment list which contains the fragId->dbId map.
            if (!scope.options.skipPropertyDb) {
                scope.delegate.loadPropertyDb(scope.sharedDbPath, scope.model);
            }
            scope.delegate.eventTarget.dispatchEvent({ type: MODEL_ROOT_LOADED_EVENT, svf: svf, model: scope.model });
            if (scope.options.skipMeshLoad) {
                scope.onGeomLoadDone();
            } else scope.onOperationComplete();
        } else if (whatIsDone === "bvh") {
            var bvh = data;
            if (scope.model) {
                scope.model.setBVH(bvh.nodes, bvh.primitives, scope.options.bvhOptions);
                if (scope.delegate.renderScene) {
                    // Refresh viewer if model is visible.
                    if (scope.delegate.renderScene.findModel(scope.model.id)) {
                        scope.delegate.requestRedraw(false);
                    }
                }
            }
            scope.onOperationComplete();
        } else if (whatIsDone === "materials_pack" || whatIsDone === "materials_offsets") {
            //Materials pack or pack offset file was loaded. In case we got both,
            //process any already requested materials
            if (scope.svf.materials_pack && scope.svf.materials_offsets) {
                for (var i = 0; i < scope.pendingMaterialIds.length; i++) {
                    var matId = scope.pendingMaterialIds[i];
                    var matHash = scope.svf.getMaterialHash(matId);
                    var matObj = scope.svf.extractMaterialFromPack(matId);
                    scope.onMaterialLoaded(matObj, matHash, matId);
                }
                //no longer need this
                scope.pendingMaterialIds = null;
            }
        }
    };
    svf.loadRemainingSvf(loadContext, pathToURL(this.currentLoadPath));
    return true;
};
OtgLoader.prototype.makeBVHInWorker = function () {
    var scope = this;
    this.initWorkerScriptToken = this.delegate.workerScript.initWorkerScript(function () {
        scope.bvhWorker = scope.delegate.workerScript.createWorkerWithIntercept();
        var onOtgWorkerEvent = function onOtgWorkerEvent(e) {
            if (e.data.bvh) {
                console.log("Received BVH from worker");
                var bvh = e.data.bvh;
                if (scope.model) {
                    scope.svf.bvh = bvh;
                    scope.model.setBVH(new NodeArray(bvh.nodes, bvh.useLeanNodes), bvh.primitives, scope.options.bvhOptions);
                    if (scope.delegate) {
                        // Refresh viewer if model is visible.
                        if (scope.delegate.renderScene.findModel(scope.model.id)) {
                            scope.delegate.requestRedraw(false);
                        }
                    }
                }
                scope.bvhWorker.clearAllEventListenerWithIntercept();
                scope.bvhWorker.terminate();
                scope.bvhWorker = null;
                scope.onOperationComplete();
            }
        };
        scope.bvhWorker.addEventListenerWithIntercept(onOtgWorkerEvent);
        //We can kick off the request for the fragments-extra file, needed
        //for the BVH build as soon as we have the metadata (i.e. placement transform)
        //Do this on the worker thread, because the BVH build can take a while.
        var workerContext = Object.assign({}, scope.loadContext);
        workerContext.operation = WORKER_LOAD_OTG_BVH;
        workerContext.onFailureCallback = null;
        workerContext.onLoaderEvent = null;
        workerContext.fragments_extra = pathToURL(scope.basePath) + scope.svf.manifest.assets.fragments_extra;
        workerContext.placementTransform = scope.svf.placementTransform;
        workerContext.placementWithOffset = scope.svf.placementWithOffset;
        workerContext.globalOffset = scope.svf.globalOffset;
        scope.bvhWorker.doOperation(workerContext);
    });
};
var _meshInfo$1 = {};
//Attempts to turn on display of a received fragment.
//If the geometry or material is missing, issue requests for those
//and delay the activation. Once the material or mesh comes in, they
//will attempt this function again.
OtgLoader.prototype.tryToActivateFragment = function (fragId, whichCaller) {
    var scope = this;
    //Was loading canceled?
    if (!scope.model) return;
    var svf = scope.svf;
    var rm = scope.model;
    var gl = rm.getGeometryList();
    var materialId = svf.fragments.materials[fragId];
    var matHash = svf.getMaterialHash(materialId);
    var materialIsHere = this.findOrLoadMaterial(rm, matHash, materialId);
    var haveToWait = false;
    //The tryToActivate function can be called up to three times, until all the
    //needed parts are received. We only want to issue a geometry load request once.
    if (!materialIsHere) {
        if (whichCaller === "fragment") {
            //Material is not yet available, so we will delay adding the mesh until it arrives
            //This should not happen too often.
            this.pendingMaterials[matHash].push(fragId);
        } else {
            /*
                var pending = this.pendingMaterials[matHash];
                if (!pending)
                    console.error("Material should be pending!");
                else if (pending.indexOf(fragId) === -1)
                    console.error("Fragment should be listed in the pending list");
                else {
                    //console.log(fragId, pending.indexOf(fragId), matHash, whichCaller);
                }
                */
        }
        if (whichCaller !== "material") {
            haveToWait = true;
        } else {
            //material loading probably failed
            console.log("material loading probably failed");
        }
    }
    var geomId = svf.fragments.geomDataIndexes[fragId];
    if (geomId === 0) {
        if (svf.failedFrags[fragId]) return;
        svf.failedFrags[fragId] = 1;
        // Note that otg translation may assign geomIndex 0 to some fragments by design.
        // This happens when the source fragment geometry was degenerated.
        // Therefore, we do not report any warning or error for this case.
        //don't block overall progress because of this
        scope.trackGeomLoadProgress(svf, fragId);
        return;
    }
    //We get the matrix from the fragments and we set it back there
    //with the activateFragment call, but this is to maintain the
    //ability to add a plain THREE.Mesh -- otherwise it could be simpler
    rm.getFragmentList().getOriginalWorldMatrix(fragId, scope.tmpMatrix);
    var geom = gl.getGeometry(geomId);
    if (!geom) {
        //The tryToActivate function can be called up to three times, until all the
        //needed parts are received. We only want to issue a geometry load request once.
        if (whichCaller === "fragment") {
            this.loadGeometry(geomId, this.options.createWireframe ? scope.tmpMatrix : null);
        }
        haveToWait = true;
    }
    if (haveToWait) return;
    //if (this.options.createWireframe)
    //    DeriveTopology.createWireframe(geom, scope.tmpMatrix);
    _meshInfo$1.geometry = geom;
    _meshInfo$1.material = this.delegate.matman.setupMaterial(rm, geom, matHash);
    _meshInfo$1.matrix = scope.tmpMatrix;
    _meshInfo$1.isLine = geom.isLines;
    _meshInfo$1.isWideLine = geom.isWideLines;
    _meshInfo$1.isPoint = geom.isPoints;
    _meshInfo$1.is2d = geom.is2d;
    // provide correct geometry id. (see GeometryList.setMesh). Note that we cannot use
    // geom.svfid, because geomIds are model-specific and geometries may be shared.
    _meshInfo$1.geomId = geomId;
    //If there is a placement transform, we tell activateFragment to also recompute the
    //world space bounding box of the fragment from the raw geometry model box, for a tighter
    //fit compared to what we get when loading the fragment list initially.
    rm.activateFragment(fragId, _meshInfo$1, !!svf.placementTransform);
    // pass new fragment to Geometry cache to update priority
    // TODO: Check if we can determine the bbox earlier, so that we can also use it to prioritize load requests
    //       from different OtgLoaders.
    this.geomCache.updateGeomImportance(rm, fragId);
    scope.trackGeomLoadProgress(svf, fragId);
};
OtgLoader.prototype.onModelRootLoadDone = function (svf) {
    // Mark svf as OTG-file. (which uses sharable materials and geometry)
    svf.isOTG = true;
    svf.geomMetadata.hashToIndex = {};
    svf.failedFrags = {};
    svf.geomMemory = 0;
    svf.gpuNumMeshes = 0;
    svf.gpuMeshMemory = 0;
    svf.fragsLoaded = 0;
    svf.nextRepaintPolys = 0;
    svf.numRepaints = 0;
    svf.urn = this.svfUrn;
    svf.acmSessionId = this.acmSessionId;
    svf.basePath = this.basePath;
    svf.loadOptions = this.options;
    var t1 = Date.now();
    this.loadTime += t1 - this.t0;
    exports.logger.log("SVF load: " + (t1 - this.t0));
    // Create the API Model object and its render proxy
    // eslint-disable-next-line new-cap
    var model = this.model = new this.delegate.model(svf);
    model.loader = this;
    model.initialize();
    this.t0 = t1;
    //The BBox object loses knowledge of its
    //type when going across the worker thread boundary...
    svf.bbox = new LmvBox3().copy(svf.bbox);
    if (svf.refPointTransform) {
        svf.refPointTransform = new LmvMatrix4(true).copy(svf.refPointTransform);
    }
    if (svf.placementTransform) {
        svf.placementTransform = new LmvMatrix4(true).copy(svf.placementTransform);
    }
    //Camera vectors also lose their prototypes when they
    //cross the thread boundary...
    if (svf.cameras) {
        for (var i = 0; i < svf.cameras.length; i++) {
            var camera = svf.cameras[i];
            camera.position = new LmvVector3$1().copy(camera.position);
            camera.target = new LmvVector3$1().copy(camera.target);
            camera.up = new LmvVector3$1().copy(camera.up);
        }
    }
    exports.logger.log("scene bounds: " + JSON.stringify(svf.bbox));
    var metadataStats = {
        category: "metadata_load_stats",
        urn: svf.urn,
        has_topology: !!svf.topology,
        has_animations: !!svf.animations,
        materials: svf.metadata.stats.num_materials,
        is_mobile: isMobileDevice()
    };
    exports.logger.track(metadataStats);
    this.delegate.signalProgress(0);
    // We don't call invalidate here: At this point, the model is not added to the viewer yet (see onSuccess()
    // in Viewer3D.loadModel). So, invalidating would just let other models flicker.
};
// Returns geometry loading progress in integer percent
function getProgress(svf) {
    return Math.floor(100 * svf.fragsLoaded / svf.metadata.stats.num_fragments);
}
// Called whenever a geom load request is finished or or has failed.
OtgLoader.prototype.trackGeomLoadProgress = function (svf, fragId) {
    // Inc geom counter and track progress in percent
    var lastPercent = getProgress(svf);
    svf.fragsLoaded++;
    var curPercent = getProgress(svf);
    // Signal progress, but not for each single geometry. Just if the percent value actually changed.
    if (curPercent > lastPercent) {
        this.delegate.signalProgress(curPercent);
        //console.log(svf.fragsLoaded, svf.metadata.stats.num_fragments);
    }
    //repaint every once in a while -- more initially, less as the load drags on.
    var geomList = this.model.getGeometryList();
    if (geomList.geomPolyCount > svf.nextRepaintPolys) {
        //logger.log("num loaded " + numLoaded);
        this.firstPixelTimestamp = this.firstPixelTimestamp || Date.now();
        svf.numRepaints++;
        svf.nextRepaintPolys += 10000 * Math.pow(1.5, svf.numRepaints);
        // refresh viewer if model is visible
        if (this.delegate.renderScene.findModel(this.model.id)) {
            this.delegate.requestRedraw(false);
        }
    }
    // If this was the last geom to receive...
    if (svf.fragsLoaded === svf.metadata.stats.num_fragments) {
        // Signal that we are done with mesh loading
        this.onOperationComplete();
    }
};
OtgLoader.prototype.onOperationComplete = function () {
    this.operationsDone++;
    //Destroy the loader if everything we are waiting to load is done
    if (this.operationsDone === 3) this.onGeomLoadDone();
};
OtgLoader.prototype.onMaterialLoaded = function (matObj, matHash, matId) {
    var matman = this.delegate.matman;
    if (matObj) {
        matObj.hash = matHash;
        var surfaceMat = matman.convertSharedMaterial(this.model, matObj, matHash);
        this.delegate.loadMaterialTextures(this.model, surfaceMat);
        if (matman.hasTwoSidedMaterials()) {
            this.delegate.toggleTwoSided(true);
        }
        var fragments = this.pendingMaterials[matHash];
        for (var i = 0; i < fragments.length; i++) {
            this.tryToActivateFragment(fragments[i], "material");
        }
    } else {
        console.error('Got null pointer for "matObj" for "matHash" ' + matHash);
    }
    this.pendingMaterialsCount--;
    delete this.pendingMaterials[matHash];
};
OtgLoader.prototype.findOrLoadMaterial = function (model, matHash, matId) {
    //Check if it's already in the material manager
    var svf = this.model.getData();
    var matman = this.delegate.matman;
    var mat = matman.findMaterial(model, matHash);
    if (mat) return true;
    //check if it's already requested, but the request is not complete
    if (this.pendingMaterials[matHash]) {
        return false;
    }
    //If it's not even requested yet, kick off the request
    this.pendingMaterialsCount++;
    this.pendingMaterials[matHash] = [];
    //If there is a built-in materials pack file, use that
    if (svf.hasMaterialsPack || svf.pendingMaterialsPack) {
        var matObj = svf.extractMaterialFromPack(matId);
        if (matObj) {
            this.onMaterialLoaded(matObj, matHash, matId);
            return true;
        } else {
            //Materials pack is not yet here, queue the material request for later
            this.pendingMaterialIds.push(matId);
            return false;
        }
    } else {
        //No materials pack, use CDN request
        // define callback to receive material
        var scope = this;
        var addMatCb = function addMatCb(matObj) {
            scope.onMaterialLoaded(matObj, matHash, matId);
        };
        this.svf.loadMaterial(this.loadContext, matHash, addMatCb);
        return false;
    }
};
OtgLoader.prototype.loadGeometry = function (geomIdx, sampleWorldMatrix) {
    var svf = this.svf;
    var isCDN = !!this.loadContext.otg_cdn;
    //get the hash string that points to the geometry
    var geomHash = svf.getGeometryHash(geomIdx);
    svf.geomMetadata.hashToIndex[geomHash] = geomIdx;
    var url = svf.makeSharedResourcePath(this.loadContext.otg_cdn, "geometry", geomHash);
    // load geometry or get it from cache
    var geomCache = this.geomCache;
    geomCache.requestGeometry(url, isCDN, geomHash, geomIdx, isCDN ? "" : this.queryParam, sampleWorldMatrix);
};
OtgLoader.prototype.onMeshError = function (mdata) {
    var fragments = this.svf.fragments;
    var geomId = this.svf.geomMetadata.hashToIndex[mdata.error.args.hash];
    var frags = fragments.mesh2frag[geomId];
    // get hashfile for more accurate error reporting
    var hashFile = this.svf.basePath + this.svf.manifest.assets.geometry_ptrs;
    console.warn("Error loading mesh", mdata.error.args.hash, '(GeomId: ' + geomId + ', HashFile: ' + hashFile + ')');
    //Update progress so it doesn't get stuck due to not receiving all geoms.
    if (typeof frags !== "undefined") {
        if (!Array.isArray(frags)) {
            this.trackGeomLoadProgress(this.svf, frags);
        } else {
            for (var i = 0; i < frags.length; i++) {
                //this.tryToActivateFragment(frags[i], "geom");
                this.trackGeomLoadProgress(this.svf, frags[i]);
            }
        }
    }
};
OtgLoader.prototype.onMeshReceived = function (geom) {
    var rm = this.model;
    if (!rm) {
        console.warn("Received geometry after loader was done. Possibly leaked event listener?", geom.hash);
        return;
    }
    var gl = rm.getGeometryList();
    var fragments = this.svf.fragments;
    var geomId = this.svf.geomMetadata.hashToIndex[geom.hash];
    //It's possible this fragment list does not use this geometry
    if (geomId === undefined) return;
    var geomAlreadyAdded = gl.getGeometry(geomId);
    var frags = fragments.mesh2frag[geomId];
    if (!geomAlreadyAdded) gl.addGeometry(geom, frags && frags.length || 1, geomId);else return; //geometry was already received, possibly due to sharing with the request done by another model loader in parallel
    if (this.svf.loadDone) {
        console.error("Geometry received after load was done");
    }
    if (typeof frags !== "undefined") {
        if (!Array.isArray(frags)) {
            this.tryToActivateFragment(frags, "geom");
        } else {
            for (var i = 0; i < frags.length; i++) {
                this.tryToActivateFragment(frags[i], "geom");
            }
        }
    }
};
OtgLoader.prototype.onGeomLoadDone = function () {
    this.svf.loadDone = true;
    // Stop listening to geometry receive events. Since all our geometry is loaded, any subsequent geom receive
    // events are just related to requests from other loaders.
    this.removeMeshReceiveListener();
    //Note that most materials are probably done already as their geometry
    //is received, so this logic will most likely just trigger the textureLoadComplete event.
    this.delegate.loadModelTextures(this.model);
    //If we were asked to just load the model root / metadata, bail early.
    if (this.options.skipMeshLoad) {
        this.currentLoadPath = null;
        this.delegate.eventTarget.dispatchEvent({ type: GEOMETRY_DOWNLOAD_COMPLETE, model: this.model, memoryLimited: false });
        return;
    }
    // We need to keep a copy of the original fragments
    // transforms in order to restore them after explosions, etc.
    // the rotation/scale 3x3 part.
    // TODO: consider only keeping the position vector and throwing out
    //
    //delete this.svf.fragments.transforms;
    // Release that won't be used. the on demand loading won't call this anyway.
    this.svf.fragments.entityIndexes = null;
    this.svf.fragments.mesh2frag = null;
    var t1 = Date.now();
    var msg = "Fragments load time: " + (t1 - this.t0);
    this.loadTime += t1 - this.t0;
    var firstPixelTime = this.firstPixelTimestamp - this.t0;
    msg += ' (first pixel time: ' + firstPixelTime + ')';
    exports.logger.log(msg);
    // Run optional consolidation step
    if (this.options.useConsolidation && this.delegate.webGLRenderer) {
        // TODO: I don't really like to access the viewer and (even worse) the renderer here. But for the
        //       consolidation, we need it to know whether we can use instancing and to dispose individual fragemnts
        //       from GPU to make space for the consolidated ones.
        var glRenderer = this.delegate.webGLRenderer;
        this.model.consolidate(this.delegate.matman, this.options.consolidationMemoryLimit, glRenderer);
    }
    var modelStats = {
        category: "model_load_stats",
        is_f2d: false,
        has_prism: this.delegate.matman.hasPrism,
        load_time: this.loadTime,
        geometry_size: this.model.getGeometryList().geomMemory,
        meshes_count: this.svf.metadata.stats.num_geoms,
        fragments_count: this.svf.metadata.stats.num_fragments,
        urn: this.svfUrn
    };
    if (firstPixelTime > 0) {
        modelStats['first_pixel_time'] = firstPixelTime; // time [ms] from SVF load to first geometry rendered
    }
    exports.logger.track(modelStats);
    this.currentLoadPath = null;
    this.delegate.eventTarget.dispatchEvent({ type: GEOMETRY_DOWNLOAD_COMPLETE, model: this.model, memoryLimited: false });
};
OtgLoader.prototype.is3d = function () {
    return true;
};

// Transcriber from AES format to Protein format
// Sourced from https://git.autodesk.com/arbreea/svf-material-conversion-example/blob/master/src/MaterialConverter.js
'use strict';
var UNITS = ['degree', 'radian', 'millimeter', 'centimeter', 'meter', 'kilometer', 'inch', 'foot', 'mile'];
var UNIT_ALIASES = {
    'mm': 'millimeter',
    'cm': 'centimeter',
    'm': 'meter',
    'km': 'kilometer',
    'in': 'inch',
    'ft': 'foot'
};
var IGNORED_FIELDS = ["AssetLibID", "Hidden", "thumbnail", "unifiedbitmap_Bitmap", "bumpmap_Bitmap", "BaseSchema", "UIName", "revision", "opaque_albedo_urn", "opaque_f0_urn", "opaque_luminance_modifier_urn", "opaque_mfp_modifier_urn", "surface_albedo_urn", "surface_anisotropy_urn", "surface_cutout_urn", "surface_normal_urn", "surface_rotation_urn", "surface_roughness_urn"];
var NDF_CHOICES = ['beckmann', 'ggx'];
var CHOICES = {
    'surface_ndf_type': NDF_CHOICES,
    'layered_ndf_type': NDF_CHOICES,
    'bumpmap_Type': ['height', 'normal'],
    'wood_pore_type': ['both', 'earlywood', 'latewood'],
    'common_Shared_Asset': [0, 1]
};
function throwParseError(key, value, message) {
    throw new Error(message + ' Key: ' + key + ' Value: ' + JSON.stringify(value));
}
function isIgnored(fieldName) {
    return IGNORED_FIELDS.indexOf(fieldName) >= 0;
}
function makeReference(key, urn, options) {
    if (key === 'bumpmap_Bitmap' || key === 'unifiedbitmap_Bitmap' || key === 'image') {
        return options.innerMats.hasOwnProperty(urn) ? convertTexture$1(options.innerMats[urn], options.getURL) : {
            IMAGE_MARKER: 'REMOVE',
            urn: urn
        };
    }
    if (key === 'surface_cutout' || key === 'wood_curly_distortion_map') {
        return [options.innerMats.hasOwnProperty(urn) ? convertTexture$1(options.innerMats[urn], options.getURL) : {
            REFERENCE_MARKER: 'REMOVE',
            urn: urn
        }];
    } else {
        return {
            texture: [options.innerMats.hasOwnProperty(urn) ? convertTexture$1(options.innerMats[urn], options.getURL) : {
                REFERENCE_MARKER: 'REMOVE',
                urn: urn
            }]
        };
    }
}
function parseConnection(key, value, options) {
    if (value.hasOwnProperty('connections')) {
        var connectionList = value.connections;
        if (connectionList.length === 1) {
            return makeReference(key, connectionList[0], options);
        }
        if (connectionList.length > 1 || connectionList.length === 0) {
            throwParseError(key, connectionList, 'Invalid connection.');
        }
    }
    return undefined;
}
function parseUnit(key, value) {
    if (value.hasOwnProperty('units')) {
        var unit = value.units;
        if (UNIT_ALIASES.hasOwnProperty(unit)) {
            unit = UNIT_ALIASES[unit];
        }
        if (unit === 'cd/m^2' || unit === 'Lux_I' || unit === '') {
            return undefined;
        }
        var match = UNITS.find(function (item) {
            return item === unit;
        });
        if (!match) {
            throwParseError(key, value, 'Value contains an illegal unit.');
        }
        return unit;
    }
    return undefined;
}
function parseValues(key, value) {
    if (value && value.hasOwnProperty('values')) {
        return value.values;
    }
    throwParseError(key, value, 'Missing values in key.');
}
function parseValueArray(key, value) {
    var valuesList = parseValues(key, value);
    if (Array.isArray(valuesList)) {
        return valuesList;
    }
    throwParseError(key, value, 'Expected an array value.');
}
function parseSingleValue(key, value) {
    var valueList = parseValueArray(key, value);
    if (valueList.length === 1) {
        return valueList[0];
    }
    throwParseError(valueList, key, 'Expected a single value.');
}
function parseColor(key, value, options) {
    var connection = parseConnection(key, value, options);
    if (connection) {
        return connection;
    }
    var cObject = parseSingleValue(key, value);
    if (!cObject.hasOwnProperty('r') || !cObject.hasOwnProperty('g') || !cObject.hasOwnProperty('b')) {
        throwParseError(cObject, key, 'Expected a color object with r, g and b fields.');
    }
    return {
        value: {
            linearFloat: [cObject.r, cObject.g, cObject.b]
        }
    };
}
function parseChoice(key, value) {
    var choiceValue = parseSingleValue(key, value);
    if (!CHOICES.hasOwnProperty(key)) {
        throwParseError(key, choiceValue, 'Unknown choice type key.');
    }
    var choiceList = CHOICES[key];
    if (choiceValue < 0 || choiceValue >= choiceList.length) {
        throwParseError(key, choiceValue, 'Choice value is out of range.');
    }
    return CHOICES[key][choiceValue];
}
function parseScalar(key, value, options) {
    var directArrayKeys = ['wood_growth_perlin_prof', 'wood_fiber_perlin_prof', 'wood_diffuse_perlin_prof', 'wood_earlycolor_perlin_prof', 'wood_latecolor_perlin_prof', 'wood_fiber_cosine_prof', 'wood_secondary_perlin_prof', 'center_direction', 'up_direction'];
    var directValueKeys = ['wood_earlywood_sharpness', 'wood_latewood_ratio', 'wood_fiber_roughness', 'wood_late_color_power', 'wood_ray_ellipse_z2x', 'wood_diffuse_perlin_scale_z', 'wood_latewood_sharpness', 'wood_diffuse_lobe_weight', 'wood_groove_roughness', 'wood_secondary_perlin_scale_z', 'wood_ray_color_power', 'wood_fiber_perlin_scale_z', 'wood_secondary_color_power', 'wood_pore_color_power', 'wood_curly_distortion_scale', 'bumpmap_RGBAmount', 'bumpmap_UOffset', 'bumpmap_VOffset', 'bumpmap_UScale', 'bumpmap_VScale', 'unifiedbitmap_RGBAmount', 'unifiedbitmap_UOffset', 'unifiedbitmap_VOffset', 'unifiedbitmap_UScale', 'unifiedbitmap_VScale', 'opaque_luminance', 'transparent_ior', 'illuminance', 'white_luminance'];
    if (directArrayKeys.indexOf(key) >= 0) {
        return parseValueArray(key, value);
    }
    if (directValueKeys.indexOf(key) >= 0) {
        return parseValueArray(key, value)[0];
    }
    var unit = parseUnit(key, value);
    var connection = parseConnection(key, value, options);
    if (connection) {
        if (unit) {
            connection.unit = unit;
        }
        return connection;
    }
    if (options.unitsProps ? options.unitsProps[key] : unit) {
        return {
            value: parseSingleValue(key, value),
            unit: unit || "inch"
        };
    }
    var valueList = parseValueArray(key, value);
    valueList = valueList.length === 1 ? valueList[0] : valueList;
    return options.scalarValues ? valueList : { value: valueList };
}
function parseString(key, value) {
    var values = parseValues(key, value);
    if (!Array.isArray(values)) {
        if (!values.hasOwnProperty('default')) {
            throwParseError(value, key, 'String object missing a default language value.');
        }
        values = values.default;
    }
    if (!Array.isArray(values)) {
        throwParseError(key, value, 'Expected an array value.');
    }
    if (values.length === 1) {
        return values[0];
    }
    return values;
}
function parseURI(key, value, options) {
    if (!value.hasOwnProperty('binary_connections')) {
        throwParseError(key, value, 'Expected binary connections field in value.');
    }
    var connections = value.binary_connections;
    if (connections.length === 1) {
        return makeReference(key, connections[0], options);
    }
    throwParseError(key, value, 'Invalid binary connections field.');
}
function parseBoolean(key, value) {
    if (typeof value == "boolean") {
        return value;
    }
    var boolValue = parseSingleValue(key, value);
    if (typeof boolValue !== 'boolean') {
        throwParseError(key, boolValue, 'Boolean value expected.');
    }
    return boolValue;
}
function parseInteger(key, value) {
    if (typeof value == "number") {
        return value;
    }
    var intValue = parseSingleValue(key, value);
    if (!Number.isInteger(intValue)) {
        throwParseError(key, intValue, 'Integer value expected.');
    }
    return intValue;
}
var PARSERS = {
    'strings': parseString,
    'booleans': parseBoolean,
    'scalars': parseScalar,
    'integers': parseInteger,
    'colors': parseColor,
    'choicelists': parseChoice,
    'uris': parseURI
};
var TEXTURE_UNITS = {
    'texture_RealWorldScaleX': true,
    'texture_RealWorldScaleY': true,
    'texture_RealWorldOffsetX': true,
    'texture_RealWorldOffsetY': true,
    'bumpmap_Depth': true,
    'bumpmap_RealWorldScaleX': true,
    'bumpmap_RealWorldScaleY': true,
    'bumpmap_RealWorldOffsetX': true,
    'bumpmap_RealWorldOffsetY': true,
    'unifiedbitmap_RealWorldScaleX': true,
    'unifiedbitmap_RealWorldScaleY': true,
    'unifiedbitmap_RealWorldOffsetX': true,
    'unifiedbitmap_RealWorldOffsetY': true
};
var TEXTURE_KEY_MAP = {
    'bumpmap_RealWorldScaleX': 'texture_RealWorldScaleX',
    'bumpmap_RealWorldScaleY': 'texture_RealWorldScaleY',
    'bumpmap_RealWorldOffsetX': 'texture_RealWorldOffsetX',
    'bumpmap_RealWorldOffsetY': 'texture_RealWorldOffsetY',
    'bumpmap_UScale': 'texture_UScale',
    'bumpmap_VScale': 'texture_VScale',
    'bumpmap_UOffset': 'texture_UOffset',
    'bumpmap_VOffset': 'texture_VOffset',
    'bumpmap_URepeat': 'texture_URepeat',
    'bumpmap_VRepeat': 'texture_VRepeat',
    'bumpmap_WAngle': 'texture_WAngle',
    'unifiedbitmap_RealWorldScaleX': 'texture_RealWorldScaleX',
    'unifiedbitmap_RealWorldScaleY': 'texture_RealWorldScaleY',
    'unifiedbitmap_RealWorldOffsetX': 'texture_RealWorldOffsetX',
    'unifiedbitmap_RealWorldOffsetY': 'texture_RealWorldOffsetY',
    'unifiedbitmap_UScale': 'texture_UScale',
    'unifiedbitmap_VScale': 'texture_VScale',
    'unifiedbitmap_UOffset': 'texture_UOffset',
    'unifiedbitmap_VOffset': 'texture_VOffset',
    'unifiedbitmap_URepeat': 'texture_URepeat',
    'unifiedbitmap_VRepeat': 'texture_VRepeat',
    'unifiedbitmap_WAngle': 'texture_WAngle'
};
function parseProperties(inProps, options) {
    var outProps = {};
    Object.keys(inProps).forEach(function (typeKey) {
        if (!PARSERS.hasOwnProperty(typeKey)) {
            return;
            //throw new Error(`Unknown AES 1.0 datatype [${typeKey}].`);
        }
        var dataTypeList = inProps[typeKey];
        var parser = PARSERS[typeKey];
        Object.keys(dataTypeList).forEach(function (entryKey) {
            var finalKey = entryKey;
            if (finalKey in TEXTURE_KEY_MAP) {
                finalKey = TEXTURE_KEY_MAP[finalKey];
            }
            if (isIgnored(finalKey)) {
                return;
            }
            outProps[finalKey] = parser(entryKey, dataTypeList[entryKey], options);
        });
    });
    return outProps;
}
function convertTexture$1(svfTex, getURL) {
    var outDef = {
        options: {},
        files: {}
    };
    outDef.options.data = parseProperties(svfTex.properties, {
        innerMats: {},
        getURL: getURL,
        unitsProps: TEXTURE_UNITS,
        scalarValues: true
    });
    if (svfTex.properties.uris) {
        var uriname = outDef.options.data.protein_type == "BumpMap" ? "bumpmap_Bitmap" : "unifiedbitmap_Bitmap";
        var uri = parseSingleValue(uriname, svfTex.properties.uris[uriname]);
        if (uri) {
            outDef.files[uriname] = {
                properties: getURL(uri),
                options: {
                    title: uri,
                    description: uri,
                    name: uri,
                    uri: uri
                }
            };
        }
    }
    return outDef;
}
function convertToAES(svfMat, getURL) {
    // Only convert prism materials, return SimpleMaterial as is
    if (!MaterialConverter.isPrismMaterial(svfMat)) {
        return null;
    }
    if (svfMat.userassets.length > 1 || svfMat.userassets.length === 0) {
        throw new Error('Illegal asset definition. Correct number of userassets: [' + svfMat.userassets + ']');
    }
    var inDefName = svfMat.userassets[0];
    if (!svfMat.materials || !svfMat.materials.hasOwnProperty(inDefName)) {
        throw new Error('Illegal asset definition. Missing user definition: [' + inDefName + ']');
    }
    var inDef = svfMat.materials[inDefName];
    var outDef = {
        type: inDef.definition,
        options: {}
    };
    var outProps = parseProperties(inDef.properties, {
        innerMats: svfMat.materials,
        getURL: getURL
    });
    outProps.protein_type = inDef.definition;
    outProps.private_tags = [inDef.tag, inDef.tag, inDef.tag, inDef.tag, inDef.tag];
    if (outProps.bumpmap_Type) {
        outProps.bumpmap_NormalScale = outProps.bumpmap_NormalScale || 1;
    }
    if (outDef.type === 'PrismWood') {
        if (!outProps.hasOwnProperty('wood_curly_distortion_enable')) {
            outProps.wood_curly_distortion_enable = false;
            outProps.wood_curly_distortion_scale = 0.15;
        }
    }
    if (outDef.type === 'PrismIBL') {
        if (outProps.hasOwnProperty('center_angle')) {
            outProps.center_angle.unit = 'radian';
        }
    }
    outDef.options.data = outProps;
    outDef.options.tags = inDef.categories;
    return outDef;
}

/* eslint-disable no-underscore-dangle */
var BUMPMAP_TYPES = {
    height: 0,
    normal: 1
};
var NDF_TYPES = {
    beckmann: 0,
    ggx: 1
};
var UNIT_PER_METER = {
    millimeter: 1000,
    MilliMeter: 1000,
    mm: 1000,
    8206: 1000,
    decimeter: 10,
    DeciMeter: 10,
    dm: 10,
    8204: 10,
    centimeter: 100,
    CentiMeter: 100,
    cm: 100,
    8205: 100,
    meter: 1,
    Meter: 1,
    m: 1,
    8193: 1,
    kilometer: 0.001,
    KiloMeter: 0.001,
    km: 0.001,
    8201: 0.001,
    inch: 39.37008,
    Inch: 39.37008,
    in: 39.37008,
    8214: 39.37008,
    foot: 3.28084,
    Foot: 3.28084,
    ft: 3.28084,
    8215: 3.28084,
    mile: 0.00062137,
    Mile: 0.00062137,
    mi: 0.00062137,
    8225: 0.00062137,
    Yard: 1.09361,
    yard: 1.09361,
    yd: 1.09361,
    8221: 1.09361
};
var prismImportanceSamplingTexture = void 0;
var prismWoodTexture = void 0;
function parseMaterialColor$1(val) {
    var linear = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : true;
    var defaultColor = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : new THREE$1.Color(1, 1, 1);

    val = (val || {}).value || {};
    var k = defaultColor;
    if (val.srgb24bit && val.srgb24bit.length >= 3) {
        var _val$srgb24bit$slice$ = val.srgb24bit.slice(0, 3).map(function (v) {
            return v / 255;
        }),
            _val$srgb24bit$slice$2 = slicedToArray(_val$srgb24bit$slice$, 3),
            r = _val$srgb24bit$slice$2[0],
            g = _val$srgb24bit$slice$2[1],
            b = _val$srgb24bit$slice$2[2];

        if (linear) {
            var _map = [r, g, b].map(sRGBToLinearFloat);

            var _map2 = slicedToArray(_map, 3);

            r = _map2[0];
            g = _map2[1];
            b = _map2[2];
        }
        k.setRGB(r, g, b);
    } else if (val.linearFloat && val.linearFloat.length >= 3) {
        var _val$linearFloat$slic = val.linearFloat.slice(0, 3),
            _val$linearFloat$slic2 = slicedToArray(_val$linearFloat$slic, 3),
            _r = _val$linearFloat$slic2[0],
            _g = _val$linearFloat$slic2[1],
            _b = _val$linearFloat$slic2[2];

        if (!linear) {
            var _map3 = [_r, _g, _b].map(linearFloatToSRGB);

            var _map4 = slicedToArray(_map3, 3);

            _r = _map4[0];
            _g = _map4[1];
            _b = _map4[2];
        }
        k.setRGB(_r, _g, _b);
    }
    return k;
}
function sRGBToLinearFloat(v) {
    if (v <= 0.04045) {
        return v / 12.92;
    } else {
        return Math.pow((v + 0.055) / 1.055, 2.4);
    }
}
function linearFloatToSRGB(v) {
    if (v <= 0.0031308) {
        return v * 12.92;
    } else {
        return 1.055 * Math.pow(v, 1 / 2.4);
    }
}
function parseMaterialDirectTexture(val) {
    if (val && val.length) {
        return val[0];
    } else {
        return undefined;
    }
}
function parseMaterialGenericTexture(val) {
    if (val && val.texture) {
        return val.texture[0];
    } else {
        return undefined;
    }
}
function parseMaterialGenericValue(val) {
    var defaultValue = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;

    if (!val) {
        return defaultValue;
    }
    if ((typeof val === "undefined" ? "undefined" : _typeof(val)) === 'object') {
        return val.value === undefined ? defaultValue : val.value;
    }
    return val;
}
function parseMaterialScalarWithSceneUnit$1(val, units) {
    var defaultUnit = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 'inch';
    var defaultValue = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 0;

    val = val || {};
    var sourceUnits = val.unit || defaultUnit;
    var value = val.value || defaultValue;
    var factor = UNIT_PER_METER[units] || 1;
    var divisor = UNIT_PER_METER[sourceUnits] || 1;
    return value * factor / divisor;
}
function parseMaterialAngle(val) {
    var inDegrees = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : true;
    var defaultValue = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;

    val = val || {};
    var sourceUnits = val.unit || 'degree';
    var value = val.value || defaultValue;
    if (inDegrees) {
        if (sourceUnits === 'degree') {
            return value;
        } else {
            return value * 180 / Math.PI;
        }
    } else if (sourceUnits === 'degree') {
        return value * Math.PI / 180;
    } else {
        return value;
    }
}
function initPrismImportanceSamplingTextures() {
    //random number texture for prism important sampling.
    //We can reuse 3d wood noise texture, but to align with Fusion,
    //use the same random number texture.
    var randomNum = [0, 128, 64, 191, 32, 160, 96, 223, 16, 143, 80, 207, 48, 175, 112, 239, 8, 135, 72, 199, 40, 167, 103, 231, 25, 151, 88, 215, 56, 183, 120, 250];
    var randomNumBuffer = new Uint8Array(randomNum);
    var randomNumTex = new THREE$1.DataTexture(randomNumBuffer, 32, 1, THREE$1.LuminanceFormat, THREE$1.UnsignedByteType, THREE$1.UVMapping, THREE$1.RepeatWrapping, THREE$1.RepeatWrapping, THREE$1.NearestFilter, THREE$1.NearestFilter, 0);
    randomNumTex.generateMipmaps = false;
    randomNumTex.flipY = false;
    randomNumTex.needsUpdate = true;
    var areaElement = function areaElement(x, y) {
        return Math.atan2(x * y, Math.sqrt(x * x + y * y + 1.0));
    };
    //Calculate the solid angle, so we don't need to do this in the shader.
    /// http://www.mpia-hd.mpg.de/~mathar/public/mathar20051002.pdf
    /// http://www.rorydriscoll.com/2012/01/15/cubemap-texel-solid-angle/
    var solidAngleBuffer = new Uint8Array(128 * 128);
    var invFaceSize = 1.0 / 128.0;
    for (var i = 0; i < 128; ++i) {
        for (var j = 0; j < 128; ++j) {
            var u = i / 128.0 * 2.0 - 1.0;
            var v = j / 128.0 * 2.0 - 1.0;
            u = Math.min(Math.max(-1.0 + invFaceSize, u), 1.0 - invFaceSize);
            v = Math.min(Math.max(-1.0 + invFaceSize, v), 1.0 - invFaceSize);
            var x0 = u - invFaceSize;
            var x1 = u + invFaceSize;
            var y0 = v - invFaceSize;
            var y1 = v + invFaceSize;
            // Compute solid angle of texel area.
            var solidAngle = areaElement(x1, y1) - areaElement(x0, y1) - areaElement(x1, y0) + areaElement(x0, y0);
            //The max result is 0.000244125724. Map to [0, 255]
            solidAngleBuffer[i * 128 + j] = solidAngle * 1000000;
        }
    }
    var solidAngleTex = new THREE$1.DataTexture(solidAngleBuffer, 128, 128, THREE$1.LuminanceFormat, THREE$1.UnsignedByteType, THREE$1.UVMapping, THREE$1.RepeatWrapping, THREE$1.RepeatWrapping, THREE$1.NearestFilter, THREE$1.NearestFilter, 0);
    solidAngleTex.generateMipmaps = false;
    solidAngleTex.flipY = false;
    solidAngleTex.needsUpdate = true;
    prismImportanceSamplingTexture = {
        randomNum: randomNumTex,
        solidAngle: solidAngleTex
    };
}
function initPrismWoodTextures() {
    var permutation = [151, 160, 137, 91, 90, 15, 131, 13, 201, 95, 96, 53, 194, 233, 7, 225, 140, 36, 103, 30, 69, 142, 8, 99, 37, 240, 21, 10, 23, 190, 6, 148, 247, 120, 234, 75, 0, 26, 197, 62, 94, 252, 219, 203, 117, 35, 11, 32, 57, 177, 33, 88, 237, 149, 56, 87, 174, 20, 125, 136, 171, 168, 68, 175, 74, 165, 71, 134, 139, 48, 27, 166, 77, 146, 158, 231, 83, 111, 229, 122, 60, 211, 133, 230, 220, 105, 92, 41, 55, 46, 245, 40, 244, 102, 143, 54, 65, 25, 63, 161, 1, 216, 80, 73, 209, 76, 132, 187, 208, 89, 18, 169, 200, 196, 135, 130, 116, 188, 159, 86, 164, 100, 109, 198, 173, 186, 3, 64, 52, 217, 226, 250, 124, 123, 5, 202, 38, 147, 118, 126, 255, 82, 85, 212, 207, 206, 59, 227, 47, 16, 58, 17, 182, 189, 28, 42, 223, 183, 170, 213, 119, 248, 152, 2, 44, 154, 163, 70, 221, 153, 101, 155, 167, 43, 172, 9, 129, 22, 39, 253, 19, 98, 108, 110, 79, 113, 224, 232, 178, 185, 112, 104, 218, 246, 97, 228, 251, 34, 242, 193, 238, 210, 144, 12, 191, 179, 162, 241, 81, 51, 145, 235, 249, 14, 239, 107, 49, 192, 214, 31, 181, 199, 106, 157, 184, 84, 204, 176, 115, 121, 50, 45, 127, 4, 150, 254, 138, 236, 205, 93, 222, 114, 67, 29, 24, 72, 243, 141, 128, 195, 78, 66, 215, 61, 156, 180];
    var permutationBuffer = new Uint8Array(permutation);
    var permutationTex = new THREE$1.DataTexture(permutationBuffer, 256, 1, THREE$1.LuminanceFormat, THREE$1.UnsignedByteType, THREE$1.UVMapping, THREE$1.RepeatWrapping, THREE$1.RepeatWrapping, THREE$1.NearestFilter, THREE$1.NearestFilter, 0);
    permutationTex.generateMipmaps = false;
    permutationTex.flipY = false;
    permutationTex.needsUpdate = true;
    var gradientData = [225, 39, 122, 231, 29, 173, 15, 159, 75, 88, 233, 19, 179, 79, 72, 94, 54, 73, 151, 161, 171, 113, 221, 144, 127, 83, 168, 19, 88, 122, 62, 225, 109, 128, 246, 247, 172, 101, 61, 139, 211, 168, 64, 210, 224, 82, 87, 97, 119, 250, 201, 44, 242, 239, 154, 99, 126, 13, 44, 70, 246, 170, 100, 52, 135, 28, 187, 22, 207, 119, 199, 1, 235, 187, 55, 131, 190, 124, 222, 249, 236, 53, 225, 231, 71, 30, 173, 185, 153, 47, 79, 133, 225, 10, 140, 62, 17, 99, 100, 29, 137, 95, 142, 244, 76, 5, 83, 124, 38, 216, 253, 195, 44, 210, 148, 185, 188, 39, 78, 195, 132, 30, 60, 73, 92, 223, 133, 80, 230, 56, 118, 207, 79, 15, 251, 211, 111, 21, 79, 23, 240, 146, 150, 207, 3, 61, 103, 27, 148, 6, 31, 127, 235, 58, 173, 244, 116, 81, 34, 120, 192, 213, 188, 226, 97, 23, 16, 161, 106, 80, 242, 148, 35, 37, 91, 117, 51, 216, 97, 193, 126, 222, 39, 38, 133, 217, 215, 23, 237, 57, 205, 42, 222, 165, 126, 133, 33, 8, 227, 154, 27, 18, 56, 11, 192, 120, 80, 92, 236, 38, 210, 207, 128, 31, 135, 39, 123, 5, 49, 127, 107, 200, 34, 14, 153, 239, 134, 19, 248, 162, 58, 201, 159, 198, 243, 158, 72, 5, 138, 184, 222, 200, 34, 141, 233, 40, 195, 238, 191, 122, 171, 32, 66, 254, 229, 197];
    var gradientBuffer = new Uint8Array(gradientData);
    var gradientTex = new THREE$1.DataTexture(gradientBuffer, 256, 1, THREE$1.LuminanceFormat, THREE$1.UnsignedByteType, THREE$1.UVMapping, THREE$1.RepeatWrapping, THREE$1.RepeatWrapping, THREE$1.NearestFilter, THREE$1.NearestFilter, 0);
    gradientTex.generateMipmaps = false;
    gradientTex.flipY = false;
    gradientTex.needsUpdate = true;
    var perm = function perm(x) {
        return permutation[x % 256];
    };
    var perm2d = new Array(256 * 256 * 4);
    for (var y = 0; y < 256; y++) {
        for (var x = 0; x < 256; x++) {
            var a = perm(x) + y;
            var aa = perm(a);
            var ab = perm(a + 1);
            var b = perm(x + 1) + y;
            var ba = perm(b);
            var bb = perm(b + 1);
            var index = 4 * (y * 256 + x);
            perm2d[index] = aa;
            perm2d[index + 1] = ab;
            perm2d[index + 2] = ba;
            perm2d[index + 3] = bb;
        }
    }
    var perm2dBuffer = new Uint8Array(perm2d);
    var perm2dTex = new THREE$1.DataTexture(perm2dBuffer, 256, 256, THREE$1.RGBAFormat, THREE$1.UnsignedByteType, THREE$1.UVMapping, THREE$1.RepeatWrapping, THREE$1.RepeatWrapping, THREE$1.NearestFilter, THREE$1.NearestFilter, 0);
    perm2dTex.generateMipmaps = false;
    perm2dTex.flipY = false;
    perm2dTex.needsUpdate = true;
    var gradients3d = [1, 1, 0, -1, 1, 0, 1, -1, 0, -1, -1, 0, 1, 0, 1, -1, 0, 1, 1, 0, -1, -1, 0, -1, 0, 1, 1, 0, -1, 1, 0, 1, -1, 0, -1, -1, 1, 1, 0, 0, -1, 1, -1, 1, 0, 0, -1, -1];
    var permGrad = new Array(1024);
    for (var _x8 = 0; _x8 < 256; ++_x8) {
        var i = permutation[_x8] % 16;
        permGrad[_x8 * 4] = gradients3d[i * 3] * 127 + 128;
        permGrad[_x8 * 4 + 1] = gradients3d[i * 3 + 1] * 127 + 128;
        permGrad[_x8 * 4 + 2] = gradients3d[i * 3 + 2] * 127 + 128;
        permGrad[_x8 * 4 + 3] = 0;
    }
    var permGradBuffer = new Uint8Array(permGrad);
    var permGradTex = new THREE$1.DataTexture(permGradBuffer, 256, 1, THREE$1.RGBAFormat, THREE$1.UnsignedByteType, THREE$1.UVMapping, THREE$1.RepeatWrapping, THREE$1.RepeatWrapping, THREE$1.NearestFilter, THREE$1.NearestFilter, 0);
    permGradTex.generateMipmaps = false;
    permGradTex.flipY = false;
    permGradTex.needsUpdate = true;
    prismWoodTexture = {
        permutation: permutationTex,
        gradient: gradientTex,
        perm2d: perm2dTex,
        permGrad: permGradTex
    };
}
function parseWoodProfile$1(tm, mat, profileName) {
    var bands = 0;
    var weights = new THREE$1.Vector4(1, 1, 1, 1);
    var frequencies = new THREE$1.Vector4(1, 1, 1, 1);
    var profile = mat.options.data["wood_" + profileName + "_prof"];
    if (profile && profile.length > 0) {
        bands = profile.length / 2;
        for (var i = 0; i < bands; i++) {
            frequencies.setComponent(i, 1 / profile[2 * i]);
            weights.setComponent(i, profile[2 * i + 1]);
        }
    }
    tm["wood_" + profileName + "_enable"] = parseMaterialGenericValue(mat.options.data["wood_" + profileName + "_enable"]);
    tm["wood_" + profileName + "_bands"] = bands;
    tm["wood_" + profileName + "_weights"] = weights;
    tm["wood_" + profileName + "_frequencies"] = frequencies;
}
function convertTexture$2(map, tex, units, anisotropy) {
    var texData = map.textureObj;
    tex.name = texData.options.title;
    tex.clampS = !(texData.options.data["texture_URepeat"] || true);
    tex.clampT = !(texData.options.data["texture_VRepeat"] || true);
    tex.wrapS = !tex.clampS ? THREE$1.RepeatWrapping : THREE$1.ClampToEdgeWrapping;
    tex.wrapT = !tex.clampT ? THREE$1.RepeatWrapping : THREE$1.ClampToEdgeWrapping;
    var worldOffsetX = parseMaterialScalarWithSceneUnit$1(texData.options.data["texture_RealWorldOffsetX"], units, 'inch');
    var worldOffsetY = parseMaterialScalarWithSceneUnit$1(texData.options.data["texture_RealWorldOffsetY"], units, 'inch');
    var texOffsetU = texData.options.data["texture_UOffset"] || 0;
    var texOffsetV = texData.options.data["texture_VOffset"] || 0;
    var worldScaleX = void 0,
        worldScaleY = void 0;
    worldScaleX = parseMaterialScalarWithSceneUnit$1(texData.options.data["texture_RealWorldScaleX"], units, 'inch', 1);
    worldScaleY = parseMaterialScalarWithSceneUnit$1(texData.options.data["texture_RealWorldScaleY"], units, 'inch', 1);
    var texScaleU = texData.options.data["texture_UScale"] || 1;
    var texScaleV = texData.options.data["texture_VScale"] || 1;
    var angle = parseMaterialAngle(texData.options.data["texture_WAngle"], false);
    var c = Math.cos(angle),
        s = Math.sin(angle);
    var cx = texScaleU / worldScaleX,
        cy = texScaleV / worldScaleY;
    tex.matrix = {
        elements: [c * cx, s * cy, 0, -s * cy, c * cy, 0, -c * cx * worldOffsetX + s * cy * worldOffsetY + texOffsetU, -s * cx * worldOffsetX - c * cy * worldOffsetY + texOffsetV, 1]
    };
    if (texData.options.data.protein_type === 'BumpMap') {
        tex.bumpmapType = BUMPMAP_TYPES[texData.options.data.bumpmap_Type] || 0;
        if (tex.bumpmapType === 0) {
            var depth = parseMaterialScalarWithSceneUnit$1(texData.options.data.bumpmap_Depth, units, 'inch', 1);
            tex.bumpScale = new THREE$1.Vector2(depth / worldScaleX, depth / worldScaleY);
        } else {
            var normalScale = texData.options.data.bumpmap_NormalScale || 1;
            tex.bumpScale = new THREE$1.Vector2(normalScale, normalScale);
        }
    } else {
        tex.invert = texData.options.data["unifiedbitmap_Invert"] || false;
    }
}
// eslint-disable-next-line complexity
function convertMaterial$1(mat, sceneUnits, textures, tm) {
    if (!tm) {
        tm = createPrismMaterial();
    } else if (!tm.isPrismMaterial) {
        return null;
    } else {
        tm.needsUpdate = true;
    }
    // todo(tgv): Remove this horrible deferred-type hack!
    tm.proteinMat = mat;
    tm.proteinCategories = mat.options.tags;
    tm.packedNormals = true;
    tm.name = mat.options.data.private_tags[2];
    tm.tag = mat.options.data.private_tags[2];
    tm.prismType = mat.options.data.protein_type || '';
    tm.side = THREE$1.DoubleSide;
    tm.transparent = false;
    tm.envExponentMin = 1.0;
    tm.envExponentMax = 512.0;
    tm.envExponentCount = 10.0;
    var tx = textures || {};
    tm.surface_albedo = parseMaterialColor$1(mat.options.data.surface_albedo);
    tx.surface_albedo_map = parseMaterialGenericTexture(mat.options.data.surface_albedo);
    tm.surface_anisotropy = parseMaterialGenericValue(mat.options.data.surface_anisotropy);
    tx.surface_anisotropy_map = parseMaterialGenericTexture(mat.options.data.surface_anisotropy);
    tx.surface_cutout_map = parseMaterialDirectTexture(mat.options.data.surface_cutout);
    tm.surface_ndf_type = NDF_TYPES[mat.options.data.surface_ndf_type] || 1;
    tx.surface_normal_map = parseMaterialGenericTexture(mat.options.data.surface_normal);
    tm.surface_rotation = parseMaterialAngle(mat.options.data.surface_rotation, true);
    tx.surface_rotation_map = parseMaterialGenericTexture(mat.options.data.surface_rotation);
    tm.surface_roughness = parseMaterialGenericValue(mat.options.data.surface_roughness, 0.2);
    tx.surface_roughness_map = parseMaterialGenericTexture(mat.options.data.surface_roughness);
    if (tx.surface_cutout_map) {
        tm.side = THREE$1.DoubleSide;
        tm.transparent = true;
    }
    switch (tm.prismType) {
        case 'PrismOpaque':
            tm.opaque_albedo = parseMaterialColor$1(mat.options.data.opaque_albedo);
            tx.opaque_albedo_map = parseMaterialGenericTexture(mat.options.data.opaque_albedo);
            tm.opaque_emission = !!mat.options.data.opaque_emission || false;
            tm.opaque_f0 = parseMaterialGenericValue(mat.options.data.opaque_f0, 0.02);
            tx.opaque_f0_map = parseMaterialGenericTexture(mat.options.data.opaque_f0);
            tm.opaque_luminance = mat.options.data.opaque_luminance || 0;
            tm.opaque_luminance_modifier = parseMaterialColor$1(mat.options.data.opaque_luminance_modifier, true);
            tx.opaque_luminance_modifier_map = parseMaterialGenericTexture(mat.options.data.opaque_luminance_modifier);
            tm.opaque_mfp = parseMaterialScalarWithSceneUnit$1(mat.options.data.opaque_mfp, sceneUnits, 'millimeter');
            tm.opaque_mfp_modifier = parseMaterialColor$1(mat.options.data.opaque_mfp_modifier);
            tx.opaque_mfp_modifier_map = parseMaterialGenericTexture(mat.options.data.opaque_mfp_modifier);
            tm.opaque_translucency = !!mat.options.data.opaque_translucency || false;
            break;
        case 'PrismMetal':
            tm.metal_f0 = parseMaterialColor$1(mat.options.data.metal_f0, true);
            tx.metal_f0_map = parseMaterialGenericTexture(mat.options.data.metal_f0);
            break;
        case 'PrismLayered':
            tm.layered_anisotropy = parseMaterialGenericValue(mat.options.data.layered_anisotropy);
            tx.layered_anisotropy_map = parseMaterialGenericTexture(mat.options.data.layered_anisotropy);
            tm.layered_bottom_f0 = parseMaterialColor$1(mat.options.data.layered_bottom_f0, true);
            tx.layered_bottom_f0_map = parseMaterialGenericTexture(mat.options.data.layered_bottom_f0);
            tm.layered_diffuse = parseMaterialColor$1(mat.options.data.layered_diffuse, true);
            tx.layered_diffuse_map = parseMaterialGenericTexture(mat.options.data.layered_diffuse);
            tm.layered_f0 = parseMaterialGenericValue(mat.options.data.layered_f0, 0.02);
            tx.layered_f0_map = parseMaterialGenericTexture(mat.options.data.layered_f0);
            tm.layered_fraction = parseMaterialGenericValue(mat.options.data.layered_fraction, 0.5);
            tx.layered_fraction_map = parseMaterialGenericTexture(mat.options.data.layered_fraction);
            tm.layered_ndf_type = NDF_TYPES[mat.options.data.layered_ndf_type] || 1;
            tx.layered_normal_map = parseMaterialGenericTexture(mat.options.data.layered_normal);
            tm.layered_rotation = parseMaterialAngle(mat.options.data.layered_rotation, true);
            tx.layered_rotation_map = parseMaterialGenericTexture(mat.options.data.layered_rotation);
            tm.layered_roughness = parseMaterialGenericValue(mat.options.data.layered_roughness, 0.2);
            tx.layered_roughness_map = parseMaterialGenericTexture(mat.options.data.layered_roughness);
            break;
        case 'PrismTransparent':
            tm.transparent = true;
            tm.transparent_color = parseMaterialColor$1(mat.options.data.transparent_color, true);
            tm.transparent_distance = parseMaterialScalarWithSceneUnit$1(mat.options.data.transparent_distance, sceneUnits, 'inch', 0.125);
            tm.transparent_ior = mat.options.data.transparent_ior || 1.5;
            break;
        case 'PrismWood':
            parseWoodProfile$1(tm, mat, 'diffuse_perlin');
            parseWoodProfile$1(tm, mat, 'earlycolor_perlin');
            parseWoodProfile$1(tm, mat, 'fiber_cosine');
            parseWoodProfile$1(tm, mat, 'fiber_perlin');
            parseWoodProfile$1(tm, mat, 'growth_perlin');
            parseWoodProfile$1(tm, mat, 'latecolor_perlin');
            tx.wood_curly_distortion_map = parseMaterialDirectTexture(mat.options.data.wood_curly_distortion_map);
            tm.wood_curly_distortion_enable = parseMaterialGenericValue(mat.options.data.wood_curly_distortion_enable);
            tm.wood_curly_distortion_scale = parseMaterialGenericValue(mat.options.data.wood_curly_distortion_scale);
            tm.wood_diffuse_lobe_weight = parseMaterialGenericValue(mat.options.data.wood_diffuse_lobe_weight);
            tm.wood_diffuse_perlin_scale_z = parseMaterialGenericValue(mat.options.data.wood_diffuse_perlin_scale_z);
            tm.wood_early_color = parseMaterialColor$1(mat.options.data.wood_early_color, true);
            tm.wood_earlywood_sharpness = parseMaterialGenericValue(mat.options.data.wood_earlywood_sharpness);
            tm.wood_latewood_sharpness = parseMaterialGenericValue(mat.options.data.wood_latewood_sharpness);
            tm.wood_fiber_perlin_scale_z = parseMaterialGenericValue(mat.options.data.wood_fiber_perlin_scale_z);
            tm.wood_groove_roughness = parseMaterialGenericValue(mat.options.data.wood_groove_roughness);
            tm.wood_late_color_power = parseMaterialGenericValue(mat.options.data.wood_late_color_power);
            tm.wood_latewood_bump_depth = parseMaterialGenericValue(mat.options.data.wood_latewood_bump_depth);
            tm.wood_latewood_ratio = parseMaterialGenericValue(mat.options.data.wood_latewood_ratio);
            tm.wood_manual_late_color = parseMaterialColor$1(mat.options.data.wood_manual_late_color, true);
            tm.wood_pore_cell_dim = parseMaterialGenericValue(mat.options.data.wood_pore_cell_dim);
            tm.wood_pore_color_power = parseMaterialGenericValue(mat.options.data.wood_pore_color_power);
            tm.wood_pore_depth = parseMaterialGenericValue(mat.options.data.wood_pore_depth);
            tm.wood_pore_radius = parseMaterialGenericValue(mat.options.data.wood_pore_radius);
            tm.wood_pore_type = parseMaterialGenericValue(mat.options.data.wood_pore_type);
            tm.wood_ray_color_power = parseMaterialGenericValue(mat.options.data.wood_ray_color_power);
            tm.wood_ray_ellipse_radius_x = parseMaterialGenericValue(mat.options.data.wood_ray_ellipse_radius_x);
            tm.wood_ray_ellipse_z2x = parseMaterialGenericValue(mat.options.data.wood_ray_ellipse_z2x);
            tm.wood_ray_num_slices = parseMaterialGenericValue(mat.options.data.wood_ray_num_slices);
            tm.wood_ray_seg_length_z = parseMaterialGenericValue(mat.options.data.wood_ray_seg_length_z);
            tm.wood_ring_thickness = parseMaterialGenericValue(mat.options.data.wood_ring_thickness);
            tm.wood_use_groove_roughness = parseMaterialGenericValue(mat.options.data.wood_use_groove_roughness);
            tm.wood_use_latewood_bump = parseMaterialGenericValue(mat.options.data.wood_use_latewood_bump);
            tm.wood_use_manual_late_color = parseMaterialGenericValue(mat.options.data.wood_use_manual_late_color);
            tm.wood_use_pores = parseMaterialGenericValue(mat.options.data.wood_use_pores);
            tm.wood_use_rays = parseMaterialGenericValue(mat.options.data.wood_use_rays);
            if (!prismWoodTexture) {
                initPrismWoodTextures();
            }
            tm.uniforms.permutationMap.value = prismWoodTexture.permutation;
            tm.uniforms.gradientMap.value = prismWoodTexture.gradient;
            tm.uniforms.perm2DMap.value = prismWoodTexture.perm2d;
            tm.uniforms.permGradMap.value = prismWoodTexture.permGrad;
            break;
        default:
            THREE$1.warn("Unknown Prism type: " + tm.prismType);
            break;
    }
    if (tm.enableImportantSampling && (tm.surface_anisotropy || tm.surface_rotation || tm.layered_anisotropy || tm.layered_rotation)) {
        if (!prismImportanceSamplingTexture) {
            initPrismImportanceSamplingTextures();
        }
        tm.uniforms.importantSamplingRandomMap.value = prismImportanceSamplingTexture.randomNum;
        tm.uniforms.importantSamplingSolidAngleMap.value = prismImportanceSamplingTexture.solidAngle;
    }
    tm.defines = {};
    tm.textureMaps = {};
    tm.defines[tm.prismType.toUpperCase()] = '';
    if (tm.prismType === 'PrismWood' && tm.enable3DWoodBump) {
        tm.defines.PRISMWOODBUMP = '';
    }
    if (tm.enableImportantSampling) {
        tm.defines.ENABLEIMPORTANTSAMPLING = '';
    }
    if (tm.transparent) {
        tm.lmv_depthWriteTransparent = true;
        tm.depthWrite = true;
    }
    Object.keys(tx).forEach(function (k) {
        if (!tx[k]) {
            delete tx[k];
        } else {
            tm.textureMaps[k] = {
                mapName: k,
                isPrism: true
            };
            // This array gives the various #defines that are associated with this instance of
            // the PRISM material.
            tm.defines["USE_" + k.toUpperCase()] = "";
        }
    });
    return tm;
}
var convertAesMaterial = {
    convertMaterial: convertMaterial$1,
    convertTexture: convertTexture$2
};

// New model API
var ModelEditor = function () {
    function ModelEditor(model, eventTarget, matman, initLoadContext, webGlRenderer) {
        classCallCheck(this, ModelEditor);

        this._aesMaterials = {};
        this._nextId = -1;
        this._model = model;
        this._textureDelegate = {
            eventTarget: eventTarget,
            matman: matman,
            initLoadContext: initLoadContext,
            webGLRenderer: webGlRenderer
        };
        var svf = model.getData();
        this._nextId = 0;
        if (svf && svf.materials) {
            // Calculate the max
            for (var a in svf.materials.materials) {
                this._aesMaterials[a] = undefined;
                var n = parseInt(a, 10);
                if (this._nextId < n) {
                    this._nextId = n;
                }
            }
            ++this._nextId;
        }
    }
    /**
     * Get the number of materials
     * @returns An array of material ids, or null if the model isn't loaded.
     */


    createClass(ModelEditor, [{
        key: "getMaterialIds",
        value: function getMaterialIds() {
            return Object.keys(this._aesMaterials);
        }
        /**
         * Get the persistent id for an internal material id
         * @param id Id of the material.
         * @returns The persistent id string or null if index is invalid
         */

    }, {
        key: "getMaterialUrn",
        value: function getMaterialUrn(id) {
            // Just use mid:xxxx for the persistent id until we figure out what to use for real
            return this._aesMaterials.hasOwnProperty(id) ? "mid:" + id : null;
        }
        /**
         * Get internal material id for a persistent id
         * @param id Persistent id string
         * @returns null if the urn isn't the urn for a material
         */

    }, {
        key: "getMaterialId",
        value: function getMaterialId(urn) {
            // Parse midnnnn to get an index
            if (urn == null) {
                return null;
            }
            if (urn.substr(0, 4) != "mid:") {
                return null;
            }
            var id = urn.substr(4);
            if (!this._aesMaterials.hasOwnProperty(id)) {
                return null;
            }
            return id;
        }
        /**
         * Get the id for the root object in the model
         * @returns the dbid for the root object, or 0 if the hierarchy isn't loaded.
         */

    }, {
        key: "getRootObjectId",
        value: function getRootObjectId() {
            var objects = this._model.getFragmentMap();
            if (!objects) {
                return 0;
            }
            return objects.getRootId();
        }
        /**
         * Enumerate child ids of an object in the model
         * @param dbid Parent whose children are enumerated
         * @param callback Function called with each child id
         * @param recursive True to list children recursively.
         * @returns True if the object hierarchy is loaded. False otherwise.
         */

    }, {
        key: "enumerateChildObjectIds",
        value: function enumerateChildObjectIds(dbid, callback, recursive) {
            var objects = this._model.getFragmentMap();
            if (!objects) {
                return false;
            }
            objects.enumNodeChildren(dbid, callback, recursive);
            return true;
        }
        /**
         * Get the persistent object id for an object id
         * @param dbid database id of the object or an array of ids
         * @return A Promise that resolves to the persistent object ids. If dbid is
         *         single number the Promise resolves to a single string. If dbid is
         *         an array of numbers the Promise resolves to an array of strings, with
         *         one entry for each entry in dbid. The persistent id for an invalid
         *         local object id is null.
         *
         * Note this implementation is temporary until we get the objects ids from the property database
         */

    }, {
        key: "getObjectUrn",
        value: function getObjectUrn(dbid) {
            var resolve = void 0;
            if (!dbid) {
                resolve = null;
            } else if (Array.isArray(dbid)) {
                var r = [];
                dbid.forEach(function (id) {
                    r.push(id ? "dbid:" + id.toString() : null);
                });
                resolve = r;
            } else {
                resolve = "dbid:" + dbid.toString();
            }
            return Promise.resolve(resolve);
        }
        /**
         * Get the database id for the persisten object id
         * @param id persistent id for the object
         * @return A Promise that resolve to the local object ids. If urn is
         *         single string the Promise resolves to a single number. If urn is
         *         an array of strings the Promise resolves to an array of numbers, with
         *         one entry for each entry in urn. The local id for an invalid
         *         persistent object id is 0.
         *
         * Note this implementation is temporary until we get the objects ids from the property database
         */

    }, {
        key: "getObjectId",
        value: function getObjectId(urn) {
            var resolve = void 0;
            if (!urn) {
                resolve = 0;
            } else if (Array.isArray(urn)) {
                var n = [];
                urn.forEach(function (dbid) {
                    if (!dbid || dbid.substr(0, 5) != "dbid:") {
                        n.push(0);
                    } else {
                        var id = dbid.substr(5);
                        n.push(parseInt(id));
                    }
                });
                resolve = n;
            } else if (urn.substr(0, 5) != "dbid:") {
                resolve = 0;
            } else {
                var id = urn.substr(5);
                resolve = parseInt(id);
            }
            return Promise.resolve(resolve);
        }
        /**
         * Get material json definition
         * @param matid Material id for the material
         */

    }, {
        key: "getMaterialDefinition",
        value: function getMaterialDefinition(matid) {
            // Material doesn't exist, return null
            if (!this._aesMaterials.hasOwnProperty(matid)) {
                return null;
            }
            // If material has been converted to AES, or created by AES, then return it
            var def = this._aesMaterials[matid];
            if (def !== undefined) {
                return def;
            }
            var svf = this._model.getData();
            // This must be an unconverted svf material, get the simple or protein material
            var mat = svf.materials.materials[matid];
            if (svf.proteinMaterials) {
                var protein = svf.proteinMaterials.materials[matid];
                if (protein && MaterialConverter.isPrismMaterial(protein)) mat = protein;
            }
            var scope = this;
            var aes = mat ? convertToAES(mat, function (uri) {
                var material = null;
                // Need a material manager to update or create a material
                material = scope._textureDelegate.matman.lookupMaterial(scope._model, matid);
                var asset = {};
                var return_value = {
                    url: TextureLoader.calculateTexturePath(scope._model, uri, material, scope._textureDelegate.initLoadContext, asset).path
                };
                if (asset.asset) {
                    return_value.size = asset.asset.size;
                }
                return return_value;
            }) : null;
            this._aesMaterials[matid] = aes;
            return aes;
        }
    }, {
        key: "_parseMaterial",
        value: function _parseMaterial(definition, textures, matid, original) {
            // Get the material id, either supplied, or the next one
            var id = matid ? matid : this._nextId.toString();
            var svf = this._model.getData();
            var units = svf && svf.materials ? svf.materials.scene.SceneUnit : "inch";
            if (definition.hasOwnProperty("userassets") && definition.hasOwnProperty("materials")) {
                this._textureDelegate.matman.convertOneMaterial(this._model, definition, id);
            } else {
                var mat = convertAesMaterial.convertMaterial(definition, units, textures, this._textureDelegate.matman.lookupMaterial(this._model, id));
                if (!mat) {
                    return null;
                }
                if (!matid) {
                    this._textureDelegate.matman.addObjectMaterial(this._model, mat, id);
                    ++this._nextId;
                }
            }
            this._aesMaterials[id] = definition;
            return id;
        }
        /**
         * Create a material
         * @param definition Object the contains the material definition
         * @param type The type of material valid values are "LMVTK Simple Materials"
         *             and "LMVTK Protein Materials". Defaults to "LMVTK Protein Materials".
         * @param textures Object that holds the texture objects from the definition
         * @returns The created material id, or null if the material can't be created
         * We will only convert prism materials if the type is "LMVTK Protein Materials".
         */

    }, {
        key: "createMaterial",
        value: function createMaterial(definition, textures) {
            return this._parseMaterial(definition, textures);
        }
        /**
         * Update an existing material with a new definition.
         * @param matid The id of the material to be updated
         * @param definition The definition of the material
         * @param textures Object that holds the texture objects from the definition
         * @returns True if the material was updated.
         * This will only update materials whose definition is compatible with
         * the new definition. This means you can't used this method to
         * make a material change from prism to non-prism material.
         */

    }, {
        key: "updateMaterial",
        value: function updateMaterial(matid, definition, textures) {
            if (typeof matid !== "string" || !matid || !this._aesMaterials.hasOwnProperty(matid)) {
                return false;
            }
            return !!this._parseMaterial(definition, textures, matid);
        }
        /**
         * Set the texture definition for a map on a material
         * @param matid The id of the material to be updated
         * @param mapName The name of the map being defined
         * @param definition The definition of the material
         * @returns True if the definition was accepted. The definition will not be
         *          accepted if the model doesn't have a MaterialManager or if mapName
         *          isn't a texture on the material.
         */

    }, {
        key: "setTextureDefinition",
        value: function setTextureDefinition(matid, mapName, definition) {
            var mat = this._textureDelegate.matman.lookupMaterial(this._model, matid);
            if (!mat) {
                return false;
            }
            // Hack Hack - WebGLRenderer.getPrismClampFlags is looking for the u/v repeat
            // values at definition.properties.booleans, so we put them there
            if (!definition.properties) {
                definition.properties = {};
            }
            if (!definition.properties.booleans) {
                definition.properties.booleans = {};
            }
            definition.properties.booleans.texture_URepeat = { values: [definition.options.data.texture_URepeat] };
            definition.properties.booleans.texture_VRepeat = { values: [definition.options.data.texture_VRepeat] };
            return TextureLoader.setTextureDefinition(this._textureDelegate, this._model, mat, mapName, definition);
        }
        /**
         * Load the image for map on a material
         * @param matid The id of the material to be updated
         * @param mapName The name of the map being defined
         * @param urn A unique id for the texture
         * @param url The url to the image for the texture
         * @returns Return a Promise that resolves this object:
         *          {
         *              matid: matid,
         *              mapName: mapName,
         *              urn: urn,
         *              url: url
         *          }
         *          The values are just the arguments for the loadTexture call returned the promise.
         */

    }, {
        key: "loadTexture",
        value: function loadTexture(matid, mapName, urn, url) {
            var scope = this;
            return new Promise(function (resolve, reject) {
                var mat = scope._textureDelegate.matman.lookupMaterial(scope._model, matid);
                if (!mat) {
                    reject("Invalid Material Id");
                    return;
                }
                if (!TextureLoader.loadTexture(scope._textureDelegate, scope._model, mat, mapName, urn, url, false, convertAesMaterial.convertTexture, function (error$$1, tex) {
                    if (error$$1) {
                        reject(error$$1);
                    } else {
                        resolve({ matid: matid, mapName: mapName, urn: urn, url: url });
                    }
                })) {
                    reject("Invalid Arguments");
                }
            });
        }
        /**
         * Get the material ids for an object
         * @param dbid The dbid whose material id is returned.
         * @returns Array with all of the materials ids
         * Objects can have multiple fragments with different materials.
         */

    }, {
        key: "getObjectMaterialIds",
        value: function getObjectMaterialIds(dbid) {
            var objects = this._model.getFragmentMap();
            if (!objects) {
                return null;
            }
            var fragments = this._model.getData().fragments;
            if (!fragments) return null;
            var matids = [];
            objects.enumNodeFragments(dbid, function (fragid) {
                // Make sure this material is really assigned to the object
                var matid = fragments.materials[fragid].toString();
                matids.push(matid);
            }, false);
            return matids;
        }
        /**
         * Get an objects visibility
         * @param dbid The id of the object
         */

    }, {
        key: "getObjectVisibility",
        value: function getObjectVisibility(dbid) {
            if (!this._model.visibilityManager) {
                return true;
            }
            return this._model.visibilityManager.isNodeVisible(dbid);
        }
        /**
         * Set the material on an object
         * @param dbid The object id
         * @param matids The material ids, can be a single id or an array of ids
         * @returns True if the object ids are loaded, otherwise false.
         */

    }, {
        key: "setObjectMaterials",
        value: function setObjectMaterials(dbid, matids) {
            var objects = this._model.getFragmentMap();
            if (!objects) {
                return false;
            }
            var model = this._model;
            var fragments = this._model.getData().fragments;
            if (!fragments) return null;
            var frags = this._model.getFragmentList();
            var delegate = this._textureDelegate;
            var callback = void 0;
            if (Array.isArray(matids)) {
                var i = 0;
                callback = function callback(fragid) {
                    var matid = matids[i++];
                    if (matid) {
                        fragments.materials[fragid] = parseInt(matid);
                        var mtl = delegate.matman.lookupMaterial(model, matid);
                        if (mtl) {
                            frags.setMaterial(fragid, mtl);
                        }
                    }
                };
            } else {
                var mtl = this._textureDelegate.matman.lookupMaterial(model, matids);
                if (mtl) {
                    var matnum = parseInt(matids);
                    callback = function callback(fragid) {
                        fragments.materials[fragid] = matnum;
                        frags.setMaterial(fragid, mtl);
                    };
                }
            }
            objects.enumNodeFragments(dbid, callback, false);
            return true;
        }
        /**
         * Set the visibility of an object
         * @param dbid The object id
         * @param visibility True for visible, false for hidden
         * @returns True if the object ids are loaded, otherwise false
         * Invisible objects will be ghosted, when ghosting is on
         */

    }, {
        key: "setObjectVisibility",
        value: function setObjectVisibility(dbid, visibility) {
            if (!this._model.visibilityManager) {
                return false;
            }
            // Hide/show the object. If showing the object make sure it is on.
            visibility ? this._model.visibilityManager.show(dbid) : this._model.visibilityManager.hide(dbid);
            return true;
        }
    }]);
    return ModelEditor;
}();

var VERSION = json.version;

"use strict";
var WebWorkerCreator = function () {
    /**
     * Build the worker creator.
     * @param url - The full resolved URL to the worker script.
     * @param enableInlineWorker - True means use the cached resource. False means use the resource directly.
     */
    function WebWorkerCreator(url, enableInlineWorker) {
        classCallCheck(this, WebWorkerCreator);

        // A cache of entire worker script as data URL.
        this.WORKER_DATA_URL = null;
        this.WORKER_FETCHING_SCRIPT = false;
        this.WORKER_FETCHING_CALLBACKS = [];
        this._url = url;
        this._enableInlineWorker = enableInlineWorker;
    }
    // This mainly is used for testing.


    createClass(WebWorkerCreator, [{
        key: 'clearWorkerDataURL',
        value: function clearWorkerDataURL() {
            this.WORKER_DATA_URL = null;
        }
    }, {
        key: 'initWorkerScript',
        value: function initWorkerScript(successCB, errorCB) {
            if (this._enableInlineWorker && !this.WORKER_DATA_URL) {
                this.WORKER_FETCHING_CALLBACKS.push({
                    successCB: successCB
                });
                var _this = this;
                if (!this.WORKER_FETCHING_SCRIPT) {
                    var xhr = new XMLHttpRequest();
                    var scriptURL = this._url;
                    xhr.open("GET", scriptURL, true);
                    xhr.withCredentials = false;
                    xhr.onload = function () {
                        // Set up global cached worker script.
                        _this.WORKER_FETCHING_SCRIPT = false;
                        var blob = void 0;
                        window.URL = window.URL || window.webkitURL;
                        try {
                            blob = new Blob([xhr.responseText], { type: 'application/javascript' });
                        } catch (e) {
                            // Backward compatibility.
                            var builder = new BlobBuilder();
                            builder.append(xhr.responseText);
                            blob = builder.getBlob();
                        }
                        _this.WORKER_DATA_URL = URL.createObjectURL(blob);
                        var callbacks = _this.WORKER_FETCHING_CALLBACKS.concat(); // Shallow copy
                        _this.WORKER_FETCHING_CALLBACKS = [];
                        for (var i = 0; i < callbacks.length; ++i) {
                            callbacks[i].successCB && callbacks[i].successCB();
                        }
                    };
                    this.WORKER_FETCHING_SCRIPT = true;
                    xhr.send();
                }
                // Return a token that can be used to cancel the async call result.
                var token = {};
                token.cancel = function () {
                    var idx = -1;
                    if (_this.WORKER_FETCHING_CALLBACKS.some(function (cb, i) {
                        if (cb.successCB == successCB) {
                            idx = i;
                            return true;
                        }
                        return false;
                    })) {
                        _this.WORKER_FETCHING_CALLBACKS.splice(idx, 1);
                        return true;
                    }
                    return false;
                };
                return token;
            } else {
                if (successCB) successCB();
            }
            return null;
        }
    }, {
        key: 'createWorker',

        // Create a web worker.
        value: function createWorker() {
            var w = void 0;
            // When we are not at release mode, create web worker directly from URL.
            if (this._enableInlineWorker) {
                w = new Worker(this.WORKER_DATA_URL);
            } else {
                w = new Worker(this._url);
            }
            w.doOperation = w.postMessage;
            return w;
        }
    }, {
        key: 'createWorkerWithIntercept',
        value: function createWorkerWithIntercept() {
            var worker = this.createWorker();
            worker.checkEvent = function (e) {
                if (e.data && e.data.assetRequest) {
                    if (exports.assets) {
                        exports.assets.push(e.data.assetRequest);
                    }
                    return true;
                }
                return false;
            };
            var interceptListeners = [];
            function popCallback(listener) {
                if (!interceptListeners) return null;
                for (var i = 0; i < interceptListeners.length; ++i) {
                    if (interceptListeners[i].arg === listener) {
                        var ret = interceptListeners[i].callback;
                        interceptListeners.splice(i, 1);
                        if (interceptListeners.length === 0) interceptListeners = null;
                        return ret;
                    }
                }
                return null;
            }
            worker.addEventListenerWithIntercept = function (listener) {
                var callbackFn = function callbackFn(ew) {
                    if (worker.checkEvent(ew)) return;
                    listener(ew);
                };
                if (!interceptListeners) interceptListeners = [];
                interceptListeners.push({ arg: listener, callback: callbackFn });
                worker.addEventListener('message', callbackFn, false);
                return callbackFn;
            };
            worker.removeEventListenerWithIntercept = function (listener) {
                var callbackFn = popCallback(listener);
                if (callbackFn) {
                    worker.removeEventListener('message', callbackFn, false);
                }
            };
            worker.clearAllEventListenerWithIntercept = function () {
                if (!interceptListeners) return;
                var copy = interceptListeners.concat();
                for (var i = 0; i < copy.length; ++i) {
                    worker.removeEventListenerWithIntercept(copy[i].arg);
                }
            };
            return worker;
        }
    }]);
    return WebWorkerCreator;
}();
workerScript.webWorkerClass = WebWorkerCreator;

var getUniforms = function getUniforms(name) {
    name = name + "_map";
    return "\n    #if defined(USE_" + name.toUpperCase() + ")\n        uniform sampler2D " + name + ";\n        uniform mat3 " + name + "_texMatrix;\n        uniform bool " + name + "_invert;\n    #endif\n    ";
};
var getBumpUniforms = function getBumpUniforms(name) {
    name = name + "_map";
    return "\n    #if defined(USE_" + name.toUpperCase() + ")\n        uniform sampler2D " + name + ";\n        uniform mat3 " + name + "_texMatrix;\n        uniform vec2 " + name + "_bumpScale;\n        uniform int " + name + "_bumpmapType;\n    #endif\n    ";
};
var getSampleBlock = function getSampleBlock(name, type) {
    var uniformName = name;
    var mapName = name + "_map";
    // catch uniform types
    var typeMap = {
        f: "float",
        c: "vec3",
        v2: "vec2",
        v3: "vec3",
        v4: "vec4"
    };
    type = typeMap[type] || type;
    var out = "_" + uniformName;
    var swizzle = "";
    switch (type) {
        case "float":
            swizzle = "x";
            break;
        case "vec2":
            swizzle = "xy";
            break;
        case "vec3":
            swizzle = "xyz";
            break;
        case "vec4":
            swizzle = "xyzw";
            break;
        default:
            throw new Error("Unexpected swizzle type: " + type);
    }
    // TODO: de-gamma
    return "\n    " + type + " " + out + " = " + uniformName + ";\n    #if defined(USE_" + mapName.toUpperCase() + ")\n    {\n        " + out + " = texture2D(" + mapName + ", (" + mapName + "_texMatrix * vec3(uv, 1.0)).xy)." + swizzle + ";\n        if (" + mapName + "_invert) {\n            " + out + " = " + type + "(1.0) - " + out + ";\n        }\n    }\n    #endif\n    ";
};
var loadMapChunk = function loadMapChunk(name, type) {
    THREE$1.ShaderChunk["prism_uniforms_" + name] = getUniforms(name);
    THREE$1.ShaderChunk["prism_sample_" + name] = getSampleBlock(name, type);
};
var loadMapChunksFromUniforms = function loadMapChunksFromUniforms(uniforms) {
    for (var name in uniforms) {
        loadMapChunk(name, uniforms[name].type);
    }
};

var vertexShader = "varying vec3 vViewPosition;\nvarying vec3 vNormal;\nvarying vec2 vUv;\nvarying vec3 vTangent;\nvarying vec3 vBitangent;\n#if defined(PRISMWOOD)\nvarying vec3 vUvw;\n#endif\n#if defined(PRISMWOOD) && defined(PRISMWOODBUMP)\nvarying vec3 vtNormal;\nvarying mat3 vNormalMatrix;\n#endif\nvoid computeTangents(vec3 normal, out vec3 u, out vec3 v) {\n    float scale = normal.z < 0.0 ? -1.0 : 1.0;\n    vec3 temp = scale * normal;\n    float e = temp.z;\n    float h = 1.0/(1.0 + e);\n    float hvx = h * temp.y;\n    float hvxy = hvx * -temp.x;\n    u = vec3(e + hvx * temp.y, hvxy, -temp.x);\n    v = vec3(hvxy, e + h * temp.x * temp.x, -temp.y);\n    u *= scale;\n    v *= scale;\n}\nvoid main() {\n    vUv = uv;\n    vec4 mvPosition = modelViewMatrix * vec4(position, 1.0);\n    gl_Position = projectionMatrix * mvPosition;\n    vViewPosition = -mvPosition.xyz;\n    vNormal = normalize(normalMatrix * normal);\n    vec3 Tu, Tv;\n    computeTangents(vNormal, Tu, Tv);\n    vTangent = Tu;\n    vBitangent = Tv;\n#if defined(PRISMWOOD)\n    vUvw = position;\n#endif\n#if defined(PRISMWOOD) && defined(PRISMWOODBUMP)\n    vtNormal = normalize(normal);\n    vNormalMatrix = normalMatrix;\n#endif\n}\n";

var fragmentShader$1 = "varying vec3 vViewPosition;\nvarying vec3 vNormal;\nvarying vec2 vUv;\nvarying vec3 vTangent;\nvarying vec3 vBitangent;\nuniform vec3 surface_albedo;\nuniform float surface_roughness;\nuniform float surface_anisotropy;\nuniform float surface_rotation;\nuniform vec3 opaque_albedo;\nuniform float opaque_f0;\nuniform float opaque_luminance;\nuniform vec3 opaque_luminance_modifier;\nuniform float uEnvExp;\n#include <prism_uniforms_surface_albedo>\n#include <prism_uniforms_surface_roughness>\n#include <prism_uniforms_surface_cutout>\n#include <prism_uniforms_surface_anisotropy>\n#include <prism_uniforms_surface_rotation>\n#include <prism_uniforms_surface_normal>\n#include <prism_uniforms_opaque_albedo>\n#include <prism_uniforms_opaque_f0>\n#include <prism_uniforms_opaque_luminance>\n#include <prism_uniforms_opaque_luminance_modifier>\n#include <common>\n#include <bsdfs>\n#include <lights_pars>\n#include <envmap_pars_fragment>\n#include <prism_common>\n#include <prism_math>\n#include <prism_env_opaque>\n#include <prism_brdf_opaque>\n#if (NUM_DIR_LIGHTS > 0) || (NUM_POINT_LIGHTS > 0) || (NUM_SPOT_LIGHTS > 0)\nvec3 getDiscreteLightRadiance(\n    GeometricContext geometry,\n    float NdotV, vec3 Tu, vec3 Tv,\n    vec3 surfaceAlbedo,\n    float surfaceRoughness,\n    float surfaceAnisotropy,\n    float surfaceRotation,\n    float opaqueF0,\n    vec3 opaqueAlbedo\n) {\n    vec3 N = geometry.normal;\n    vec3 V = geometry.viewDir;\n    IncidentLight directLight;\n    vec3 accumLight = vec3(0.0);\n#define ACCUM_LIGHT { vec3 L = directLight.direction; float NdotL = max(EPSILON, dot(N, L)); vec3 H = normalize(L + V); float NdotH = dot(N, H); float VdotH = dot(V, H); float Hu = dot(H, Tu); float Hv = dot(H, Tv); vec3 Hlocal = vec3(Hu, Hv, NdotH); accumLight += directLight.color * PrismOpaqueBRDF(Hlocal, NdotL, NdotH, NdotV, VdotH, surfaceAlbedo, surfaceRoughness, surfaceAnisotropy, surfaceRotation, opaqueF0, opaqueAlbedo ); }\n#if NUM_DIR_LIGHTS > 0\n    for (int i = 0; i < NUM_DIR_LIGHTS; i++) {\n        DirectionalLight directionalLight = directionalLights[i];\n        getDirectionalDirectLightIrradiance(directionalLight, geometry, directLight);\n        ACCUM_LIGHT\n    }\n#endif\n#if NUM_POINT_LIGHTS > 0\n    for (int i = 0; i < NUM_POINT_LIGHTS; i++) {\n        PointLight pointLight = pointLights[i];\n        getPointDirectLightIrradiance(pointLight, geometry, directLight);\n        ACCUM_LIGHT\n    }\n#endif\n#if NUM_SPOT_LIGHTS > 0\n    for (int i = 0; i < NUM_SPOT_LIGHTS; i++) {\n        SpotLight spotLight = spotLights[i];\n        getSpotDirectLightIrradiance(spotLight, geometry, directLight);\n        ACCUM_LIGHT\n    }\n#endif\n    return accumLight;\n}\n#endif\nvoid main() {\n    vec3 N;\n    vec3 V;\n    vec3 Tu;\n    vec3 Tv;\n    getGeoContext(\n        vViewPosition, vNormal, vUv,\n        vTangent, vBitangent,\n        N, V, Tu, Tv\n    );\n    float NdotV = clamp(dot(N, V), EPSILON, 1.0);\n    float surface_cutout = 1.0;\n    #include <prism_sample_surface_cutout>\n    if (_surface_cutout < 0.01) discard;\n    #include <prism_sample_surface_albedo>\n    #include <prism_sample_surface_roughness>\n    #include <prism_sample_surface_anisotropy>\n    #include <prism_sample_surface_rotation>\n    #include <prism_sample_opaque_albedo>\n    #include <prism_sample_opaque_f0>\n    #include <prism_sample_opaque_luminance_modifier>\n    #include <prism_sample_opaque_luminance>\n    vec3 outRadiance = vec3(0.0);\n#if (NUM_DIR_LIGHTS > 0) || (NUM_POINT_LIGHTS > 0) || (NUM_SPOT_LIGHTS > 0)\n    GeometricContext geometry;\n    geometry.position = -vViewPosition;\n    geometry.normal = N;\n    geometry.viewDir = V;\n    outRadiance += getDiscreteLightRadiance(\n        geometry,\n        NdotV, Tu, Tv,\n        _surface_albedo,\n        _surface_roughness,\n        _surface_anisotropy,\n        _surface_rotation,\n        _opaque_f0,\n        _opaque_albedo\n    );\n#endif\n#if defined(USE_ENVMAP)\n    outRadiance += PrismOpaqueIBL(\n        N, V, NdotV, Tu, Tv,\n        _surface_albedo,\n        _surface_roughness,\n        _surface_anisotropy,\n        _surface_rotation,\n        _opaque_f0,\n        _opaque_albedo,\n        _opaque_luminance,\n        _opaque_luminance_modifier\n    );\n#endif\n    outRadiance *= uEnvExp;\n    outRadiance = toneMapping(outRadiance);\n    gl_FragColor = LinearToGamma(vec4(outRadiance, 1.0), float(GAMMA_FACTOR));\n}\n";

// cached
var _params = null;
var opaqueShader = function () {
    if (_params) {
        return _params;
    }
    _params = {
        uniforms: {
            opaque_albedo: { type: "c", value: new THREE$1.Color(0.963976, 0.963976, 0.954687) },
            opaque_f0: { type: "f", value: 0.0529 },
            opaque_luminance_modifier: { type: "c", value: new THREE$1.Color() },
            opaque_luminance: { type: "f", value: 0.0 }
        },
        vertexShader: vertexShader,
        fragmentShader: fragmentShader$1
    };
    loadMapChunksFromUniforms(_params.uniforms);
    return _params;
};

var fragmentShader$2 = "varying vec3 vViewPosition;\nvarying vec3 vNormal;\nvarying vec2 vUv;\nvarying vec3 vTangent;\nvarying vec3 vBitangent;\nuniform vec3 surface_albedo;\nuniform float surface_roughness;\nuniform float surface_anisotropy;\nuniform float surface_rotation;\nuniform vec3 metal_f0;\nuniform float uEnvExp;\n#include <prism_uniforms_surface_albedo>\n#include <prism_uniforms_surface_roughness>\n#include <prism_uniforms_surface_cutout>\n#include <prism_uniforms_surface_anisotropy>\n#include <prism_uniforms_surface_rotation>\n#include <prism_uniforms_surface_normal>\n#include <prism_uniforms_metal_f0>\n#include <common>\n#include <bsdfs>\n#include <lights_pars>\n#include <envmap_pars_fragment>\n#include <prism_common>\n#include <prism_math>\n#include <prism_env_metal>\n#include <prism_brdf_metal>\n#if (NUM_DIR_LIGHTS > 0) || (NUM_POINT_LIGHTS > 0) || (NUM_SPOT_LIGHTS > 0)\nvec3 getDiscreteLightRadiance(\n    GeometricContext geometry,\n    float NdotV, vec3 Tu, vec3 Tv,\n    vec3 surfaceAlbedo,\n    float surfaceRoughness,\n    float surfaceAnisotropy,\n    float surfaceRotation,\n    vec3 metalF0\n) {\n    vec3 N = geometry.normal;\n    vec3 V = geometry.viewDir;\n    IncidentLight directLight;\n    vec3 accumLight = vec3(0.0);\n#define ACCUM_LIGHT { vec3 L = directLight.direction; float NdotL = max(EPSILON, dot(N, L)); vec3 H = normalize(L + V); float NdotH = dot(N, H); float VdotH = dot(V, H); float Hu = dot(H, Tu); float Hv = dot(H, Tv); vec3 Hlocal = vec3(Hu, Hv, NdotH); accumLight += directLight.color * PrismMetalBRDF(Hlocal, NdotL, NdotH, NdotV, VdotH, surfaceAlbedo, surfaceRoughness, surfaceAnisotropy, surfaceRotation, metalF0); }\n#if NUM_DIR_LIGHTS > 0\n    for (int i = 0; i < NUM_DIR_LIGHTS; i++) {\n        DirectionalLight directionalLight = directionalLights[i];\n        getDirectionalDirectLightIrradiance(directionalLight, geometry, directLight);\n        ACCUM_LIGHT\n    }\n#endif\n#if NUM_POINT_LIGHTS > 0\n    for (int i = 0; i < NUM_POINT_LIGHTS; i++) {\n        PointLight pointLight = pointLights[i];\n        getPointDirectLightIrradiance(pointLight, geometry, directLight);\n        ACCUM_LIGHT\n    }\n#endif\n#if (NUM_SPOT_LIGHTS > 0)\n    for (int i = 0; i < NUM_SPOT_LIGHTS; i++) {\n        SpotLight spotLight = spotLights[i];\n        getSpotDirectLightIrradiance(spotLight, geometry, directLight);\n        ACCUM_LIGHT\n    }\n#endif\n    return accumLight;\n}\n#endif\nvoid main() {\n    vec3 N;\n    vec3 V;\n    vec3 Tu;\n    vec3 Tv;\n    getGeoContext(\n        vViewPosition, vNormal, vUv,\n        vTangent, vBitangent,\n        N, V, Tu, Tv\n    );\n    float NdotV = clamp(dot(N, V), EPSILON, 1.0);\n    float surface_cutout = 1.0;\n    #include <prism_sample_surface_cutout>\n    if (_surface_cutout < 0.01) discard;\n    #include <prism_sample_surface_albedo>\n    #include <prism_sample_surface_roughness>\n    #include <prism_sample_surface_anisotropy>\n    #include <prism_sample_surface_rotation>\n    #include <prism_sample_metal_f0>\n    vec3 outRadiance = vec3(0.0);\n#if (NUM_DIR_LIGHTS > 0) || (NUM_POINT_LIGHTS > 0) || (NUM_SPOT_LIGHTS > 0)\n    GeometricContext geometry;\n    geometry.position = -vViewPosition;\n    geometry.normal = N;\n    geometry.viewDir = V;\n    outRadiance += getDiscreteLightRadiance(\n        geometry,\n        NdotV, Tu, Tv,\n        _surface_albedo,\n        _surface_roughness,\n        _surface_anisotropy,\n        _surface_rotation,\n        _metal_f0\n    );\n#endif\n#if defined(USE_ENVMAP)\n    outRadiance += PrismMetalIBL(\n        N, V, NdotV, Tu, Tv,\n        _surface_albedo,\n        _surface_roughness,\n        _surface_anisotropy,\n        _surface_rotation,\n        _metal_f0\n    );\n#endif\n    outRadiance *= uEnvExp;\n    outRadiance = toneMapping(outRadiance);\n    gl_FragColor = LinearToGamma(vec4(outRadiance, 1.0), float(GAMMA_FACTOR));\n}\n";

// cached
var _params$1 = null;
var metalShader = function () {
    if (_params$1) {
        return _params$1;
    }
    _params$1 = {
        uniforms: {
            metal_f0: { type: "c", value: new THREE$1.Color(0.963976, 0.963976, 0.954687) }
        },
        vertexShader: vertexShader,
        fragmentShader: fragmentShader$2
    };
    loadMapChunksFromUniforms(_params$1.uniforms);
    return _params$1;
};

var fragmentShader$3 = "varying vec3 vViewPosition;\nvarying vec3 vNormal;\nvarying vec2 vUv;\nvarying vec3 vTangent;\nvarying vec3 vBitangent;\nuniform vec3 surface_albedo;\nuniform float surface_roughness;\nuniform float surface_anisotropy;\nuniform float surface_rotation;\nuniform float layered_f0;\nuniform vec3 layered_diffuse;\nuniform float layered_fraction;\nuniform vec3 layered_bottom_f0;\nuniform float layered_roughness;\nuniform float layered_anisotropy;\nuniform float layered_rotation;\nuniform float uEnvExp;\n#include <prism_uniforms_surface_albedo>\n#include <prism_uniforms_surface_roughness>\n#include <prism_uniforms_surface_cutout>\n#include <prism_uniforms_surface_anisotropy>\n#include <prism_uniforms_surface_rotation>\n#include <prism_uniforms_surface_normal>\n#include <prism_uniforms_layered_f0>\n#include <prism_uniforms_layered_diffuse>\n#include <prism_uniforms_layered_fraction>\n#include <prism_uniforms_layered_bottom_f0>\n#include <prism_uniforms_layered_roughness>\n#include <prism_uniforms_layered_anisotropy>\n#include <prism_uniforms_layered_rotation>\n#include <common>\n#include <bsdfs>\n#include <lights_pars>\n#include <envmap_pars_fragment>\n#include <prism_common>\n#include <prism_math>\n#include <prism_env_layered>\n#include <prism_brdf_layered>\n#if (NUM_DIR_LIGHTS > 0) || (NUM_POINT_LIGHTS > 0) || (NUM_SPOT_LIGHTS > 0)\nvec3 getDiscreteLightRadiance(\n    GeometricContext geometry,\n    float NdotV, vec3 Tu, vec3 Tv,\n    vec3 surfaceAlbedo,\n    float surfaceRoughness,\n    float surfaceAnisotropy,\n    float surfaceRotation,\n    float layeredF0,\n    vec3 layeredDiffuse,\n    float layeredRoughness,\n    float layeredAnisotropy,\n    float layeredRotation,\n    vec3 layeredBottomF0,\n    float layeredFraction\n) {\n    vec3 N = geometry.normal;\n    vec3 V = geometry.viewDir;\n    IncidentLight directLight;\n    vec3 accumLight = vec3(0.0);\n#define ACCUM_LIGHT { vec3 L = directLight.direction; float NdotL = max(EPSILON, dot(N, L)); vec3 H = normalize(L + V); float NdotH = dot(N, H); float VdotH = dot(V, H); float Hu = dot(H, Tu); float Hv = dot(H, Tv); vec3 Hlocal = vec3(Hu, Hv, NdotH); accumLight += directLight.color * PrismLayeredBRDF( Hlocal, NdotL, NdotH, NdotV, VdotH, Hlocal, NdotL, NdotH, NdotV, surfaceAlbedo, surfaceRoughness, surfaceAnisotropy, surfaceRotation, layeredF0, layeredDiffuse, layeredRoughness, layeredAnisotropy, layeredRotation, layeredBottomF0, layeredFraction ); }\n#if NUM_DIR_LIGHTS > 0\n    for (int i = 0; i < NUM_DIR_LIGHTS; i++) {\n        DirectionalLight directionalLight = directionalLights[i];\n        getDirectionalDirectLightIrradiance(directionalLight, geometry, directLight);\n        ACCUM_LIGHT\n    }\n#endif\n#if NUM_POINT_LIGHTS > 0\n    for (int i = 0; i < NUM_POINT_LIGHTS; i++) {\n        PointLight pointLight = pointLights[i];\n        getPointDirectLightIrradiance(pointLight, geometry, directLight);\n        ACCUM_LIGHT\n    }\n#endif\n#if NUM_SPOT_LIGHTS > 0\n    for (int i = 0; i < NUM_SPOT_LIGHTS; i++) {\n        SpotLight spotLight = spotLights[i];\n        getSpotDirectLightIrradiance(spotLight, geometry, directLight);\n        ACCUM_LIGHT\n    }\n#endif\n    return accumLight;\n}\n#endif\nvoid main() {\n    vec3 N;\n    vec3 V;\n    vec3 Tu;\n    vec3 Tv;\n    getGeoContext(\n        vViewPosition, vNormal, vUv,\n        vTangent, vBitangent,\n        N, V, Tu, Tv\n    );\n    float NdotV = clamp(dot(N, V), EPSILON, 1.0);\n    float surface_cutout = 1.0;\n    #include <prism_sample_surface_cutout>\n    if (_surface_cutout < 0.01) discard;\n    #include <prism_sample_surface_albedo>\n    #include <prism_sample_surface_roughness>\n    #include <prism_sample_surface_anisotropy>\n    #include <prism_sample_surface_rotation>\n    #include <prism_sample_layered_f0>\n    #include <prism_sample_layered_diffuse>\n    #include <prism_sample_layered_fraction>\n    #include <prism_sample_layered_bottom_f0>\n    #include <prism_sample_layered_roughness>\n    #include <prism_sample_layered_anisotropy>\n    #include <prism_sample_layered_rotation>\n    vec3 outRadiance = vec3(0.0);\n#if (NUM_DIR_LIGHTS > 0) || (NUM_POINT_LIGHTS > 0) || (NUM_SPOT_LIGHTS > 0)\n    GeometricContext geometry;\n    geometry.position = -vViewPosition;\n    geometry.normal = N;\n    geometry.viewDir = V;\n    outRadiance += getDiscreteLightRadiance(\n        geometry,\n        NdotV, Tu, Tv,\n        _surface_albedo,\n        _surface_roughness,\n        _surface_anisotropy,\n        _surface_rotation,\n        _layered_f0,\n        _layered_diffuse,\n        _layered_roughness,\n        _layered_anisotropy,\n        _layered_rotation,\n        _layered_bottom_f0,\n        _layered_fraction\n    );\n#endif\n#if defined(USE_ENVMAP)\n    outRadiance += PrismLayeredIBL(\n        N, V, NdotV, Tu, Tv,\n        N, NdotV,\n        _surface_albedo,\n        _surface_roughness,\n        _surface_anisotropy,\n        _surface_rotation,\n        _layered_f0,\n        _layered_diffuse,\n        _layered_roughness,\n        _layered_anisotropy,\n        _layered_rotation,\n        _layered_bottom_f0,\n        _layered_fraction\n    );\n#endif\n    outRadiance *= uEnvExp;\n    outRadiance = toneMapping(outRadiance);\n    gl_FragColor = LinearToGamma(vec4(outRadiance, 1.0), float(GAMMA_FACTOR));\n}\n";

// cached
var _params$2 = null;
var layeredShader = function () {
    if (_params$2) {
        return _params$2;
    }
    _params$2 = {
        uniforms: {
            layered_f0: { type: "f", value: 0.0603 },
            layered_diffuse: { type: "c", value: new THREE$1.Color(0.9673, 0.9556, 0.9137) },
            layered_fraction: { type: "f", value: 0.25 },
            layered_bottom_f0: { type: "c", value: new THREE$1.Color(0.9673, 0.9556, 0.9137) },
            layered_roughness: { type: "f", value: 0.0 },
            layered_anisotropy: { type: "f", value: 0.0 },
            layered_rotation: { type: "f", value: 0.0 }
        },
        vertexShader: vertexShader,
        fragmentShader: fragmentShader$3
    };
    loadMapChunksFromUniforms(_params$2.uniforms);
    return _params$2;
};

var fragmentShader$4 = "varying vec3 vViewPosition;\nvarying vec3 vNormal;\nvarying vec2 vUv;\nvarying vec3 vTangent;\nvarying vec3 vBitangent;\nuniform vec3 surface_albedo;\nuniform float surface_roughness;\nuniform float surface_anisotropy;\nuniform float surface_rotation;\nuniform vec3 transparent_color;\nuniform float transparent_ior;\nuniform float uEnvExp;\n#include <prism_uniforms_surface_albedo>\n#include <prism_uniforms_surface_roughness>\n#include <prism_uniforms_surface_cutout>\n#include <prism_uniforms_surface_anisotropy>\n#include <prism_uniforms_surface_rotation>\n#include <prism_uniforms_surface_normal>\n#include <prism_uniforms_transparent_color>\n#include <prism_uniforms_transparent_ior>\n#include <common>\n#include <bsdfs>\n#include <lights_pars>\n#include <envmap_pars_fragment>\n#include <prism_common>\n#include <prism_math>\n#include <prism_env_transparent>\n#include <prism_brdf_transparent>\n#include <prism_transparency>\n#if (NUM_DIR_LIGHTS > 0) || (NUM_POINT_LIGHTS > 0) || (NUM_SPOT_LIGHTS > 0)\nvec3 getDiscreteLightRadiance(\n    GeometricContext geometry,\n    float NdotV, vec3 Tu, vec3 Tv,\n    vec3 surfaceAlbedo,\n    float surfaceRoughness,\n    float surfaceAnisotropy,\n    float surfaceRotation,\n    float transparentIor\n) {\n    vec3 N = geometry.normal;\n    vec3 V = geometry.viewDir;\n    IncidentLight directLight;\n    vec3 accumLight = vec3(0.0);\n#define ACCUM_LIGHT { vec3 L = directLight.direction; float NdotL = max(EPSILON, dot(N, L)); vec3 H = normalize(L + V); float NdotH = dot(N, H); float VdotH = dot(V, H); float Hu = dot(H, Tu); float Hv = dot(H, Tv); vec3 Hlocal = vec3(Hu, Hv, NdotH); accumLight += directLight.color * PrismTransparentBRDF(Hlocal, NdotL, NdotH, NdotV, VdotH, surfaceAlbedo, surfaceRoughness, surfaceAnisotropy, surfaceRotation, transparentIor); }\n#if NUM_DIR_LIGHTS > 0\n    for (int i = 0; i < NUM_DIR_LIGHTS; i++) {\n        DirectionalLight directionalLight = directionalLights[i];\n        getDirectionalDirectLightIrradiance(directionalLight, geometry, directLight);\n        ACCUM_LIGHT\n    }\n#endif\n#if NUM_POINT_LIGHTS > 0\n    for (int i = 0; i < NUM_POINT_LIGHTS; i++) {\n        PointLight pointLight = pointLights[i];\n        getPointDirectLightIrradiance(pointLight, geometry, directLight);\n        ACCUM_LIGHT\n    }\n#endif\n#if (NUM_SPOT_LIGHTS > 0)\n    for (int i = 0; i < NUM_SPOT_LIGHTS; i++) {\n        SpotLight spotLight = spotLights[i];\n        getSpotDirectLightIrradiance(spotLight, geometry, directLight);\n        ACCUM_LIGHT\n    }\n#endif\n    return accumLight;\n}\n#endif\nvoid main() {\n    vec3 N;\n    vec3 V;\n    vec3 Tu;\n    vec3 Tv;\n    getGeoContext(\n        vViewPosition, vNormal, vUv,\n        vTangent, vBitangent,\n        N, V, Tu, Tv\n    );\n    float NdotV = clamp(dot(N, V), EPSILON, 1.0);\n    float surface_cutout = 1.0;\n    #include <prism_sample_surface_cutout>\n    if (_surface_cutout < 0.01) discard;\n    #include <prism_sample_surface_albedo>\n    #include <prism_sample_surface_roughness>\n    #include <prism_sample_surface_anisotropy>\n    #include <prism_sample_surface_rotation>\n    #include <prism_sample_transparent_color>\n    #include <prism_sample_transparent_ior>\n    vec3 outRadiance = vec3(0.0);\n#if (NUM_DIR_LIGHTS > 0) || (NUM_POINT_LIGHTS > 0) || (NUM_SPOT_LIGHTS > 0)\n    GeometricContext geometry;\n    geometry.position = -vViewPosition;\n    geometry.normal = N;\n    geometry.viewDir = V;\n    outRadiance += getDiscreteLightRadiance(\n        geometry,\n        NdotV, Tu, Tv,\n        _surface_albedo,\n        _surface_roughness,\n        _surface_anisotropy,\n        _surface_rotation,\n        _transparent_ior\n    );\n#endif\n#if defined(USE_ENVMAP)\n    outRadiance += PrismTransparentIBL(\n        N, V, NdotV, Tu, Tv,\n        _surface_albedo,\n        _surface_roughness,\n        _surface_anisotropy,\n        _surface_rotation,\n        _transparent_color,\n        _transparent_ior\n    );\n#endif\n    outRadiance *= uEnvExp;\n    outRadiance = toneMapping(outRadiance);\n    gl_FragColor = LinearToGamma(vec4(outRadiance, 1.0), float(GAMMA_FACTOR));\n    applyPrismTransparency(gl_FragColor, _transparent_color, _transparent_ior);\n}\n";

// cached
var _params$3 = null;
var transparentShader = function () {
    if (_params$3) {
        return _params$3;
    }
    _params$3 = {
        transparent: true,
        depthWrite: false,
        uniforms: {
            transparent_color: { type: "c", value: new THREE$1.Color(0x111111) },
            transparent_ior: { type: "f", value: 2.0 }
        },
        vertexShader: vertexShader,
        fragmentShader: fragmentShader$4
    };
    loadMapChunksFromUniforms(_params$3.uniforms);
    return _params$3;
};

var fragmentShader$5 = "varying vec3 vViewPosition;\nvarying vec3 vNormal;\nvarying vec2 vUv;\nvarying vec3 vTangent;\nvarying vec3 vBitangent;\nvarying vec3 vUvw;\nvarying vec3 vtNormal;\nvarying mat3 vNormalMatrix;\nuniform vec3 surface_albedo;\nuniform float surface_roughness;\nuniform float surface_anisotropy;\nuniform float surface_rotation;\nuniform bool wood_fiber_cosine_enable;\nuniform int wood_fiber_cosine_bands;\nuniform vec4 wood_fiber_cosine_weights;\nuniform vec4 wood_fiber_cosine_frequencies;\nuniform bool wood_fiber_perlin_enable;\nuniform int wood_fiber_perlin_bands;\nuniform vec4 wood_fiber_perlin_weights;\nuniform vec4 wood_fiber_perlin_frequencies;\nuniform float wood_fiber_perlin_scale_z;\nuniform bool wood_growth_perlin_enable;\nuniform int wood_growth_perlin_bands;\nuniform vec4 wood_growth_perlin_weights;\nuniform vec4 wood_growth_perlin_frequencies;\nuniform float wood_latewood_ratio;\nuniform float wood_earlywood_sharpness;\nuniform float wood_latewood_sharpness;\nuniform float wood_ring_thickness;\nuniform bool wood_earlycolor_perlin_enable;\nuniform int wood_earlycolor_perlin_bands;\nuniform vec4 wood_earlycolor_perlin_weights;\nuniform vec4 wood_earlycolor_perlin_frequencies;\nuniform vec3 wood_early_color;\nuniform bool wood_use_manual_late_color;\nuniform vec3 wood_manual_late_color;\nuniform bool wood_latecolor_perlin_enable;\nuniform int wood_latecolor_perlin_bands;\nuniform vec4 wood_latecolor_perlin_weights;\nuniform vec4 wood_latecolor_perlin_frequencies;\nuniform float wood_late_color_power;\nuniform bool wood_diffuse_perlin_enable;\nuniform int wood_diffuse_perlin_bands;\nuniform vec4 wood_diffuse_perlin_weights;\nuniform vec4 wood_diffuse_perlin_frequencies;\nuniform float wood_diffuse_perlin_scale_z;\nuniform bool wood_use_pores;\nuniform int wood_pore_type;\nuniform float wood_pore_radius;\nuniform float wood_pore_cell_dim;\nuniform float wood_pore_color_power;\nuniform float wood_pore_depth;\nuniform bool wood_use_rays;\nuniform float wood_ray_color_power;\nuniform float wood_ray_seg_length_z;\nuniform float wood_ray_num_slices;\nuniform float wood_ray_ellipse_z2x;\nuniform float wood_ray_ellipse_radius_x;\nuniform bool wood_use_latewood_bump;\nuniform float wood_latewood_bump_depth;\nuniform bool wood_use_groove_roughness;\nuniform float wood_groove_roughness;\nuniform float wood_diffuse_lobe_weight;\nuniform vec4 wood_ring_fraction;\nuniform vec2 wood_fall_rise;\nuniform bool wood_curly_distortion_enable;\nuniform float wood_curly_distortion_scale;\nuniform sampler2D permutationMap;\nuniform sampler2D gradientMap;\nuniform sampler2D perm2DMap;\nuniform sampler2D permGradMap;\nuniform float uEnvExp;\n#include <common>\n#include <bsdfs>\n#include <lights_pars>\n#include <envmap_pars_fragment>\n#include <prism_common>\n#include <prism_math>\n#include <prism_env_opaque>\n#include <prism_brdf_opaque>\n#include <prism_wood>\n#if (NUM_DIR_LIGHTS > 0) || (NUM_POINT_LIGHTS > 0) || (NUM_SPOT_LIGHTS > 0)\nvec3 getDiscreteLightRadiance(\n    GeometricContext geometry,\n    float NdotV, vec3 Tu, vec3 Tv,\n    vec3 surfaceAlbedo,\n    float surfaceRoughness,\n    float surfaceAnisotropy,\n    float surfaceRotation,\n    float opaqueF0,\n    vec3 opaqueAlbedo\n) {\n    vec3 N = geometry.normal;\n    vec3 V = geometry.viewDir;\n    IncidentLight directLight;\n    vec3 accumLight = vec3(0.0);\n#define ACCUM_LIGHT { vec3 L = directLight.direction; float NdotL = max(EPSILON, dot(N, L)); vec3 H = normalize(L + V); float NdotH = dot(N, H); float VdotH = dot(V, H); float Hu = dot(H, Tu); float Hv = dot(H, Tv); vec3 Hlocal = vec3(Hu, Hv, NdotH); accumLight += directLight.color * PrismOpaqueBRDF(Hlocal, NdotL, NdotH, NdotV, VdotH, surfaceAlbedo, surfaceRoughness, surfaceAnisotropy, surfaceRotation, opaqueF0, opaqueAlbedo ); }\n#if NUM_DIR_LIGHTS > 0\n    for (int i = 0; i < NUM_DIR_LIGHTS; i++) {\n        DirectionalLight directionalLight = directionalLights[i];\n        getDirectionalDirectLightIrradiance(directionalLight, geometry, directLight);\n        ACCUM_LIGHT\n    }\n#endif\n#if NUM_POINT_LIGHTS > 0\n    for (int i = 0; i < NUM_POINT_LIGHTS; i++) {\n        PointLight pointLight = pointLights[i];\n        getPointDirectLightIrradiance(pointLight, geometry, directLight);\n        ACCUM_LIGHT\n    }\n#endif\n#if NUM_SPOT_LIGHTS > 0\n    for (int i = 0; i < NUM_SPOT_LIGHTS; i++) {\n        SpotLight spotLight = spotLights[i];\n        getSpotDirectLightIrradiance(spotLight, geometry, directLight);\n        ACCUM_LIGHT\n    }\n#endif\n    return accumLight;\n}\n#endif\nvoid main() {\n    vec3 N;\n    vec3 V;\n    vec3 Tu;\n    vec3 Tv;\n    getGeoContext(\n        vViewPosition, vNormal, vUv,\n        vTangent, vBitangent,\n        N, V, Tu, Tv\n    );\n#if defined(PRISMWOODBUMP)\n    getFinalWoodContext(\n        N, V, Tu, Tv, vUvw,\n        vNormal, vtNormal, vNormalMatrix\n    );\n#endif\n    float NdotV = clamp(dot(N, V), EPSILON, 1.0);\n    float woodRoughness = surface_roughness;\n    vec3 woodDiffuse = NoiseWood(vUvw, woodRoughness);\n    vec3 outRadiance = vec3(0.0);\n#if (NUM_DIR_LIGHTS > 0) || (NUM_POINT_LIGHTS > 0) || (NUM_SPOT_LIGHTS > 0)\n    GeometricContext geometry;\n    geometry.position = -vViewPosition;\n    geometry.normal = N;\n    geometry.viewDir = V;\n    outRadiance += getDiscreteLightRadiance(\n        geometry,\n        NdotV, Tu, Tv,\n        surface_albedo,\n        woodRoughness,\n        surface_anisotropy,\n        surface_rotation,\n        0.04,\n        woodDiffuse\n    );\n#endif\n#if defined(USE_ENVMAP)\n    outRadiance += PrismOpaqueIBL(\n        N, V, NdotV, Tu, Tv,\n        surface_albedo,\n        woodRoughness,\n        surface_anisotropy,\n        surface_rotation,\n        0.04,\n        woodDiffuse,\n        0.0,\n        vec3(0.0)\n    );\n#endif\n    outRadiance *= uEnvExp;\n    outRadiance = toneMapping(outRadiance);\n    gl_FragColor = LinearToGamma(vec4(outRadiance, 1.0), float(GAMMA_FACTOR));\n}\n";

// cached
var _params$4 = null;
var _woodTextures = null;
var generateWoodTextures = function generateWoodTextures() {
    // Generate permutationTex
    var permutation = [151, 160, 137, 91, 90, 15, 131, 13, 201, 95, 96, 53, 194, 233, 7, 225, 140, 36, 103, 30, 69, 142, 8, 99, 37, 240, 21, 10, 23, 190, 6, 148, 247, 120, 234, 75, 0, 26, 197, 62, 94, 252, 219, 203, 117, 35, 11, 32, 57, 177, 33, 88, 237, 149, 56, 87, 174, 20, 125, 136, 171, 168, 68, 175, 74, 165, 71, 134, 139, 48, 27, 166, 77, 146, 158, 231, 83, 111, 229, 122, 60, 211, 133, 230, 220, 105, 92, 41, 55, 46, 245, 40, 244, 102, 143, 54, 65, 25, 63, 161, 1, 216, 80, 73, 209, 76, 132, 187, 208, 89, 18, 169, 200, 196, 135, 130, 116, 188, 159, 86, 164, 100, 109, 198, 173, 186, 3, 64, 52, 217, 226, 250, 124, 123, 5, 202, 38, 147, 118, 126, 255, 82, 85, 212, 207, 206, 59, 227, 47, 16, 58, 17, 182, 189, 28, 42, 223, 183, 170, 213, 119, 248, 152, 2, 44, 154, 163, 70, 221, 153, 101, 155, 167, 43, 172, 9, 129, 22, 39, 253, 19, 98, 108, 110, 79, 113, 224, 232, 178, 185, 112, 104, 218, 246, 97, 228, 251, 34, 242, 193, 238, 210, 144, 12, 191, 179, 162, 241, 81, 51, 145, 235, 249, 14, 239, 107, 49, 192, 214, 31, 181, 199, 106, 157, 184, 84, 204, 176, 115, 121, 50, 45, 127, 4, 150, 254, 138, 236, 205, 93, 222, 114, 67, 29, 24, 72, 243, 141, 128, 195, 78, 66, 215, 61, 156, 180];
    var permutationBuffer = new Uint8Array(permutation);
    var permutationTex = new THREE$1.DataTexture(permutationBuffer, 256, 1, THREE$1.LuminanceFormat, THREE$1.UnsignedByteType, THREE$1.UVMapping, THREE$1.RepeatWrapping, THREE$1.RepeatWrapping, THREE$1.NearestFilter, THREE$1.NearestFilter, 0);
    permutationTex.generateMipmaps = false;
    permutationTex.flipY = false;
    permutationTex.needsUpdate = true;
    // Generate gradientTex
    // This is different with OGS desktop. OGS uses a float texture. I map these number to
    // unsight byte, since some platform may not support float texture. Test result shows that
    // the pixel diffrence is very small.
    var gradientData = [225, 39, 122, 231, 29, 173, 15, 159, 75, 88, 233, 19, 179, 79, 72, 94, 54, 73, 151, 161, 171, 113, 221, 144, 127, 83, 168, 19, 88, 122, 62, 225, 109, 128, 246, 247, 172, 101, 61, 139, 211, 168, 64, 210, 224, 82, 87, 97, 119, 250, 201, 44, 242, 239, 154, 99, 126, 13, 44, 70, 246, 170, 100, 52, 135, 28, 187, 22, 207, 119, 199, 1, 235, 187, 55, 131, 190, 124, 222, 249, 236, 53, 225, 231, 71, 30, 173, 185, 153, 47, 79, 133, 225, 10, 140, 62, 17, 99, 100, 29, 137, 95, 142, 244, 76, 5, 83, 124, 38, 216, 253, 195, 44, 210, 148, 185, 188, 39, 78, 195, 132, 30, 60, 73, 92, 223, 133, 80, 230, 56, 118, 207, 79, 15, 251, 211, 111, 21, 79, 23, 240, 146, 150, 207, 3, 61, 103, 27, 148, 6, 31, 127, 235, 58, 173, 244, 116, 81, 34, 120, 192, 213, 188, 226, 97, 23, 16, 161, 106, 80, 242, 148, 35, 37, 91, 117, 51, 216, 97, 193, 126, 222, 39, 38, 133, 217, 215, 23, 237, 57, 205, 42, 222, 165, 126, 133, 33, 8, 227, 154, 27, 18, 56, 11, 192, 120, 80, 92, 236, 38, 210, 207, 128, 31, 135, 39, 123, 5, 49, 127, 107, 200, 34, 14, 153, 239, 134, 19, 248, 162, 58, 201, 159, 198, 243, 158, 72, 5, 138, 184, 222, 200, 34, 141, 233, 40, 195, 238, 191, 122, 171, 32, 66, 254, 229, 197];
    var gradientBuffer = new Uint8Array(gradientData);
    var gradientTex = new THREE$1.DataTexture(gradientBuffer, 256, 1, THREE$1.LuminanceFormat, THREE$1.UnsignedByteType, THREE$1.UVMapping, THREE$1.RepeatWrapping, THREE$1.RepeatWrapping, THREE$1.NearestFilter, THREE$1.NearestFilter, 0);
    gradientTex.generateMipmaps = false;
    gradientTex.flipY = false;
    gradientTex.needsUpdate = true;
    // Generate perm2DTex
    var perm = function perm(v) {
        return permutation[v % 256];
    };
    var perm2D = new Array(256 * 256 * 4);
    var y = void 0;
    var x = void 0;
    var A = void 0;
    var AA = void 0;
    var AB = void 0;
    var B = void 0;
    var BA = void 0;
    var BB = void 0;
    var index = void 0;
    for (y = 0; y < 256; ++y) {
        for (x = 0; x < 256; ++x) {
            A = perm(x) + y;
            AA = perm(A);
            AB = perm(A + 1);
            B = perm(x + 1) + y;
            BA = perm(B);
            BB = perm(B + 1);
            // Store (AA, AB, BA, BB) in pixel (x,y)
            index = 4 * (y * 256 + x);
            perm2D[index] = AA;
            perm2D[index + 1] = AB;
            perm2D[index + 2] = BA;
            perm2D[index + 3] = BB;
        }
    }
    var perm2DBuffer = new Uint8Array(perm2D);
    var perm2DTex = new THREE$1.DataTexture(perm2DBuffer, 256, 256, THREE$1.RGBAFormat, THREE$1.UnsignedByteType, THREE$1.UVMapping, THREE$1.RepeatWrapping, THREE$1.RepeatWrapping, THREE$1.NearestFilter, THREE$1.NearestFilter, 0);
    perm2DTex.generateMipmaps = false;
    perm2DTex.flipY = false;
    perm2DTex.needsUpdate = true;
    // Generate permGradTex
    var gradients3D = [1, 1, 0, -1, 1, 0, 1, -1, 0, -1, -1, 0, 1, 0, 1, -1, 0, 1, 1, 0, -1, -1, 0, -1, 0, 1, 1, 0, -1, 1, 0, 1, -1, 0, -1, -1, 1, 1, 0, 0, -1, 1, -1, 1, 0, 0, -1, -1];
    var permGrad = new Array(1024);
    for (x = 0; x < 256; ++x) {
        var i = permutation[x] % 16;
        // convert the gradient to signed-normalized int.
        permGrad[x * 4] = gradients3D[i * 3] * 127 + 128;
        permGrad[x * 4 + 1] = gradients3D[i * 3 + 1] * 127 + 128;
        permGrad[x * 4 + 2] = gradients3D[i * 3 + 2] * 127 + 128;
        permGrad[x * 4 + 3] = 0;
    }
    var permGradBuffer = new Uint8Array(permGrad);
    var permGradTex = new THREE$1.DataTexture(permGradBuffer, 256, 1, THREE$1.RGBAFormat, THREE$1.UnsignedByteType, THREE$1.UVMapping, THREE$1.RepeatWrapping, THREE$1.RepeatWrapping, THREE$1.NearestFilter, THREE$1.NearestFilter, 0);
    permGradTex.generateMipmaps = false;
    permGradTex.flipY = false;
    permGradTex.needsUpdate = true;
    return {
        permutationTex: permutationTex,
        gradientTex: gradientTex,
        perm2DTex: perm2DTex,
        permGradTex: permGradTex
    };
};
var woodShader = function () {
    if (_params$4) {
        return _params$4;
    }
    _woodTextures = generateWoodTextures();
    // default parameters from "3D Cherry - Glossy"
    _params$4 = {
        // PRISMWOODBUMP disabled, due to bad performance and IE support
        // To enable:
        // material.defines.PRISMWOODBUMP: "";
        // material.needsUpdate = true;
        defines: {
            PRISMWOOD: ""
        },
        uniforms: {
            wood_fiber_cosine_enable: { type: "i", value: false },
            wood_fiber_cosine_bands: { type: "i", value: 1 },
            wood_fiber_cosine_weights: { type: "v4", value: new THREE$1.Vector4(0.1, 1, 1, 1) },
            wood_fiber_cosine_frequencies: { type: "v4", value: new THREE$1.Vector4(1, 1, 1, 1) },
            wood_fiber_perlin_enable: { type: "i", value: true },
            wood_fiber_perlin_bands: { type: "i", value: 4 },
            wood_fiber_perlin_weights: { type: "v4", value: new THREE$1.Vector4(8, 2, 0.5, 0.05) },
            wood_fiber_perlin_frequencies: { type: "v4", value: new THREE$1.Vector4(0.016666666666666666, 0.05, 0.18181818181818182, 1) },
            wood_fiber_perlin_scale_z: { type: "f", value: 0.2 },
            wood_growth_perlin_enable: { type: "i", value: true },
            wood_growth_perlin_bands: { type: "i", value: 2 },
            wood_growth_perlin_weights: { type: "v4", value: new THREE$1.Vector4(2, 0.5, 1, 1) },
            wood_growth_perlin_frequencies: { type: "v4", value: new THREE$1.Vector4(0.2, 1, 1, 1) },
            wood_latewood_ratio: { type: "f", value: 0.082 },
            wood_earlywood_sharpness: { type: "f", value: 0.25 },
            wood_latewood_sharpness: { type: "f", value: 0.812 },
            wood_ring_thickness: { type: "f", value: 0.6 },
            wood_earlycolor_perlin_enable: { type: "i", value: true },
            wood_earlycolor_perlin_bands: { type: "i", value: 2 },
            wood_earlycolor_perlin_weights: { type: "v4", value: new THREE$1.Vector4(0.85, 0.3, 1, 1) },
            wood_earlycolor_perlin_frequencies: { type: "v4", value: new THREE$1.Vector4(0.125, 0.3333333333333333, 1, 1) },
            wood_early_color: { type: "c", value: new THREE$1.Color(0.42050799696531205, 0.14799801144636357, 0.0563742292350767) },
            wood_use_manual_late_color: { type: "i", value: false },
            wood_manual_late_color: { type: "c", value: new THREE$1.Color(0, 0, 0) },
            wood_latecolor_perlin_enable: { type: "i", value: true },
            wood_latecolor_perlin_bands: { type: "i", value: 1 },
            wood_latecolor_perlin_weights: { type: "v4", value: new THREE$1.Vector4(0.35, 1, 1, 1) },
            wood_latecolor_perlin_frequencies: { type: "v4", value: new THREE$1.Vector4(0.2222222222222222, 1, 1, 1) },
            wood_late_color_power: { type: "f", value: 1.36 },
            wood_diffuse_perlin_enable: { type: "i", value: true },
            wood_diffuse_perlin_bands: { type: "i", value: 2 },
            wood_diffuse_perlin_weights: { type: "v4", value: new THREE$1.Vector4(0.1, 0.25, 1, 1) },
            wood_diffuse_perlin_frequencies: { type: "v4", value: new THREE$1.Vector4(0.5, 20, 1, 1) },
            wood_diffuse_perlin_scale_z: { type: "f", value: 0.2 },
            wood_use_pores: { type: "i", value: true },
            wood_pore_type: { type: "i", value: 0 },
            wood_pore_radius: { type: "f", value: 0.04 },
            wood_pore_cell_dim: { type: "f", value: 0.15 },
            wood_pore_color_power: { type: "f", value: 1.45 },
            wood_pore_depth: { type: "f", value: 0.02 },
            wood_use_rays: { type: "i", value: true },
            wood_ray_color_power: { type: "f", value: 1.2 },
            wood_ray_seg_length_z: { type: "f", value: 5 },
            wood_ray_num_slices: { type: "f", value: 160 },
            wood_ray_ellipse_z2x: { type: "f", value: 10 },
            wood_ray_ellipse_radius_x: { type: "f", value: 0.2 },
            wood_use_latewood_bump: { type: "i", value: true },
            wood_latewood_bump_depth: { type: "f", value: 0.01 },
            wood_use_groove_roughness: { type: "i", value: true },
            wood_groove_roughness: { type: "f", value: 0.2 },
            wood_diffuse_lobe_weight: { type: "f", value: 0.85 },
            // not yet implemented
            wood_curly_distortion_enable: { type: "i", value: false },
            wood_curly_distortion_scale: { type: "f", value: 0.25 },
            wood_ring_fraction: { type: "v4", value: new THREE$1.Vector4(0.918, 0.2295, 0.066584, 0.984584) },
            wood_fall_rise: { type: "v2", value: new THREE$1.Vector2(0.6885, 0.015416) },
            permutationMap: { type: "t", value: _woodTextures.permutationTex },
            gradientMap: { type: "t", value: _woodTextures.gradientTex },
            perm2DMap: { type: "t", value: _woodTextures.perm2DTex },
            permGradMap: { type: "t", value: _woodTextures.permGradTex }
        },
        vertexShader: vertexShader,
        fragmentShader: fragmentShader$5
    };
    return _params$4;
};

var prismCommonChunk = "#include <normal_map>\nfloat sqr(float x) {\n    return x * x;\n}\nvoid getGeoContext(\n    vec3 viewPosition,\n    vec3 normal,\n    vec2 uv,\n    vec3 tangent,\n    vec3 bitangent,\n    out vec3 N,\n    out vec3 V,\n    out vec3 Tu,\n    out vec3 Tv\n) {\n    N = normalize(normal);\n    V = normalize(viewPosition);\n    Tu = normalize(tangent);\n    Tv = normalize(bitangent);\n#if defined(USE_MAP)\n    vec3 q0 = dFdx(-viewPosition);\n    vec3 q1 = dFdy(-viewPosition);\n    vec2 st0 = dFdx(uv);\n    vec2 st1 = dFdy(uv);\n    Tu = normalize(q0 * st1.t - q1 * st0.t);\n    Tv = normalize(-q0 * st1.s + q1 * st0.s);\n#endif\n#if defined(USE_SURFACE_NORMAL_MAP)\n    if (surface_normal_map_bumpmapType == 0) {\n        heightMapTransform(surface_normal_map, uv, surface_normal_map_texMatrix, surface_normal_map_bumpScale, Tu, Tv, N);\n    } else {\n        normalMapTransform(surface_normal_map, uv, surface_normal_map_texMatrix, surface_normal_map_bumpScale, Tu, Tv, N);\n    }\n#endif\n}";

var prismMathChunk = "\nvec2 RoughnessToAlpha(float roughness, float anisotropy) {\n    vec2 alpha = roughness * vec2(1.0, 1.0 - anisotropy);\n    alpha = alpha * alpha;\n    alpha = clamp(alpha, 0.001, 1.0);\n    return alpha;\n}\nvec3 FresnelSchlick(vec3 f0, float cosAngle) {\n    float x = 1.0 - cosAngle;\n    float x2 = x * x;\n    float x5 = x * x2 * x2;\n    return f0 + (1.0 - f0) * x5;\n}\nvec3 FresnelRough(vec3 f0, float cosAngle, float alpha) {\n    float x = 1.0 - cosAngle;\n    float x2 = x * x;\n    float x5 = x * x2 * x2;\n    vec3 maxReflectance = mix(vec3(1.0), f0, vec3(min(0.7, alpha)) / 0.7);\n    return f0 + (maxReflectance - f0) * x5;\n}\nfloat IORToReflectance(float ior) {\n    return sqr((1.0 - ior) / (1.0 + ior));\n}\n";

var prismEnvChunk = "#if defined(USE_ENVMAP)\nfloat alphaToPhong(float alpha) {\n    return max(0.0, 2.56/alpha - 7.0);\n}\nfloat phongToReflMipIndex(float exponent) {\n    const float EXP_COUNT = 10.0;\n    const float LOG_MIN = 0.0;\n    const float LOG_MAX = 9.0;\n    const float NUM_MIPS = 6.0;\n    float targetLog = log2(exponent);\n    float deltaLog = clamp(targetLog - LOG_MIN, 0.0, LOG_MAX - LOG_MIN);\n    float level = clamp((1.0-(deltaLog + 0.5) / EXP_COUNT), 0.0, 1.0) * NUM_MIPS;\n    return level;\n}\nvec3 decodeRGBM(in vec4 vRGBM) {\n    vec3 ret = vRGBM.rgb * (vRGBM.a * 16.0);\n    ret *= ret / uEnvExp;\n    return ret;\n}\nvec3 sampleReflection(vec3 n, vec3 v, float a) {\n    float mipLevel = phongToReflMipIndex(alphaToPhong(a));\n    v = reflect(-v, n);\n    v = inverseTransformDirection(v, viewMatrix);\n#ifdef GL_EXT_shader_texture_lod\n    return decodeRGBM(textureCubeLodEXT(envMap, v, mipLevel));\n#else\n    return decodeRGBM(textureCube(envMap, v, mipLevel));\n#endif\n}\nuniform samplerCube irrMap;\nvec3 sampleIrradiance(vec3 v) {\n    v = inverseTransformDirection(v, viewMatrix);\n    return decodeRGBM(textureCube(irrMap, v));\n}\n#endif\n";

var prismEnvOpaque = "#include <prism_env>\n#if defined(USE_ENVMAP)\nvec3 PrismOpaqueIBL(\n    vec3 N, vec3 V, float NdotV, vec3 Tu, vec3 Tv,\n    vec3 surfaceAlbedo,\n    float surfaceRoughness,\n    float surfaceAnisotropy,\n    float surfaceRotation,\n    float opaqueF0,\n    vec3 opaqueAlbedo,\n    float opaqueLuminance,\n    vec3 opaqueLuminanceModifier\n) {\n    float alpha = RoughnessToAlpha(surfaceRoughness, 0.0).x;\n    vec3 F = FresnelRough(vec3(opaqueF0), NdotV, alpha);\n    vec3 envSpecular = sampleReflection(N, V, alpha);\n    vec3 specular = F * surfaceAlbedo * envSpecular;\n    vec3 envIrradiance = sampleIrradiance(N);\n    vec3 diffuse = (1.0 - F) * opaqueAlbedo * envIrradiance;\n    vec3 emission = opaqueLuminanceModifier * opaqueLuminance;\n    return diffuse + specular + emission;\n}\n#endif\n";

var prismEnvMetal = "#include <prism_env>\n#if defined(USE_ENVMAP)\nvec3 PrismMetalIBL(\n    vec3 N, vec3 V, float NdotV, vec3 Tu, vec3 Tv,\n    vec3 surfaceAlbedo,\n    float surfaceRoughness,\n    float surfaceAnisotropy,\n    float surfaceRotation,\n    vec3 metalF0\n) {\n    float alpha = RoughnessToAlpha(surfaceRoughness, 0.0).x;\n    vec3 F = FresnelRough(metalF0, NdotV, alpha);\n    vec3 envSpecular = sampleReflection(N, V, alpha);\n    vec3 specular = F * surfaceAlbedo * envSpecular;\n    return specular;\n}\n#endif\n";

var prismEnvLayered = "#include <prism_env>\n#if defined(USE_ENVMAP)\nvec3 PrismLayeredIBL(\n    vec3 N, vec3 V, float NdotV, vec3 Tu, vec3 Tv,\n    vec3 N2, float N2dotV,\n    vec3 surfaceAlbedo,\n    float surfaceRoughness,\n    float surfaceAnisotropy,\n    float surfaceRotation,\n    float layeredF0,\n    vec3 layeredDiffuse,\n    float layeredRoughness,\n    float layeredAnisotropy,\n    float layeredRotation,\n    vec3 bottomF0,\n    float layeredFraction\n) {\n    vec3 F = FresnelSchlick(vec3(layeredF0), NdotV);\n    float alpha = RoughnessToAlpha(surfaceRoughness, 0.0).x;\n    vec3 envSpecular = sampleReflection(N, V, alpha);\n    vec3 topSpecular = F * surfaceAlbedo * envSpecular;\n    vec3 amount = (1.0 - F);\n    vec3 envIrradiance = sampleIrradiance(N);\n    vec3 topDiffuse = layeredDiffuse * envIrradiance;\n    alpha = RoughnessToAlpha(layeredRoughness, 0.0).x;\n    envSpecular = sampleReflection(N2, V, alpha);\n    F = FresnelRough(bottomF0, N2dotV, alpha);\n    vec3 botSpecular = F * envSpecular;\n    return topSpecular + amount * mix(topDiffuse, botSpecular, layeredFraction);\n}\n#endif";

var prismEnvTransparent = "#include <prism_env>\n#if defined(USE_ENVMAP)\nvec3 PrismTransparentIBL(\n    vec3 N, vec3 V, float NdotV, vec3 Tu, vec3 Tv,\n    vec3 surfaceAlbedo,\n    float surfaceRoughness,\n    float surfaceAnisotropy,\n    float surfaceRotation,\n    vec3 transparentColor,\n    float transparentIor\n) {\n    vec3 reflectance = vec3(IORToReflectance(transparentIor));\n    float alpha = RoughnessToAlpha(surfaceRoughness, 0.0).x;\n    vec3 F = FresnelRough(reflectance, NdotV, alpha);\n    vec3 envSpecular = sampleReflection(N, V, alpha);\n    vec3 specular = F * surfaceAlbedo * envSpecular;\n    vec3 envIrradiance = sampleIrradiance(N);\n    vec3 color = F * surfaceRoughness * transparentColor * envIrradiance;\n    return specular + color;\n}\n#endif";

var prismBrdfChunk = "float aSqrd(float maxAlphaSqr, float cosTheta) {\n    if (abs(cosTheta) < 1e-10) {\n        return 1e10;\n    }\n    float tan2 = 1.0/sqr(cosTheta) - 1.0;\n    return maxAlphaSqr * tan2;\n}\nvec3 Rotate(vec3 vec, float angle) {\n    float s = sin(angle);\n    float c = cos(angle);\n    return vec3(vec.x * c - vec.y * s, vec.x * s + vec.y * c, vec.z);\n}\nfloat NDF_GGX(float alphaU, float alphaV, vec3 normal) {\n    float nx2 = sqr(normal.x);\n    float ny2 = sqr(normal.y);\n    float nz2 = sqr(normal.z);\n    float scale = 1.0/(alphaU * alphaV * PI);\n    return scale/sqr(nx2/sqr(alphaU) + ny2/sqr(alphaV) + nz2);\n}\nfloat G1_GGX(float aSqrd) {\n    return 2.0 / (1.0 + sqrt(1.0 + aSqrd));\n}\nvec3 MicrofacetLobe(\n    vec3 Hlocal,\n    float NdotL,\n    float NdotH,\n    float NdotV,\n    float VdotH,\n    float roughness,\n    float anisotropy,\n    float rotation,\n    vec3 reflectance\n) {\n    vec2 alpha = RoughnessToAlpha(roughness, anisotropy);\n    Hlocal = Rotate(Hlocal, rotation);\n    vec3 F = FresnelSchlick(reflectance, VdotH);\n    float D = NDF_GGX(alpha.x, alpha.y, Hlocal);\n    float alpha2 = max(sqr(alpha.x), sqr(alpha.y));\n    float alpha2NL = aSqrd(alpha2, NdotL);\n    float alpha2NV = aSqrd(alpha2, NdotV);\n    float G = G1_GGX(alpha2NL) * G1_GGX(alpha2NV);\n    return max(F * D * G / (4.0 * NdotL * NdotV), vec3(0.0));\n}\nvec3 DiffuseLobe(vec3 diffuseColor) {\n    return diffuseColor * RECIPROCAL_PI;\n}\n";

var prismBrdfOpaque = "#include <prism_brdf>\nvec3 PrismOpaqueBRDF(\n    vec3 Hlocal,\n    float NdotL,\n    float NdotH,\n    float NdotV,\n    float VdotH,\n    vec3 surfaceAlbedo,\n    float surfaceRoughness,\n    float surfaceAnisotropy,\n    float surfaceRotation,\n    float opaqueF0,\n    vec3 opaqueAlbedo\n) {\n    vec3 diffuse = DiffuseLobe(opaqueAlbedo);\n    vec3 specular = surfaceAlbedo * MicrofacetLobe(\n        Hlocal,\n        NdotL,\n        NdotH,\n        NdotV,\n        VdotH,\n        surfaceRoughness,\n        surfaceAnisotropy,\n        surfaceRotation,\n        vec3(opaqueF0)\n    );\n    return (specular + diffuse) * NdotL;\n}\n";

var prismBrdfMetal = "#include <prism_brdf>\nvec3 PrismMetalBRDF(\n    vec3 Hlocal,\n    float NdotL,\n    float NdotH,\n    float NdotV,\n    float VdotH,\n    vec3 surfaceAlbedo,\n    float surfaceRoughness,\n    float surfaceAnisotropy,\n    float surfaceRotation,\n    vec3 metalF0\n) {\n    vec3 specular = surfaceAlbedo * MicrofacetLobe(\n        Hlocal,\n        NdotL,\n        NdotH,\n        NdotV,\n        VdotH,\n        surfaceRoughness,\n        surfaceAnisotropy,\n        surfaceRotation,\n        metalF0\n    );\n    return specular * NdotL;\n}\n";

var prismBrdfLayered = "#include <prism_brdf>\nvec3 PrismLayeredBRDF(\n    vec3 Hlocal,\n    float NdotL,\n    float NdotH,\n    float NdotV,\n    float VdotH,\n    vec3 Hlocal2,\n    float N2dotL,\n    float N2dotH,\n    float N2dotV,\n    vec3 surfaceAlbedo,\n    float surfaceRoughness,\n    float surfaceAnisotropy,\n    float surfaceRotation,\n    float layeredF0,\n    vec3 layeredDiffuse,\n    float layeredRoughness,\n    float layeredAnisotropy,\n    float layeredRotation,\n    vec3 layeredBottomF0,\n    float layeredFraction\n) {\n    vec3 Fl = FresnelSchlick(vec3(layeredF0), NdotL);\n    vec3 Fv = FresnelSchlick(vec3(layeredF0), NdotV);\n    vec3 amount = (1.0 - Fl) * (1.0 - Fv);\n    vec3 topSpecular = surfaceAlbedo * MicrofacetLobe(\n        Hlocal,\n        NdotL,\n        NdotH,\n        NdotV,\n        VdotH,\n        surfaceRoughness,\n        surfaceAnisotropy,\n        surfaceRotation,\n        vec3(layeredF0)\n    );\n    vec3 topDiffuse = DiffuseLobe(layeredDiffuse);\n    vec3 botSpecular = MicrofacetLobe(\n        Hlocal2,\n        N2dotL,\n        N2dotH,\n        N2dotV,\n        VdotH,\n        layeredRoughness,\n        layeredAnisotropy,\n        layeredRotation,\n        layeredBottomF0\n    );\n    return topSpecular * NdotL + amount * mix(\n        topDiffuse * NdotL,\n        botSpecular * N2dotL,\n        layeredFraction\n    );\n}\n";

var prismBrdfTransparent = "#include <prism_brdf>\nvec3 PrismTransparentBRDF(\n    vec3 Hlocal,\n    float NdotL,\n    float NdotH,\n    float NdotV,\n    float VdotH,\n    vec3 surfaceAlbedo,\n    float surfaceRoughness,\n    float surfaceAnisotropy,\n    float surfaceRotation,\n    float transparentIor\n) {\n    vec3 reflectance = vec3(IORToReflectance(transparentIor));\n    vec3 specular = surfaceAlbedo * MicrofacetLobe(\n        Hlocal,\n        NdotL,\n        NdotH,\n        NdotV,\n        VdotH,\n        surfaceRoughness,\n        surfaceAnisotropy,\n        surfaceRotation,\n        reflectance\n    );\n    return specular * NdotL;\n}\n";

var loadPrismChunks = function loadPrismChunks() {
    THREE$1.ShaderChunk["normal_map"] = normalMapChunk;
    THREE$1.ShaderChunk["prism_common"] = prismCommonChunk;
    THREE$1.ShaderChunk["prism_math"] = prismMathChunk;
    THREE$1.ShaderChunk["prism_env"] = prismEnvChunk;
    THREE$1.ShaderChunk["prism_env_opaque"] = prismEnvOpaque;
    THREE$1.ShaderChunk["prism_env_metal"] = prismEnvMetal;
    THREE$1.ShaderChunk["prism_env_layered"] = prismEnvLayered;
    THREE$1.ShaderChunk["prism_env_transparent"] = prismEnvTransparent;
    THREE$1.ShaderChunk["prism_brdf"] = prismBrdfChunk;
    THREE$1.ShaderChunk["prism_brdf_opaque"] = prismBrdfOpaque;
    THREE$1.ShaderChunk["prism_brdf_metal"] = prismBrdfMetal;
    THREE$1.ShaderChunk["prism_brdf_layered"] = prismBrdfLayered;
    THREE$1.ShaderChunk["prism_brdf_transparent"] = prismBrdfTransparent;
    THREE$1.ShaderChunk["prism_wood"] = prismWood;
    THREE$1.ShaderChunk["prism_transparency"] = prismTransparency;
    THREE$1.ShaderChunk["prism_uniforms_surface_normal"] = getBumpUniforms("surface_normal");
    loadMapChunk("surface_albedo", "vec3");
    loadMapChunk("surface_roughness", "float");
    loadMapChunk("surface_anisotropy", "float");
    loadMapChunk("surface_rotation", "float");
    loadMapChunk("surface_cutout", "float");
};

loadPrismChunks();
var _commonParams = {
    uniforms: {
        surface_albedo: { type: "c", value: new THREE$1.Color() },
        surface_roughness: { type: "f", value: 0.1 },
        surface_anisotropy: { type: "f", value: 0.0 },
        surface_rotation: { type: "f", value: 0.0 },
        uEnvExp: { type: "f", value: 1.0 }
    },
    extensions: {
        derivatives: true,
        shaderTextureLOD: true
    }
};
var _typesToShaders = {};
// TODO: should add Symbol type, but typescript bug:
// https://github.com/Microsoft/TypeScript/issues/1863
var _getShaderParams = function _getShaderParams(symbol) {
    var shaderGetter = _typesToShaders[symbol] || opaqueShader;
    return shaderGetter();
};

var PrismMaterial = function (_ShaderMaterial) {
    inherits(PrismMaterial, _ShaderMaterial);

    function PrismMaterial(symbol) {
        classCallCheck(this, PrismMaterial);

        var shaderParams = _getShaderParams(symbol);
        var params = Object.assign({}, _commonParams, shaderParams);
        params.uniforms = THREE$1.UniformsUtils.merge([_commonParams.uniforms, shaderParams.uniforms]);

        // carry over already-initialized textures
        var _this = possibleConstructorReturn(this, (PrismMaterial.__proto__ || Object.getPrototypeOf(PrismMaterial)).call(this, params));

        for (var k in shaderParams.uniforms) {
            var uniform = shaderParams.uniforms[k];
            if (uniform.type === "t" && uniform.value) {
                _this.uniforms[k].value = uniform.value;
            }
        }
        _this._lights = false;
        return _this;
    }

    createClass(PrismMaterial, [{
        key: "lights",
        get: function get$$1() {
            return this._lights;
        },
        set: function set$$1(value) {
            if (value && this.uniforms) {
                var lightUniforms = THREE$1.UniformsLib["lights"];
                for (var k in lightUniforms) {
                    this.uniforms[k] = THREE$1.UniformsUtils.clone(lightUniforms[k]);
                }
            }
            this._lights = value;
        }
    }]);
    return PrismMaterial;
}(THREE$1.ShaderMaterial);

PrismMaterial.OPAQUE = Symbol("Opaque");
PrismMaterial.METAL = Symbol("Metal");
PrismMaterial.LAYERED = Symbol("Layered");
PrismMaterial.TRANSPARENT = Symbol("Transparent");
PrismMaterial.WOOD = Symbol("Wood");
_typesToShaders[PrismMaterial.OPAQUE] = opaqueShader;
_typesToShaders[PrismMaterial.METAL] = metalShader;
_typesToShaders[PrismMaterial.LAYERED] = layeredShader;
_typesToShaders[PrismMaterial.TRANSPARENT] = transparentShader;
_typesToShaders[PrismMaterial.WOOD] = woodShader;

// Source
// http://graphicrants.blogspot.ca/2009/04/rgbm-color-encoding.html
/**
 * Decode LogLUV to uncompressed RGB
 * @param  {Array} src 4-component 8-bit range LogLUV
 * @param  {Array} dst 3-component HDR RGB
 */
var decodeLogLuv = function decodeLogLuv(src, dst) {
    // jshint camelcase: false
    var M = [6.0014, -2.7008, -1.7996, -1.3320, 3.1029, -5.7721, 0.3008, -1.0882, 5.6268];
    var Le = src[2] * 255.0 + src[3];
    var Xp_Y_XYZp_y = Math.pow(2.0, (Le - 127.0) / 2.0);
    var Xp_Y_XYZp_z = Xp_Y_XYZp_y / src[1];
    var Xp_Y_XYZp_x = src[0] * Xp_Y_XYZp_z;
    var r = M[0] * Xp_Y_XYZp_x + M[3] * Xp_Y_XYZp_y + M[6] * Xp_Y_XYZp_z;
    var g = M[1] * Xp_Y_XYZp_x + M[4] * Xp_Y_XYZp_y + M[7] * Xp_Y_XYZp_z;
    var b = M[2] * Xp_Y_XYZp_x + M[5] * Xp_Y_XYZp_y + M[8] * Xp_Y_XYZp_z;
    if (r < 0) r = 0;
    if (g < 0) g = 0;
    if (b < 0) b = 0;
    dst[0] = r;
    dst[1] = g;
    dst[2] = b;
};
// Fixed scale for RGBM encoding, in square space
var RGBM_SCALE = 1.0 / 16.0;
/**
 * Encode uncompressed RGB to RGBM
 * @param  {Array}  src   3-component HDR RGB
 * @param  {Array}  dst   4-component 8-bit range RGBM
 * @param  {Number} scale Multiplier in linear space to further compress HDR range to fit into RGBM
 */
var encodeRGBM = function encodeRGBM(src, dst, scale) {
    var r = Math.sqrt(src[0] * scale) * RGBM_SCALE;
    var g = Math.sqrt(src[1] * scale) * RGBM_SCALE;
    var b = Math.sqrt(src[2] * scale) * RGBM_SCALE;
    var a = Math.min(Math.max(Math.max(r, g), Math.max(b, 1e-6)), 1.0);
    a = Math.ceil(a * 255.0) / 255.0;
    dst[0] = r / a;
    dst[1] = g / a;
    dst[2] = b / a;
    dst[3] = a;
};

var iblCubemapShader = "uniform samplerCube tCube;\nuniform float tFlip;\nuniform float opacity;\nvarying vec3 vWorldPosition;\n#include <common>\nvec3 decodeRGBM(in vec4 vRGBM) {\n    vec3 ret = vRGBM.rgb * (vRGBM.a * 16.0);\n    ret *= ret;\n    return ret;\n}\nvoid main() {\n    vec4 texel = textureCube(tCube, vWorldPosition.xyz);\n    vec3 color = toneMapping(decodeRGBM(texel));\n    gl_FragColor = vec4(color, opacity);\n    gl_FragColor = LinearToGamma(gl_FragColor, float(GAMMA_FACTOR));\n}\n";

// decodes LogLuv and encodes to RGBM at a given expScale
var _convertDDS = function _convertDDS(dds, expScale) {
    var tmpPix1 = new Float32Array(4);
    var tmpPix2 = new Float32Array(4);
    for (var i = 0; i < dds.image.length; i++) {
        var image = dds.image[i];
        for (var j = 0; j < image.mipmaps.length; j++) {
            var buffer = image.mipmaps[j].data;
            for (var k = 0; k < buffer.length; k += 4) {
                tmpPix1[0] = buffer[k] / 255.0;
                tmpPix1[1] = buffer[k + 1] / 255.0;
                tmpPix1[2] = buffer[k + 2] / 255.0;
                tmpPix1[3] = buffer[k + 3] / 255.0;
                decodeLogLuv(tmpPix1, tmpPix2);
                encodeRGBM(tmpPix2, tmpPix1, expScale);
                buffer[k] = Math.round(tmpPix1[0] * 255.0);
                buffer[k + 1] = Math.round(tmpPix1[1] * 255.0);
                buffer[k + 2] = Math.round(tmpPix1[2] * 255.0);
                buffer[k + 3] = Math.round(tmpPix1[3] * 255.0);
            }
        }
    }
};
// NOTE: assumes map stored in a DDS file using LogLuv
var _loadLogLuvToRGBM = function _loadLogLuvToRGBM(url, exposure) {
    return new Promise(function (resolve, reject) {
        var loader = new THREE$1.DDSLoader();
        var cubemap = new THREE$1.CubeTexture();
        cubemap.format = THREE$1.RGBAFormat;
        cubemap.encoding = THREE$1.LinearEncoding;
        cubemap.mapping = THREE$1.CubeReflectionMapping;
        cubemap.isCompressedTexture = true;
        cubemap.generateMipmaps = false;
        var expScale = Math.pow(2.0, exposure);
        loader.load(url, function (dds) {
            _convertDDS(dds, expScale);
            for (var i = 0; i < dds.image.length; i++) {
                cubemap.image[i] = dds.image[i];
            }
            cubemap.minFilter = cubemap.image[0].mipmaps.length > 1 ? cubemap.minFilter : THREE$1.LinearFilter;
            cubemap.needsUpdate = true;
            resolve(cubemap);
        }, function () {}, function (xhr) {
            reject(new Error("environment map load failed"));
        });
    });
};

var Environment = function () {
    function Environment() {
        classCallCheck(this, Environment);

        this._specMap = null;
        this._irrMap = null;
        this._exposure = 0.0;
    }

    createClass(Environment, [{
        key: "load",
        value: function load(specUrl, irrUrl, exposure) {
            var _this = this;

            return Promise.all([_loadLogLuvToRGBM(specUrl, exposure), _loadLogLuvToRGBM(irrUrl, exposure)]).then(function (maps) {
                var _maps = slicedToArray(maps, 2),
                    specMap = _maps[0],
                    irrMap = _maps[1];

                _this._specMap = specMap;
                _this._irrMap = irrMap;
                _this._exposure = exposure;
                return _this;
            });
        }
    }, {
        key: "setToScene",
        value: function setToScene(scene) {
            Environment.registerSceneShader(true);
            scene.background = this._specMap;
        }
    }, {
        key: "setToMaterial",
        value: function setToMaterial(material) {
            material.envMap = this._specMap;
            material.uniforms.envMap = { value: this._specMap };
            material.uniforms.irrMap = { value: this._irrMap };
            material.uniforms.uEnvExp = { value: Math.pow(2, this._exposure) };
            material.needsUpdate = true;
        }
    }], [{
        key: "load",
        value: function load(specUrl, irrUrl, exposure) {
            var env = new Environment();
            return env.load(specUrl, irrUrl, exposure);
        }
    }, {
        key: "registerSceneShader",
        value: function registerSceneShader(value) {
            // save / restore default shader
            if (value) {
                if (!THREE$1.ShaderLib["cube_orig"]) {
                    THREE$1.ShaderLib["cube_orig"] = {
                        fragmentShader: THREE$1.ShaderLib["cube"].fragmentShader
                    };
                }
                THREE$1.ShaderLib["cube"].fragmentShader = iblCubemapShader;
            } else if (THREE$1.ShaderLib["cube_orig"]) {
                THREE$1.ShaderLib["cube"].fragmentShader = THREE$1.ShaderLib["cube_orig"].fragmentShader;
            }
        }
    }]);
    return Environment;
}();

var RIVERBANK = Symbol("Riverbank");
var CONTRAST = Symbol("Contrast");
var RIM_HIGHLIGHTS = Symbol("Rim Highlights");
var COOL_LIGHT = Symbol("Cool Light");
var WARM_LIGHT = Symbol("Warm Light");
var SOFT_LIGHT = Symbol("Soft Light");
var GRID_LIGHT = Symbol("Grid Light");
var PLAZA = Symbol("Plaza");
var SNOW_FIELD = Symbol("Snow Field");
var FIELD = Symbol("Field");
var BOARDWALK = Symbol("Boardwalk");
var CROSSROADS = Symbol("Crossroads");
var SEAPORT = Symbol("Seaport");
var GLACIER = Symbol("Glacier");
var RAAS_TEST = Symbol("RaaS Test Env");
var _presetData = {};
_presetData[RIVERBANK] = {
    name: "Riverbank",
    path: "riverbank",
    exposure: -5.7
};
_presetData[CONTRAST] = {
    name: "Contrast",
    path: "IDViz",
    exposure: 0
};
_presetData[RIM_HIGHLIGHTS] = {
    name: "Rim Highlights",
    path: "RimHighlights",
    exposure: -9.0
};
_presetData[COOL_LIGHT] = {
    name: "Cool Light",
    path: "CoolLight",
    exposure: -9.0
};
_presetData[WARM_LIGHT] = {
    name: "Warm Light",
    path: "WarmLight",
    exposure: -9.0
};
_presetData[SOFT_LIGHT] = {
    name: "Soft Light",
    path: "SoftLight",
    exposure: -9.0
};
_presetData[GRID_LIGHT] = {
    name: "Grid Light",
    path: "GridLight",
    exposure: -9.0
};
_presetData[PLAZA] = {
    name: "Plaza",
    path: "Plaza",
    exposure: -14.0
};
_presetData[SNOW_FIELD] = {
    name: "Snow Field",
    path: "SnowField",
    exposure: -10.461343
};
_presetData[FIELD] = {
    name: "Field",
    path: "field",
    exposure: -2.9
};
_presetData[BOARDWALK] = {
    name: "Boardwalk",
    path: "boardwalk",
    exposure: -7.0
};
_presetData[CROSSROADS] = {
    name: "Crossroads",
    path: "crossroads",
    exposure: -5.5
};
_presetData[SEAPORT] = {
    name: "Seaport",
    path: "seaport",
    exposure: -6.5
};
_presetData[GLACIER] = {
    name: "Glacier",
    path: "glacier",
    exposure: 0
};
_presetData[RAAS_TEST] = {
    name: "RaaS Test Env",
    path: "Reflection",
    exposure: -1.5
};
var _ENDPOINT_PATH = "https://autodeskviewer.com/viewers/latest/res/environments/";
var _SPEC_POSTFIX = "_mipdrop.logluv.dds";
var _IRR_POSTFIX = "_irr.logluv.dds";
// TODO: should add Symbol type, but typescript bug:
// https://github.com/Microsoft/TypeScript/issues/1863
var get$1 = function get(symbol) {
    return _presetData[symbol];
};
var load = function load(symbol) {
    var preset = get$1(symbol);
    if (!preset) {
        return Promise.reject(new Error("Preset does not exist: " + symbol));
    }
    return Environment.load(_ENDPOINT_PATH + preset["path"] + _SPEC_POSTFIX, _ENDPOINT_PATH + preset["path"] + _IRR_POSTFIX, preset["exposure"]);
};



var EnvPresets = Object.freeze({
	RIVERBANK: RIVERBANK,
	CONTRAST: CONTRAST,
	RIM_HIGHLIGHTS: RIM_HIGHLIGHTS,
	COOL_LIGHT: COOL_LIGHT,
	WARM_LIGHT: WARM_LIGHT,
	SOFT_LIGHT: SOFT_LIGHT,
	GRID_LIGHT: GRID_LIGHT,
	PLAZA: PLAZA,
	SNOW_FIELD: SNOW_FIELD,
	FIELD: FIELD,
	BOARDWALK: BOARDWALK,
	CROSSROADS: CROSSROADS,
	SEAPORT: SEAPORT,
	GLACIER: GLACIER,
	RAAS_TEST: RAAS_TEST,
	get: get$1,
	load: load
});

var vertexShader$1 = "varying vec3 vNormal;\nvarying float depth;\n#include <pack_normals>\nvoid main() {\n#ifdef UNPACK_NORMALS\n    vec3 objectNormal = decodeNormal(normal);\n#else\n    vec3 objectNormal = normal;\n#endif\n#ifdef FLIP_SIDED\n    objectNormal = -objectNormal;\n#endif\n    objectNormal = objectNormal;\n    vec3 instPos = position;\n    vec3 transformedNormal = normalMatrix * objectNormal;\n    vNormal = normalize( transformedNormal );\n    vec4 mvPosition = modelViewMatrix * vec4( instPos, 1.0 );\n    depth = mvPosition.z;\n    vec4 p_Position = projectionMatrix * mvPosition;\n    gl_Position = p_Position;\n}";

var fragmentShader$6 = "varying highp vec3 vNormal;\nvarying highp float depth;\nvoid main() {\n    vec3 n = vNormal;\n    n = n * ( -1.0 + 2.0 * float( gl_FrontFacing ) );\n    n = normalize( n );\n    gl_FragColor = vec4(n.x, n.y, depth, 1.0);\n}\n";

// This shader computes and stores the depth and the x and y camera-space normal components.
//
// The z component of the normal can be derived, since we know it is a positive number and x^2 + y^2 + z^2 = 1.
// The depth is returned in camera space (before projection), so is relative to the world's space. It will need to be
// multiplied by the projection matrix to get the z-depth. For a perspective camera, visible values will be negative
// numbers; for an orthographic camera this is not necessarily the case.
var DepthNormalShader = {
    vertexShader: vertexShader$1,
    fragmentShader: fragmentShader$6
};

var vertexShader$2 = "varying vec2 vUv;\nvoid main() {\n    vUv = uv;\n    gl_Position = projectionMatrix * modelViewMatrix * vec4( position, 1.0 );\n}\n";

/* Scalable Ambient Obscurance implementation based on:
   {http://graphics.cs.williams.edu/papers/SAOHPG12/} */
// latest code as of 3/1/2016 found at
// http://g3d.cs.williams.edu/websvn/filedetails.php?repname=g3d&path=%2FG3D10%2Fdata-files%2Fshader%2FAmbientOcclusion%2FAmbientOcclusion_AO.pix
var SAOShader$1 = {
    extensions: {
        derivatives: true
    },
    uniforms: {
        // DepthTextureUniforms
        // Uniforms used for reconstructing positions from depth-texture in post-passes. (depth_texture.glsl)
        tDepth: { type: "t", value: null },
        projInfo: { type: "v4", value: new THREE$1.Vector4() },
        isOrtho: { type: "f", value: 0.0 },
        worldMatrix_mainPass: { type: "m4", value: new THREE$1.Matrix4() },
        size: { type: "v2", value: new THREE$1.Vector2(512, 512) },
        resolution: { type: "v2", value: new THREE$1.Vector2(1 / 512, 1 / 512) },
        cameraNear: { type: "f", value: 1 },
        cameraFar: { type: "f", value: 100 },
        radius: { type: "f", value: 10.0 },
        bias: { type: "f", value: 0.1 },
        projScale: { type: "f", value: 500 },
        intensity: { type: "f", value: 0.4 },
        tDepth_mip1: { type: "t", value: null },
        tDepth_mip2: { type: "t", value: null },
        tDepth_mip3: { type: "t", value: null },
        tDepth_mip4: { type: "t", value: null },
        tDepth_mip5: { type: "t", value: null }
    },
    vertexShader: vertexShader$2,
    fragmentShader: fragmentShader
};

var fragmentShader$7 = "uniform sampler2D tDiffuse;\nuniform sampler2D tAO;\nuniform float aoOpacity;\nvarying vec2 vUv;\nvec4 sampleColor() {\n    return texture2D(tDiffuse, vUv);\n}\nfloat sampleAO() {\n    return sqrt(texture2D(tAO, vUv).r);\n}\nvoid main() {\n    vec4 texel = sampleColor();\n    float ao = sampleAO();\n    ao = 1.0 - (1.0 - ao) * aoOpacity;\n    texel.rgb *= ao;\n    gl_FragColor = texel;\n}\n";

// Shader that composes a final frame from the color target and SAO target
var SAOBlendShader = {
    uniforms: {
        tDiffuse: { type: "t", value: null },
        tAO: { type: "t", value: null },
        aoOpacity: { type: "f", value: 1.0 }
    },
    vertexShader: vertexShader$2,
    fragmentShader: fragmentShader$7
};

var packDepthChunk = "\nvec4 packDepth( const in float depth ) {\n    vec4 enc = vec4(1.0, 255.0, 65025.0, 160581375.0) * depth;\n    enc = fract(enc);\n    enc -= enc.yzww * vec4(1.0/255.0,1.0/255.0,1.0/255.0,0.0);\n    return enc;\n}\nfloat unpackDepth( const in vec4 rgba_depth ) {\n    return dot( rgba_depth, vec4(1.0, 1.0/255.0, 1.0/65025.0, 1.0/160581375.0) );\n}\n";

var packNormalsChunk = "\n#define kPI 3.14159265358979\nvec2 encodeNormal (vec3 n) {\n    return (vec2(atan(n.y,n.x)/kPI, n.z)+1.0)*0.5;\n}\nvec3 decodeNormal (vec2 enc) {\n    vec2 ang = enc * 2.0 - 1.0;\n    vec2 scth = vec2(sin(ang.x * kPI), cos(ang.x * kPI));\n    vec2 scphi = vec2(sqrt(1.0 - ang.y * ang.y), ang.y);\n    return vec3(scth.y * scphi.x, scth.x * scphi.x, scphi.y);\n}\n";

var depthTextureChunk = "\nuniform sampler2D tDepth;\nuniform vec4 projInfo;\nuniform float isOrtho;\nuniform mat4 worldMatrix_mainPass;\nvec3 reconstructCSPosition(vec2 fragCoords, float z) {\n    return vec3((fragCoords * projInfo.xy + projInfo.zw) * mix(z, -1.0, isOrtho), z);\n}\nvec3 reconstructWorldPosition(vec2 fragCoords, vec2 screenUv) {\n    float zCam = texture2D(tDepth, screenUv).z;\n    vec3 csPos = reconstructCSPosition(fragCoords, zCam);\n    return (worldMatrix_mainPass * vec4(csPos, 1.0)).xyz;\n}\n";

///////////////////////////////////////////////////////////////////////////////
THREE$1.ShaderChunk["pack_depth"] = packDepthChunk;
THREE$1.ShaderChunk["pack_normals"] = packNormalsChunk;
THREE$1.ShaderChunk["depth_texture"] = depthTextureChunk;
///////////////////////////////////////////////////////////////////////////////
// Scalable Ambient Obscurance (SAO)

var SAOEffect = function () {
    function SAOEffect() {
        classCallCheck(this, SAOEffect);

        // public parameters
        this.isMobile = false;
        this.radius = 10.0; // radius of effect, in meters
        this.bias = 1.0; // bias tweaker, start at 1.0
        this.intensity = 0.4; // strength of effect
        this.depthTarget = null;
        this.depthMipMap = null;
        this.saoTarget = null;
        this.postTarget1 = null;
        this.depthMaterial = new THREE$1.ShaderMaterial(DepthNormalShader);
        this.saoMipFirstPass = new ShaderPass(SAOMinifyFirstShader);
        this.saoMipPass = new ShaderPass(SAOMinifyShader);
        this.saoMainPass = new ShaderPass(SAOShader$1);
        // TODO the second blur pass and the blend pass could be merged to make one less pass;
        // could be hacked, but something that would compose postprocess shaders would be better.
        this.saoBlurPass = new ShaderPass(SAOBlurShader);
        this.blendPass = new ShaderPass(SAOBlendShader);
    }

    createClass(SAOEffect, [{
        key: "_allocTargets",
        value: function _allocTargets(sw, sh) {
            var resX = 1.0 / sw;
            var resY = 1.0 / sh;
            this.depthTarget = new THREE$1.WebGLRenderTarget(sw, sh, {
                minFilter: THREE$1.NearestFilter,
                magFilter: THREE$1.NearestFilter,
                format: THREE$1.RGBFormat,
                type: this.isMobile ? THREE$1.HalfFloatType : THREE$1.FloatType,
                stencilBuffer: false
            });
            // offscreen post-processing ping-pong buffers
            this.postTarget1 = new THREE$1.WebGLRenderTarget(sw, sh, {
                minFilter: THREE$1.LinearFilter,
                magFilter: THREE$1.LinearFilter,
                format: THREE$1.RGBAFormat,
                stencilBuffer: false,
                depthBuffer: false
            });
            this.postTarget1.texture.generateMipmaps = false;
            this.saoTarget = this.postTarget1.clone();
            // SAO depth/normals mip maps. These are "manually" created
            // because we use custom sampling. Also, they are separately bound into
            // the shader because there doesn't seem to be an easy way to load them
            // as mip levels of the same texture, in the case they were render buffers initially.
            var NUM_MIPMAPS = 5;
            this.depthMipMap = [];
            for (var i = 0; i < NUM_MIPMAPS; i++) {
                var w = 0 | sw / (2 << i);
                var h = 0 | sh / (2 << i);
                var mip = new THREE$1.WebGLRenderTarget(w, h, {
                    minFilter: THREE$1.NearestFilter,
                    magFilter: THREE$1.NearestFilter,
                    format: THREE$1.RGBAFormat,
                    depthBuffer: false,
                    stencilBuffer: false
                });
                mip.texture.generateMipmaps = false;
                this.depthMipMap.push(mip);
                this.saoMainPass.uniforms["tDepth_mip" + (i + 1)].value = mip.texture;
            }
            this.saoMainPass.uniforms["size"].value.set(sw, sh);
            this.saoMainPass.uniforms["resolution"].value.set(resX, resY);
            this.saoMainPass.uniforms["tDepth"].value = this.depthTarget.texture;
            this.saoBlurPass.uniforms["size"].value.set(sw, sh);
            this.saoBlurPass.uniforms["resolution"].value.set(resX, resY);
            this.blendPass.uniforms["tAO"].value = this.saoTarget.texture;
            this.blendPass.uniforms["aoOpacity"].value = 1.0;
        }
    }, {
        key: "_updateUniforms",
        value: function _updateUniforms(width, height, camera) {
            // set these uniforms outside of initialization
            // since they use public variables that could change
            this.saoMainPass.uniforms["radius"].value = this.radius;
            this.saoMainPass.uniforms["bias"].value = this.bias * this.radius * (this.isMobile ? 0.1 : 0.01);
            this.saoMainPass.uniforms["intensity"].value = this.intensity;
            this.saoBlurPass.uniforms["radius"].value = this.radius;
            var near = camera.near;
            var far = camera.far;
            this.saoMainPass.uniforms["cameraNear"].value = near;
            this.saoMainPass.uniforms["cameraFar"].value = far;
            this.saoMipFirstPass.uniforms["cameraNear"].value = near;
            this.saoMipFirstPass.uniforms["cameraInvNearFar"].value = 1.0 / (near - far);
            // Scaling factor needed to increase contrast of our SAO.
            var isPerspective = camera instanceof THREE$1.PerspectiveCamera;
            var P = camera.projectionMatrix.elements;
            if (isPerspective) {
                // TODO: Not certain if we need + or - here for OpenGL off-center matrix (original is DX-style)
                // would have to verify if some day we have off-center projections.
                this.saoMainPass.uniforms["projInfo"].value.set(-2.0 / (width * P[0]), -2.0 / (height * P[5]), (1.0 - P[8]) / P[0], (1.0 + P[9]) / P[5]);
            } else {
                this.saoMainPass.uniforms["projInfo"].value.set(-2.0 / (width * P[0]), -2.0 / (height * P[5]), (1.0 - P[12]) / P[0], (1.0 - P[13]) / P[5]);
            }
            this.saoMainPass.uniforms["isOrtho"].value = isPerspective ? 0.0 : 1.0;
            this.saoMainPass.uniforms["projScale"].value = 0.25 * 0.5 * (height * P[5]);
        }
    }, {
        key: "render",
        value: function render(renderer, scene, camera, colorTarget, outTarget) {
            var width = colorTarget.width;
            var height = colorTarget.height;
            // is depthTarget allocated and of proper size?
            if (!this.depthTarget || this.depthTarget.width !== width || this.depthTarget.height !== height) {
                this._allocTargets(width, height);
            }
            this._updateUniforms(width, height, camera);
            // Render the depth pass - TODO: currently this is a bit inefficient, in that the depth and normal are both
            // written to the target, then the depth is stripped out. More efficient is to write just the depth target.
            // This could be done, bu the old WGS system uses this same shader for things such as NPR, saving the normal
            // out. So this pass could be reusable when combined with other effects.
            // clear buffers
            var oldClearColor = renderer.getClearColor().getHex();
            var oldClearAlpha = renderer.getClearAlpha();
            var oldAutoClear = renderer.autoClear;
            renderer.autoClear = false;
            renderer.setClearColor(0x000000, 1.0);
            renderer.clearTarget(this.depthTarget, true, true, false);
            renderer.setClearColor(oldClearColor, oldClearAlpha);
            // render scene with depthMaterial
            var oldMat = scene.overrideMaterial;
            scene.overrideMaterial = this.depthMaterial;
            renderer.render(scene, camera, this.depthTarget, false);
            scene.overrideMaterial = oldMat;
            // mipmap depth texture
            var prevMip = this.depthMipMap[0];
            this.saoMipFirstPass.uniforms["resolution"].value.set(1.0 / prevMip.width, 1.0 / prevMip.height);
            this.saoMipFirstPass.render(renderer, prevMip, this.depthTarget);
            for (var i = 1; i < this.depthMipMap.length; ++i) {
                var curMip = this.depthMipMap[i];
                this.saoMipPass.uniforms["resolution"].value.set(1.0 / curMip.width, 1.0 / curMip.height);
                this.saoMipPass.render(renderer, curMip, prevMip);
                prevMip = curMip;
            }
            // draw SAO from depth textures into saoTarget
            this.saoMainPass.render(renderer, this.saoTarget);
            // postprocess separable blur, horizontal and vertical
            this.saoBlurPass.uniforms["axis"].value.set(1, 0);
            this.saoBlurPass.render(renderer, this.postTarget1, this.saoTarget);
            this.saoBlurPass.uniforms["axis"].value.set(0, 1);
            this.saoBlurPass.render(renderer, this.saoTarget, this.postTarget1);
            this.blendPass.render(renderer, outTarget, colorTarget);
            renderer.autoClear = oldAutoClear;
        }
    }]);
    return SAOEffect;
}();

var vertexShader$3 = "varying vec2 vUv;\nvarying vec2 vGaussianUVs[14];\nvoid main() {\n    vUv = vec2(uv.x, uv.y);\n    gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);\n    vGaussianUVs[ 0] = vUv + vec2(-7.0 * KERNEL_SCALE, 0.0)UV_SWIZZLE;\n    vGaussianUVs[ 1] = vUv + vec2(-6.0 * KERNEL_SCALE, 0.0)UV_SWIZZLE;\n    vGaussianUVs[ 2] = vUv + vec2(-5.0 * KERNEL_SCALE, 0.0)UV_SWIZZLE;\n    vGaussianUVs[ 3] = vUv + vec2(-4.0 * KERNEL_SCALE, 0.0)UV_SWIZZLE;\n    vGaussianUVs[ 4] = vUv + vec2(-3.0 * KERNEL_SCALE, 0.0)UV_SWIZZLE;\n    vGaussianUVs[ 5] = vUv + vec2(-2.0 * KERNEL_SCALE, 0.0)UV_SWIZZLE;\n    vGaussianUVs[ 6] = vUv + vec2(-1.0 * KERNEL_SCALE, 0.0)UV_SWIZZLE;\n    vGaussianUVs[ 7] = vUv + vec2( 1.0 * KERNEL_SCALE, 0.0)UV_SWIZZLE;\n    vGaussianUVs[ 8] = vUv + vec2( 2.0 * KERNEL_SCALE, 0.0)UV_SWIZZLE;\n    vGaussianUVs[ 9] = vUv + vec2( 3.0 * KERNEL_SCALE, 0.0)UV_SWIZZLE;\n    vGaussianUVs[10] = vUv + vec2( 4.0 * KERNEL_SCALE, 0.0)UV_SWIZZLE;\n    vGaussianUVs[11] = vUv + vec2( 5.0 * KERNEL_SCALE, 0.0)UV_SWIZZLE;\n    vGaussianUVs[12] = vUv + vec2( 6.0 * KERNEL_SCALE, 0.0)UV_SWIZZLE;\n    vGaussianUVs[13] = vUv + vec2( 7.0 * KERNEL_SCALE, 0.0)UV_SWIZZLE;\n}";

var fragmentShader$8 = "uniform sampler2D tDiffuse;\nvarying vec2 vUv;\nvarying vec2 vGaussianUVs[14];\nvoid main() {\n    gl_FragColor = vec4(0.0);\n    gl_FragColor += texture2D(tDiffuse, vGaussianUVs[ 0]) * 0.0044299121055113265;\n    gl_FragColor += texture2D(tDiffuse, vGaussianUVs[ 1]) * 0.00895781211794;\n    gl_FragColor += texture2D(tDiffuse, vGaussianUVs[ 2]) * 0.0215963866053;\n    gl_FragColor += texture2D(tDiffuse, vGaussianUVs[ 3]) * 0.0443683338718;\n    gl_FragColor += texture2D(tDiffuse, vGaussianUVs[ 4]) * 0.0776744219933;\n    gl_FragColor += texture2D(tDiffuse, vGaussianUVs[ 5]) * 0.115876621105;\n    gl_FragColor += texture2D(tDiffuse, vGaussianUVs[ 6]) * 0.147308056121;\n    gl_FragColor += texture2D(tDiffuse, vUv             ) * 0.159576912161;\n    gl_FragColor += texture2D(tDiffuse, vGaussianUVs[ 7]) * 0.147308056121;\n    gl_FragColor += texture2D(tDiffuse, vGaussianUVs[ 8]) * 0.115876621105;\n    gl_FragColor += texture2D(tDiffuse, vGaussianUVs[ 9]) * 0.0776744219933;\n    gl_FragColor += texture2D(tDiffuse, vGaussianUVs[10]) * 0.0443683338718;\n    gl_FragColor += texture2D(tDiffuse, vGaussianUVs[11]) * 0.0215963866053;\n    gl_FragColor += texture2D(tDiffuse, vGaussianUVs[12]) * 0.00895781211794;\n    gl_FragColor += texture2D(tDiffuse, vGaussianUVs[13]) * 0.0044299121055113265;\n}\n";

var BlurHShader = {
    defines: {
        UV_SWIZZLE: ".xy",
        KERNEL_SCALE: "1.0"
    },
    uniforms: {
        tDiffuse: { type: "t", value: null }
    },
    vertexShader: vertexShader$3,
    fragmentShader: fragmentShader$8
};

var BlurVShader = {
    defines: {
        UV_SWIZZLE: ".yx",
        KERNEL_SCALE: "1.0"
    },
    uniforms: {
        tDiffuse: { type: "t", value: null }
    },
    vertexShader: vertexShader$3,
    fragmentShader: fragmentShader$8
};

var GaussianBlurPass = function () {
    function GaussianBlurPass(width, height) {
        classCallCheck(this, GaussianBlurPass);

        this.passH = new ShaderPass(BlurHShader);
        this.passV = new ShaderPass(BlurVShader);
        this.setSize(width, height);
    }

    createClass(GaussianBlurPass, [{
        key: "setSize",
        value: function setSize(width, height) {
            this.passH.material.defines.KERNEL_SCALE = (1.0 / width).toFixed(8);
            this.passV.material.defines.KERNEL_SCALE = (1.0 / height).toFixed(8);
            this.passH.material.needsUpdate = true;
            this.passV.material.needsUpdate = true;
        }
    }, {
        key: "render",
        value: function render(renderer, readBuffer, tempBuffer, writeBuffer) {
            this.passH.render(renderer, tempBuffer, readBuffer);
            this.passV.render(renderer, writeBuffer, tempBuffer);
        }
    }]);
    return GaussianBlurPass;
}();

var fragmentShader$9 = "uniform sampler2D tDiffuse;\nuniform vec4 color;\nvarying vec2 vUv;\nvoid main() {\n    float shadow = 1.0 - texture2D(tDiffuse, vUv).r;\n    gl_FragColor = vec4(color.rgb, color.a * shadow);\n}\n";

var GroundShadowShader$1 = {
    uniforms: {
        tDiffuse: { type: "t", value: null },
        color: { type: "v4", value: new THREE$1.Vector4(1.0, 1.0, 1.0, 1.0) }
    },
    vertexShader: vertexShader$2,
    fragmentShader: fragmentShader$9
};

var ShadowPlane = function (_Mesh) {
    inherits(ShadowPlane, _Mesh);

    function ShadowPlane(params) {
        classCallCheck(this, ShadowPlane);

        // init params
        var _this = possibleConstructorReturn(this, (ShadowPlane.__proto__ || Object.getPrototypeOf(ShadowPlane)).call(this));
        // "as new any" TS workaround, until we remove our hack index.d.ts
        // super(
        //     new BufferGeometry(),
        //     new MeshBasicMaterial({ color: "#ffffff" })
        // );


        _this.params = Object.assign({
            resolution: 128,
            blurLevel: 1,
            color: new THREE$1.Color(0.0, 0.0, 0.0),
            alpha: 1.0,
            debug: false
        }, params);
        // init geometry
        _this.geometry.addAttribute("position", new THREE$1.BufferAttribute(new Float32Array([-0.5, -0.5, -0.5, -0.5, -0.5, 0.5, 0.5, -0.5, 0.5, 0.5, -0.5, -0.5]), 3));
        _this.geometry.addAttribute("uv", new THREE$1.BufferAttribute(new Float32Array([0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0]), 2));
        _this.geometry.setIndex(new THREE$1.BufferAttribute(new Uint16Array([0, 1, 2, 2, 3, 0]), 1));
        // init render targets
        _this._target1 = new THREE$1.WebGLRenderTarget(_this.params.resolution, _this.params.resolution, {
            format: THREE$1.RGBFormat,
            stencilBuffer: false
        });
        _this._target2 = _this._target1.clone();
        // init passes and materials
        _this._matDepth = new THREE$1.ShaderMaterial({
            vertexShader: THREE$1.ShaderLib.depth.vertexShader,
            fragmentShader: THREE$1.ShaderLib.depth.fragmentShader.replace(/DEPTH_PACKING/g, "3200")
        });
        _this._matDepth.blending = THREE$1.NoBlending;
        _this._blurPass = new GaussianBlurPass(_this.params.resolution, _this.params.resolution);
        _this.material = new THREE$1.ShaderMaterial(GroundShadowShader$1);
        _this.material.uniforms.tDiffuse.value = _this._target1.texture;
        _this.material.uniforms.color.value.set(_this.params.color.r, _this.params.color.g, _this.params.color.b, _this.params.alpha);
        _this.material.transparent = true;
        _this.material.depthWrite = false;
        // init ortho camera, unit size, pointing from bottom up
        _this._camera = new THREE$1.OrthographicCamera(-0.5, 0.5, 0.5, -0.5, 0.01, 0.99);
        _this._camera.position.y = -0.5;
        _this._camera.rotation.x = Math.PI / 2;
        _this.add(_this._camera);
        // init debug box
        if (_this.params.debug) {
            _this._debugBox = new THREE$1.Mesh(new THREE$1.BoxGeometry(1, 1, 1), new THREE$1.MeshBasicMaterial({ color: 0x00ff00, wireframe: true }));
            _this.add(_this._debugBox);
        }
        return _this;
    }

    createClass(ShadowPlane, [{
        key: "render",
        value: function render(renderer, scene) {
            this.updateParams();
            this.clear(renderer);
            this.renderShadow(renderer, scene);
            this.postprocess(renderer);
        }
    }, {
        key: "updateParams",
        value: function updateParams() {
            if (this.params.resolution !== this._target1.width) {
                this._target1.setSize(this.params.resolution, this.params.resolution);
                this._target2.setSize(this.params.resolution, this.params.resolution);
                this._blurPass.setSize(this.params.resolution, this.params.resolution);
            }
            this.material.uniforms.color.value.set(this.params.color.r, this.params.color.g, this.params.color.b, this.params.alpha);
        }
    }, {
        key: "clear",
        value: function clear(renderer) {
            var oldTarget = renderer.getRenderTarget();
            var oldClearColor = renderer.getClearColor().getHex();
            var oldClearAlpha = renderer.getClearAlpha();
            renderer.setClearColor(0xffffff, 1);
            renderer.clearTarget(this._target1, true, true, false);
            renderer.setRenderTarget(oldTarget);
            renderer.setClearColor(oldClearColor, oldClearAlpha);
        }
    }, {
        key: "renderShadow",
        value: function renderShadow(renderer, scene) {
            // turn off rendering for self
            this.visible = false;
            // set override depth material
            var oldMat = scene.overrideMaterial;
            scene.overrideMaterial = this._matDepth;
            // save render settings
            var oldTarget = renderer.getRenderTarget();
            var oldAutoClear = renderer.autoClear;
            renderer.autoClear = false;
            // render
            renderer.render(scene, this._camera, this._target1);
            // restore settings
            renderer.setRenderTarget(oldTarget);
            renderer.autoClear = oldAutoClear;
            scene.overrideMaterial = oldMat;
            this.visible = true;
        }
    }, {
        key: "postprocess",
        value: function postprocess(renderer) {
            for (var i = 0; i < this.params.blurLevel; ++i) {
                this._blurPass.render(renderer, this._target1, this._target2, this._target1);
            }
        }
    }]);
    return ShadowPlane;
}(THREE$1.Mesh);

exports.PrismMaterial = PrismMaterial;
exports.Environment = Environment;
exports.EnvPresets = EnvPresets;
exports.SAOEffect = SAOEffect;
exports.ShadowPlane = ShadowPlane;
exports.GaussianBlurPass = GaussianBlurPass;
exports.WebWorkerCreator = WebWorkerCreator;
exports.VERSION = VERSION;
exports.BackgroundShader = BackgroundShader;
exports.BasicShader = BasicShader;
exports.BlendShader = BlendShader;
exports.CelShader = CelShader;
exports.CopyShader = CopyShader;
exports.ClearShader = ClearShader;
exports.HighlightShader = HighlightShader;
exports.FXAAShader = FXAAShader;
exports.SAOBlurShader = SAOBlurShader;
exports.SAOShader = SAOShader;
exports.NormalsShader = NormalsShader;
exports.EdgeShader = EdgeShader;
exports.LineShader = LineShader;
exports.OcclusionShader = OcclusionShader;
exports.ShaderPass = ShaderPass;
exports.GaussianPass = GaussianPass;
exports.GroundReflection = GroundReflection;
exports.PhongShader = PhongShader;
exports.VertexEnumerator = VertexEnumerator;
exports.DeriveTopology = DeriveTopology;
exports.VBIntersector = VBIntersector;
exports.GeometryList = GeometryList;
exports.RenderBatch = RenderBatch;
exports.InstanceBufferBuilder = InstanceBufferBuilder;
exports.WebGLRenderer = WebGLRenderer;
exports.ModelIteratorLinear = ModelIteratorLinear;
exports.ConsolidationIterator = ConsolidationIterator;
exports.ModelIteratorBVH = ModelIteratorBVH;
exports.BufferGeometryUtils = BufferGeometryUtils;
exports.RenderScene = RenderScene;
exports.SortedList = SortedList;
exports.RenderModel = RenderModel;
exports.MaterialConverter = MaterialConverter;
exports.MaterialManager = MaterialManager;
exports.SvfLoader = SvfLoader;
exports.TextureLoader = TextureLoader;
exports.OtgLoader = OtgLoader;
exports.OtgGeomCache = OtgGeomCache;
exports.DEBUG_SHADERS = DEBUG_SHADERS;
exports.WebGLShader = WebGLShader;
exports.consolidateFragmentList = consolidateFragmentList;
exports.copyVertexFormat = copyVertexFormat;
exports.copyPrimitiveProps = copyPrimitiveProps;
exports.mergeGeometries = mergeGeometries;
exports.Consolidation = Consolidation;
exports.ConsolidationBuilder = ConsolidationBuilder;
exports.registerWorkerSupport = registerWorkerSupport;
exports.multithreadingSupported = multithreadingSupported;
exports.ConsolidationUtils = ConsolidationUtils;
exports.isIOSDevice = isIOSDevice;
exports.isAndroidDevice = isAndroidDevice;
exports.isMobileDevice = isMobileDevice;
exports.isChrome = isChrome;
exports.isSafari = isSafari;
exports.isFirefox = isFirefox;
exports.isMac = isMac;
exports.isWindows = isWindows;
exports.isNodeJS = isNodeJS;
exports.rescueFromPolymer = rescueFromPolymer;
exports.pathToURL = pathToURL;
exports.clearAssets = clearAssets;
exports.MODEL_ROOT_LOADED_EVENT = MODEL_ROOT_LOADED_EVENT;
exports.MODEL_UNLOADED_EVENT = MODEL_UNLOADED_EVENT;
exports.LOAD_MISSING_GEOMETRY = LOAD_MISSING_GEOMETRY;
exports.FRAGMENTS_LOADED_EVENT = FRAGMENTS_LOADED_EVENT;
exports.FILE_LOAD_STARTED = FILE_LOAD_STARTED;
exports.GEOMETRY_DOWNLOAD_COMPLETE = GEOMETRY_DOWNLOAD_COMPLETE;
exports.OBJECT_TREE_CREATED_EVENT = OBJECT_TREE_CREATED_EVENT;
exports.OBJECT_TREE_UNAVAILABLE_EVENT = OBJECT_TREE_UNAVAILABLE_EVENT;
exports.TEXTURES_LOADED_EVENT = TEXTURES_LOADED_EVENT;
exports.setMemoryOptimizedLoading = setMemoryOptimizedLoading;
exports.GPU_MEMORY_LIMIT = GPU_MEMORY_LIMIT;
exports.GPU_OBJECT_LIMIT = GPU_OBJECT_LIMIT;
exports.GEOMETRY_OVERHEAD = GEOMETRY_OVERHEAD;
exports.PIXEL_CULLING_THRESHOLD = PIXEL_CULLING_THRESHOLD;
exports.PAGEOUT_SUCCESS = PAGEOUT_SUCCESS;
exports.PAGEOUT_FAIL = PAGEOUT_FAIL;
exports.PAGEOUT_NONE = PAGEOUT_NONE;
exports.RENDER_NORMAL = RENDER_NORMAL;
exports.RENDER_HIGHLIGHTED1 = RENDER_HIGHLIGHTED1;
exports.RENDER_HIGHLIGHTED2 = RENDER_HIGHLIGHTED2;
exports.RENDER_HIDDEN = RENDER_HIDDEN;
exports.RENDER_SHADOWMAP = RENDER_SHADOWMAP;
exports.RENDER_FINISHED = RENDER_FINISHED;
exports.GROUND_UNFINISHED = GROUND_UNFINISHED;
exports.GROUND_FINISHED = GROUND_FINISHED;
exports.GROUND_RENDERED = GROUND_RENDERED;
exports.MESH_VISIBLE = MESH_VISIBLE;
exports.MESH_HIGHLIGHTED = MESH_HIGHLIGHTED;
exports.MESH_HIDE = MESH_HIDE;
exports.MESH_ISLINE = MESH_ISLINE;
exports.MESH_MOVED = MESH_MOVED;
exports.MESH_TRAVERSED = MESH_TRAVERSED;
exports.MESH_DRAWN = MESH_DRAWN;
exports.MESH_RENDERFLAG = MESH_RENDERFLAG;
exports.MESH_ISPOINT = MESH_ISPOINT;
exports.MESH_ISWIDELINE = MESH_ISWIDELINE;
exports.DB_ID = DB_ID;
exports.FRAGMENT_ID = FRAGMENT_ID;
exports.RESET_NORMAL = RESET_NORMAL;
exports.RESET_REDRAW = RESET_REDRAW;
exports.RESET_RELOAD = RESET_RELOAD;
exports.POSTPROC_STYLE_OFF = POSTPROC_STYLE_OFF;
exports.POSTPROC_STYLE_EDGING = POSTPROC_STYLE_EDGING;
exports.POSTPROC_STYLE_CEL = POSTPROC_STYLE_CEL;
exports.POSTPROC_STYLE_GRAPHITE = POSTPROC_STYLE_GRAPHITE;
exports.POSTPROC_STYLE_PENCIL = POSTPROC_STYLE_PENCIL;
exports.CreateCubeMapFromColors = CreateCubeMapFromColors;
exports.CutPlanesUniforms = CutPlanesUniforms;
exports.IdUniforms = IdUniforms;
exports.ThemingUniform = ThemingUniform;
exports.ShadowMapCommonUniforms = ShadowMapCommonUniforms;
exports.ShadowMapUniforms = ShadowMapUniforms;
exports.PointSizeUniforms = PointSizeUniforms;
exports.WideLinesUniforms = WideLinesUniforms;
exports.DepthTextureUniforms = DepthTextureUniforms;
exports.GetPrismMapSampleChunk = GetPrismMapSampleChunk;
exports.GetPrismMapUniformChunk = GetPrismMapUniformChunk;
exports.resolve = resolve;
exports.PackDepthShaderChunk = PackDepthShaderChunk;
exports.TonemapShaderChunk = TonemapShaderChunk;
exports.OrderedDitheringShaderChunk = OrderedDitheringShaderChunk;
exports.CutPlanesShaderChunk = CutPlanesShaderChunk;
exports.PackNormalsShaderChunk = PackNormalsShaderChunk;
exports.HatchPatternShaderChunk = HatchPatternShaderChunk;
exports.EnvSamplingShaderChunk = EnvSamplingShaderChunk;
exports.IdVertexDeclaration = IdVertexDeclaration;
exports.IdVertexShaderChunk = IdVertexShaderChunk;
exports.IdFragmentDeclaration = IdFragmentDeclaration;
exports.IdOutputShaderChunk = IdOutputShaderChunk;
exports.FinalOutputShaderChunk = FinalOutputShaderChunk;
exports.ThemingFragmentDeclaration = ThemingFragmentDeclaration;
exports.ThemingFragmentShaderChunk = ThemingFragmentShaderChunk;
exports.InstancingVertexDeclaration = InstancingVertexDeclaration;
exports.ShadowMapDeclareCommonUniforms = ShadowMapDeclareCommonUniforms;
exports.ShadowMapVertexDeclaration = ShadowMapVertexDeclaration;
exports.ShadowMapVertexShaderChunk = ShadowMapVertexShaderChunk;
exports.ShadowMapFragmentDeclaration = ShadowMapFragmentDeclaration;
exports.PointSizeDeclaration = PointSizeDeclaration;
exports.PointSizeShaderChunk = PointSizeShaderChunk;
exports.ShaderChunks = ShaderChunks;
exports.SAOMinifyFirstShader = SAOMinifyFirstShader;
exports.SAOMinifyShader = SAOMinifyShader;
exports.LineStyleDefs = LineStyleDefs;
exports.CreateLinePatternTexture = CreateLinePatternTexture;
exports.LineStyleDef = LineStyleDef;
exports.FloatToHalf = FloatToHalf;
exports.HalfToFloat = HalfToFloat;
exports.HALF_INT_MAX = HALF_INT_MAX;
exports.IntToHalf = IntToHalf;
exports.HalfToInt = HalfToInt;
exports.HalfTest = HalfTest;
exports.HalfFloat = HalfFloat;
exports.createShaderMaterial = createShaderMaterial;
exports.setMacro = setMacro;
exports.removeMacro = removeMacro;
exports.ShaderUtils = ShaderUtils;
exports.createGroundShape = createGroundShape;
exports.setGroundShapeTransform = setGroundShapeTransform;
exports.GroundShadow = GroundShadow;
exports.GroundShadowUtils = GroundShadowUtils;
exports.PrismMaps = PrismMaps;
exports.GetPrismMapChunk = GetPrismMapChunk;
exports.WebGLProgram = WebGLProgram;
exports.WebGLProgramUtils = WebGLProgramUtils;
exports.GetPrismMapUniforms = GetPrismMapUniforms;
exports.PrismShader = PrismShader;
exports.createPrismMaterial = createPrismMaterial;
exports.clonePrismMaterial = clonePrismMaterial$1;
exports.PrismShaderUtils = PrismShaderUtils;
exports.ShadowMapShader = ShadowMapShader;
exports.GroundShadowShader = GroundShadowShader;
exports.ShadowMapOverrideMaterials = ShadowMapOverrideMaterials;
exports.ShadowConfig = ShadowConfig;
exports.SHADOWMAP_NEEDS_UPDATE = SHADOWMAP_NEEDS_UPDATE;
exports.SHADOWMAP_INCOMPLETE = SHADOWMAP_INCOMPLETE;
exports.SHADOWMAP_VALID = SHADOWMAP_VALID;
exports.ShadowMaps = ShadowMaps;
exports.ShadowRender = ShadowRender;
exports.ShadowMapUtils = ShadowMapUtils;
exports.FrustumIntersector = FrustumIntersector;
exports.OUTSIDE = OUTSIDE;
exports.INTERSECTS = INTERSECTS;
exports.CONTAINS = CONTAINS;
exports.CONTAINMENT_UNKNOWN = CONTAINMENT_UNKNOWN;
exports.FragmentList = FragmentList;
exports.FragmentPointer = FragmentPointer;
exports.FragmentListUtils = FragmentListUtils;
exports.TileCoords = TileCoords;
exports.tile2Index = tile2Index;
exports.index2Tile = index2Tile;
exports.TileUtils = TileUtils;
exports.TexQuadConfig = TexQuadConfig;
exports.ModelIteratorTexQuad = ModelIteratorTexQuad;
exports.ModelIteratorTexQuadUtils = ModelIteratorTexQuadUtils;
exports.LeafletDiffModes = LeafletDiffModes;
exports.LeafletDiffIterator = LeafletDiffIterator;
exports.SelectionMode = SelectionMode;
exports.InstanceTree = InstanceTree;
exports.DbidFragmentMap = DbidFragmentMap;
exports.InstanceTreeStorage = InstanceTreeStorage;
exports.InstanceTreeAccess = InstanceTreeAccess;
exports.NodeArray = NodeArray;
exports.BVHModule = BVHModule;
exports.BVHBuilder = BVHBuilder;
exports.workerScript = workerScript;
exports.loadWorker = loadWorker;
exports.setLogger = setLogger;
exports.errorCodeString = errorCodeString;
exports.getErrorCode = getErrorCode;
exports.LmvVector3 = LmvVector3$1;
exports.LmvMatrix4 = LmvMatrix4;
exports.LmvBox3 = LmvBox3;
exports.ViewingService = ViewingService;
exports.textToArrayBuffer = textToArrayBuffer;
exports.FileLoader = FileLoader;
exports.clearPropertyWorkerCache = clearPropertyWorkerCache;
exports.PropDbLoader = PropDbLoader;
exports.DecodeEnvMap = DecodeEnvMap;
exports.getTransferables = getTransferables;
exports.DecodeEnvMapAsync = DecodeEnvMapAsync;
exports.ModelEditor = ModelEditor;

return exports;

}({},THREE));
//# sourceMappingURL=wgs.js.map
